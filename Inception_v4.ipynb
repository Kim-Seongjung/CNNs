{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#conv Neural Network\n",
    "# tensorboard --logdir=/home/ncc/notebook/learn/tensorboard/log\n",
    "\"\"\"\n",
    "created by kim Seong jung\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 128, 128, 3)\n",
      "(15, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_locate='/home/seongjung/바탕화면/sample/'\n",
    "#file_locate ='/media/seongjung/Seagate Backup Plus Drive/data/Eye/npy/npy_128/'\n",
    "sess = tf.InteractiveSession()\n",
    "test_img=np.load(file_locate+'test_img.npy');\n",
    "test_lab=np.load(file_locate+'test_lab.npy');\n",
    "try:\n",
    "    print np.shape(test_img)\n",
    "    print np.shape(test_lab)\n",
    "    img_row = np.shape(test_img)[1]\n",
    "    img_col = np.shape(test_img)[2]\n",
    "except:\n",
    "    np.shape(test_img)\n",
    "    test_img=np.reshape(test_img , newshape = [np.shape(test_img)[0] , 32, 32 ,3] )\n",
    "    img_row = np.shape(test_img)[1]\n",
    "    img_col = np.shape(test_img)[2]\n",
    "\n",
    "    \n",
    "divide_flag= True\n",
    "aug_flag = True\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "train_img=test_img[0:15]\n",
    "train_lab=test_lab[0:15]\n",
    "val_img =test_img[15:30]\n",
    "val_lab =test_lab[15:30]\n",
    "test_img = test_img[30:45]\n",
    "test_lab =test_lab[30:45]\n",
    "path='/home/seongjung/바탕화면/sample/'\n",
    "\n",
    "np.save(path+'train_img',train_img)\n",
    "np.save(path+'train_lab',train_lab)\n",
    "np.save(path+'val_img',val_img)\n",
    "np.save(path+'val_lab',val_lab)\n",
    "np.save(path+'test_img',test_img)\n",
    "np.save(path+'test_lab',test_lab)\n",
    "\n",
    "print np.shape(train_img)\n",
    "print np.shape(train_lab)\n",
    "print np.shape(val_img)\n",
    "print np.shape(val_lab)\n",
    "print np.shape(test_img)\n",
    "print np.shape(test_img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/home/seongjung/바탕화면/sample/test_lab.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load Training , Validation , Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (15, 128, 128, 3)\n",
      "Training Data Label (15, 2)\n",
      "Test Data Label (15, 2)\n",
      "val Data Label (15, 2)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "#with tf.device('/gpu:0'):\n",
    "    if divide_flag == False:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_img)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n",
    "\n",
    "    if divide_flag == True:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_ch =3\n",
    "n_classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    def next_batch(batch_size , image , label):\n",
    "\n",
    "        a=np.random.randint(np.shape(image)[0] -batch_size)\n",
    "        batch_x = image[a:a+batch_size,:]\n",
    "        batch_y= label[a:a+batch_size,:]\n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define Variable , and placeholder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "x = tf.placeholder(\"float\",shape=[None,img_row , img_col , in_ch],  name = 'x-input')\n",
    "y_= tf.placeholder(\"float\",shape=[None , n_classes] , name = 'y-input')\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "x_image= tf.reshape(x,[-1,img_row,img_col,3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"def weight_variable(name,shape):\n",
    "    #initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    initial = tf.get_variable(name,shape=shape , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)\"\"\"\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1 , shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def conv2d(x,w,strides_):\n",
    "    return tf.nn.conv2d(x,w, strides = strides_, padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x , ksize=[1,2,2,1] ,strides = [1,2,2,1] , padding = 'SAME')\n",
    "def max_pool(x , ksize , strides , padding='SAME'):\n",
    "    return tf.nn.max_pool(x ,ksize , strides , padding )\n",
    "def make_weights_biases(layer_name , w_name , ksize ,device_name,initializer='xavier'):\n",
    "    if len(ksize)==4: # convolution filter shape [batch , row , col , color_ch]\n",
    "        out_ch=ksize[3]\n",
    "    elif len(ksize)==2: #fully connected layer shape [in_ch , output_ch]\n",
    "        out_ch=ksize[1]\n",
    "    with tf.device(device_name):\n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            try:\n",
    "                w_conv = tf.get_variable(w_name, ksize , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv = tf.get_variable(w_name, ksize , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            try:\n",
    "                b_conv = bias_variable([out_ch])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv = bias_variable([out_ch])\n",
    "    return w_conv , b_conv \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_A(x):\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch1=32 ; out_ch2=32;out_ch3=64;out_ch4=96;\n",
    "    \n",
    "    c_ksize1=[3,3,in_ch , out_ch1]\n",
    "    c_ksize2=[3,3,out_ch1 , out_ch2]\n",
    "    c_ksize3=[3,3,out_ch2 , out_ch3]\n",
    "    c_ksize4=[3,3,out_ch3 , out_ch4]\n",
    "    w_conv1 , b_conv1 =make_weights_biases('STEM_A' , 'W1' , c_ksize1 ,device_name = '/gpu:0')\n",
    "    w_conv2 , b_conv2= make_weights_biases('STEM_A' , 'W2' , c_ksize2 ,device_name = '/gpu:0')\n",
    "    w_conv3 , b_conv3= make_weights_biases('STEM_A' , 'W3' , c_ksize3 ,device_name = '/gpu:0')\n",
    "    w_conv4 , b_conv4= make_weights_biases('STEM_A' , 'W4' , c_ksize4 ,device_name = '/gpu:0')\n",
    "        \n",
    "    c_strides1=[1,2,2,1]\n",
    "    c_strides2=[1,1,1,1]\n",
    "    c_strides3=[1,1,1,1]\n",
    "    c_strides4=[1,2,2,1]\n",
    "    \n",
    "    c_pooling1='VALID'\n",
    "    c_pooling2='VALID'\n",
    "    c_pooling3='SAME'\n",
    "    c_pooling4='VALID'\n",
    "    \n",
    "    b_p_ksize4=[1,3,3,1]\n",
    "    b_p_strides4=[1,2,2,1]\n",
    "    b_p_padding4 ='VALID'\n",
    "    \n",
    "\n",
    "    \n",
    "    layer1=tf.nn.conv2d(    x ,      w_conv1, c_strides1, c_pooling1  )+b_conv1\n",
    "    layer1=tf.nn.relu(layer1)\n",
    "    layer2=tf.nn.conv2d(    layer1 , w_conv2, c_strides2, c_pooling2  )+b_conv2\n",
    "    layer2=tf.nn.relu(layer2)\n",
    "    layer3=tf.nn.conv2d(    layer2 , w_conv3, c_strides3, c_pooling3  )+b_conv3\n",
    "    layer3=tf.nn.relu(layer3)\n",
    "    layer4=tf.nn.conv2d(    layer3 , w_conv4, c_strides4, c_pooling4  )+b_conv4\n",
    "    layer4=tf.nn.relu(layer4)\n",
    "    \n",
    "    \n",
    "    b_layer4=tf.nn.max_pool(layer3 , b_p_ksize4, b_p_strides4, b_p_padding4 ) #b is branch\n",
    "    b_layer4=tf.nn.relu(b_layer4)\n",
    "    print layer1\n",
    "    print layer2\n",
    "    print layer3\n",
    "    print layer4\n",
    "    print b_layer4\n",
    "    \n",
    "    \n",
    "    concat_layer=tf.concat(3 , [layer4 , b_layer4])\n",
    "    ret_layer=concat_layer\n",
    "    print concat_layer\n",
    "    return ret_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def STEM_B( x ):\n",
    "    in_ch=x.get_shape()[3]\n",
    "    \n",
    "    \n",
    "    #########################################################################\n",
    "    out_ch1=64 ; out_ch2=64;out_ch3=64;out_ch4=96;\n",
    "    ##############################right side##################################\n",
    "    c_ksize1=[1,1,in_ch , out_ch1]\n",
    "    c_ksize2=[7,1,out_ch1 , out_ch2]\n",
    "    c_ksize3=[1,7,out_ch2 , out_ch3]\n",
    "    c_ksize4=[3,3,out_ch3 , out_ch4]\n",
    "    \n",
    "    w_conv1 , b_conv1 =make_weights_biases('STEM_B' , 'W1' , c_ksize1 ,device_name = '/gpu:0')\n",
    "    w_conv2 , b_conv2= make_weights_biases('STEM_B' , 'W2' , c_ksize2 ,device_name = '/gpu:0')\n",
    "    w_conv3 , b_conv3= make_weights_biases('STEM_B' , 'W3' , c_ksize3 ,device_name = '/gpu:0')\n",
    "    w_conv4 , b_conv4= make_weights_biases('STEM_B' , 'W4' , c_ksize4 ,device_name = '/gpu:0')\n",
    "        \n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2=[1,1,1,1]\n",
    "    c_strides3=[1,1,1,1]\n",
    "    c_strides4=[1,1,1,1]\n",
    "    \n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2='SAME'\n",
    "    c_pooling3='SAME'\n",
    "    c_pooling4='VALID'\n",
    "    \n",
    "    ##############################left side##################################\n",
    "    out_ch1=64 ; out_ch2=96;    \n",
    "    #########################################################################\n",
    "    b_c_ksize1=[1,1,in_ch , out_ch1]\n",
    "    b_c_ksize2=[3,3,out_ch1 , out_ch2]\n",
    "    b_w_conv1 , b_b_conv1 =make_weights_biases('STEM_B' , 'b_W1' , b_c_ksize1 ,device_name = '/gpu:0')\n",
    "    b_w_conv2 , b_b_conv2= make_weights_biases('STEM_B' , 'b_W2' , b_c_ksize2 ,device_name = '/gpu:0')\n",
    "    \n",
    "    b_c_strides1=[1,1,1,1]\n",
    "    b_c_strides2=[1,1,1,1]\n",
    "    \n",
    "    b_c_pooling1='SAME'\n",
    "    b_c_pooling2='VALID'\n",
    "    \n",
    "    \n",
    "    ##############################convolution ##################################\n",
    "    layer1 = tf.nn.conv2d(x ,      w_conv1 , c_strides1 , c_pooling1)+b_conv1\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "    layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 , c_pooling2)+b_conv2\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "    layer3 = tf.nn.conv2d(layer2 , w_conv3 , c_strides3 , c_pooling3)+b_conv3\n",
    "    layer3 = tf.nn.relu(layer3)\n",
    "    layer4 = tf.nn.conv2d(layer3 , w_conv4 , c_strides4 , c_pooling4)+b_conv4\n",
    "    layer4 = tf.nn.relu(layer4)\n",
    "    \n",
    "    b_layer1 =tf.nn.conv2d(    x ,      b_w_conv1, b_c_strides1, b_c_pooling1  ) + b_b_conv1\n",
    "    b_layer1 = tf.nn.relu(layer1)\n",
    "    b_layer2=tf.nn.conv2d(  b_layer1 , b_w_conv2, b_c_strides2, b_c_pooling2  ) + b_b_conv2\n",
    "    \n",
    "    ##############################concatenate layers###########################\n",
    "    concat_layer=tf.concat(3 , [layer4 , b_layer2])\n",
    "    ret_layer=concat_layer\n",
    "    return ret_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_C( x ):\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch1 = 192\n",
    "\n",
    "\n",
    "    c_ksize=[3,3,in_ch,out_ch1]\n",
    "    w_conv , b_conv =make_weights_biases('STEM_C' , 'W1' , c_ksize ,device_name = '/gpu:0')\n",
    "    c_strides=[1,1,1,1]\n",
    "    c_pooling='SAME'\n",
    "\n",
    "    b_p_ksize=[1,2,2,1]\n",
    "    b_p_strides=[1,1,1,1]\n",
    "    b_p_pooling='SAME'\n",
    "\n",
    "    layer1 = tf.nn.conv2d(x , w_conv   , c_strides   , c_pooling)+b_conv\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "    b_layer1 = tf.nn.max_pool(x , b_p_ksize , b_p_strides , b_p_pooling)\n",
    "    b_layer1 = tf.nn.relu(b_layer1)\n",
    "    \n",
    "    print layer1\n",
    "    print b_layer1\n",
    "    \n",
    "    concat_layer=tf.concat(3,[layer1 , b_layer1])\n",
    "    ret_layer = concat_layer\n",
    "    return ret_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FLAT(x):\n",
    "    \n",
    "    row=int(x.get_shape()[1])\n",
    "    col=int(x.get_shape()[2])\n",
    "    ch=int(x.get_shape()[3])\n",
    "    \n",
    "    res_x = tf.reshape(x , shape=[-1,row*col*ch])\n",
    "    return res_x\n",
    "    #connect fully connected layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FC_A(x , n_classes):\n",
    "    \n",
    "    fully_ch1=1024; fully_ch2=1024\n",
    "    \n",
    "    fc_ksize1=[x.get_shape()[1],fully_ch1]\n",
    "    fc_ksize2=[fully_ch1,fully_ch2]\n",
    "\n",
    "    w_fc1 ,b_fc1 = make_weights_biases('fc1' , 'fc_W1' , fc_ksize1 ,  '/gpu:0')\n",
    "    w_fc2 ,b_fc2 = make_weights_biases('fc2' , 'fc_W2' , fc_ksize2 ,  '/gpu:0')\n",
    "    \n",
    "    h_fc1=tf.matmul(x, w_fc1 )+b_fc1\n",
    "    h_fc1=tf.nn.dropout(h_fc1 , keep_prob)\n",
    "    h_fc2=tf.matmul(h_fc1 , w_fc2 )+b_fc2\n",
    "    h_fc2=tf.nn.dropout(h_fc2 , keep_prob)\n",
    "    end_fc=h_fc2\n",
    "    \n",
    "    end_ksize=[end_fc.get_shape()[1] , n_classes]   \n",
    "    w_end ,b_end = make_weights_biases('fc_end' , 'fc_end_W' , end_ksize ,  '/gpu:0')\n",
    "    y_conv = tf.matmul(end_fc , w_end)+b_end\n",
    "    \n",
    "   \n",
    "    return y_conv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FC_B(x , n_classes):\n",
    "    \n",
    "    \n",
    "    end_ksize=[x.get_shape()[1] , n_classes]   \n",
    "    w_end ,b_end = make_weights_biases('fc_end' , 'fc_end_W' , end_ksize ,  '/gpu:0')\n",
    "    y_conv = tf.matmul(x , w_end)+b_end\n",
    "    \n",
    "   \n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_list(folder_path):\n",
    "    list_files=os.walk(folder_path).next()[2]\n",
    "    ret_train_img_list=[]\n",
    "    ret_train_lab_list=[]\n",
    "    for i , ele in enumerate(list_files):\n",
    "\n",
    "        if 'train'  in ele and 'img'in ele:\n",
    "            ret_train_img_list.append(ele)\n",
    "        elif 'train' in ele  and  'lab' in ele:\n",
    "            ret_train_lab_list.append(ele)\n",
    "    return ret_train_img_list ,ret_train_lab_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_img.npy'] ['train_lab.npy']\n"
     ]
    }
   ],
   "source": [
    "train_images , train_labels  = get_batch_list(file_locate)\n",
    "print train_images , train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_img.npy']\n",
      "['train_lab.npy']\n"
     ]
    }
   ],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "\n",
    "train_images.sort(key=natural_keys)\n",
    "train_labels.sort(key = natural_keys)\n",
    "print(train_images)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col , label):\n",
    "    \n",
    "    n_img = np.shape(np_img)[0] \n",
    "    n_ret_img = n_img*(img_row - crop_img_row) * (img_col - crop_img_col)*2\n",
    "    ret_images = np.zeros([n_ret_img ,crop_img_row , crop_img_col,color_ch])\n",
    "    len_label= np.shape(label)[1]\n",
    "    ret_labels =  np.zeros([n_ret_img  ,len_label])\n",
    "    #print \"n_augmented image size : \" , n_ret_img \n",
    "    #print \"n classes :\", len_label\n",
    "    #copy label in factor by 2014\n",
    "    \n",
    "    if len(np.shape(np_img))==2:\n",
    "        np_img=np.reshape(np_img , newshape = [np.shape(np_img)[0] , img_row , img_col ,color_ch])\n",
    "        print np.shape(np_img)\n",
    "    for n  in range(len(np_img)):\n",
    "        ret_labels[n*2 , : ] = label[n,:]\n",
    "        ret_labels[n*2+1 , : ] = label[n,:]\n",
    "        for r in range(img_row - crop_img_row):\n",
    "            for c in range(img_col - crop_img_col):\n",
    "                \n",
    "                cropped_img = np_img[n, r:crop_img_row +r , c:crop_img_col+c ,: ]\n",
    "                \n",
    "                ret_images[n*2,:,:,:]=cropped_img  \n",
    "                ret_images[(n*2+1) , :,:,:] =np.fliplr(cropped_img )\n",
    "\n",
    "    \n",
    "    return ret_images ,ret_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_test_img(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col ):\n",
    "    left_top =(0,0)\n",
    "    right_top =(  img_row  - crop_img_row  , 0 )\n",
    "    center =  ((img_row  - crop_img_row)/2  , (img_col - crop_img_row)/2)\n",
    "    left_buttom = (0,(img_col - crop_img_row)/2 )\n",
    "    right_buttom =  (img_row  - crop_img_row , img_col - crop_img_row)\n",
    "    \n",
    "    left_top_images  = np_img[: , left_top[0]:crop_img_row+left_top[0] , left_top[1] : crop_img_col+left_top[1] , :  ]\n",
    "    right_top_images = np_img[: , right_top[0]:crop_img_row +right_top[0], right_top[1] : crop_img_col +right_top[1], :  ]\n",
    "    center_images    = np_img[: , center[0]:crop_img_row +center[0], center[1] : crop_img_col +center[1], :  ]\n",
    "    left_buttom_images=np_img[: , left_buttom[0]:crop_img_row +left_buttom[0], left_buttom[1] : crop_img_col +left_buttom[1], :  ]\n",
    "    right_buttom_images= np_img[: , right_buttom[0]:crop_img_row+right_buttom[0] , right_buttom[1] : crop_img_col +right_buttom[1] , :  ]\n",
    "\n",
    "    \n",
    "        \n",
    "    return left_top_images , right_top_images , center_images , left_buttom_images , right_buttom_images \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TRAIN_STRUCTURE_A(y_conv , y_):\n",
    "    \"\"\"\n",
    "    Return Value : cost , train_step ,correct_prediction , accuracy \n",
    "    \n",
    "    \"\"\"\n",
    "    with tf.device('/gpu:0'):\n",
    "    #sm_conv= tf.nn.softmax(y_conv)\n",
    "        #cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "\n",
    "\n",
    "        regular=0.01*(tf.reduce_sum(tf.square(y_conv)))\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( y_conv, y_))\n",
    "    with tf.device('/gpu:0'):\n",
    "        cost = cost+regular\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cost) #1e-4\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            with tf.name_scope('correct_prediction'):\n",
    "                correct_prediction = tf.equal(tf.argmax(y_conv,1) ,tf.argmax(y_,1))\n",
    "            with tf.name_scope('accuracy'):\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\")) \n",
    "    return cost , train_step ,correct_prediction , accuracy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def START_SESS():\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    return sess \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Terminal Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dirname = '/home/ncc/notebook/mammo/result/'\n",
    "def make_logdir(dirname):\n",
    "  \n",
    "\n",
    "    count=0\n",
    "    while(True):\n",
    "        if not os.path.isdir(dirname):\n",
    "            os.mkdir(dirname)\n",
    "            break\n",
    "        elif not os.path.isdir(dirname + str(count)):\n",
    "            dirname=dirname+str(count)\n",
    "            os.mkdir(dirname)\n",
    "            break\n",
    "        else:\n",
    "            count+=1\n",
    "    print 'it is recorded at :'+str(count)\n",
    "\n",
    "    f=open(dirname+\"/log.txt\",'w')\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_acc_loss(sess, x , y ):\n",
    "    \"\"\"\n",
    "    x type  : numpy \n",
    "    x shape : [n , row , col , ch]\n",
    "    \"\"\"\n",
    "    y=labels\n",
    "    acc_list=[]\n",
    "    loss_list=[]\n",
    "    for img_ind ,ele  in enumerate(x):\n",
    "        accuracy = sess.run( accuracy , feed_dict={x:ele , y_: labels , keep_prob: 1.0})        \n",
    "        loss = sess.run(cost , feed_dict = {x:ele , y_:  labels , keep_prob: 1.0})\n",
    "        acc_list.append(accuracy)\n",
    "        loss_list.append(loss)\n",
    "\n",
    "    acc_list=np.asarray(acc_list)\n",
    "    loss_list=np.asarray(loss_list)\n",
    "    acc=np.mean(acc_list)\n",
    "    loss=np.mean(loss_list)\n",
    "    \n",
    "    return  acc,  loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def write_log(step,train_acc, train_loss , val_acc , val_loss ,fp):\n",
    "    \"\"\"\n",
    "    fp = File Pointer\n",
    "    \n",
    "    \"\"\"\n",
    "    #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "    print step\n",
    "    print(\"step %d , training  accuracy %g\" %(step,train_acc))\n",
    "    print(\"step %d , loss : %g\" %(step,train_loss))\n",
    "    train_str = 'step:\\t'+str(step)+'\\tval_loss:\\t'+str(train_loss) +'\\tval accuracy:\\t'+str(train_acc)+'\\n'\n",
    "\n",
    "    print(\"step %d , validation  accuracy %g\" %(step,val_acc))\n",
    "    print(\"step %d , validation loss : %g\" %(step,val_loss))\n",
    "    val_str = 'step:\\t'+str(step)+'\\tval_loss:\\t'+str(val_loss) +'\\tval accuracy:\\t'+str(val_acc)+'\\n'\n",
    "\n",
    "    fp.write(train_str)\n",
    "    fp.write(val_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def BATCH_TRAINING(maxiter , batch_size,file_locate, cost , train_step ,correct_prediction , accuracy  ,fp,divide_flag =False, aug_flag =False ):\n",
    "   \n",
    "    start_time = time.time()\n",
    "#with tf.device('/gpu:0'):\n",
    "    if divide_flag == False:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_img)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n",
    "\n",
    "    if divide_flag == True:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n",
    "\n",
    "    for i in range(maxiter): \n",
    "        #print i\n",
    "        if divide_flag ==True:\n",
    "            n_batch =len(train_images)\n",
    "            batch_count=0\n",
    "            print batch_count , i\n",
    "            if batch_count >= n_batch:    \n",
    "                train_img =np.load(file_locate+train_images[batch_count])\n",
    "                train_lab =np.load(file_locate+train_labels[batch_count])\n",
    "\n",
    "        batch_xs , batch_ys = next_batch(batch_size, train_img , train_lab)    \n",
    "        \n",
    "        \n",
    "        \n",
    "        if i%100 ==0: # in here, add to validation \n",
    "            try:\n",
    "                if aug_flag == True:\n",
    "                    color_ch = in_ch\n",
    "                    val_images=extract_test_img(val_img ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "                    train_images=extract_test_img(val_img ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "                    val_acc, val_loss =get_acc_loss(val_images)\n",
    "                    train_acc, train_loss =get_acc_loss(train_images )\n",
    "\n",
    "                else:\n",
    "                    val_accuracy = sess.run( accuracy , feed_dict={x:val_img , y_:val_lab , keep_prob: 1.0})        \n",
    "                    val_loss = sess.run(cost , feed_dict = {x:val_img , y_: val_lab , keep_prob: 1.0})\n",
    "                    train_accuracy = sess.run( accuracy , feed_dict={x:batch_xs , y_:batch_ys , keep_prob: 1.0})        \n",
    "                    train_loss = sess.run(cost , feed_dict = {x:batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "\n",
    "                    \n",
    "                write_log(i,train_acc, train_loss , val_acc , val_loss ,fp)\n",
    "\n",
    "                if divide_flag ==True:\n",
    "                    batch_count+=1\n",
    "            except :\n",
    "                n_divide=len(val_img)/batch_size\n",
    "                j=0\n",
    "                if aug_flag == True:\n",
    "                    list_val_acc=[]\n",
    "                    list_val_loss=[]\n",
    "                    for j in range(n_divide):\n",
    "                        \n",
    "                        # j*batch_size :(j+1)*batch_size\n",
    "                        val_batch_xs =val_img[ j*batch_size :(j+1)*batch_size] \n",
    "                        val_batch_ys =val_lab[ j*batch_size :(j+1)*batch_size]\n",
    "                        val_images = extract_test_img( val_batch_xs  ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "                        val_acc ,val_loss =get_acc_loss(sess, val_images , val_batch_ys)    \n",
    "                        list_val_acc.append(val_acc)\n",
    "                        list_val_loss.append(val_loss)\n",
    "                        \n",
    "                    #right above code have to modify\n",
    "                    val_batch_xs = val_img[ (j+1)*batch_size :  ] \n",
    "                    val_batch_ys = val_lab[ (j+1)*batch_size :  ]\n",
    "                    val_images = extract_test_img( val_batch_xs  ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "                    val_acc ,val_loss =get_acc_loss(sess, val_images , val_batch_ys)\n",
    "                    list_val_acc.append(val_acc)\n",
    "                    list_val_loss.append(val_loss)\n",
    "                        \n",
    "                    \n",
    "                    val_acc_list=np.asarray(val_acc_list)\n",
    "                    val_loss_list= np.asarray(val_loss_list)\n",
    "                    val_acc=np.mean(val_acc_list)\n",
    "                    val_loss = np.mean(val_loss_list)\n",
    "\n",
    "                    #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "                    train_images = extract_test_img( batch_xs  ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "                    train_acc, train_loss = get_acc_loss(train_images,batch_ys )\n",
    "\n",
    "                    \n",
    "                else:\n",
    "                    for j in range(n_divide):\n",
    "                        list_acc=[]\n",
    "                        list_loss=[]\n",
    "                        # j*batch_size :(j+1)*batch_size\n",
    "                        val_batch_xs =  val_img[ j*batch_size :(j+1)*batch_size] \n",
    "                        val_batch_ys =  val_lab[ j*batch_size :(j+1)*batch_size]                        \n",
    "                        val_accuracy,val_loss = sess.run([accuracy ,cost], feed_dict={x:val_batch_xs , y_:val_batch_ys , keep_prob: 1.0})        \n",
    "                        list_acc.append(float(val_accuracy))\n",
    "                        list_loss.append(float(val_loss))\n",
    "                        #right above code have to modify\n",
    "                    val_batch_xs = val_img[ (j+1)*batch_size :  ] \n",
    "                    val_batch_ys = val_lab[ (j+1)*batch_size :  ]\n",
    "                    list_acc=np.asarray(list_acc)\n",
    "                    list_loss= np.asarray(list_loss)\n",
    "                    val_acc=np.mean(list_acc)\n",
    "                    val_loss = np.mean(list_loss)\n",
    "\n",
    "                    #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "\n",
    "                    train_acc = sess.run( accuracy , feed_dict={x:batch_xs , y_:batch_ys , keep_prob: 1.0})        \n",
    "                    train_loss = sess.run(cost , feed_dict = {x:batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "\n",
    "\n",
    "                write_log(i,train_acc, train_loss , val_acc , val_loss ,fp)\n",
    "\n",
    "                if divide_flag == True:\n",
    "                    batch_count+=1\n",
    "\n",
    "        if aug_flag == True:\n",
    "            aug_batch_xs , aug_batch_ys=aug(np_img=batch_xs[:int(batch_size)] ,img_row= img_row  ,img_col =img_col\\\n",
    "                                            , color_ch=3, crop_img_row =118, crop_img_col =118, label = batch_ys )\n",
    "            share= len(aug_batch_xs) / batch_size\n",
    "\n",
    "            for i in xrange(share):\n",
    "                batch_xs=aug_batch_xs[i*batch_size : (i+1)*batch_size,:,:,:]  \n",
    "                batch_ys=aug_batch_ys[i*batch_size : (i+1)*batch_size,:]  \n",
    "                sess.run(train_step ,feed_dict={x: batch_xs, y_:batch_ys , keep_prob : 0.7})\n",
    "            share= len(aug_batch_xs) / batch_size\n",
    "\n",
    "        else:\n",
    "            sess.run(train_step ,feed_dict={x: batch_xs, y_:batch_ys , keep_prob : 0.7})\n",
    "\n",
    "    print(\"--- Training Time : %s ---\" % (time.time() - start_time))\n",
    "    train_time=\"--- Training Time : ---:\\t\" +str(time.time() - start_time)\n",
    "    f.write(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_180:0\", shape=(?, 63, 63, 32), dtype=float32)\n",
      "Tensor(\"Relu_181:0\", shape=(?, 61, 61, 32), dtype=float32)\n",
      "Tensor(\"Relu_182:0\", shape=(?, 61, 61, 64), dtype=float32)\n",
      "Tensor(\"Relu_183:0\", shape=(?, 30, 30, 96), dtype=float32)\n",
      "Tensor(\"Relu_184:0\", shape=(?, 30, 30, 64), dtype=float32)\n",
      "Tensor(\"concat_75:0\", shape=(?, 30, 30, 160), dtype=float32)\n",
      "Tensor(\"Relu_190:0\", shape=(?, 28, 28, 192), dtype=float32)\n",
      "Tensor(\"Relu_191:0\", shape=(?, 28, 28, 192), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-44-8df76ab5861c>:3 in START_SESS.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "it is recorded at :25\n",
      "Training Data (15, 128, 128, 3)\n",
      "Training Data Label (15, 2)\n",
      "Test Data Label (15, 2)\n",
      "val Data Label (15, 128, 128, 3)\n",
      "0\n",
      "step 0 , training  accuracy 0\n",
      "step 0 , loss : 12.9537\n",
      "step 0 , validation  accuracy 0.5\n",
      "step 0 , validation loss : 6.61507\n",
      "100\n",
      "step 100 , training  accuracy 0\n",
      "step 100 , loss : 0.155218\n",
      "step 100 , validation  accuracy 0.5\n",
      "step 100 , validation loss : 1.48255\n",
      "200\n",
      "step 200 , training  accuracy 0\n",
      "step 200 , loss : 0.139796\n",
      "step 200 , validation  accuracy 0.5\n",
      "step 200 , validation loss : 1.07939\n",
      "300\n",
      "step 300 , training  accuracy 0\n",
      "step 300 , loss : 0.137639\n",
      "step 300 , validation  accuracy 0.5\n",
      "step 300 , validation loss : 1.01441\n",
      "400\n",
      "step 400 , training  accuracy 0\n",
      "step 400 , loss : 0.137456\n",
      "step 400 , validation  accuracy 0.5\n",
      "step 400 , validation loss : 1.01194\n",
      "500\n",
      "step 500 , training  accuracy 0\n",
      "step 500 , loss : 0.137422\n",
      "step 500 , validation  accuracy 0.5\n",
      "step 500 , validation loss : 1.01093\n",
      "600\n",
      "step 600 , training  accuracy 0\n",
      "step 600 , loss : 0.137421\n",
      "step 600 , validation  accuracy 0.5\n",
      "step 600 , validation loss : 1.01041\n",
      "700\n",
      "step 700 , training  accuracy 0\n",
      "step 700 , loss : 0.137421\n",
      "step 700 , validation  accuracy 0.5\n",
      "step 700 , validation loss : 1.01048\n",
      "800\n",
      "step 800 , training  accuracy 0\n",
      "step 800 , loss : 0.137421\n",
      "step 800 , validation  accuracy 0.5\n",
      "step 800 , validation loss : 1.01045\n",
      "900\n",
      "step 900 , training  accuracy 0\n",
      "step 900 , loss : 0.137421\n",
      "step 900 , validation  accuracy 0.5\n",
      "step 900 , validation loss : 1.01055\n",
      "1000\n",
      "step 1000 , training  accuracy 0\n",
      "step 1000 , loss : 0.137421\n",
      "step 1000 , validation  accuracy 0.5\n",
      "step 1000 , validation loss : 1.01038\n",
      "1100\n",
      "step 1100 , training  accuracy 0\n",
      "step 1100 , loss : 0.137537\n",
      "step 1100 , validation  accuracy 0.5\n",
      "step 1100 , validation loss : 1.01141\n",
      "1200\n",
      "step 1200 , training  accuracy 0\n",
      "step 1200 , loss : 0.138603\n",
      "step 1200 , validation  accuracy 0.5\n",
      "step 1200 , validation loss : 0.984856\n",
      "1300\n",
      "step 1300 , training  accuracy 0\n",
      "step 1300 , loss : 0.189089\n",
      "step 1300 , validation  accuracy 0.5\n",
      "step 1300 , validation loss : 1.17666\n",
      "1400\n",
      "step 1400 , training  accuracy 0\n",
      "step 1400 , loss : 0.221409\n",
      "step 1400 , validation  accuracy 0.5\n",
      "step 1400 , validation loss : 1.25915\n",
      "1500\n",
      "step 1500 , training  accuracy 0\n",
      "step 1500 , loss : 0.139516\n",
      "step 1500 , validation  accuracy 0.5\n",
      "step 1500 , validation loss : 1.03538\n",
      "1600\n",
      "step 1600 , training  accuracy 0\n",
      "step 1600 , loss : 0.137569\n",
      "step 1600 , validation  accuracy 0.5\n",
      "step 1600 , validation loss : 0.99031\n",
      "1700\n",
      "step 1700 , training  accuracy 0\n",
      "step 1700 , loss : 0.137422\n",
      "step 1700 , validation  accuracy 0.5\n",
      "step 1700 , validation loss : 0.990288\n",
      "1800\n",
      "step 1800 , training  accuracy 0\n",
      "step 1800 , loss : 0.137422\n",
      "step 1800 , validation  accuracy 0.5\n",
      "step 1800 , validation loss : 0.990687\n",
      "1900\n",
      "step 1900 , training  accuracy 0\n",
      "step 1900 , loss : 0.137421\n",
      "step 1900 , validation  accuracy 0.5\n",
      "step 1900 , validation loss : 0.99115\n",
      "2000\n",
      "step 2000 , training  accuracy 0\n",
      "step 2000 , loss : 0.137421\n",
      "step 2000 , validation  accuracy 0.5\n",
      "step 2000 , validation loss : 0.991229\n",
      "2100\n",
      "step 2100 , training  accuracy 0\n",
      "step 2100 , loss : 0.137421\n",
      "step 2100 , validation  accuracy 0.5\n",
      "step 2100 , validation loss : 0.991261\n",
      "2200\n",
      "step 2200 , training  accuracy 0\n",
      "step 2200 , loss : 0.137421\n",
      "step 2200 , validation  accuracy 0.5\n",
      "step 2200 , validation loss : 0.99129\n",
      "2300\n",
      "step 2300 , training  accuracy 0\n",
      "step 2300 , loss : 0.137421\n",
      "step 2300 , validation  accuracy 0.5\n",
      "step 2300 , validation loss : 0.991303\n",
      "2400\n",
      "step 2400 , training  accuracy 0\n",
      "step 2400 , loss : 0.137421\n",
      "step 2400 , validation  accuracy 0.5\n",
      "step 2400 , validation loss : 0.991309\n",
      "2500\n",
      "step 2500 , training  accuracy 0\n",
      "step 2500 , loss : 0.137421\n",
      "step 2500 , validation  accuracy 0.5\n",
      "step 2500 , validation loss : 0.991311\n",
      "2600\n",
      "step 2600 , training  accuracy 0\n",
      "step 2600 , loss : 0.137421\n",
      "step 2600 , validation  accuracy 0.5\n",
      "step 2600 , validation loss : 0.991312\n",
      "2700\n",
      "step 2700 , training  accuracy 0\n",
      "step 2700 , loss : 0.137421\n",
      "step 2700 , validation  accuracy 0.5\n",
      "step 2700 , validation loss : 0.991312\n",
      "2800\n",
      "step 2800 , training  accuracy 0\n",
      "step 2800 , loss : 0.137421\n",
      "step 2800 , validation  accuracy 0.5\n",
      "step 2800 , validation loss : 0.991313\n",
      "2900\n",
      "step 2900 , training  accuracy 0\n",
      "step 2900 , loss : 0.137421\n",
      "step 2900 , validation  accuracy 0.5\n",
      "step 2900 , validation loss : 0.991312\n",
      "3000\n",
      "step 3000 , training  accuracy 0\n",
      "step 3000 , loss : 0.137421\n",
      "step 3000 , validation  accuracy 0.5\n",
      "step 3000 , validation loss : 0.991312\n",
      "3100\n",
      "step 3100 , training  accuracy 0\n",
      "step 3100 , loss : 0.137421\n",
      "step 3100 , validation  accuracy 0.5\n",
      "step 3100 , validation loss : 0.991312\n",
      "3200\n",
      "step 3200 , training  accuracy 0\n",
      "step 3200 , loss : 0.137421\n",
      "step 3200 , validation  accuracy 0.5\n",
      "step 3200 , validation loss : 0.991312\n",
      "3300\n",
      "step 3300 , training  accuracy 0\n",
      "step 3300 , loss : 0.137421\n",
      "step 3300 , validation  accuracy 0.5\n",
      "step 3300 , validation loss : 0.991312\n",
      "3400\n",
      "step 3400 , training  accuracy 0\n",
      "step 3400 , loss : 0.137421\n",
      "step 3400 , validation  accuracy 0.5\n",
      "step 3400 , validation loss : 0.991312\n",
      "3500\n",
      "step 3500 , training  accuracy 0\n",
      "step 3500 , loss : 0.137421\n",
      "step 3500 , validation  accuracy 0.5\n",
      "step 3500 , validation loss : 0.991312\n",
      "3600\n",
      "step 3600 , training  accuracy 0\n",
      "step 3600 , loss : 0.137421\n",
      "step 3600 , validation  accuracy 0.5\n",
      "step 3600 , validation loss : 0.991312\n",
      "3700\n",
      "step 3700 , training  accuracy 0\n",
      "step 3700 , loss : 0.137421\n",
      "step 3700 , validation  accuracy 0.5\n",
      "step 3700 , validation loss : 0.991312\n",
      "3800\n",
      "step 3800 , training  accuracy 0\n",
      "step 3800 , loss : 0.137421\n",
      "step 3800 , validation  accuracy 0.5\n",
      "step 3800 , validation loss : 0.991312\n",
      "3900\n",
      "step 3900 , training  accuracy 0\n",
      "step 3900 , loss : 0.137421\n",
      "step 3900 , validation  accuracy 0.5\n",
      "step 3900 , validation loss : 0.991312\n",
      "4000\n",
      "step 4000 , training  accuracy 0\n",
      "step 4000 , loss : 0.137421\n",
      "step 4000 , validation  accuracy 0.5\n",
      "step 4000 , validation loss : 0.991312\n",
      "4100\n",
      "step 4100 , training  accuracy 0\n",
      "step 4100 , loss : 0.137421\n",
      "step 4100 , validation  accuracy 0.5\n",
      "step 4100 , validation loss : 0.991312\n",
      "4200\n",
      "step 4200 , training  accuracy 0\n",
      "step 4200 , loss : 0.137421\n",
      "step 4200 , validation  accuracy 0.5\n",
      "step 4200 , validation loss : 0.991312\n",
      "4300\n",
      "step 4300 , training  accuracy 0\n",
      "step 4300 , loss : 0.137421\n",
      "step 4300 , validation  accuracy 0.5\n",
      "step 4300 , validation loss : 0.991312\n",
      "4400\n",
      "step 4400 , training  accuracy 0\n",
      "step 4400 , loss : 0.137421\n",
      "step 4400 , validation  accuracy 0.5\n",
      "step 4400 , validation loss : 0.991312\n",
      "4500\n",
      "step 4500 , training  accuracy 0\n",
      "step 4500 , loss : 0.137421\n",
      "step 4500 , validation  accuracy 0.5\n",
      "step 4500 , validation loss : 0.991312\n",
      "4600\n",
      "step 4600 , training  accuracy 0\n",
      "step 4600 , loss : 0.137421\n",
      "step 4600 , validation  accuracy 0.5\n",
      "step 4600 , validation loss : 0.991312\n",
      "4700\n",
      "step 4700 , training  accuracy 0\n",
      "step 4700 , loss : 0.137421\n",
      "step 4700 , validation  accuracy 0.5\n",
      "step 4700 , validation loss : 0.991312\n",
      "4800\n",
      "step 4800 , training  accuracy 0\n",
      "step 4800 , loss : 0.137421\n",
      "step 4800 , validation  accuracy 0.5\n",
      "step 4800 , validation loss : 0.991312\n",
      "4900\n",
      "step 4900 , training  accuracy 0\n",
      "step 4900 , loss : 0.137421\n",
      "step 4900 , validation  accuracy 0.5\n",
      "step 4900 , validation loss : 0.991312\n",
      "5000\n",
      "step 5000 , training  accuracy 0\n",
      "step 5000 , loss : 0.137421\n",
      "step 5000 , validation  accuracy 0.5\n",
      "step 5000 , validation loss : 0.991312\n",
      "5100\n",
      "step 5100 , training  accuracy 0\n",
      "step 5100 , loss : 0.137421\n",
      "step 5100 , validation  accuracy 0.5\n",
      "step 5100 , validation loss : 0.991312\n",
      "5200\n",
      "step 5200 , training  accuracy 0\n",
      "step 5200 , loss : 0.137421\n",
      "step 5200 , validation  accuracy 0.5\n",
      "step 5200 , validation loss : 0.991312\n",
      "5300\n",
      "step 5300 , training  accuracy 0\n",
      "step 5300 , loss : 0.137421\n",
      "step 5300 , validation  accuracy 0.5\n",
      "step 5300 , validation loss : 0.991313\n",
      "5400\n",
      "step 5400 , training  accuracy 0\n",
      "step 5400 , loss : 3.64728\n",
      "step 5400 , validation  accuracy 0.5\n",
      "step 5400 , validation loss : 8.68511\n",
      "5500\n",
      "step 5500 , training  accuracy 0\n",
      "step 5500 , loss : 0.445059\n",
      "step 5500 , validation  accuracy 0.5\n",
      "step 5500 , validation loss : 1.13152\n",
      "5600\n",
      "step 5600 , training  accuracy 0\n",
      "step 5600 , loss : 0.150684\n",
      "step 5600 , validation  accuracy 0.5\n",
      "step 5600 , validation loss : 0.930957\n",
      "5700\n",
      "step 5700 , training  accuracy 0\n",
      "step 5700 , loss : 0.14005\n",
      "step 5700 , validation  accuracy 0.5\n",
      "step 5700 , validation loss : 0.934852\n",
      "5800\n",
      "step 5800 , training  accuracy 0\n",
      "step 5800 , loss : 0.137427\n",
      "step 5800 , validation  accuracy 0.5\n",
      "step 5800 , validation loss : 0.923386\n",
      "5900\n",
      "step 5900 , training  accuracy 0\n",
      "step 5900 , loss : 0.137436\n",
      "step 5900 , validation  accuracy 0.5\n",
      "step 5900 , validation loss : 0.922015\n",
      "6000\n",
      "step 6000 , training  accuracy 0\n",
      "step 6000 , loss : 0.13743\n",
      "step 6000 , validation  accuracy 0.5\n",
      "step 6000 , validation loss : 0.923095\n",
      "6100\n",
      "step 6100 , training  accuracy 0\n",
      "step 6100 , loss : 0.137421\n",
      "step 6100 , validation  accuracy 0.5\n",
      "step 6100 , validation loss : 0.922795\n",
      "6200\n",
      "step 6200 , training  accuracy 0\n",
      "step 6200 , loss : 0.137423\n",
      "step 6200 , validation  accuracy 0.5\n",
      "step 6200 , validation loss : 0.922774\n",
      "6300\n",
      "step 6300 , training  accuracy 0\n",
      "step 6300 , loss : 0.137422\n",
      "step 6300 , validation  accuracy 0.5\n",
      "step 6300 , validation loss : 0.922808\n",
      "6400\n",
      "step 6400 , training  accuracy 0\n",
      "step 6400 , loss : 0.137422\n",
      "step 6400 , validation  accuracy 0.5\n",
      "step 6400 , validation loss : 0.922872\n",
      "6500\n",
      "step 6500 , training  accuracy 0\n",
      "step 6500 , loss : 0.137421\n",
      "step 6500 , validation  accuracy 0.5\n",
      "step 6500 , validation loss : 0.922826\n",
      "6600\n",
      "step 6600 , training  accuracy 0\n",
      "step 6600 , loss : 0.137421\n",
      "step 6600 , validation  accuracy 0.5\n",
      "step 6600 , validation loss : 0.922816\n",
      "6700\n",
      "step 6700 , training  accuracy 0\n",
      "step 6700 , loss : 0.137421\n",
      "step 6700 , validation  accuracy 0.5\n",
      "step 6700 , validation loss : 0.922806\n",
      "6800\n",
      "step 6800 , training  accuracy 0\n",
      "step 6800 , loss : 0.137421\n",
      "step 6800 , validation  accuracy 0.5\n",
      "step 6800 , validation loss : 0.922807\n",
      "6900\n",
      "step 6900 , training  accuracy 0\n",
      "step 6900 , loss : 0.137421\n",
      "step 6900 , validation  accuracy 0.5\n",
      "step 6900 , validation loss : 0.922806\n",
      "7000\n",
      "step 7000 , training  accuracy 0\n",
      "step 7000 , loss : 0.137421\n",
      "step 7000 , validation  accuracy 0.5\n",
      "step 7000 , validation loss : 0.922843\n",
      "7100\n",
      "step 7100 , training  accuracy 0\n",
      "step 7100 , loss : 0.137421\n",
      "step 7100 , validation  accuracy 0.5\n",
      "step 7100 , validation loss : 0.92283\n",
      "7200\n",
      "step 7200 , training  accuracy 0\n",
      "step 7200 , loss : 0.137421\n",
      "step 7200 , validation  accuracy 0.5\n",
      "step 7200 , validation loss : 0.922829\n",
      "7300\n",
      "step 7300 , training  accuracy 0\n",
      "step 7300 , loss : 0.137421\n",
      "step 7300 , validation  accuracy 0.5\n",
      "step 7300 , validation loss : 0.922834\n",
      "7400\n",
      "step 7400 , training  accuracy 0\n",
      "step 7400 , loss : 0.137421\n",
      "step 7400 , validation  accuracy 0.5\n",
      "step 7400 , validation loss : 0.922845\n",
      "7500\n",
      "step 7500 , training  accuracy 0\n",
      "step 7500 , loss : 0.137421\n",
      "step 7500 , validation  accuracy 0.5\n",
      "step 7500 , validation loss : 0.922847\n",
      "7600\n",
      "step 7600 , training  accuracy 0\n",
      "step 7600 , loss : 0.137421\n",
      "step 7600 , validation  accuracy 0.5\n",
      "step 7600 , validation loss : 0.922846\n",
      "7700\n",
      "step 7700 , training  accuracy 0\n",
      "step 7700 , loss : 0.137421\n",
      "step 7700 , validation  accuracy 0.5\n",
      "step 7700 , validation loss : 0.922848\n",
      "7800\n",
      "step 7800 , training  accuracy 0\n",
      "step 7800 , loss : 0.137421\n",
      "step 7800 , validation  accuracy 0.5\n",
      "step 7800 , validation loss : 0.922848\n",
      "7900\n",
      "step 7900 , training  accuracy 0\n",
      "step 7900 , loss : 0.137421\n",
      "step 7900 , validation  accuracy 0.5\n",
      "step 7900 , validation loss : 0.922849\n",
      "8000\n",
      "step 8000 , training  accuracy 0\n",
      "step 8000 , loss : 0.137421\n",
      "step 8000 , validation  accuracy 0.5\n",
      "step 8000 , validation loss : 0.922849\n",
      "8100\n",
      "step 8100 , training  accuracy 0\n",
      "step 8100 , loss : 0.137421\n",
      "step 8100 , validation  accuracy 0.5\n",
      "step 8100 , validation loss : 0.922849\n",
      "8200\n",
      "step 8200 , training  accuracy 0\n",
      "step 8200 , loss : 0.137421\n",
      "step 8200 , validation  accuracy 0.5\n",
      "step 8200 , validation loss : 0.922849\n",
      "8300\n",
      "step 8300 , training  accuracy 0\n",
      "step 8300 , loss : 0.137421\n",
      "step 8300 , validation  accuracy 0.5\n",
      "step 8300 , validation loss : 0.922849\n",
      "8400\n",
      "step 8400 , training  accuracy 0\n",
      "step 8400 , loss : 0.137421\n",
      "step 8400 , validation  accuracy 0.5\n",
      "step 8400 , validation loss : 0.922849\n",
      "8500\n",
      "step 8500 , training  accuracy 0\n",
      "step 8500 , loss : 0.137421\n",
      "step 8500 , validation  accuracy 0.5\n",
      "step 8500 , validation loss : 0.922849\n",
      "8600\n",
      "step 8600 , training  accuracy 0\n",
      "step 8600 , loss : 0.137421\n",
      "step 8600 , validation  accuracy 0.5\n",
      "step 8600 , validation loss : 0.922849\n",
      "8700\n",
      "step 8700 , training  accuracy 0\n",
      "step 8700 , loss : 0.137421\n",
      "step 8700 , validation  accuracy 0.5\n",
      "step 8700 , validation loss : 0.922849\n",
      "8800\n",
      "step 8800 , training  accuracy 0\n",
      "step 8800 , loss : 0.137421\n",
      "step 8800 , validation  accuracy 0.5\n",
      "step 8800 , validation loss : 0.922849\n",
      "8900\n",
      "step 8900 , training  accuracy 0\n",
      "step 8900 , loss : 0.137421\n",
      "step 8900 , validation  accuracy 0.5\n",
      "step 8900 , validation loss : 0.922849\n",
      "9000\n",
      "step 9000 , training  accuracy 0\n",
      "step 9000 , loss : 0.137421\n",
      "step 9000 , validation  accuracy 0.5\n",
      "step 9000 , validation loss : 0.922845\n",
      "9100\n",
      "step 9100 , training  accuracy 0\n",
      "step 9100 , loss : 0.137432\n",
      "step 9100 , validation  accuracy 0.5\n",
      "step 9100 , validation loss : 0.924186\n",
      "9200\n",
      "step 9200 , training  accuracy 0\n",
      "step 9200 , loss : 0.139878\n",
      "step 9200 , validation  accuracy 0.5\n",
      "step 9200 , validation loss : 0.929794\n",
      "9300\n",
      "step 9300 , training  accuracy 0\n",
      "step 9300 , loss : 0.141035\n",
      "step 9300 , validation  accuracy 0.5\n",
      "step 9300 , validation loss : 0.932961\n",
      "9400\n",
      "step 9400 , training  accuracy 0\n",
      "step 9400 , loss : 0.138186\n",
      "step 9400 , validation  accuracy 0.5\n",
      "step 9400 , validation loss : 0.919273\n",
      "9500\n",
      "step 9500 , training  accuracy 0\n",
      "step 9500 , loss : 0.141652\n",
      "step 9500 , validation  accuracy 0.5\n",
      "step 9500 , validation loss : 0.864562\n",
      "9600\n",
      "step 9600 , training  accuracy 0\n",
      "step 9600 , loss : 0.146916\n",
      "step 9600 , validation  accuracy 0.5\n",
      "step 9600 , validation loss : 0.925184\n",
      "9700\n",
      "step 9700 , training  accuracy 0\n",
      "step 9700 , loss : 0.189648\n",
      "step 9700 , validation  accuracy 0.5\n",
      "step 9700 , validation loss : 1.09464\n",
      "9800\n",
      "step 9800 , training  accuracy 0\n",
      "step 9800 , loss : 0.14388\n",
      "step 9800 , validation  accuracy 0.5\n",
      "step 9800 , validation loss : 0.876124\n",
      "9900\n",
      "step 9900 , training  accuracy 0\n",
      "step 9900 , loss : 0.137515\n",
      "step 9900 , validation  accuracy 0.5\n",
      "step 9900 , validation loss : 0.892077\n",
      "--- Training Time : 101.485355139 ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-7f44bd5bd539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTART_SESS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_logdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mBATCH_TRAINING\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_locate\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtrain_step\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcorrect_prediction\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-90-b512f3ddb5a0>\u001b[0m in \u001b[0;36mBATCH_TRAINING\u001b[0;34m(maxiter, batch_size, file_locate, cost, train_step, correct_prediction, accuracy, fp, divide_flag, aug_flag)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Training Time : %s ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mtrain_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"--- Training Time : ---:\\t\"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: global name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "dirname='/home/seongjung/바탕화면/thyroid/result'\n",
    "A=STEM_A(x)\n",
    "B=STEM_B(A)\n",
    "C=STEM_C(B)\n",
    "flat_C=FLAT(C)\n",
    "y_conv=FC_B(flat_C , 2)\n",
    "cost , train_step ,correct_prediction , accuracy = TRAIN_STRUCTURE_A(y_conv , y_)\n",
    "sess=START_SESS()\n",
    "fp=make_logdir(dirname)\n",
    "BATCH_TRAINING(10000 , 2,file_locate , cost , train_step ,correct_prediction , accuracy  ,fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    test_accuracy = sess.run( accuracy , feed_dict={x:test_img , y_:test_lab , keep_prob: 1.0})        \n",
    "    test_loss = sess.run(cost , feed_dict = {x:test_img , y_: test_lab , keep_prob: 1.0})\n",
    "\n",
    "    #result = sess.run(sm_conv , feed_dict = {x:test_img , y_:batch_ys , keep_prob :1.0})\n",
    "    print(\"step %d , testidation  accuracy %g\" %(i,test_accuracy))\n",
    "    print(\"step %d , testidation loss : %g\" %(i,test_loss))\n",
    "    test_str = 'step:\\t'+str(i)+'\\ttest_loss:\\t'+str(test_loss) +'\\ttest accuracy:\\t'+str(test_accuracy)+'\\n'\n",
    "\n",
    "    f.write(test_str)\n",
    "except :\n",
    "    list_acc=[]\n",
    "    list_loss=[]\n",
    "    n_divide=len(test_img)/batch_size\n",
    "    for j in range(n_divide):\n",
    "\n",
    "        # j*batch_size :(j+1)*batch_size\n",
    "        test_accuracy,test_loss = sess.run([accuracy ,cost], feed_dict={x:test_img[ j*batch_size :(j+1)*batch_size] , y_:test_lab[ j*batch_size :(j+1)*batch_size ] , keep_prob: 1.0})        \n",
    "        list_acc.append(float(test_accuracy))\n",
    "        list_loss.append(float(test_loss))\n",
    "    test_accuracy , test_loss=sess.run([accuracy,cost] , feed_dict={x:test_img[(j+1)*batch_size : ] , y_:test_lab[(j+1)*(batch_size) : ] , keep_prob : 1.0})\n",
    "    #right above code have to modify\n",
    "\n",
    "    list_acc.append(test_accuracy)\n",
    "    list_loss.append(test_loss)\n",
    "    list_acc=np.asarray(list_acc)\n",
    "    list_loss= np.asarray(list_loss)\n",
    "\n",
    "    test_accuracy=np.mean(list_acc)\n",
    "    test_loss = np.mean(list_loss)\n",
    "\n",
    "    #result = sess.run(sm_conv , feed_dict = {x:test_img , y_:batch_ys , keep_prob :1.0})\n",
    "    print(\"step %d , testidation  accuracy %g\" %(i,test_accuracy))\n",
    "    print(\"step %d , testidation loss : %g\" %(i,test_loss))\n",
    "    test_str = 'step:\\t'+str(i)+'\\ttest_loss:\\t'+str(test_loss) +'\\ttest accuracy:\\t'+str(test_accuracy)+'\\n'\n",
    "\n",
    "    f.write(test_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
