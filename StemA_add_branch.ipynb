{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "32 32\n"
     ]
    }
   ],
   "source": [
    "#conv Neural Network\n",
    "# tensorboard --logdir=/home/ncc/notebook/learn/tensorboard/log\n",
    "\"\"\"\n",
    "created by kim Seong jung\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "\n",
    "file_locate='/home/user01/notebook/cifar_extracted/'\n",
    "file_locate='/media/seongjung/Seagate Backup Plus Drive/data/cifar/cifar-10-images_labels/res/'\n",
    "file_locate='/media/seongjung/Seagate Backup Plus Drive/data/cifar/cifar-10-images_labels/'\n",
    "sess = tf.InteractiveSession()\n",
    "test_img=np.load(file_locate+'test_img.npy');\n",
    "\n",
    "img_row=32\n",
    "img_col=32\n",
    "in_ch=3\n",
    "\n",
    "    \n",
    "divide_flag= True\n",
    "batch_size=30\n",
    "print img_row ,img_col\n",
    "n_classes =10\n",
    "\n",
    "\n",
    "in_ch =3\n",
    "out_ch1=32\n",
    "out_ch2=32\n",
    "out_ch3=64\n",
    "out_ch4_a=96\n",
    "out_ch4_b=0 #maxpooling\n",
    "\n",
    "###########stem B#########\n",
    "stem_B_ch1=64; \n",
    "stem_B_ch2=64;\n",
    "stem_B_ch3=64;\n",
    "stem_B_ch4=96;\n",
    "\n",
    "\n",
    "##########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fully_ch1=1024\n",
    "fully_ch2 =1024\n",
    "\n",
    "\n",
    "\n",
    "strides_1=[1,2,2,1]\n",
    "strides_2=[1,1,1,1]\n",
    "strides_3=[1,1,1,1]\n",
    "strides_4=[1,2,2,1]\n",
    "\n",
    "\n",
    "x= tf.placeholder(\"float\",shape=[None,img_col * img_row * in_ch],  name = 'x-input')\n",
    "y_=tf.placeholder(\"float\",shape=[None , n_classes] , name = 'y-input')\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "x_image= tf.reshape(x,[-1,img_row,img_col,in_ch])\n",
    "\n",
    "iterate=300000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weight_row =3 ; weight_col=3\n",
    "\n",
    "pooling_row_size1=int(img_row/2)\n",
    "pooling_row_size2=int(pooling_row_size1/2)\n",
    "pooling_row_size3=int(pooling_row_size2/2)\n",
    "pooling_row_size4=int(pooling_row_size3/2)\n",
    "pooling_row_size5=int(pooling_row_size4/2)\n",
    "pooling_col_size1=int(img_col/2)\n",
    "pooling_col_size2=int(pooling_col_size1/2)\n",
    "pooling_col_size3=int(pooling_col_size2/2)\n",
    "pooling_col_size4=int(pooling_col_size3/2)\n",
    "pooling_col_size5=int(pooling_col_size4/2)\n",
    "\n",
    "print img_col , img_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/seongjung/jupyter'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (10000, 3072)\n",
      "Training Data Label (10000, 10)\n",
      "Test Data Label (5000, 10)\n",
      "val Data Label (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:3'):\n",
    "#with tf.device('/gpu:1'):\n",
    "\n",
    "    if divide_flag == False:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_img)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n",
    "\n",
    "    if divide_flag == True:\n",
    "        train_img=np.load(file_locate+'train_img_1.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab_1.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"def weight_variable(name,shape):\n",
    "    #initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    initial = tf.get_variable(name,shape=shape , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)\"\"\"\n",
    "with tf.device('/gpu:0'):\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.1 , shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    def next_batch(batch_size , image , label):\n",
    "\n",
    "        a=np.random.randint(np.shape(image)[0] -batch_size)\n",
    "        batch_x = image[a:a+batch_size,:]\n",
    "        batch_y= label[a:a+batch_size,:]\n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "\n",
    "    def conv2d(x,w,strides_):\n",
    "        return tf.nn.conv2d(x,w, strides = strides_, padding='SAME')\n",
    "    def max_pool_2x2(x):\n",
    "        return tf.nn.max_pool(x , ksize=[1,2,2,1] ,strides = [1,2,2,1] , padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"layer1\") as scope:\n",
    "    try:\n",
    "        w_conv1 = tf.get_variable(\"W1\",[weight_row,weight_col,3,out_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        w_conv1 = tf.get_variable(\"W1\",[weight_row,weight_col,3,out_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "with tf.variable_scope(\"layer1\") as scope:\n",
    "    try:\n",
    "        b_conv1 = bias_variable([out_ch1])\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        b_conv1 = bias_variable([out_ch1])                            \n",
    "        \n",
    "with tf.variable_scope('layer2') as scope:\n",
    "    try:\n",
    "        w_conv2 = tf.get_variable(\"W2\",[weight_row,weight_col,out_ch1,out_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        w_conv2 = tf.get_variable(\"W2\",[weight_row,weight_col,out_ch1,out_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "with tf.variable_scope('layer2') as scope:\n",
    "    try:\n",
    "        b_conv2= bias_variable([out_ch2])\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        b_conv2= bias_variable([out_ch2])\n",
    "                \n",
    "with tf.variable_scope('layer3') as scope:\n",
    "    try:\n",
    "        w_conv3 = tf.get_variable(\"W3\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        w_conv3 = tf.get_variable(\"W3\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "with tf.variable_scope('layer3') as scope:\n",
    "    try:\n",
    "        b_conv3 = bias_variable([out_ch3])\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        b_conv3 = bias_variable([out_ch3])\n",
    "        \n",
    "with tf.variable_scope('layer4') as scope:\n",
    "    try:\n",
    "        w_conv4_a =tf.get_variable(\"W4\" ,[weight_row,weight_col,out_ch3,out_ch4_a] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        w_conv4_a = tf.get_variable(\"W4\" ,[weight_row,weight_col,out_ch3,out_ch4_a] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "with tf.variable_scope('layer4') as scope:\n",
    "    try:\n",
    "        b_conv4_a = bias_variable([out_ch4_a])\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        b_conv4 = bias_variable([out_ch4_a])\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"stem_B_layer1\") as scope:\n",
    "    try:\n",
    "        w_conv1 = tf.get_variable(\"W1\",[1,1,in_ch,out_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        w_conv1 = tf.get_variable(\"W1\",[weight_row,weight_col,in_ch,out_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "with tf.variable_scope(\"stem_B_layer1\") as scope:\n",
    "    try:\n",
    "        b_conv1 = bias_variable([out_ch1])\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        b_conv1 = bias_variable([out_ch1])\n",
    "                \n",
    "            \n",
    "            \n",
    "with tf.variable_scope('stem_B_layer2') as scope:\n",
    "    try:\n",
    "        w_conv2 = tf.get_variable(\"W2\",[weight_row,weight_col,out_ch1,out_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        w_conv2 = tf.get_variable(\"W2\",[weight_row,weight_col,out_ch1,out_ch2] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "with tf.variable_scope('stem_B_layer2') as scope:\n",
    "    try:\n",
    "        b_conv2= bias_variable([out_ch2])\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        b_conv2= bias_variable([out_ch2])\n",
    "                \n",
    "with tf.variable_scope('stem_B_layer3') as scope:\n",
    "    try:\n",
    "        w_conv3 = tf.get_variable(\"W3\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        w_conv3 = tf.get_variable(\"W3\" ,[weight_row,weight_col,out_ch2,out_ch3] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "with tf.variable_scope('stem_B_layer3') as scope:\n",
    "    try:\n",
    "        b_conv3 = bias_variable([out_ch3])\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        b_conv3 = bias_variable([out_ch3])\n",
    "        \n",
    "with tf.variable_scope('stem_B_layer4') as scope:\n",
    "    try:\n",
    "        w_conv4_a =tf.get_variable(\"W4\" ,[weight_row,weight_col,out_ch3,out_ch4_a] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        w_conv4_a = tf.get_variable(\"W4\" ,[weight_row,weight_col,out_ch3,out_ch4_a] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "with tf.variable_scope('stem_B_layer4') as scope:\n",
    "    try:\n",
    "        b_conv4_a = bias_variable([out_ch4_a])\n",
    "    except:\n",
    "        scope.reuse_variables()\n",
    "        b_conv4 = bias_variable([out_ch4_a])\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu:0\", shape=(?, 16, 16, 32), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 16, 16, 32), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 16, 16, 64), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"Relu_3:0\", shape=(?, 8, 8, 96), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 8, 8, 64), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"concat:0\", shape=(?, 8, 8, 160), dtype=float32, device=/device:GPU:0)\n"
     ]
    }
   ],
   "source": [
    "#conncect hidden layer \n",
    "with tf.device('/gpu:0'):\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image , w_conv1 ,strides_1)+b_conv1)\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1 , w_conv2 ,strides_2)+b_conv2)\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2 , w_conv3,strides_3)+b_conv3)\n",
    "    h_conv4_a = tf.nn.relu(conv2d(h_conv3 , w_conv4_a,strides_4)+b_conv4_a)\n",
    "    h_conv4_b = tf.nn.max_pool(h_conv3 ,[1,3,3,1] ,[1,2,2,1],'SAME')\n",
    "\n",
    "    print h_conv1\n",
    "    print h_conv2\n",
    "    print h_conv3\n",
    "    print h_conv4_a\n",
    "    print h_conv4_b\n",
    "    \n",
    "    \n",
    "    end_conv=tf.concat(3,[h_conv4_a,h_conv4_b])\n",
    "    print end_conv\n",
    "    #print conv2d(h_pool1 , w_conv2).get_shape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_conv_row=int(end_conv.get_shape()[1])\n",
    "end_conv_col=int(end_conv.get_shape()[2])\n",
    "end_conv_ch=int(end_conv.get_shape()[3])\n",
    "#connect fully connected layer \n",
    "with tf.device('/gpu:0'):\n",
    "    with tf.variable_scope(\"fc1\") as scope:\n",
    "        try:\n",
    "            w_fc1=tf.get_variable(\"fc1_W\",[end_conv_col*end_conv_row*end_conv_ch,fully_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_fc1=tf.get_variable(\"fc1_W\",[end_conv_col*end_conv_row*end_conv_ch,fully_ch1] , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        try:\n",
    "            b_fc1 = bias_variable([fully_ch1])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_fc1 = bias_variable([fully_ch1])\n",
    "\n",
    "        \n",
    "with tf.device('/gpu:0'): # flat conv layer \n",
    "    end_flat_conv =tf.reshape(end_conv, [-1,end_conv_col*end_conv_row*end_conv_ch])\n",
    "   \n",
    "with tf.device('/gpu:0'): # connect flat layer with fully  connnected layer \n",
    "    h_fc1 = tf.nn.relu(tf.matmul(end_flat_conv , w_fc1)+ b_fc1)\n",
    "    h_fc1 = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    with tf.variable_scope('fc2') as scope:\n",
    "        try:\n",
    "            w_fc2 =tf.get_variable(\"fc2_W\",[fully_ch1 , fully_ch2],initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_fc2 =tf.get_variable(\"fc2_W\",[fully_ch1 , fully_ch2],initializer = tf.contrib.layers.xavier_initializer())\n",
    "        try:\n",
    "            b_fc2 = bias_variable([fully_ch2])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_fc2 = bias_variable([fully_ch2])\n",
    "\n",
    "with tf.device('/gpu:0'):  # join flat layer with fully  connnected layer \n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1 , w_fc2)+b_fc2)\n",
    "    h_fc2= tf.nn.dropout(h_fc2 , keep_prob)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_fc=h_fc2\n",
    "end_ch=int(end_fc.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    with tf.variable_scope('end_layer') as scope:\n",
    "        try:\n",
    "            w_end =tf.get_variable(\"end_W\",[end_ch , n_classes ],initializer = tf.contrib.layers.xavier_initializer())\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            w_end =tf.get_variable(\"end_W\",[end_ch , n_classes],initializer = tf.contrib.layers.xavier_initializer())\n",
    "        try:\n",
    "            b_end = bias_variable([n_classes])\n",
    "        except:\n",
    "            scope.reuse_variables()\n",
    "            b_end = bias_variable([n_classes])\n",
    "\n",
    "with tf.device('/gpu:0'):  # join flat layer with fully  connnected layer \n",
    "    y_conv = tf.matmul(end_fc , w_end)+b_end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is recorded at :24\n"
     ]
    }
   ],
   "source": [
    "#dirname = '/home/ncc/notebook/mammo/result/'\n",
    "\n",
    "dirname='./result/'\n",
    "    \n",
    "count=0\n",
    "while(True):\n",
    "    if not os.path.isdir(dirname):\n",
    "        os.mkdir(dirname)\n",
    "        break\n",
    "    elif not os.path.isdir(dirname + str(count)):\n",
    "        dirname=dirname+str(count)\n",
    "        os.mkdir(dirname)\n",
    "        break\n",
    "    else:\n",
    "        count+=1\n",
    "print 'it is recorded at :'+str(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=open(dirname+\"/log.txt\",'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_list(folder_path):\n",
    "    list_files=os.walk(folder_path).next()[2]\n",
    "    print list_files\n",
    "    ret_train_img_list=[]\n",
    "    ret_train_lab_list=[]\n",
    "    for i , ele in enumerate(list_files):\n",
    "\n",
    "        if 'train'  in ele and 'img'in ele:\n",
    "            ret_train_img_list.append(ele)\n",
    "        elif 'train' in ele  and  'lab' in ele:\n",
    "            ret_train_lab_list.append(ele)\n",
    "    return ret_train_img_list ,ret_train_lab_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_img.npy', 'test_lab.npy', 'train_img_1.npy', 'train_img_2.npy', 'train_img_3.npy', 'train_img_4.npy', 'train_img_5.npy', 'train_lab_1.npy', 'train_lab_2.npy', 'train_lab_3.npy', 'train_lab_4.npy', 'train_lab_5.npy', 'val_img.npy', 'val_lab.npy']\n"
     ]
    }
   ],
   "source": [
    "train_images , train_labels  = get_batch_list(file_locate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_img_1.npy', 'train_img_2.npy', 'train_img_3.npy', 'train_img_4.npy', 'train_img_5.npy']\n",
      "['train_lab_1.npy', 'train_lab_2.npy', 'train_lab_3.npy', 'train_lab_4.npy', 'train_lab_5.npy']\n"
     ]
    }
   ],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "\n",
    "train_images.sort(key=natural_keys)\n",
    "train_labels.sort(key = natural_keys)\n",
    "print(train_images)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-135b699c8b96>:18 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "step 0 , training  accuracy 0.1\n",
      "step 0 , loss : 792.74\n",
      "step 0 , validation  accuracy 0.1022\n",
      "step 0 , validation loss : 103595\n",
      "step 100 , training  accuracy 0.1\n",
      "step 100 , loss : 2.67796\n",
      "step 100 , validation  accuracy 0.1168\n",
      "step 100 , validation loss : 51.6831\n",
      "step 200 , training  accuracy 0.0333333\n",
      "step 200 , loss : 2.36875\n",
      "step 200 , validation  accuracy 0.1434\n",
      "step 200 , validation loss : 12.7812\n",
      "step 300 , training  accuracy 0.0666667\n",
      "step 300 , loss : 2.34413\n",
      "step 300 , validation  accuracy 0.141\n",
      "step 300 , validation loss : 6.78185\n",
      "step 400 , training  accuracy 0.2\n",
      "step 400 , loss : 2.29383\n",
      "step 400 , validation  accuracy 0.1208\n",
      "step 400 , validation loss : 4.38745\n",
      "step 500 , training  accuracy 0.233333\n",
      "step 500 , loss : 2.31877\n",
      "step 500 , validation  accuracy 0.1252\n",
      "step 500 , validation loss : 3.41703\n",
      "step 600 , training  accuracy 0.133333\n",
      "step 600 , loss : 2.29845\n",
      "step 600 , validation  accuracy 0.1284\n",
      "step 600 , validation loss : 3.06409\n",
      "step 700 , training  accuracy 0.233333\n",
      "step 700 , loss : 2.29698\n",
      "step 700 , validation  accuracy 0.1356\n",
      "step 700 , validation loss : 2.98408\n",
      "step 800 , training  accuracy 0.166667\n",
      "step 800 , loss : 2.29792\n",
      "step 800 , validation  accuracy 0.1272\n",
      "step 800 , validation loss : 2.7753\n",
      "step 900 , training  accuracy 0.2\n",
      "step 900 , loss : 2.3017\n",
      "step 900 , validation  accuracy 0.135\n",
      "step 900 , validation loss : 2.7678\n",
      "step 1000 , training  accuracy 0.1\n",
      "step 1000 , loss : 2.28475\n",
      "step 1000 , validation  accuracy 0.1492\n",
      "step 1000 , validation loss : 3.01462\n",
      "step 1100 , training  accuracy 0.1\n",
      "step 1100 , loss : 2.30054\n",
      "step 1100 , validation  accuracy 0.1266\n",
      "step 1100 , validation loss : 2.61784\n",
      "step 1200 , training  accuracy 0.1\n",
      "step 1200 , loss : 2.29907\n",
      "step 1200 , validation  accuracy 0.1354\n",
      "step 1200 , validation loss : 2.79379\n",
      "step 1300 , training  accuracy 0.0666667\n",
      "step 1300 , loss : 2.29801\n",
      "step 1300 , validation  accuracy 0.1342\n",
      "step 1300 , validation loss : 2.89998\n",
      "step 1400 , training  accuracy 0.166667\n",
      "step 1400 , loss : 2.29488\n",
      "step 1400 , validation  accuracy 0.1454\n",
      "step 1400 , validation loss : 2.8971\n",
      "step 1500 , training  accuracy 0.133333\n",
      "step 1500 , loss : 2.29034\n",
      "step 1500 , validation  accuracy 0.1452\n",
      "step 1500 , validation loss : 2.9506\n",
      "step 1600 , training  accuracy 0.266667\n",
      "step 1600 , loss : 2.29096\n",
      "step 1600 , validation  accuracy 0.119\n",
      "step 1600 , validation loss : 2.53536\n",
      "step 1700 , training  accuracy 0.0333333\n",
      "step 1700 , loss : 2.30472\n",
      "step 1700 , validation  accuracy 0.1326\n",
      "step 1700 , validation loss : 2.76647\n",
      "step 1800 , training  accuracy 0.0333333\n",
      "step 1800 , loss : 2.30203\n",
      "step 1800 , validation  accuracy 0.1268\n",
      "step 1800 , validation loss : 2.62067\n",
      "step 1900 , training  accuracy 0.1\n",
      "step 1900 , loss : 2.30245\n",
      "step 1900 , validation  accuracy 0.113\n",
      "step 1900 , validation loss : 2.4241\n",
      "step 2000 , training  accuracy 0.266667\n",
      "step 2000 , loss : 2.28528\n",
      "step 2000 , validation  accuracy 0.1458\n",
      "step 2000 , validation loss : 2.97448\n",
      "step 2100 , training  accuracy 0.0666667\n",
      "step 2100 , loss : 2.30448\n",
      "step 2100 , validation  accuracy 0.1352\n",
      "step 2100 , validation loss : 2.74424\n",
      "step 2200 , training  accuracy 0.4\n",
      "step 2200 , loss : 2.2706\n",
      "step 2200 , validation  accuracy 0.1534\n",
      "step 2200 , validation loss : 3.97351\n",
      "step 2300 , training  accuracy 0.0666667\n",
      "step 2300 , loss : 2.29631\n",
      "step 2300 , validation  accuracy 0.14\n",
      "step 2300 , validation loss : 2.93796\n",
      "step 2400 , training  accuracy 0.133333\n",
      "step 2400 , loss : 2.30771\n",
      "step 2400 , validation  accuracy 0.1304\n",
      "step 2400 , validation loss : 2.77674\n",
      "step 2500 , training  accuracy 0.0666667\n",
      "step 2500 , loss : 2.30381\n",
      "step 2500 , validation  accuracy 0.139\n",
      "step 2500 , validation loss : 2.95291\n",
      "step 2600 , training  accuracy 0.1\n",
      "step 2600 , loss : 2.29709\n",
      "step 2600 , validation  accuracy 0.1288\n",
      "step 2600 , validation loss : 2.75987\n",
      "step 2700 , training  accuracy 0.2\n",
      "step 2700 , loss : 2.28642\n",
      "step 2700 , validation  accuracy 0.1458\n",
      "step 2700 , validation loss : 3.19437\n",
      "step 2800 , training  accuracy 0.166667\n",
      "step 2800 , loss : 2.30195\n",
      "step 2800 , validation  accuracy 0.1222\n",
      "step 2800 , validation loss : 2.66369\n",
      "step 2900 , training  accuracy 0.166667\n",
      "step 2900 , loss : 2.26335\n",
      "step 2900 , validation  accuracy 0.1498\n",
      "step 2900 , validation loss : 3.92133\n",
      "step 3000 , training  accuracy 0.2\n",
      "step 3000 , loss : 2.28851\n",
      "step 3000 , validation  accuracy 0.1476\n",
      "step 3000 , validation loss : 3.13396\n",
      "step 3100 , training  accuracy 0.166667\n",
      "step 3100 , loss : 2.2783\n",
      "step 3100 , validation  accuracy 0.1462\n",
      "step 3100 , validation loss : 3.29305\n",
      "step 3200 , training  accuracy 0.0333333\n",
      "step 3200 , loss : 2.29767\n",
      "step 3200 , validation  accuracy 0.1406\n",
      "step 3200 , validation loss : 3.06357\n",
      "step 3300 , training  accuracy 0.0666667\n",
      "step 3300 , loss : 2.30399\n",
      "step 3300 , validation  accuracy 0.1012\n",
      "step 3300 , validation loss : 2.40613\n",
      "step 3400 , training  accuracy 0.233333\n",
      "step 3400 , loss : 2.27462\n",
      "step 3400 , validation  accuracy 0.1148\n",
      "step 3400 , validation loss : 2.51675\n",
      "step 3500 , training  accuracy 0.233333\n",
      "step 3500 , loss : 2.29485\n",
      "step 3500 , validation  accuracy 0.1454\n",
      "step 3500 , validation loss : 3.26189\n",
      "step 3600 , training  accuracy 0.0333333\n",
      "step 3600 , loss : 2.30779\n",
      "step 3600 , validation  accuracy 0.126\n",
      "step 3600 , validation loss : 2.81703\n",
      "step 3700 , training  accuracy 0.166667\n",
      "step 3700 , loss : 2.29122\n",
      "step 3700 , validation  accuracy 0.1524\n",
      "step 3700 , validation loss : 3.65683\n",
      "step 3800 , training  accuracy 0.166667\n",
      "step 3800 , loss : 2.30207\n",
      "step 3800 , validation  accuracy 0.1372\n",
      "step 3800 , validation loss : 3.20976\n",
      "step 3900 , training  accuracy 0.166667\n",
      "step 3900 , loss : 2.28442\n",
      "step 3900 , validation  accuracy 0.1432\n",
      "step 3900 , validation loss : 3.26081\n",
      "step 4000 , training  accuracy 0.1\n",
      "step 4000 , loss : 2.29303\n",
      "step 4000 , validation  accuracy 0.119\n",
      "step 4000 , validation loss : 2.59304\n",
      "step 4100 , training  accuracy 0.233333\n",
      "step 4100 , loss : 2.28614\n",
      "step 4100 , validation  accuracy 0.143\n",
      "step 4100 , validation loss : 3.2917\n",
      "step 4200 , training  accuracy 0.0333333\n",
      "step 4200 , loss : 2.30452\n",
      "step 4200 , validation  accuracy 0.1014\n",
      "step 4200 , validation loss : 2.43915\n",
      "step 4300 , training  accuracy 0.1\n",
      "step 4300 , loss : 2.30292\n",
      "step 4300 , validation  accuracy 0.1028\n",
      "step 4300 , validation loss : 2.35673\n",
      "step 4400 , training  accuracy 0.166667\n",
      "step 4400 , loss : 2.30514\n",
      "step 4400 , validation  accuracy 0.1324\n",
      "step 4400 , validation loss : 2.8414\n",
      "step 4500 , training  accuracy 0.0333333\n",
      "step 4500 , loss : 2.30453\n",
      "step 4500 , validation  accuracy 0.1614\n",
      "step 4500 , validation loss : 4.76376\n",
      "step 4600 , training  accuracy 0.1\n",
      "step 4600 , loss : 2.30499\n",
      "step 4600 , validation  accuracy 0.1402\n",
      "step 4600 , validation loss : 3.07773\n",
      "step 4700 , training  accuracy 0.0666667\n",
      "step 4700 , loss : 2.30393\n",
      "step 4700 , validation  accuracy 0.11\n",
      "step 4700 , validation loss : 2.45335\n",
      "step 4800 , training  accuracy 0.166667\n",
      "step 4800 , loss : 2.28785\n",
      "step 4800 , validation  accuracy 0.1182\n",
      "step 4800 , validation loss : 2.5711\n",
      "step 4900 , training  accuracy 0.1\n",
      "step 4900 , loss : 2.30412\n",
      "step 4900 , validation  accuracy 0.1138\n",
      "step 4900 , validation loss : 2.45673\n",
      "step 5000 , training  accuracy 0.166667\n",
      "step 5000 , loss : 2.29081\n",
      "step 5000 , validation  accuracy 0.125\n",
      "step 5000 , validation loss : 2.66841\n",
      "step 5100 , training  accuracy 0.1\n",
      "step 5100 , loss : 2.30387\n",
      "step 5100 , validation  accuracy 0.1016\n",
      "step 5100 , validation loss : 2.33341\n",
      "step 5200 , training  accuracy 0.1\n",
      "step 5200 , loss : 2.30042\n",
      "step 5200 , validation  accuracy 0.1002\n",
      "step 5200 , validation loss : 2.35464\n",
      "step 5300 , training  accuracy 0.1\n",
      "step 5300 , loss : 2.3014\n",
      "step 5300 , validation  accuracy 0.0978\n",
      "step 5300 , validation loss : 2.35593\n",
      "step 5400 , training  accuracy 0.1\n",
      "step 5400 , loss : 2.30096\n",
      "step 5400 , validation  accuracy 0.1008\n",
      "step 5400 , validation loss : 2.33859\n",
      "step 5500 , training  accuracy 0\n",
      "step 5500 , loss : 2.30212\n",
      "step 5500 , validation  accuracy 0.1016\n",
      "step 5500 , validation loss : 2.32653\n",
      "step 5600 , training  accuracy 0.166667\n",
      "step 5600 , loss : 2.30081\n",
      "step 5600 , validation  accuracy 0.0994\n",
      "step 5600 , validation loss : 2.33891\n",
      "step 5700 , training  accuracy 0.133333\n",
      "step 5700 , loss : 2.30137\n",
      "step 5700 , validation  accuracy 0.0978\n",
      "step 5700 , validation loss : 2.33459\n",
      "step 5800 , training  accuracy 0.0333333\n",
      "step 5800 , loss : 2.30322\n",
      "step 5800 , validation  accuracy 0.1018\n",
      "step 5800 , validation loss : 2.38454\n",
      "step 5900 , training  accuracy 0.166667\n",
      "step 5900 , loss : 2.30215\n",
      "step 5900 , validation  accuracy 0.0976\n",
      "step 5900 , validation loss : 2.34538\n",
      "step 6000 , training  accuracy 0.1\n",
      "step 6000 , loss : 2.30387\n",
      "step 6000 , validation  accuracy 0.1014\n",
      "step 6000 , validation loss : 2.3569\n",
      "step 6100 , training  accuracy 0.1\n",
      "step 6100 , loss : 2.30371\n",
      "step 6100 , validation  accuracy 0.103\n",
      "step 6100 , validation loss : 2.36832\n",
      "step 6200 , training  accuracy 0.0333333\n",
      "step 6200 , loss : 2.30355\n",
      "step 6200 , validation  accuracy 0.0992\n",
      "step 6200 , validation loss : 2.33648\n",
      "step 6300 , training  accuracy 0.166667\n",
      "step 6300 , loss : 2.3014\n",
      "step 6300 , validation  accuracy 0.0992\n",
      "step 6300 , validation loss : 2.35457\n",
      "step 6400 , training  accuracy 0.166667\n",
      "step 6400 , loss : 2.30106\n",
      "step 6400 , validation  accuracy 0.0986\n",
      "step 6400 , validation loss : 2.35574\n",
      "step 6500 , training  accuracy 0.0666667\n",
      "step 6500 , loss : 2.30407\n",
      "step 6500 , validation  accuracy 0.0978\n",
      "step 6500 , validation loss : 2.33783\n",
      "step 6600 , training  accuracy 0.2\n",
      "step 6600 , loss : 2.30296\n",
      "step 6600 , validation  accuracy 0.0988\n",
      "step 6600 , validation loss : 2.31941\n",
      "step 6700 , training  accuracy 0.0333333\n",
      "step 6700 , loss : 2.30354\n",
      "step 6700 , validation  accuracy 0.0992\n",
      "step 6700 , validation loss : 2.36462\n",
      "step 6800 , training  accuracy 0.2\n",
      "step 6800 , loss : 2.3035\n",
      "step 6800 , validation  accuracy 0.0992\n",
      "step 6800 , validation loss : 2.35527\n",
      "step 6900 , training  accuracy 0.1\n",
      "step 6900 , loss : 2.30003\n",
      "step 6900 , validation  accuracy 0.0994\n",
      "step 6900 , validation loss : 2.33401\n",
      "step 7000 , training  accuracy 0.1\n",
      "step 7000 , loss : 2.3021\n",
      "step 7000 , validation  accuracy 0.102\n",
      "step 7000 , validation loss : 2.36806\n",
      "step 7100 , training  accuracy 0.0666667\n",
      "step 7100 , loss : 2.30318\n",
      "step 7100 , validation  accuracy 0.0988\n",
      "step 7100 , validation loss : 2.34156\n",
      "step 7200 , training  accuracy 0.166667\n",
      "step 7200 , loss : 2.30359\n",
      "step 7200 , validation  accuracy 0.1026\n",
      "step 7200 , validation loss : 2.36893\n",
      "step 7300 , training  accuracy 0.0333333\n",
      "step 7300 , loss : 2.3057\n",
      "step 7300 , validation  accuracy 0.0994\n",
      "step 7300 , validation loss : 2.37591\n",
      "step 7400 , training  accuracy 0.0666667\n",
      "step 7400 , loss : 2.303\n",
      "step 7400 , validation  accuracy 0.0974\n",
      "step 7400 , validation loss : 2.31414\n",
      "step 7500 , training  accuracy 0.166667\n",
      "step 7500 , loss : 2.30256\n",
      "step 7500 , validation  accuracy 0.1004\n",
      "step 7500 , validation loss : 2.34058\n",
      "step 7600 , training  accuracy 0.133333\n",
      "step 7600 , loss : 2.2955\n",
      "step 7600 , validation  accuracy 0.0994\n",
      "step 7600 , validation loss : 2.39084\n",
      "step 7700 , training  accuracy 0.166667\n",
      "step 7700 , loss : 2.30389\n",
      "step 7700 , validation  accuracy 0.1024\n",
      "step 7700 , validation loss : 2.36905\n",
      "step 7800 , training  accuracy 0.0666667\n",
      "step 7800 , loss : 2.30199\n",
      "step 7800 , validation  accuracy 0.1026\n",
      "step 7800 , validation loss : 2.35223\n",
      "step 7900 , training  accuracy 0.0333333\n",
      "step 7900 , loss : 2.30318\n",
      "step 7900 , validation  accuracy 0.0996\n",
      "step 7900 , validation loss : 2.32109\n",
      "step 8000 , training  accuracy 0.266667\n",
      "step 8000 , loss : 2.29979\n",
      "step 8000 , validation  accuracy 0.1022\n",
      "step 8000 , validation loss : 2.3354\n",
      "step 8100 , training  accuracy 0.166667\n",
      "step 8100 , loss : 2.30273\n",
      "step 8100 , validation  accuracy 0.1012\n",
      "step 8100 , validation loss : 2.35106\n",
      "step 8200 , training  accuracy 0.0666667\n",
      "step 8200 , loss : 2.30367\n",
      "step 8200 , validation  accuracy 0.099\n",
      "step 8200 , validation loss : 2.33572\n",
      "step 8300 , training  accuracy 0.1\n",
      "step 8300 , loss : 2.29997\n",
      "step 8300 , validation  accuracy 0.1028\n",
      "step 8300 , validation loss : 2.36082\n",
      "step 8400 , training  accuracy 0.1\n",
      "step 8400 , loss : 2.30206\n",
      "step 8400 , validation  accuracy 0.0974\n",
      "step 8400 , validation loss : 2.3436\n",
      "step 8500 , training  accuracy 0.2\n",
      "step 8500 , loss : 2.29964\n",
      "step 8500 , validation  accuracy 0.1008\n",
      "step 8500 , validation loss : 2.38331\n",
      "step 8600 , training  accuracy 0.0666667\n",
      "step 8600 , loss : 2.30361\n",
      "step 8600 , validation  accuracy 0.101\n",
      "step 8600 , validation loss : 2.41277\n",
      "step 8700 , training  accuracy 0.166667\n",
      "step 8700 , loss : 2.30067\n",
      "step 8700 , validation  accuracy 0.1008\n",
      "step 8700 , validation loss : 2.38085\n",
      "step 8800 , training  accuracy 0.2\n",
      "step 8800 , loss : 2.30203\n",
      "step 8800 , validation  accuracy 0.0988\n",
      "step 8800 , validation loss : 2.36159\n",
      "step 8900 , training  accuracy 0.133333\n",
      "step 8900 , loss : 2.303\n",
      "step 8900 , validation  accuracy 0.101\n",
      "step 8900 , validation loss : 2.34469\n",
      "step 9000 , training  accuracy 0.233333\n",
      "step 9000 , loss : 2.29939\n",
      "step 9000 , validation  accuracy 0.1026\n",
      "step 9000 , validation loss : 2.41217\n",
      "step 9100 , training  accuracy 0.0333333\n",
      "step 9100 , loss : 2.30416\n",
      "step 9100 , validation  accuracy 0.0986\n",
      "step 9100 , validation loss : 2.40507\n",
      "step 9200 , training  accuracy 0.1\n",
      "step 9200 , loss : 2.30359\n",
      "step 9200 , validation  accuracy 0.099\n",
      "step 9200 , validation loss : 2.37882\n",
      "step 9300 , training  accuracy 0.1\n",
      "step 9300 , loss : 2.30253\n",
      "step 9300 , validation  accuracy 0.1026\n",
      "step 9300 , validation loss : 2.38273\n",
      "step 9400 , training  accuracy 0.0333333\n",
      "step 9400 , loss : 2.30336\n",
      "step 9400 , validation  accuracy 0.0992\n",
      "step 9400 , validation loss : 2.33256\n",
      "step 9500 , training  accuracy 0.166667\n",
      "step 9500 , loss : 2.30109\n",
      "step 9500 , validation  accuracy 0.0992\n",
      "step 9500 , validation loss : 2.3615\n",
      "step 9600 , training  accuracy 0.0666667\n",
      "step 9600 , loss : 2.30752\n",
      "step 9600 , validation  accuracy 0.097\n",
      "step 9600 , validation loss : 2.40659\n",
      "step 9700 , training  accuracy 0.133333\n",
      "step 9700 , loss : 2.30595\n",
      "step 9700 , validation  accuracy 0.0974\n",
      "step 9700 , validation loss : 2.38135\n",
      "step 9800 , training  accuracy 0.1\n",
      "step 9800 , loss : 2.30588\n",
      "step 9800 , validation  accuracy 0.1012\n",
      "step 9800 , validation loss : 2.44401\n",
      "step 9900 , training  accuracy 0.133333\n",
      "step 9900 , loss : 2.30307\n",
      "step 9900 , validation  accuracy 0.1006\n",
      "step 9900 , validation loss : 2.38325\n",
      "step 10000 , training  accuracy 0.1\n",
      "step 10000 , loss : 2.301\n",
      "step 10000 , validation  accuracy 0.0976\n",
      "step 10000 , validation loss : 2.38771\n",
      "step 10100 , training  accuracy 0.2\n",
      "step 10100 , loss : 2.30126\n",
      "step 10100 , validation  accuracy 0.1008\n",
      "step 10100 , validation loss : 2.33353\n",
      "step 10200 , training  accuracy 0.1\n",
      "step 10200 , loss : 2.30173\n",
      "step 10200 , validation  accuracy 0.099\n",
      "step 10200 , validation loss : 2.35966\n",
      "step 10300 , training  accuracy 0.2\n",
      "step 10300 , loss : 2.30456\n",
      "step 10300 , validation  accuracy 0.1006\n",
      "step 10300 , validation loss : 2.37899\n",
      "step 10400 , training  accuracy 0.1\n",
      "step 10400 , loss : 2.3024\n",
      "step 10400 , validation  accuracy 0.0988\n",
      "step 10400 , validation loss : 2.36093\n",
      "step 10500 , training  accuracy 0.0666667\n",
      "step 10500 , loss : 2.30034\n",
      "step 10500 , validation  accuracy 0.1018\n",
      "step 10500 , validation loss : 2.41993\n",
      "step 10600 , training  accuracy 0.166667\n",
      "step 10600 , loss : 2.29838\n",
      "step 10600 , validation  accuracy 0.1018\n",
      "step 10600 , validation loss : 2.37948\n",
      "step 10700 , training  accuracy 0.0333333\n",
      "step 10700 , loss : 2.30393\n",
      "step 10700 , validation  accuracy 0.0988\n",
      "step 10700 , validation loss : 2.36727\n",
      "step 10800 , training  accuracy 0.0666667\n",
      "step 10800 , loss : 2.30198\n",
      "step 10800 , validation  accuracy 0.1006\n",
      "step 10800 , validation loss : 2.31784\n",
      "step 10900 , training  accuracy 0.1\n",
      "step 10900 , loss : 2.30384\n",
      "step 10900 , validation  accuracy 0.0986\n",
      "step 10900 , validation loss : 2.35293\n",
      "step 11000 , training  accuracy 0.133333\n",
      "step 11000 , loss : 2.30133\n",
      "step 11000 , validation  accuracy 0.0974\n",
      "step 11000 , validation loss : 2.34932\n",
      "step 11100 , training  accuracy 0.0666667\n",
      "step 11100 , loss : 2.30468\n",
      "step 11100 , validation  accuracy 0.0988\n",
      "step 11100 , validation loss : 2.44059\n",
      "step 11200 , training  accuracy 0.1\n",
      "step 11200 , loss : 2.30348\n",
      "step 11200 , validation  accuracy 0.0974\n",
      "step 11200 , validation loss : 2.33937\n",
      "step 11300 , training  accuracy 0.133333\n",
      "step 11300 , loss : 2.30153\n",
      "step 11300 , validation  accuracy 0.0974\n",
      "step 11300 , validation loss : 2.33298\n",
      "step 11400 , training  accuracy 0.2\n",
      "step 11400 , loss : 2.30245\n",
      "step 11400 , validation  accuracy 0.0992\n",
      "step 11400 , validation loss : 2.33572\n",
      "step 11500 , training  accuracy 0.133333\n",
      "step 11500 , loss : 2.30352\n",
      "step 11500 , validation  accuracy 0.0974\n",
      "step 11500 , validation loss : 2.34151\n",
      "step 11600 , training  accuracy 0.1\n",
      "step 11600 , loss : 2.30714\n",
      "step 11600 , validation  accuracy 0.0986\n",
      "step 11600 , validation loss : 2.3912\n",
      "step 11700 , training  accuracy 0.166667\n",
      "step 11700 , loss : 2.30093\n",
      "step 11700 , validation  accuracy 0.1024\n",
      "step 11700 , validation loss : 2.4082\n",
      "step 11800 , training  accuracy 0.0333333\n",
      "step 11800 , loss : 2.30386\n",
      "step 11800 , validation  accuracy 0.0992\n",
      "step 11800 , validation loss : 2.35119\n",
      "step 11900 , training  accuracy 0.0666667\n",
      "step 11900 , loss : 2.30387\n",
      "step 11900 , validation  accuracy 0.1026\n",
      "step 11900 , validation loss : 2.38983\n",
      "step 12000 , training  accuracy 0.1\n",
      "step 12000 , loss : 2.30285\n",
      "step 12000 , validation  accuracy 0.0974\n",
      "step 12000 , validation loss : 2.3751\n",
      "step 12100 , training  accuracy 0.1\n",
      "step 12100 , loss : 2.30375\n",
      "step 12100 , validation  accuracy 0.099\n",
      "step 12100 , validation loss : 2.35566\n",
      "step 12200 , training  accuracy 0.0333333\n",
      "step 12200 , loss : 2.3078\n",
      "step 12200 , validation  accuracy 0.102\n",
      "step 12200 , validation loss : 2.38497\n",
      "step 12300 , training  accuracy 0.0333333\n",
      "step 12300 , loss : 2.30531\n",
      "step 12300 , validation  accuracy 0.0974\n",
      "step 12300 , validation loss : 2.3403\n",
      "step 12400 , training  accuracy 0.0333333\n",
      "step 12400 , loss : 2.30497\n",
      "step 12400 , validation  accuracy 0.0994\n",
      "step 12400 , validation loss : 2.3869\n",
      "step 12500 , training  accuracy 0.1\n",
      "step 12500 , loss : 2.30664\n",
      "step 12500 , validation  accuracy 0.0992\n",
      "step 12500 , validation loss : 2.40955\n",
      "step 12600 , training  accuracy 0\n",
      "step 12600 , loss : 2.30269\n",
      "step 12600 , validation  accuracy 0.1018\n",
      "step 12600 , validation loss : 2.3472\n",
      "step 12700 , training  accuracy 0.166667\n",
      "step 12700 , loss : 2.30316\n",
      "step 12700 , validation  accuracy 0.0986\n",
      "step 12700 , validation loss : 2.39383\n",
      "step 12800 , training  accuracy 0.1\n",
      "step 12800 , loss : 2.30329\n",
      "step 12800 , validation  accuracy 0.1008\n",
      "step 12800 , validation loss : 2.34715\n",
      "step 12900 , training  accuracy 0.1\n",
      "step 12900 , loss : 2.30178\n",
      "step 12900 , validation  accuracy 0.0986\n",
      "step 12900 , validation loss : 2.34985\n",
      "step 13000 , training  accuracy 0\n",
      "step 13000 , loss : 2.30741\n",
      "step 13000 , validation  accuracy 0.1042\n",
      "step 13000 , validation loss : 2.4697\n",
      "step 13100 , training  accuracy 0.1\n",
      "step 13100 , loss : 2.3028\n",
      "step 13100 , validation  accuracy 0.0984\n",
      "step 13100 , validation loss : 2.36537\n",
      "step 13200 , training  accuracy 0.0666667\n",
      "step 13200 , loss : 2.30432\n",
      "step 13200 , validation  accuracy 0.1018\n",
      "step 13200 , validation loss : 2.35132\n",
      "step 13300 , training  accuracy 0.133333\n",
      "step 13300 , loss : 2.30137\n",
      "step 13300 , validation  accuracy 0.099\n",
      "step 13300 , validation loss : 2.39729\n",
      "step 13400 , training  accuracy 0.0333333\n",
      "step 13400 , loss : 2.30367\n",
      "step 13400 , validation  accuracy 0.1008\n",
      "step 13400 , validation loss : 2.37467\n",
      "step 13500 , training  accuracy 0.133333\n",
      "step 13500 , loss : 2.30289\n",
      "step 13500 , validation  accuracy 0.101\n",
      "step 13500 , validation loss : 2.37241\n",
      "step 13600 , training  accuracy 0.1\n",
      "step 13600 , loss : 2.30283\n",
      "step 13600 , validation  accuracy 0.0994\n",
      "step 13600 , validation loss : 2.35676\n",
      "step 13700 , training  accuracy 0.133333\n",
      "step 13700 , loss : 2.3015\n",
      "step 13700 , validation  accuracy 0.0986\n",
      "step 13700 , validation loss : 2.35296\n",
      "step 13800 , training  accuracy 0.166667\n",
      "step 13800 , loss : 2.30357\n",
      "step 13800 , validation  accuracy 0.0976\n",
      "step 13800 , validation loss : 2.36948\n",
      "step 13900 , training  accuracy 0.1\n",
      "step 13900 , loss : 2.30111\n",
      "step 13900 , validation  accuracy 0.1008\n",
      "step 13900 , validation loss : 2.39552\n",
      "step 14000 , training  accuracy 0.1\n",
      "step 14000 , loss : 2.30314\n",
      "step 14000 , validation  accuracy 0.1018\n",
      "step 14000 , validation loss : 2.38932\n",
      "step 14100 , training  accuracy 0.133333\n",
      "step 14100 , loss : 2.30174\n",
      "step 14100 , validation  accuracy 0.1022\n",
      "step 14100 , validation loss : 2.33289\n",
      "step 14200 , training  accuracy 0.0666667\n",
      "step 14200 , loss : 2.30149\n",
      "step 14200 , validation  accuracy 0.0974\n",
      "step 14200 , validation loss : 2.37103\n",
      "step 14300 , training  accuracy 0.1\n",
      "step 14300 , loss : 2.3034\n",
      "step 14300 , validation  accuracy 0.0984\n",
      "step 14300 , validation loss : 2.34791\n",
      "step 14400 , training  accuracy 0.166667\n",
      "step 14400 , loss : 2.30261\n",
      "step 14400 , validation  accuracy 0.0992\n",
      "step 14400 , validation loss : 2.32998\n",
      "step 14500 , training  accuracy 0.166667\n",
      "step 14500 , loss : 2.30019\n",
      "step 14500 , validation  accuracy 0.0974\n",
      "step 14500 , validation loss : 2.37277\n",
      "step 14600 , training  accuracy 0.0666667\n",
      "step 14600 , loss : 2.30336\n",
      "step 14600 , validation  accuracy 0.1018\n",
      "step 14600 , validation loss : 2.38541\n",
      "step 14700 , training  accuracy 0.0666667\n",
      "step 14700 , loss : 2.30447\n",
      "step 14700 , validation  accuracy 0.0974\n",
      "step 14700 , validation loss : 2.40943\n",
      "step 14800 , training  accuracy 0.0666667\n",
      "step 14800 , loss : 2.30195\n",
      "step 14800 , validation  accuracy 0.0976\n",
      "step 14800 , validation loss : 2.36943\n",
      "step 14900 , training  accuracy 0.0666667\n",
      "step 14900 , loss : 2.30248\n",
      "step 14900 , validation  accuracy 0.1006\n",
      "step 14900 , validation loss : 2.33901\n",
      "step 15000 , training  accuracy 0.133333\n",
      "step 15000 , loss : 2.30216\n",
      "step 15000 , validation  accuracy 0.0974\n",
      "step 15000 , validation loss : 2.38911\n",
      "step 15100 , training  accuracy 0.1\n",
      "step 15100 , loss : 2.30527\n",
      "step 15100 , validation  accuracy 0.101\n",
      "step 15100 , validation loss : 2.37421\n",
      "step 15200 , training  accuracy 0.0333333\n",
      "step 15200 , loss : 2.30528\n",
      "step 15200 , validation  accuracy 0.099\n",
      "step 15200 , validation loss : 2.38652\n",
      "step 15300 , training  accuracy 0.0333333\n",
      "step 15300 , loss : 2.30459\n",
      "step 15300 , validation  accuracy 0.0986\n",
      "step 15300 , validation loss : 2.36474\n",
      "step 15400 , training  accuracy 0.0666667\n",
      "step 15400 , loss : 2.30263\n",
      "step 15400 , validation  accuracy 0.1024\n",
      "step 15400 , validation loss : 2.35575\n",
      "step 15500 , training  accuracy 0.133333\n",
      "step 15500 , loss : 2.30394\n",
      "step 15500 , validation  accuracy 0.1018\n",
      "step 15500 , validation loss : 2.42123\n",
      "step 15600 , training  accuracy 0.133333\n",
      "step 15600 , loss : 2.30262\n",
      "step 15600 , validation  accuracy 0.0992\n",
      "step 15600 , validation loss : 2.44018\n",
      "step 15700 , training  accuracy 0.0333333\n",
      "step 15700 , loss : 2.30976\n",
      "step 15700 , validation  accuracy 0.1022\n",
      "step 15700 , validation loss : 2.39847\n",
      "step 15800 , training  accuracy 0.1\n",
      "step 15800 , loss : 2.30285\n",
      "step 15800 , validation  accuracy 0.0974\n",
      "step 15800 , validation loss : 2.42869\n",
      "step 15900 , training  accuracy 0.0666667\n",
      "step 15900 , loss : 2.30285\n",
      "step 15900 , validation  accuracy 0.1016\n",
      "step 15900 , validation loss : 2.34265\n",
      "step 16000 , training  accuracy 0.133333\n",
      "step 16000 , loss : 2.30176\n",
      "step 16000 , validation  accuracy 0.1006\n",
      "step 16000 , validation loss : 2.40587\n",
      "step 16100 , training  accuracy 0.0333333\n",
      "step 16100 , loss : 2.30824\n",
      "step 16100 , validation  accuracy 0.0986\n",
      "step 16100 , validation loss : 2.46094\n",
      "step 16200 , training  accuracy 0.0666667\n",
      "step 16200 , loss : 2.30131\n",
      "step 16200 , validation  accuracy 0.1006\n",
      "step 16200 , validation loss : 2.3961\n",
      "step 16300 , training  accuracy 0\n",
      "step 16300 , loss : 2.30658\n",
      "step 16300 , validation  accuracy 0.1024\n",
      "step 16300 , validation loss : 2.36951\n",
      "step 16400 , training  accuracy 0.133333\n",
      "step 16400 , loss : 2.30305\n",
      "step 16400 , validation  accuracy 0.1022\n",
      "step 16400 , validation loss : 2.34029\n",
      "step 16500 , training  accuracy 0.166667\n",
      "step 16500 , loss : 2.30883\n",
      "step 16500 , validation  accuracy 0.0978\n",
      "step 16500 , validation loss : 2.49696\n",
      "step 16600 , training  accuracy 0.133333\n",
      "step 16600 , loss : 2.30482\n",
      "step 16600 , validation  accuracy 0.1012\n",
      "step 16600 , validation loss : 2.4804\n",
      "step 16700 , training  accuracy 0.233333\n",
      "step 16700 , loss : 2.30023\n",
      "step 16700 , validation  accuracy 0.1022\n",
      "step 16700 , validation loss : 2.33224\n",
      "step 16800 , training  accuracy 0.166667\n",
      "step 16800 , loss : 2.30132\n",
      "step 16800 , validation  accuracy 0.0992\n",
      "step 16800 , validation loss : 2.37595\n",
      "step 16900 , training  accuracy 0\n",
      "step 16900 , loss : 2.30704\n",
      "step 16900 , validation  accuracy 0.1018\n",
      "step 16900 , validation loss : 2.35984\n",
      "step 17000 , training  accuracy 0.1\n",
      "step 17000 , loss : 2.30475\n",
      "step 17000 , validation  accuracy 0.1022\n",
      "step 17000 , validation loss : 2.41507\n",
      "step 17100 , training  accuracy 0.1\n",
      "step 17100 , loss : 2.30148\n",
      "step 17100 , validation  accuracy 0.099\n",
      "step 17100 , validation loss : 2.40115\n",
      "step 17200 , training  accuracy 0.1\n",
      "step 17200 , loss : 2.3028\n",
      "step 17200 , validation  accuracy 0.1024\n",
      "step 17200 , validation loss : 2.37056\n",
      "step 17300 , training  accuracy 0.0666667\n",
      "step 17300 , loss : 2.30494\n",
      "step 17300 , validation  accuracy 0.0986\n",
      "step 17300 , validation loss : 2.38433\n",
      "step 17400 , training  accuracy 0.1\n",
      "step 17400 , loss : 2.30666\n",
      "step 17400 , validation  accuracy 0.1006\n",
      "step 17400 , validation loss : 2.39175\n",
      "step 17500 , training  accuracy 0.133333\n",
      "step 17500 , loss : 2.30422\n",
      "step 17500 , validation  accuracy 0.1006\n",
      "step 17500 , validation loss : 2.41055\n",
      "step 17600 , training  accuracy 0.1\n",
      "step 17600 , loss : 2.30065\n",
      "step 17600 , validation  accuracy 0.0986\n",
      "step 17600 , validation loss : 2.37137\n",
      "step 17700 , training  accuracy 0.1\n",
      "step 17700 , loss : 2.30383\n",
      "step 17700 , validation  accuracy 0.0988\n",
      "step 17700 , validation loss : 2.36899\n",
      "step 17800 , training  accuracy 0.133333\n",
      "step 17800 , loss : 2.30121\n",
      "step 17800 , validation  accuracy 0.0974\n",
      "step 17800 , validation loss : 2.38431\n",
      "step 17900 , training  accuracy 0.0666667\n",
      "step 17900 , loss : 2.30488\n",
      "step 17900 , validation  accuracy 0.0992\n",
      "step 17900 , validation loss : 2.39682\n",
      "step 18000 , training  accuracy 0\n",
      "step 18000 , loss : 2.29972\n",
      "step 18000 , validation  accuracy 0.1018\n",
      "step 18000 , validation loss : 2.46914\n",
      "step 18100 , training  accuracy 0.166667\n",
      "step 18100 , loss : 2.30218\n",
      "step 18100 , validation  accuracy 0.1012\n",
      "step 18100 , validation loss : 2.36436\n",
      "step 18200 , training  accuracy 0.0333333\n",
      "step 18200 , loss : 2.30722\n",
      "step 18200 , validation  accuracy 0.0992\n",
      "step 18200 , validation loss : 2.35854\n",
      "step 18300 , training  accuracy 0.1\n",
      "step 18300 , loss : 2.30357\n",
      "step 18300 , validation  accuracy 0.0984\n",
      "step 18300 , validation loss : 2.38502\n",
      "step 18400 , training  accuracy 0.0333333\n",
      "step 18400 , loss : 2.30489\n",
      "step 18400 , validation  accuracy 0.0992\n",
      "step 18400 , validation loss : 2.34615\n",
      "step 18500 , training  accuracy 0.166667\n",
      "step 18500 , loss : 2.30109\n",
      "step 18500 , validation  accuracy 0.1016\n",
      "step 18500 , validation loss : 2.37109\n",
      "step 18600 , training  accuracy 0.133333\n",
      "step 18600 , loss : 2.30279\n",
      "step 18600 , validation  accuracy 0.0988\n",
      "step 18600 , validation loss : 2.40962\n",
      "step 18700 , training  accuracy 0.133333\n",
      "step 18700 , loss : 2.30285\n",
      "step 18700 , validation  accuracy 0.099\n",
      "step 18700 , validation loss : 2.37933\n",
      "step 18800 , training  accuracy 0.1\n",
      "step 18800 , loss : 2.30226\n",
      "step 18800 , validation  accuracy 0.0976\n",
      "step 18800 , validation loss : 2.36559\n",
      "step 18900 , training  accuracy 0.0333333\n",
      "step 18900 , loss : 2.30453\n",
      "step 18900 , validation  accuracy 0.1022\n",
      "step 18900 , validation loss : 2.33196\n",
      "step 19000 , training  accuracy 0.1\n",
      "step 19000 , loss : 2.30099\n",
      "step 19000 , validation  accuracy 0.0976\n",
      "step 19000 , validation loss : 2.4683\n",
      "step 19100 , training  accuracy 0.1\n",
      "step 19100 , loss : 2.30215\n",
      "step 19100 , validation  accuracy 0.0992\n",
      "step 19100 , validation loss : 2.37753\n",
      "step 19200 , training  accuracy 0.133333\n",
      "step 19200 , loss : 2.30207\n",
      "step 19200 , validation  accuracy 0.0976\n",
      "step 19200 , validation loss : 2.38293\n",
      "step 19300 , training  accuracy 0.133333\n",
      "step 19300 , loss : 2.30223\n",
      "step 19300 , validation  accuracy 0.0986\n",
      "step 19300 , validation loss : 2.3372\n",
      "step 19400 , training  accuracy 0.1\n",
      "step 19400 , loss : 2.30191\n",
      "step 19400 , validation  accuracy 0.1022\n",
      "step 19400 , validation loss : 2.33365\n",
      "step 19500 , training  accuracy 0.133333\n",
      "step 19500 , loss : 2.29781\n",
      "step 19500 , validation  accuracy 0.0986\n",
      "step 19500 , validation loss : 2.35704\n",
      "step 19600 , training  accuracy 0.0333333\n",
      "step 19600 , loss : 2.30431\n",
      "step 19600 , validation  accuracy 0.1018\n",
      "step 19600 , validation loss : 2.38084\n",
      "step 19700 , training  accuracy 0.0666667\n",
      "step 19700 , loss : 2.30532\n",
      "step 19700 , validation  accuracy 0.1024\n",
      "step 19700 , validation loss : 2.42139\n",
      "step 19800 , training  accuracy 0.1\n",
      "step 19800 , loss : 2.30081\n",
      "step 19800 , validation  accuracy 0.0976\n",
      "step 19800 , validation loss : 2.37867\n",
      "step 19900 , training  accuracy 0\n",
      "step 19900 , loss : 2.30552\n",
      "step 19900 , validation  accuracy 0.101\n",
      "step 19900 , validation loss : 2.34477\n",
      "step 20000 , training  accuracy 0.133333\n",
      "step 20000 , loss : 2.30273\n",
      "step 20000 , validation  accuracy 0.1024\n",
      "step 20000 , validation loss : 2.39952\n",
      "step 20100 , training  accuracy 0.1\n",
      "step 20100 , loss : 2.29969\n",
      "step 20100 , validation  accuracy 0.1018\n",
      "step 20100 , validation loss : 2.41624\n",
      "step 20200 , training  accuracy 0.0333333\n",
      "step 20200 , loss : 2.30479\n",
      "step 20200 , validation  accuracy 0.1024\n",
      "step 20200 , validation loss : 2.33908\n",
      "step 20300 , training  accuracy 0.0666667\n",
      "step 20300 , loss : 2.30266\n",
      "step 20300 , validation  accuracy 0.1018\n",
      "step 20300 , validation loss : 2.3422\n",
      "step 20400 , training  accuracy 0.133333\n",
      "step 20400 , loss : 2.30097\n",
      "step 20400 , validation  accuracy 0.102\n",
      "step 20400 , validation loss : 2.33781\n",
      "step 20500 , training  accuracy 0.1\n",
      "step 20500 , loss : 2.3016\n",
      "step 20500 , validation  accuracy 0.0988\n",
      "step 20500 , validation loss : 2.34242\n",
      "step 20600 , training  accuracy 0.1\n",
      "step 20600 , loss : 2.30494\n",
      "step 20600 , validation  accuracy 0.1008\n",
      "step 20600 , validation loss : 2.35607\n",
      "step 20700 , training  accuracy 0.0666667\n",
      "step 20700 , loss : 2.30399\n",
      "step 20700 , validation  accuracy 0.099\n",
      "step 20700 , validation loss : 2.36178\n",
      "step 20800 , training  accuracy 0.133333\n",
      "step 20800 , loss : 2.30637\n",
      "step 20800 , validation  accuracy 0.0976\n",
      "step 20800 , validation loss : 2.40427\n",
      "step 20900 , training  accuracy 0.0666667\n",
      "step 20900 , loss : 2.30439\n",
      "step 20900 , validation  accuracy 0.1006\n",
      "step 20900 , validation loss : 2.35522\n",
      "step 21000 , training  accuracy 0.1\n",
      "step 21000 , loss : 2.30251\n",
      "step 21000 , validation  accuracy 0.1006\n",
      "step 21000 , validation loss : 2.35658\n",
      "step 21100 , training  accuracy 0.0666667\n",
      "step 21100 , loss : 2.30523\n",
      "step 21100 , validation  accuracy 0.0976\n",
      "step 21100 , validation loss : 2.33877\n",
      "step 21200 , training  accuracy 0.1\n",
      "step 21200 , loss : 2.30282\n",
      "step 21200 , validation  accuracy 0.1024\n",
      "step 21200 , validation loss : 2.37132\n",
      "step 21300 , training  accuracy 0.133333\n",
      "step 21300 , loss : 2.30251\n",
      "step 21300 , validation  accuracy 0.0976\n",
      "step 21300 , validation loss : 2.37223\n",
      "step 21400 , training  accuracy 0.233333\n",
      "step 21400 , loss : 2.29977\n",
      "step 21400 , validation  accuracy 0.1022\n",
      "step 21400 , validation loss : 2.41681\n",
      "step 21500 , training  accuracy 0.0666667\n",
      "step 21500 , loss : 2.30798\n",
      "step 21500 , validation  accuracy 0.0974\n",
      "step 21500 , validation loss : 2.42425\n",
      "step 21600 , training  accuracy 0.0666667\n",
      "step 21600 , loss : 2.30224\n",
      "step 21600 , validation  accuracy 0.1018\n",
      "step 21600 , validation loss : 2.34145\n",
      "step 21700 , training  accuracy 0.133333\n",
      "step 21700 , loss : 2.30067\n",
      "step 21700 , validation  accuracy 0.099\n",
      "step 21700 , validation loss : 2.3922\n",
      "step 21800 , training  accuracy 0\n",
      "step 21800 , loss : 2.30509\n",
      "step 21800 , validation  accuracy 0.101\n",
      "step 21800 , validation loss : 2.39146\n",
      "step 21900 , training  accuracy 0.0333333\n",
      "step 21900 , loss : 2.3039\n",
      "step 21900 , validation  accuracy 0.0992\n",
      "step 21900 , validation loss : 2.40414\n",
      "step 22000 , training  accuracy 0.0333333\n",
      "step 22000 , loss : 2.3034\n",
      "step 22000 , validation  accuracy 0.0976\n",
      "step 22000 , validation loss : 2.33611\n",
      "step 22100 , training  accuracy 0.133333\n",
      "step 22100 , loss : 2.30312\n",
      "step 22100 , validation  accuracy 0.1016\n",
      "step 22100 , validation loss : 2.41859\n",
      "step 22200 , training  accuracy 0.1\n",
      "step 22200 , loss : 2.30555\n",
      "step 22200 , validation  accuracy 0.099\n",
      "step 22200 , validation loss : 2.4543\n",
      "step 22300 , training  accuracy 0.133333\n",
      "step 22300 , loss : 2.30261\n",
      "step 22300 , validation  accuracy 0.0992\n",
      "step 22300 , validation loss : 2.32293\n",
      "step 22400 , training  accuracy 0.1\n",
      "step 22400 , loss : 2.30726\n",
      "step 22400 , validation  accuracy 0.0972\n",
      "step 22400 , validation loss : 2.41863\n",
      "step 22500 , training  accuracy 0.0666667\n",
      "step 22500 , loss : 2.3058\n",
      "step 22500 , validation  accuracy 0.0976\n",
      "step 22500 , validation loss : 2.36955\n",
      "step 22600 , training  accuracy 0.133333\n",
      "step 22600 , loss : 2.30077\n",
      "step 22600 , validation  accuracy 0.1018\n",
      "step 22600 , validation loss : 2.31401\n",
      "step 22700 , training  accuracy 0.0333333\n",
      "step 22700 , loss : 2.30641\n",
      "step 22700 , validation  accuracy 0.0988\n",
      "step 22700 , validation loss : 2.39872\n",
      "step 22800 , training  accuracy 0.166667\n",
      "step 22800 , loss : 2.30053\n",
      "step 22800 , validation  accuracy 0.1024\n",
      "step 22800 , validation loss : 2.43201\n",
      "step 22900 , training  accuracy 0.1\n",
      "step 22900 , loss : 2.30469\n",
      "step 22900 , validation  accuracy 0.1024\n",
      "step 22900 , validation loss : 2.33235\n",
      "step 23000 , training  accuracy 0.1\n",
      "step 23000 , loss : 2.30269\n",
      "step 23000 , validation  accuracy 0.1018\n",
      "step 23000 , validation loss : 2.32343\n",
      "step 23100 , training  accuracy 0.133333\n",
      "step 23100 , loss : 2.30363\n",
      "step 23100 , validation  accuracy 0.1018\n",
      "step 23100 , validation loss : 2.3566\n",
      "step 23200 , training  accuracy 0.0333333\n",
      "step 23200 , loss : 2.30109\n",
      "step 23200 , validation  accuracy 0.1018\n",
      "step 23200 , validation loss : 2.35575\n",
      "step 23300 , training  accuracy 0.233333\n",
      "step 23300 , loss : 2.29811\n",
      "step 23300 , validation  accuracy 0.1024\n",
      "step 23300 , validation loss : 2.3564\n",
      "step 23400 , training  accuracy 0.133333\n",
      "step 23400 , loss : 2.30435\n",
      "step 23400 , validation  accuracy 0.101\n",
      "step 23400 , validation loss : 2.35638\n",
      "step 23500 , training  accuracy 0.0333333\n",
      "step 23500 , loss : 2.30488\n",
      "step 23500 , validation  accuracy 0.099\n",
      "step 23500 , validation loss : 2.35212\n",
      "step 23600 , training  accuracy 0.0666667\n",
      "step 23600 , loss : 2.30506\n",
      "step 23600 , validation  accuracy 0.101\n",
      "step 23600 , validation loss : 2.42734\n",
      "step 23700 , training  accuracy 0.0666667\n",
      "step 23700 , loss : 2.30441\n",
      "step 23700 , validation  accuracy 0.0974\n",
      "step 23700 , validation loss : 2.38316\n",
      "step 23800 , training  accuracy 0\n",
      "step 23800 , loss : 2.30319\n",
      "step 23800 , validation  accuracy 0.0984\n",
      "step 23800 , validation loss : 2.32926\n",
      "step 23900 , training  accuracy 0.1\n",
      "step 23900 , loss : 2.3028\n",
      "step 23900 , validation  accuracy 0.1024\n",
      "step 23900 , validation loss : 2.32758\n",
      "step 24000 , training  accuracy 0.1\n",
      "step 24000 , loss : 2.30306\n",
      "step 24000 , validation  accuracy 0.1006\n",
      "step 24000 , validation loss : 2.34132\n",
      "step 24100 , training  accuracy 0.0333333\n",
      "step 24100 , loss : 2.30667\n",
      "step 24100 , validation  accuracy 0.099\n",
      "step 24100 , validation loss : 2.33984\n",
      "step 24200 , training  accuracy 0.0666667\n",
      "step 24200 , loss : 2.30483\n",
      "step 24200 , validation  accuracy 0.0976\n",
      "step 24200 , validation loss : 2.3562\n",
      "step 24300 , training  accuracy 0.0666667\n",
      "step 24300 , loss : 2.30192\n",
      "step 24300 , validation  accuracy 0.1024\n",
      "step 24300 , validation loss : 2.32214\n",
      "step 24400 , training  accuracy 0.1\n",
      "step 24400 , loss : 2.30301\n",
      "step 24400 , validation  accuracy 0.1006\n",
      "step 24400 , validation loss : 2.36993\n",
      "step 24500 , training  accuracy 0.166667\n",
      "step 24500 , loss : 2.304\n",
      "step 24500 , validation  accuracy 0.1024\n",
      "step 24500 , validation loss : 2.34804\n",
      "step 24600 , training  accuracy 0.1\n",
      "step 24600 , loss : 2.30742\n",
      "step 24600 , validation  accuracy 0.1024\n",
      "step 24600 , validation loss : 2.36606\n",
      "step 24700 , training  accuracy 0.133333\n",
      "step 24700 , loss : 2.29668\n",
      "step 24700 , validation  accuracy 0.1024\n",
      "step 24700 , validation loss : 2.44505\n",
      "step 24800 , training  accuracy 0.133333\n",
      "step 24800 , loss : 2.3016\n",
      "step 24800 , validation  accuracy 0.101\n",
      "step 24800 , validation loss : 2.34084\n",
      "step 24900 , training  accuracy 0.0333333\n",
      "step 24900 , loss : 2.30467\n",
      "step 24900 , validation  accuracy 0.1024\n",
      "step 24900 , validation loss : 2.42415\n",
      "step 25000 , training  accuracy 0.133333\n",
      "step 25000 , loss : 2.30418\n",
      "step 25000 , validation  accuracy 0.1018\n",
      "step 25000 , validation loss : 2.37193\n",
      "step 25100 , training  accuracy 0.0333333\n",
      "step 25100 , loss : 2.30281\n",
      "step 25100 , validation  accuracy 0.0986\n",
      "step 25100 , validation loss : 2.32055\n",
      "step 25200 , training  accuracy 0.0666667\n",
      "step 25200 , loss : 2.304\n",
      "step 25200 , validation  accuracy 0.1024\n",
      "step 25200 , validation loss : 2.35586\n",
      "step 25300 , training  accuracy 0.133333\n",
      "step 25300 , loss : 2.30258\n",
      "step 25300 , validation  accuracy 0.1024\n",
      "step 25300 , validation loss : 2.34304\n",
      "step 25400 , training  accuracy 0.1\n",
      "step 25400 , loss : 2.30251\n",
      "step 25400 , validation  accuracy 0.1024\n",
      "step 25400 , validation loss : 2.36048\n",
      "step 25500 , training  accuracy 0.0666667\n",
      "step 25500 , loss : 2.30378\n",
      "step 25500 , validation  accuracy 0.0976\n",
      "step 25500 , validation loss : 2.39025\n",
      "step 25600 , training  accuracy 0.1\n",
      "step 25600 , loss : 2.30577\n",
      "step 25600 , validation  accuracy 0.0976\n",
      "step 25600 , validation loss : 2.39779\n",
      "step 25700 , training  accuracy 0.1\n",
      "step 25700 , loss : 2.3041\n",
      "step 25700 , validation  accuracy 0.0974\n",
      "step 25700 , validation loss : 2.33554\n",
      "step 25800 , training  accuracy 0.1\n",
      "step 25800 , loss : 2.30634\n",
      "step 25800 , validation  accuracy 0.1024\n",
      "step 25800 , validation loss : 2.37509\n",
      "step 25900 , training  accuracy 0.2\n",
      "step 25900 , loss : 2.29915\n",
      "step 25900 , validation  accuracy 0.1006\n",
      "step 25900 , validation loss : 2.33039\n",
      "step 26000 , training  accuracy 0.0666667\n",
      "step 26000 , loss : 2.3035\n",
      "step 26000 , validation  accuracy 0.1006\n",
      "step 26000 , validation loss : 2.3337\n",
      "step 26100 , training  accuracy 0.1\n",
      "step 26100 , loss : 2.30262\n",
      "step 26100 , validation  accuracy 0.1024\n",
      "step 26100 , validation loss : 2.31405\n",
      "step 26200 , training  accuracy 0.1\n",
      "step 26200 , loss : 2.30295\n",
      "step 26200 , validation  accuracy 0.099\n",
      "step 26200 , validation loss : 2.37476\n",
      "step 26300 , training  accuracy 0.133333\n",
      "step 26300 , loss : 2.30139\n",
      "step 26300 , validation  accuracy 0.1018\n",
      "step 26300 , validation loss : 2.35352\n",
      "step 26400 , training  accuracy 0.2\n",
      "step 26400 , loss : 2.3\n",
      "step 26400 , validation  accuracy 0.101\n",
      "step 26400 , validation loss : 2.32845\n",
      "step 26500 , training  accuracy 0.1\n",
      "step 26500 , loss : 2.30413\n",
      "step 26500 , validation  accuracy 0.0992\n",
      "step 26500 , validation loss : 2.35464\n",
      "step 26600 , training  accuracy 0.1\n",
      "step 26600 , loss : 2.30289\n",
      "step 26600 , validation  accuracy 0.101\n",
      "step 26600 , validation loss : 2.34758\n",
      "step 26700 , training  accuracy 0.1\n",
      "step 26700 , loss : 2.30076\n",
      "step 26700 , validation  accuracy 0.0992\n",
      "step 26700 , validation loss : 2.38333\n",
      "step 26800 , training  accuracy 0.0333333\n",
      "step 26800 , loss : 2.30581\n",
      "step 26800 , validation  accuracy 0.1006\n",
      "step 26800 , validation loss : 2.34078\n",
      "step 26900 , training  accuracy 0.0333333\n",
      "step 26900 , loss : 2.30118\n",
      "step 26900 , validation  accuracy 0.099\n",
      "step 26900 , validation loss : 2.35955\n",
      "step 27000 , training  accuracy 0.1\n",
      "step 27000 , loss : 2.30464\n",
      "step 27000 , validation  accuracy 0.1006\n",
      "step 27000 , validation loss : 2.39398\n",
      "step 27100 , training  accuracy 0.133333\n",
      "step 27100 , loss : 2.30305\n",
      "step 27100 , validation  accuracy 0.0976\n",
      "step 27100 , validation loss : 2.37312\n",
      "step 27200 , training  accuracy 0.0666667\n",
      "step 27200 , loss : 2.30325\n",
      "step 27200 , validation  accuracy 0.099\n",
      "step 27200 , validation loss : 2.32982\n",
      "step 27300 , training  accuracy 0.166667\n",
      "step 27300 , loss : 2.30166\n",
      "step 27300 , validation  accuracy 0.0992\n",
      "step 27300 , validation loss : 2.33235\n",
      "step 27400 , training  accuracy 0.166667\n",
      "step 27400 , loss : 2.30093\n",
      "step 27400 , validation  accuracy 0.099\n",
      "step 27400 , validation loss : 2.37061\n",
      "step 27500 , training  accuracy 0.1\n",
      "step 27500 , loss : 2.30481\n",
      "step 27500 , validation  accuracy 0.1006\n",
      "step 27500 , validation loss : 2.43264\n",
      "step 27600 , training  accuracy 0.0666667\n",
      "step 27600 , loss : 2.30518\n",
      "step 27600 , validation  accuracy 0.0986\n",
      "step 27600 , validation loss : 2.34683\n",
      "step 27700 , training  accuracy 0.2\n",
      "step 27700 , loss : 2.29998\n",
      "step 27700 , validation  accuracy 0.1024\n",
      "step 27700 , validation loss : 2.331\n",
      "step 27800 , training  accuracy 0.166667\n",
      "step 27800 , loss : 2.30286\n",
      "step 27800 , validation  accuracy 0.099\n",
      "step 27800 , validation loss : 2.32023\n",
      "step 27900 , training  accuracy 0.0666667\n",
      "step 27900 , loss : 2.30666\n",
      "step 27900 , validation  accuracy 0.0992\n",
      "step 27900 , validation loss : 2.3558\n",
      "step 28000 , training  accuracy 0.133333\n",
      "step 28000 , loss : 2.30442\n",
      "step 28000 , validation  accuracy 0.0992\n",
      "step 28000 , validation loss : 2.36609\n",
      "step 28100 , training  accuracy 0.0666667\n",
      "step 28100 , loss : 2.30636\n",
      "step 28100 , validation  accuracy 0.099\n",
      "step 28100 , validation loss : 2.35035\n",
      "step 28200 , training  accuracy 0.233333\n",
      "step 28200 , loss : 2.30156\n",
      "step 28200 , validation  accuracy 0.0988\n",
      "step 28200 , validation loss : 2.33962\n",
      "step 28300 , training  accuracy 0.0666667\n",
      "step 28300 , loss : 2.3014\n",
      "step 28300 , validation  accuracy 0.0978\n",
      "step 28300 , validation loss : 2.34183\n",
      "step 28400 , training  accuracy 0.133333\n",
      "step 28400 , loss : 2.3009\n",
      "step 28400 , validation  accuracy 0.1024\n",
      "step 28400 , validation loss : 2.44804\n",
      "step 28500 , training  accuracy 0.1\n",
      "step 28500 , loss : 2.30319\n",
      "step 28500 , validation  accuracy 0.1008\n",
      "step 28500 , validation loss : 2.32663\n",
      "step 28600 , training  accuracy 0.0333333\n",
      "step 28600 , loss : 2.30331\n",
      "step 28600 , validation  accuracy 0.1018\n",
      "step 28600 , validation loss : 2.35564\n",
      "step 28700 , training  accuracy 0.1\n",
      "step 28700 , loss : 2.30207\n",
      "step 28700 , validation  accuracy 0.0974\n",
      "step 28700 , validation loss : 2.34609\n",
      "step 28800 , training  accuracy 0.0666667\n",
      "step 28800 , loss : 2.30578\n",
      "step 28800 , validation  accuracy 0.0986\n",
      "step 28800 , validation loss : 2.33943\n",
      "step 28900 , training  accuracy 0.266667\n",
      "step 28900 , loss : 2.30218\n",
      "step 28900 , validation  accuracy 0.1024\n",
      "step 28900 , validation loss : 2.32426\n",
      "step 29000 , training  accuracy 0.1\n",
      "step 29000 , loss : 2.30371\n",
      "step 29000 , validation  accuracy 0.0976\n",
      "step 29000 , validation loss : 2.37481\n",
      "step 29100 , training  accuracy 0.0666667\n",
      "step 29100 , loss : 2.30579\n",
      "step 29100 , validation  accuracy 0.0978\n",
      "step 29100 , validation loss : 2.37714\n",
      "step 29200 , training  accuracy 0.1\n",
      "step 29200 , loss : 2.30207\n",
      "step 29200 , validation  accuracy 0.1024\n",
      "step 29200 , validation loss : 2.35209\n",
      "step 29300 , training  accuracy 0.166667\n",
      "step 29300 , loss : 2.30168\n",
      "step 29300 , validation  accuracy 0.0986\n",
      "step 29300 , validation loss : 2.32748\n",
      "step 29400 , training  accuracy 0.1\n",
      "step 29400 , loss : 2.3044\n",
      "step 29400 , validation  accuracy 0.099\n",
      "step 29400 , validation loss : 2.34819\n",
      "step 29500 , training  accuracy 0.0333333\n",
      "step 29500 , loss : 2.30313\n",
      "step 29500 , validation  accuracy 0.0986\n",
      "step 29500 , validation loss : 2.3482\n",
      "step 29600 , training  accuracy 0.0666667\n",
      "step 29600 , loss : 2.30336\n",
      "step 29600 , validation  accuracy 0.101\n",
      "step 29600 , validation loss : 2.33658\n",
      "step 29700 , training  accuracy 0.133333\n",
      "step 29700 , loss : 2.30454\n",
      "step 29700 , validation  accuracy 0.0974\n",
      "step 29700 , validation loss : 2.34258\n",
      "step 29800 , training  accuracy 0.133333\n",
      "step 29800 , loss : 2.30193\n",
      "step 29800 , validation  accuracy 0.0992\n",
      "step 29800 , validation loss : 2.34403\n",
      "step 29900 , training  accuracy 0.1\n",
      "step 29900 , loss : 2.29885\n",
      "step 29900 , validation  accuracy 0.101\n",
      "step 29900 , validation loss : 2.3719\n",
      "step 30000 , training  accuracy 0.133333\n",
      "step 30000 , loss : 2.30417\n",
      "step 30000 , validation  accuracy 0.0992\n",
      "step 30000 , validation loss : 2.34058\n",
      "step 30100 , training  accuracy 0.0333333\n",
      "step 30100 , loss : 2.30372\n",
      "step 30100 , validation  accuracy 0.0986\n",
      "step 30100 , validation loss : 2.34048\n",
      "step 30200 , training  accuracy 0.133333\n",
      "step 30200 , loss : 2.3041\n",
      "step 30200 , validation  accuracy 0.0986\n",
      "step 30200 , validation loss : 2.38524\n",
      "step 30300 , training  accuracy 0.2\n",
      "step 30300 , loss : 2.30035\n",
      "step 30300 , validation  accuracy 0.1024\n",
      "step 30300 , validation loss : 2.33526\n",
      "step 30400 , training  accuracy 0.133333\n",
      "step 30400 , loss : 2.30191\n",
      "step 30400 , validation  accuracy 0.1024\n",
      "step 30400 , validation loss : 2.39653\n",
      "step 30500 , training  accuracy 0.0333333\n",
      "step 30500 , loss : 2.3027\n",
      "step 30500 , validation  accuracy 0.1024\n",
      "step 30500 , validation loss : 2.33604\n",
      "step 30600 , training  accuracy 0.166667\n",
      "step 30600 , loss : 2.30314\n",
      "step 30600 , validation  accuracy 0.0982\n",
      "step 30600 , validation loss : 2.32481\n",
      "step 30700 , training  accuracy 0.1\n",
      "step 30700 , loss : 2.30497\n",
      "step 30700 , validation  accuracy 0.1024\n",
      "step 30700 , validation loss : 2.33081\n",
      "step 30800 , training  accuracy 0.1\n",
      "step 30800 , loss : 2.3038\n",
      "step 30800 , validation  accuracy 0.1024\n",
      "step 30800 , validation loss : 2.34393\n",
      "step 30900 , training  accuracy 0.1\n",
      "step 30900 , loss : 2.30151\n",
      "step 30900 , validation  accuracy 0.1022\n",
      "step 30900 , validation loss : 2.39659\n",
      "step 31000 , training  accuracy 0.0333333\n",
      "step 31000 , loss : 2.30553\n",
      "step 31000 , validation  accuracy 0.0992\n",
      "step 31000 , validation loss : 2.33821\n",
      "step 31100 , training  accuracy 0.0333333\n",
      "step 31100 , loss : 2.30553\n",
      "step 31100 , validation  accuracy 0.1022\n",
      "step 31100 , validation loss : 2.35771\n",
      "step 31200 , training  accuracy 0.0666667\n",
      "step 31200 , loss : 2.30434\n",
      "step 31200 , validation  accuracy 0.1024\n",
      "step 31200 , validation loss : 2.35385\n",
      "step 31300 , training  accuracy 0.1\n",
      "step 31300 , loss : 2.305\n",
      "step 31300 , validation  accuracy 0.1018\n",
      "step 31300 , validation loss : 2.3294\n",
      "step 31400 , training  accuracy 0.1\n",
      "step 31400 , loss : 2.30381\n",
      "step 31400 , validation  accuracy 0.1024\n",
      "step 31400 , validation loss : 2.34079\n",
      "step 31500 , training  accuracy 0.166667\n",
      "step 31500 , loss : 2.30177\n",
      "step 31500 , validation  accuracy 0.1024\n",
      "step 31500 , validation loss : 2.33947\n",
      "step 31600 , training  accuracy 0.0333333\n",
      "step 31600 , loss : 2.30381\n",
      "step 31600 , validation  accuracy 0.0986\n",
      "step 31600 , validation loss : 2.34579\n",
      "step 31700 , training  accuracy 0.0666667\n",
      "step 31700 , loss : 2.30471\n",
      "step 31700 , validation  accuracy 0.099\n",
      "step 31700 , validation loss : 2.35472\n",
      "step 31800 , training  accuracy 0.1\n",
      "step 31800 , loss : 2.30352\n",
      "step 31800 , validation  accuracy 0.1024\n",
      "step 31800 , validation loss : 2.34715\n",
      "step 31900 , training  accuracy 0.233333\n",
      "step 31900 , loss : 2.29817\n",
      "step 31900 , validation  accuracy 0.1006\n",
      "step 31900 , validation loss : 2.3622\n",
      "step 32000 , training  accuracy 0.1\n",
      "step 32000 , loss : 2.30077\n",
      "step 32000 , validation  accuracy 0.0992\n",
      "step 32000 , validation loss : 2.38274\n",
      "step 32100 , training  accuracy 0.1\n",
      "step 32100 , loss : 2.30294\n",
      "step 32100 , validation  accuracy 0.1018\n",
      "step 32100 , validation loss : 2.32611\n",
      "step 32200 , training  accuracy 0.0333333\n",
      "step 32200 , loss : 2.30684\n",
      "step 32200 , validation  accuracy 0.0992\n",
      "step 32200 , validation loss : 2.3697\n",
      "step 32300 , training  accuracy 0.1\n",
      "step 32300 , loss : 2.30163\n",
      "step 32300 , validation  accuracy 0.0986\n",
      "step 32300 , validation loss : 2.36309\n",
      "step 32400 , training  accuracy 0.166667\n",
      "step 32400 , loss : 2.29895\n",
      "step 32400 , validation  accuracy 0.1024\n",
      "step 32400 , validation loss : 2.35465\n",
      "step 32500 , training  accuracy 0.133333\n",
      "step 32500 , loss : 2.30128\n",
      "step 32500 , validation  accuracy 0.0976\n",
      "step 32500 , validation loss : 2.33875\n",
      "step 32600 , training  accuracy 0.1\n",
      "step 32600 , loss : 2.30363\n",
      "step 32600 , validation  accuracy 0.1022\n",
      "step 32600 , validation loss : 2.3333\n",
      "step 32700 , training  accuracy 0.166667\n",
      "step 32700 , loss : 2.30215\n",
      "step 32700 , validation  accuracy 0.0992\n",
      "step 32700 , validation loss : 2.3585\n",
      "step 32800 , training  accuracy 0\n",
      "step 32800 , loss : 2.30469\n",
      "step 32800 , validation  accuracy 0.0976\n",
      "step 32800 , validation loss : 2.33745\n",
      "step 32900 , training  accuracy 0.0333333\n",
      "step 32900 , loss : 2.30421\n",
      "step 32900 , validation  accuracy 0.0992\n",
      "step 32900 , validation loss : 2.37658\n",
      "step 33000 , training  accuracy 0.133333\n",
      "step 33000 , loss : 2.30122\n",
      "step 33000 , validation  accuracy 0.101\n",
      "step 33000 , validation loss : 2.36562\n",
      "step 33100 , training  accuracy 0\n",
      "step 33100 , loss : 2.30496\n",
      "step 33100 , validation  accuracy 0.0974\n",
      "step 33100 , validation loss : 2.33807\n",
      "step 33200 , training  accuracy 0.1\n",
      "step 33200 , loss : 2.30454\n",
      "step 33200 , validation  accuracy 0.0988\n",
      "step 33200 , validation loss : 2.32437\n",
      "step 33300 , training  accuracy 0.0666667\n",
      "step 33300 , loss : 2.30459\n",
      "step 33300 , validation  accuracy 0.0986\n",
      "step 33300 , validation loss : 2.35058\n",
      "step 33400 , training  accuracy 0.1\n",
      "step 33400 , loss : 2.3008\n",
      "step 33400 , validation  accuracy 0.1006\n",
      "step 33400 , validation loss : 2.3646\n",
      "step 33500 , training  accuracy 0.0333333\n",
      "step 33500 , loss : 2.30343\n",
      "step 33500 , validation  accuracy 0.0974\n",
      "step 33500 , validation loss : 2.34218\n",
      "step 33600 , training  accuracy 0.166667\n",
      "step 33600 , loss : 2.30178\n",
      "step 33600 , validation  accuracy 0.0976\n",
      "step 33600 , validation loss : 2.31683\n",
      "step 33700 , training  accuracy 0.133333\n",
      "step 33700 , loss : 2.30242\n",
      "step 33700 , validation  accuracy 0.1024\n",
      "step 33700 , validation loss : 2.3914\n",
      "step 33800 , training  accuracy 0.166667\n",
      "step 33800 , loss : 2.30119\n",
      "step 33800 , validation  accuracy 0.0976\n",
      "step 33800 , validation loss : 2.33224\n",
      "step 33900 , training  accuracy 0.1\n",
      "step 33900 , loss : 2.3038\n",
      "step 33900 , validation  accuracy 0.1024\n",
      "step 33900 , validation loss : 2.35659\n",
      "step 34000 , training  accuracy 0.1\n",
      "step 34000 , loss : 2.30253\n",
      "step 34000 , validation  accuracy 0.0976\n",
      "step 34000 , validation loss : 2.33948\n",
      "step 34100 , training  accuracy 0.2\n",
      "step 34100 , loss : 2.30374\n",
      "step 34100 , validation  accuracy 0.0974\n",
      "step 34100 , validation loss : 2.32987\n",
      "step 34200 , training  accuracy 0.0666667\n",
      "step 34200 , loss : 2.30328\n",
      "step 34200 , validation  accuracy 0.0974\n",
      "step 34200 , validation loss : 2.33288\n",
      "step 34300 , training  accuracy 0.133333\n",
      "step 34300 , loss : 2.30182\n",
      "step 34300 , validation  accuracy 0.0992\n",
      "step 34300 , validation loss : 2.35583\n",
      "step 34400 , training  accuracy 0.1\n",
      "step 34400 , loss : 2.30208\n",
      "step 34400 , validation  accuracy 0.1024\n",
      "step 34400 , validation loss : 2.33158\n",
      "step 34500 , training  accuracy 0.133333\n",
      "step 34500 , loss : 2.30495\n",
      "step 34500 , validation  accuracy 0.1024\n",
      "step 34500 , validation loss : 2.40275\n",
      "step 34600 , training  accuracy 0.233333\n",
      "step 34600 , loss : 2.30149\n",
      "step 34600 , validation  accuracy 0.101\n",
      "step 34600 , validation loss : 2.34052\n",
      "step 34700 , training  accuracy 0.2\n",
      "step 34700 , loss : 2.30091\n",
      "step 34700 , validation  accuracy 0.1024\n",
      "step 34700 , validation loss : 2.32502\n",
      "step 34800 , training  accuracy 0.166667\n",
      "step 34800 , loss : 2.29927\n",
      "step 34800 , validation  accuracy 0.1018\n",
      "step 34800 , validation loss : 2.36848\n",
      "step 34900 , training  accuracy 0.2\n",
      "step 34900 , loss : 2.30136\n",
      "step 34900 , validation  accuracy 0.0976\n",
      "step 34900 , validation loss : 2.31417\n",
      "step 35000 , training  accuracy 0.166667\n",
      "step 35000 , loss : 2.30157\n",
      "step 35000 , validation  accuracy 0.1018\n",
      "step 35000 , validation loss : 2.34337\n",
      "step 35100 , training  accuracy 0.133333\n",
      "step 35100 , loss : 2.30623\n",
      "step 35100 , validation  accuracy 0.0976\n",
      "step 35100 , validation loss : 2.39275\n",
      "step 35200 , training  accuracy 0.0666667\n",
      "step 35200 , loss : 2.30245\n",
      "step 35200 , validation  accuracy 0.0934\n",
      "step 35200 , validation loss : 2.42225\n",
      "step 35300 , training  accuracy 0.0666667\n",
      "step 35300 , loss : 2.30582\n",
      "step 35300 , validation  accuracy 0.0976\n",
      "step 35300 , validation loss : 2.37431\n",
      "step 35400 , training  accuracy 0.166667\n",
      "step 35400 , loss : 2.30994\n",
      "step 35400 , validation  accuracy 0.101\n",
      "step 35400 , validation loss : 3.32626\n",
      "step 35500 , training  accuracy 0.0333333\n",
      "step 35500 , loss : 2.30137\n",
      "step 35500 , validation  accuracy 0.0974\n",
      "step 35500 , validation loss : 2.33528\n",
      "step 35600 , training  accuracy 0.1\n",
      "step 35600 , loss : 2.30154\n",
      "step 35600 , validation  accuracy 0.101\n",
      "step 35600 , validation loss : 2.35902\n",
      "step 35700 , training  accuracy 0.166667\n",
      "step 35700 , loss : 2.30061\n",
      "step 35700 , validation  accuracy 0.0976\n",
      "step 35700 , validation loss : 2.32496\n",
      "step 35800 , training  accuracy 0.1\n",
      "step 35800 , loss : 2.3032\n",
      "step 35800 , validation  accuracy 0.099\n",
      "step 35800 , validation loss : 2.31738\n",
      "step 35900 , training  accuracy 0.0333333\n",
      "step 35900 , loss : 2.3014\n",
      "step 35900 , validation  accuracy 0.0974\n",
      "step 35900 , validation loss : 2.32615\n",
      "step 36000 , training  accuracy 0.166667\n",
      "step 36000 , loss : 2.29414\n",
      "step 36000 , validation  accuracy 0.1602\n",
      "step 36000 , validation loss : 3.97142\n",
      "step 36100 , training  accuracy 0.0333333\n",
      "step 36100 , loss : 2.30379\n",
      "step 36100 , validation  accuracy 0.0994\n",
      "step 36100 , validation loss : 2.50907\n",
      "step 36200 , training  accuracy 0.1\n",
      "step 36200 , loss : 2.302\n",
      "step 36200 , validation  accuracy 0.102\n",
      "step 36200 , validation loss : 2.34135\n",
      "step 36300 , training  accuracy 0.233333\n",
      "step 36300 , loss : 2.30003\n",
      "step 36300 , validation  accuracy 0.1024\n",
      "step 36300 , validation loss : 2.35542\n",
      "step 36400 , training  accuracy 0.133333\n",
      "step 36400 , loss : 2.30336\n",
      "step 36400 , validation  accuracy 0.1024\n",
      "step 36400 , validation loss : 2.33836\n",
      "step 36500 , training  accuracy 0.1\n",
      "step 36500 , loss : 2.30714\n",
      "step 36500 , validation  accuracy 0.1366\n",
      "step 36500 , validation loss : 2.64557\n",
      "step 36600 , training  accuracy 0.233333\n",
      "step 36600 , loss : 2.29352\n",
      "step 36600 , validation  accuracy 0.132\n",
      "step 36600 , validation loss : 2.62312\n",
      "step 36700 , training  accuracy 0.166667\n",
      "step 36700 , loss : 2.27208\n",
      "step 36700 , validation  accuracy 0.1816\n",
      "step 36700 , validation loss : 3.26507\n",
      "step 36800 , training  accuracy 0.1\n",
      "step 36800 , loss : 2.28812\n",
      "step 36800 , validation  accuracy 0.1396\n",
      "step 36800 , validation loss : 2.75755\n",
      "step 36900 , training  accuracy 0.166667\n",
      "step 36900 , loss : 2.27537\n",
      "step 36900 , validation  accuracy 0.1826\n",
      "step 36900 , validation loss : 3.5715\n",
      "step 37000 , training  accuracy 0.133333\n",
      "step 37000 , loss : 2.27864\n",
      "step 37000 , validation  accuracy 0.2038\n",
      "step 37000 , validation loss : 4.42131\n",
      "step 37100 , training  accuracy 0.1\n",
      "step 37100 , loss : 2.29699\n",
      "step 37100 , validation  accuracy 0.2128\n",
      "step 37100 , validation loss : 5.41571\n",
      "step 37200 , training  accuracy 0.166667\n",
      "step 37200 , loss : 2.26875\n",
      "step 37200 , validation  accuracy 0.1872\n",
      "step 37200 , validation loss : 4.53064\n",
      "step 37300 , training  accuracy 0.3\n",
      "step 37300 , loss : 2.26645\n",
      "step 37300 , validation  accuracy 0.207\n",
      "step 37300 , validation loss : 4.95768\n",
      "step 37400 , training  accuracy 0.133333\n",
      "step 37400 , loss : 2.26539\n",
      "step 37400 , validation  accuracy 0.2276\n",
      "step 37400 , validation loss : 5.33649\n",
      "step 37500 , training  accuracy 0.3\n",
      "step 37500 , loss : 2.23777\n",
      "step 37500 , validation  accuracy 0.2286\n",
      "step 37500 , validation loss : 5.59455\n",
      "step 37600 , training  accuracy 0.2\n",
      "step 37600 , loss : 2.26664\n",
      "step 37600 , validation  accuracy 0.2508\n",
      "step 37600 , validation loss : 4.98686\n",
      "step 37700 , training  accuracy 0.266667\n",
      "step 37700 , loss : 2.24286\n",
      "step 37700 , validation  accuracy 0.2502\n",
      "step 37700 , validation loss : 5.21097\n",
      "step 37800 , training  accuracy 0.233333\n",
      "step 37800 , loss : 2.26198\n",
      "step 37800 , validation  accuracy 0.232\n",
      "step 37800 , validation loss : 6.27597\n",
      "step 37900 , training  accuracy 0.266667\n",
      "step 37900 , loss : 2.26026\n",
      "step 37900 , validation  accuracy 0.2166\n",
      "step 37900 , validation loss : 5.88418\n",
      "step 38000 , training  accuracy 0.333333\n",
      "step 38000 , loss : 2.22879\n",
      "step 38000 , validation  accuracy 0.2272\n",
      "step 38000 , validation loss : 6.0126\n",
      "step 38100 , training  accuracy 0.2\n",
      "step 38100 , loss : 2.26659\n",
      "step 38100 , validation  accuracy 0.23\n",
      "step 38100 , validation loss : 4.89954\n",
      "step 38200 , training  accuracy 0.3\n",
      "step 38200 , loss : 2.23726\n",
      "step 38200 , validation  accuracy 0.2482\n",
      "step 38200 , validation loss : 6.73896\n",
      "step 38300 , training  accuracy 0.2\n",
      "step 38300 , loss : 2.26131\n",
      "step 38300 , validation  accuracy 0.2448\n",
      "step 38300 , validation loss : 6.66261\n",
      "step 38400 , training  accuracy 0.4\n",
      "step 38400 , loss : 2.22261\n",
      "step 38400 , validation  accuracy 0.2512\n",
      "step 38400 , validation loss : 6.6483\n",
      "step 38500 , training  accuracy 0.2\n",
      "step 38500 , loss : 2.26076\n",
      "step 38500 , validation  accuracy 0.2414\n",
      "step 38500 , validation loss : 7.17466\n",
      "step 38600 , training  accuracy 0.233333\n",
      "step 38600 , loss : 2.22324\n",
      "step 38600 , validation  accuracy 0.2428\n",
      "step 38600 , validation loss : 6.51248\n",
      "step 38700 , training  accuracy 0.2\n",
      "step 38700 , loss : 2.23127\n",
      "step 38700 , validation  accuracy 0.2472\n",
      "step 38700 , validation loss : 6.9164\n",
      "step 38800 , training  accuracy 0.133333\n",
      "step 38800 , loss : 2.27363\n",
      "step 38800 , validation  accuracy 0.2438\n",
      "step 38800 , validation loss : 7.27362\n",
      "step 38900 , training  accuracy 0.3\n",
      "step 38900 , loss : 2.2513\n",
      "step 38900 , validation  accuracy 0.2468\n",
      "step 38900 , validation loss : 6.67939\n",
      "step 39000 , training  accuracy 0.2\n",
      "step 39000 , loss : 2.26503\n",
      "step 39000 , validation  accuracy 0.249\n",
      "step 39000 , validation loss : 6.20516\n",
      "step 39100 , training  accuracy 0.3\n",
      "step 39100 , loss : 2.21726\n",
      "step 39100 , validation  accuracy 0.2558\n",
      "step 39100 , validation loss : 7.23713\n",
      "step 39200 , training  accuracy 0.2\n",
      "step 39200 , loss : 2.25737\n",
      "step 39200 , validation  accuracy 0.2608\n",
      "step 39200 , validation loss : 6.75112\n",
      "step 39300 , training  accuracy 0.166667\n",
      "step 39300 , loss : 2.25588\n",
      "step 39300 , validation  accuracy 0.26\n",
      "step 39300 , validation loss : 6.36422\n",
      "step 39400 , training  accuracy 0.266667\n",
      "step 39400 , loss : 2.24823\n",
      "step 39400 , validation  accuracy 0.2718\n",
      "step 39400 , validation loss : 7.00873\n",
      "step 39500 , training  accuracy 0.2\n",
      "step 39500 , loss : 2.24048\n",
      "step 39500 , validation  accuracy 0.2636\n",
      "step 39500 , validation loss : 6.96546\n",
      "step 39600 , training  accuracy 0.166667\n",
      "step 39600 , loss : 2.25952\n",
      "step 39600 , validation  accuracy 0.251\n",
      "step 39600 , validation loss : 6.89594\n",
      "step 39700 , training  accuracy 0.433333\n",
      "step 39700 , loss : 2.23373\n",
      "step 39700 , validation  accuracy 0.2644\n",
      "step 39700 , validation loss : 7.35438\n",
      "step 39800 , training  accuracy 0.3\n",
      "step 39800 , loss : 2.22244\n",
      "step 39800 , validation  accuracy 0.2488\n",
      "step 39800 , validation loss : 7.02876\n",
      "step 39900 , training  accuracy 0.3\n",
      "step 39900 , loss : 2.24761\n",
      "step 39900 , validation  accuracy 0.2452\n",
      "step 39900 , validation loss : 7.47777\n",
      "step 40000 , training  accuracy 0.433333\n",
      "step 40000 , loss : 2.19362\n",
      "step 40000 , validation  accuracy 0.2612\n",
      "step 40000 , validation loss : 6.59423\n",
      "step 40100 , training  accuracy 0.166667\n",
      "step 40100 , loss : 2.25444\n",
      "step 40100 , validation  accuracy 0.2566\n",
      "step 40100 , validation loss : 7.48257\n",
      "step 40200 , training  accuracy 0.4\n",
      "step 40200 , loss : 2.18784\n",
      "step 40200 , validation  accuracy 0.278\n",
      "step 40200 , validation loss : 8.4413\n",
      "step 40300 , training  accuracy 0.333333\n",
      "step 40300 , loss : 2.19406\n",
      "step 40300 , validation  accuracy 0.2718\n",
      "step 40300 , validation loss : 7.08744\n",
      "step 40400 , training  accuracy 0.4\n",
      "step 40400 , loss : 2.21199\n",
      "step 40400 , validation  accuracy 0.2652\n",
      "step 40400 , validation loss : 6.49241\n",
      "step 40500 , training  accuracy 0.366667\n",
      "step 40500 , loss : 2.21819\n",
      "step 40500 , validation  accuracy 0.267\n",
      "step 40500 , validation loss : 8.54665\n",
      "step 40600 , training  accuracy 0.5\n",
      "step 40600 , loss : 2.1961\n",
      "step 40600 , validation  accuracy 0.2718\n",
      "step 40600 , validation loss : 7.28356\n",
      "step 40700 , training  accuracy 0.4\n",
      "step 40700 , loss : 2.22937\n",
      "step 40700 , validation  accuracy 0.2722\n",
      "step 40700 , validation loss : 7.09203\n",
      "step 40800 , training  accuracy 0.366667\n",
      "step 40800 , loss : 2.19503\n",
      "step 40800 , validation  accuracy 0.264\n",
      "step 40800 , validation loss : 7.53437\n",
      "step 40900 , training  accuracy 0.233333\n",
      "step 40900 , loss : 2.22034\n",
      "step 40900 , validation  accuracy 0.2688\n",
      "step 40900 , validation loss : 8.808\n",
      "step 41000 , training  accuracy 0.233333\n",
      "step 41000 , loss : 2.20923\n",
      "step 41000 , validation  accuracy 0.2704\n",
      "step 41000 , validation loss : 7.8406\n",
      "step 41100 , training  accuracy 0.266667\n",
      "step 41100 , loss : 2.24674\n",
      "step 41100 , validation  accuracy 0.2548\n",
      "step 41100 , validation loss : 6.92736\n",
      "step 41200 , training  accuracy 0.366667\n",
      "step 41200 , loss : 2.17549\n",
      "step 41200 , validation  accuracy 0.2596\n",
      "step 41200 , validation loss : 8.50681\n",
      "step 41300 , training  accuracy 0.233333\n",
      "step 41300 , loss : 2.24126\n",
      "step 41300 , validation  accuracy 0.2708\n",
      "step 41300 , validation loss : 7.10821\n",
      "step 41400 , training  accuracy 0.2\n",
      "step 41400 , loss : 2.26318\n",
      "step 41400 , validation  accuracy 0.261\n",
      "step 41400 , validation loss : 7.55504\n",
      "step 41500 , training  accuracy 0.333333\n",
      "step 41500 , loss : 2.20028\n",
      "step 41500 , validation  accuracy 0.2774\n",
      "step 41500 , validation loss : 8.18275\n",
      "step 41600 , training  accuracy 0.266667\n",
      "step 41600 , loss : 2.23804\n",
      "step 41600 , validation  accuracy 0.263\n",
      "step 41600 , validation loss : 7.99106\n",
      "step 41700 , training  accuracy 0.333333\n",
      "step 41700 , loss : 2.24268\n",
      "step 41700 , validation  accuracy 0.266\n",
      "step 41700 , validation loss : 8.04677\n",
      "step 41800 , training  accuracy 0.3\n",
      "step 41800 , loss : 2.20798\n",
      "step 41800 , validation  accuracy 0.2738\n",
      "step 41800 , validation loss : 7.60293\n",
      "step 41900 , training  accuracy 0.366667\n",
      "step 41900 , loss : 2.22217\n",
      "step 41900 , validation  accuracy 0.2674\n",
      "step 41900 , validation loss : 8.74427\n",
      "step 42000 , training  accuracy 0.266667\n",
      "step 42000 , loss : 2.23365\n",
      "step 42000 , validation  accuracy 0.2808\n",
      "step 42000 , validation loss : 8.1061\n",
      "step 42100 , training  accuracy 0.333333\n",
      "step 42100 , loss : 2.23285\n",
      "step 42100 , validation  accuracy 0.2702\n",
      "step 42100 , validation loss : 10.0122\n",
      "step 42200 , training  accuracy 0.2\n",
      "step 42200 , loss : 2.23497\n",
      "step 42200 , validation  accuracy 0.2784\n",
      "step 42200 , validation loss : 8.23432\n",
      "step 42300 , training  accuracy 0.3\n",
      "step 42300 , loss : 2.21717\n",
      "step 42300 , validation  accuracy 0.2746\n",
      "step 42300 , validation loss : 7.83668\n",
      "step 42400 , training  accuracy 0.4\n",
      "step 42400 , loss : 2.22268\n",
      "step 42400 , validation  accuracy 0.2774\n",
      "step 42400 , validation loss : 8.31349\n",
      "step 42500 , training  accuracy 0.3\n",
      "step 42500 , loss : 2.21579\n",
      "step 42500 , validation  accuracy 0.273\n",
      "step 42500 , validation loss : 8.15237\n",
      "step 42600 , training  accuracy 0.266667\n",
      "step 42600 , loss : 2.23368\n",
      "step 42600 , validation  accuracy 0.2652\n",
      "step 42600 , validation loss : 6.74631\n",
      "step 42700 , training  accuracy 0.4\n",
      "step 42700 , loss : 2.21847\n",
      "step 42700 , validation  accuracy 0.2934\n",
      "step 42700 , validation loss : 8.02846\n",
      "step 42800 , training  accuracy 0.3\n",
      "step 42800 , loss : 2.24435\n",
      "step 42800 , validation  accuracy 0.2852\n",
      "step 42800 , validation loss : 8.30293\n",
      "step 42900 , training  accuracy 0.466667\n",
      "step 42900 , loss : 2.19603\n",
      "step 42900 , validation  accuracy 0.2696\n",
      "step 42900 , validation loss : 8.07083\n",
      "step 43000 , training  accuracy 0.2\n",
      "step 43000 , loss : 2.23999\n",
      "step 43000 , validation  accuracy 0.2744\n",
      "step 43000 , validation loss : 9.06441\n",
      "step 43100 , training  accuracy 0.366667\n",
      "step 43100 , loss : 2.21992\n",
      "step 43100 , validation  accuracy 0.2806\n",
      "step 43100 , validation loss : 8.33367\n",
      "step 43200 , training  accuracy 0.2\n",
      "step 43200 , loss : 2.2233\n",
      "step 43200 , validation  accuracy 0.2982\n",
      "step 43200 , validation loss : 9.35518\n",
      "step 43300 , training  accuracy 0.3\n",
      "step 43300 , loss : 2.22012\n",
      "step 43300 , validation  accuracy 0.273\n",
      "step 43300 , validation loss : 7.60907\n",
      "step 43400 , training  accuracy 0.3\n",
      "step 43400 , loss : 2.20658\n",
      "step 43400 , validation  accuracy 0.2926\n",
      "step 43400 , validation loss : 8.22097\n",
      "step 43500 , training  accuracy 0.366667\n",
      "step 43500 , loss : 2.18087\n",
      "step 43500 , validation  accuracy 0.2858\n",
      "step 43500 , validation loss : 8.61089\n",
      "step 43600 , training  accuracy 0.233333\n",
      "step 43600 , loss : 2.21034\n",
      "step 43600 , validation  accuracy 0.272\n",
      "step 43600 , validation loss : 8.22377\n",
      "step 43700 , training  accuracy 0.466667\n",
      "step 43700 , loss : 2.17155\n",
      "step 43700 , validation  accuracy 0.284\n",
      "step 43700 , validation loss : 8.6995\n",
      "step 43800 , training  accuracy 0.366667\n",
      "step 43800 , loss : 2.20091\n",
      "step 43800 , validation  accuracy 0.2934\n",
      "step 43800 , validation loss : 8.15578\n",
      "step 43900 , training  accuracy 0.4\n",
      "step 43900 , loss : 2.22251\n",
      "step 43900 , validation  accuracy 0.2622\n",
      "step 43900 , validation loss : 7.52632\n",
      "step 44000 , training  accuracy 0.333333\n",
      "step 44000 , loss : 2.21283\n",
      "step 44000 , validation  accuracy 0.293\n",
      "step 44000 , validation loss : 9.33227\n",
      "step 44100 , training  accuracy 0.366667\n",
      "step 44100 , loss : 2.20734\n",
      "step 44100 , validation  accuracy 0.2644\n",
      "step 44100 , validation loss : 7.87916\n",
      "step 44200 , training  accuracy 0.433333\n",
      "step 44200 , loss : 2.16986\n",
      "step 44200 , validation  accuracy 0.2732\n",
      "step 44200 , validation loss : 8.78905\n",
      "step 44300 , training  accuracy 0.333333\n",
      "step 44300 , loss : 2.20713\n",
      "step 44300 , validation  accuracy 0.2916\n",
      "step 44300 , validation loss : 9.02105\n",
      "step 44400 , training  accuracy 0.466667\n",
      "step 44400 , loss : 2.17336\n",
      "step 44400 , validation  accuracy 0.2756\n",
      "step 44400 , validation loss : 7.98989\n",
      "step 44500 , training  accuracy 0.333333\n",
      "step 44500 , loss : 2.20241\n",
      "step 44500 , validation  accuracy 0.2986\n",
      "step 44500 , validation loss : 9.85243\n",
      "step 44600 , training  accuracy 0.333333\n",
      "step 44600 , loss : 2.22551\n",
      "step 44600 , validation  accuracy 0.2852\n",
      "step 44600 , validation loss : 9.03005\n",
      "step 44700 , training  accuracy 0.4\n",
      "step 44700 , loss : 2.18283\n",
      "step 44700 , validation  accuracy 0.2982\n",
      "step 44700 , validation loss : 9.43821\n",
      "step 44800 , training  accuracy 0.266667\n",
      "step 44800 , loss : 2.24082\n",
      "step 44800 , validation  accuracy 0.2856\n",
      "step 44800 , validation loss : 8.46181\n",
      "step 44900 , training  accuracy 0.333333\n",
      "step 44900 , loss : 2.24382\n",
      "step 44900 , validation  accuracy 0.282\n",
      "step 44900 , validation loss : 9.84624\n",
      "step 45000 , training  accuracy 0.366667\n",
      "step 45000 , loss : 2.19532\n",
      "step 45000 , validation  accuracy 0.2866\n",
      "step 45000 , validation loss : 9.61045\n",
      "step 45100 , training  accuracy 0.5\n",
      "step 45100 , loss : 2.15272\n",
      "step 45100 , validation  accuracy 0.2938\n",
      "step 45100 , validation loss : 9.27165\n",
      "step 45200 , training  accuracy 0.533333\n",
      "step 45200 , loss : 2.16026\n",
      "step 45200 , validation  accuracy 0.3004\n",
      "step 45200 , validation loss : 9.42\n",
      "step 45300 , training  accuracy 0.266667\n",
      "step 45300 , loss : 2.27442\n",
      "step 45300 , validation  accuracy 0.2908\n",
      "step 45300 , validation loss : 9.28838\n",
      "step 45400 , training  accuracy 0.533333\n",
      "step 45400 , loss : 2.14895\n",
      "step 45400 , validation  accuracy 0.2918\n",
      "step 45400 , validation loss : 9.4432\n",
      "step 45500 , training  accuracy 0.133333\n",
      "step 45500 , loss : 2.24448\n",
      "step 45500 , validation  accuracy 0.3012\n",
      "step 45500 , validation loss : 9.11957\n",
      "step 45600 , training  accuracy 0.266667\n",
      "step 45600 , loss : 2.21568\n",
      "step 45600 , validation  accuracy 0.268\n",
      "step 45600 , validation loss : 7.32199\n",
      "step 45700 , training  accuracy 0.3\n",
      "step 45700 , loss : 2.18447\n",
      "step 45700 , validation  accuracy 0.3006\n",
      "step 45700 , validation loss : 8.72279\n",
      "step 45800 , training  accuracy 0.233333\n",
      "step 45800 , loss : 2.2425\n",
      "step 45800 , validation  accuracy 0.2958\n",
      "step 45800 , validation loss : 10.4928\n",
      "step 45900 , training  accuracy 0.3\n",
      "step 45900 , loss : 2.23761\n",
      "step 45900 , validation  accuracy 0.3016\n",
      "step 45900 , validation loss : 9.37078\n",
      "step 46000 , training  accuracy 0.2\n",
      "step 46000 , loss : 2.25567\n",
      "step 46000 , validation  accuracy 0.279\n",
      "step 46000 , validation loss : 9.88488\n",
      "step 46100 , training  accuracy 0.3\n",
      "step 46100 , loss : 2.23076\n",
      "step 46100 , validation  accuracy 0.2972\n",
      "step 46100 , validation loss : 8.76217\n",
      "step 46200 , training  accuracy 0.3\n",
      "step 46200 , loss : 2.2367\n",
      "step 46200 , validation  accuracy 0.2932\n",
      "step 46200 , validation loss : 9.12429\n",
      "step 46300 , training  accuracy 0.366667\n",
      "step 46300 , loss : 2.19183\n",
      "step 46300 , validation  accuracy 0.2926\n",
      "step 46300 , validation loss : 9.04058\n",
      "step 46400 , training  accuracy 0.266667\n",
      "step 46400 , loss : 2.18578\n",
      "step 46400 , validation  accuracy 0.2968\n",
      "step 46400 , validation loss : 8.80361\n",
      "step 46500 , training  accuracy 0.233333\n",
      "step 46500 , loss : 2.21129\n",
      "step 46500 , validation  accuracy 0.298\n",
      "step 46500 , validation loss : 9.59981\n",
      "step 46600 , training  accuracy 0.3\n",
      "step 46600 , loss : 2.18181\n",
      "step 46600 , validation  accuracy 0.2926\n",
      "step 46600 , validation loss : 9.61086\n",
      "step 46700 , training  accuracy 0.233333\n",
      "step 46700 , loss : 2.19517\n",
      "step 46700 , validation  accuracy 0.3112\n",
      "step 46700 , validation loss : 9.33332\n",
      "step 46800 , training  accuracy 0.333333\n",
      "step 46800 , loss : 2.22379\n",
      "step 46800 , validation  accuracy 0.3074\n",
      "step 46800 , validation loss : 10.1243\n",
      "step 46900 , training  accuracy 0.3\n",
      "step 46900 , loss : 2.20592\n",
      "step 46900 , validation  accuracy 0.3016\n",
      "step 46900 , validation loss : 8.92408\n",
      "step 47000 , training  accuracy 0.266667\n",
      "step 47000 , loss : 2.23538\n",
      "step 47000 , validation  accuracy 0.2676\n",
      "step 47000 , validation loss : 7.76004\n",
      "step 47100 , training  accuracy 0.466667\n",
      "step 47100 , loss : 2.16586\n",
      "step 47100 , validation  accuracy 0.3088\n",
      "step 47100 , validation loss : 10.1013\n",
      "step 47200 , training  accuracy 0.3\n",
      "step 47200 , loss : 2.2076\n",
      "step 47200 , validation  accuracy 0.312\n",
      "step 47200 , validation loss : 9.73565\n",
      "step 47300 , training  accuracy 0.4\n",
      "step 47300 , loss : 2.2058\n",
      "step 47300 , validation  accuracy 0.3016\n",
      "step 47300 , validation loss : 9.38982\n",
      "step 47400 , training  accuracy 0.333333\n",
      "step 47400 , loss : 2.19824\n",
      "step 47400 , validation  accuracy 0.3094\n",
      "step 47400 , validation loss : 8.89849\n",
      "step 47500 , training  accuracy 0.266667\n",
      "step 47500 , loss : 2.22919\n",
      "step 47500 , validation  accuracy 0.2892\n",
      "step 47500 , validation loss : 10.2605\n",
      "step 47600 , training  accuracy 0.3\n",
      "step 47600 , loss : 2.22377\n",
      "step 47600 , validation  accuracy 0.2966\n",
      "step 47600 , validation loss : 10.0732\n",
      "step 47700 , training  accuracy 0.3\n",
      "step 47700 , loss : 2.19209\n",
      "step 47700 , validation  accuracy 0.2908\n",
      "step 47700 , validation loss : 10.0816\n",
      "step 47800 , training  accuracy 0.233333\n",
      "step 47800 , loss : 2.21345\n",
      "step 47800 , validation  accuracy 0.2938\n",
      "step 47800 , validation loss : 8.96629\n",
      "step 47900 , training  accuracy 0.266667\n",
      "step 47900 , loss : 2.24182\n",
      "step 47900 , validation  accuracy 0.3106\n",
      "step 47900 , validation loss : 9.68623\n",
      "step 48000 , training  accuracy 0.366667\n",
      "step 48000 , loss : 2.20533\n",
      "step 48000 , validation  accuracy 0.3094\n",
      "step 48000 , validation loss : 9.95068\n",
      "step 48100 , training  accuracy 0.366667\n",
      "step 48100 , loss : 2.17971\n",
      "step 48100 , validation  accuracy 0.3056\n",
      "step 48100 , validation loss : 10.593\n",
      "step 48200 , training  accuracy 0.333333\n",
      "step 48200 , loss : 2.23179\n",
      "step 48200 , validation  accuracy 0.2844\n",
      "step 48200 , validation loss : 8.47584\n",
      "step 48300 , training  accuracy 0.3\n",
      "step 48300 , loss : 2.21004\n",
      "step 48300 , validation  accuracy 0.3012\n",
      "step 48300 , validation loss : 8.84753\n",
      "step 48400 , training  accuracy 0.266667\n",
      "step 48400 , loss : 2.21631\n",
      "step 48400 , validation  accuracy 0.3034\n",
      "step 48400 , validation loss : 9.28719\n",
      "step 48500 , training  accuracy 0.333333\n",
      "step 48500 , loss : 2.22069\n",
      "step 48500 , validation  accuracy 0.2666\n",
      "step 48500 , validation loss : 9.47675\n",
      "step 48600 , training  accuracy 0.333333\n",
      "step 48600 , loss : 2.20993\n",
      "step 48600 , validation  accuracy 0.3036\n",
      "step 48600 , validation loss : 9.17291\n",
      "step 48700 , training  accuracy 0.3\n",
      "step 48700 , loss : 2.19927\n",
      "step 48700 , validation  accuracy 0.2978\n",
      "step 48700 , validation loss : 9.36788\n",
      "step 48800 , training  accuracy 0.366667\n",
      "step 48800 , loss : 2.21101\n",
      "step 48800 , validation  accuracy 0.3042\n",
      "step 48800 , validation loss : 9.02337\n",
      "step 48900 , training  accuracy 0.466667\n",
      "step 48900 , loss : 2.17579\n",
      "step 48900 , validation  accuracy 0.2984\n",
      "step 48900 , validation loss : 9.76671\n",
      "step 49000 , training  accuracy 0.366667\n",
      "step 49000 , loss : 2.19823\n",
      "step 49000 , validation  accuracy 0.2994\n",
      "step 49000 , validation loss : 10.2774\n",
      "step 49100 , training  accuracy 0.3\n",
      "step 49100 , loss : 2.22052\n",
      "step 49100 , validation  accuracy 0.2942\n",
      "step 49100 , validation loss : 9.53138\n",
      "step 49200 , training  accuracy 0.466667\n",
      "step 49200 , loss : 2.1997\n",
      "step 49200 , validation  accuracy 0.3182\n",
      "step 49200 , validation loss : 10.1145\n",
      "step 49300 , training  accuracy 0.233333\n",
      "step 49300 , loss : 2.23308\n",
      "step 49300 , validation  accuracy 0.3128\n",
      "step 49300 , validation loss : 10.3048\n",
      "step 49400 , training  accuracy 0.3\n",
      "step 49400 , loss : 2.2257\n",
      "step 49400 , validation  accuracy 0.2962\n",
      "step 49400 , validation loss : 9.53833\n",
      "step 49500 , training  accuracy 0.3\n",
      "step 49500 , loss : 2.2103\n",
      "step 49500 , validation  accuracy 0.2876\n",
      "step 49500 , validation loss : 8.78312\n",
      "step 49600 , training  accuracy 0.333333\n",
      "step 49600 , loss : 2.2021\n",
      "step 49600 , validation  accuracy 0.2876\n",
      "step 49600 , validation loss : 9.91332\n",
      "step 49700 , training  accuracy 0.366667\n",
      "step 49700 , loss : 2.2191\n",
      "step 49700 , validation  accuracy 0.3112\n",
      "step 49700 , validation loss : 9.44415\n",
      "step 49800 , training  accuracy 0.566667\n",
      "step 49800 , loss : 2.17248\n",
      "step 49800 , validation  accuracy 0.3102\n",
      "step 49800 , validation loss : 9.32922\n",
      "step 49900 , training  accuracy 0.533333\n",
      "step 49900 , loss : 2.17681\n",
      "step 49900 , validation  accuracy 0.322\n",
      "step 49900 , validation loss : 10.1879\n",
      "step 50000 , training  accuracy 0.166667\n",
      "step 50000 , loss : 2.24759\n",
      "step 50000 , validation  accuracy 0.2862\n",
      "step 50000 , validation loss : 8.90125\n",
      "step 50100 , training  accuracy 0.366667\n",
      "step 50100 , loss : 2.17809\n",
      "step 50100 , validation  accuracy 0.3078\n",
      "step 50100 , validation loss : 10.6439\n",
      "step 50200 , training  accuracy 0.4\n",
      "step 50200 , loss : 2.18065\n",
      "step 50200 , validation  accuracy 0.316\n",
      "step 50200 , validation loss : 10.3836\n",
      "step 50300 , training  accuracy 0.366667\n",
      "step 50300 , loss : 2.19533\n",
      "step 50300 , validation  accuracy 0.3076\n",
      "step 50300 , validation loss : 9.68561\n",
      "step 50400 , training  accuracy 0.366667\n",
      "step 50400 , loss : 2.23094\n",
      "step 50400 , validation  accuracy 0.3076\n",
      "step 50400 , validation loss : 9.30677\n",
      "step 50500 , training  accuracy 0.366667\n",
      "step 50500 , loss : 2.17024\n",
      "step 50500 , validation  accuracy 0.309\n",
      "step 50500 , validation loss : 11.0933\n",
      "step 50600 , training  accuracy 0.333333\n",
      "step 50600 , loss : 2.23277\n",
      "step 50600 , validation  accuracy 0.3082\n",
      "step 50600 , validation loss : 9.59332\n",
      "step 50700 , training  accuracy 0.333333\n",
      "step 50700 , loss : 2.19623\n",
      "step 50700 , validation  accuracy 0.3158\n",
      "step 50700 , validation loss : 9.63241\n",
      "step 50800 , training  accuracy 0.533333\n",
      "step 50800 , loss : 2.12909\n",
      "step 50800 , validation  accuracy 0.305\n",
      "step 50800 , validation loss : 9.26208\n",
      "step 50900 , training  accuracy 0.366667\n",
      "step 50900 , loss : 2.22273\n",
      "step 50900 , validation  accuracy 0.3164\n",
      "step 50900 , validation loss : 9.53483\n",
      "step 51000 , training  accuracy 0.333333\n",
      "step 51000 , loss : 2.19307\n",
      "step 51000 , validation  accuracy 0.3188\n",
      "step 51000 , validation loss : 10.5616\n",
      "step 51100 , training  accuracy 0.5\n",
      "step 51100 , loss : 2.1814\n",
      "step 51100 , validation  accuracy 0.3208\n",
      "step 51100 , validation loss : 10.9674\n",
      "step 51200 , training  accuracy 0.4\n",
      "step 51200 , loss : 2.17718\n",
      "step 51200 , validation  accuracy 0.3188\n",
      "step 51200 , validation loss : 10.1301\n",
      "step 51300 , training  accuracy 0.366667\n",
      "step 51300 , loss : 2.18383\n",
      "step 51300 , validation  accuracy 0.3264\n",
      "step 51300 , validation loss : 10.3665\n",
      "step 51400 , training  accuracy 0.333333\n",
      "step 51400 , loss : 2.17033\n",
      "step 51400 , validation  accuracy 0.3276\n",
      "step 51400 , validation loss : 10.3541\n",
      "step 51500 , training  accuracy 0.3\n",
      "step 51500 , loss : 2.21288\n",
      "step 51500 , validation  accuracy 0.3412\n",
      "step 51500 , validation loss : 10.7965\n",
      "step 51600 , training  accuracy 0.3\n",
      "step 51600 , loss : 2.21739\n",
      "step 51600 , validation  accuracy 0.3248\n",
      "step 51600 , validation loss : 10.2344\n",
      "step 51700 , training  accuracy 0.366667\n",
      "step 51700 , loss : 2.22295\n",
      "step 51700 , validation  accuracy 0.3042\n",
      "step 51700 , validation loss : 9.33322\n",
      "step 51800 , training  accuracy 0.2\n",
      "step 51800 , loss : 2.26557\n",
      "step 51800 , validation  accuracy 0.317\n",
      "step 51800 , validation loss : 9.30178\n",
      "step 51900 , training  accuracy 0.4\n",
      "step 51900 , loss : 2.18357\n",
      "step 51900 , validation  accuracy 0.3232\n",
      "step 51900 , validation loss : 10.2565\n",
      "step 52000 , training  accuracy 0.433333\n",
      "step 52000 , loss : 2.19294\n",
      "step 52000 , validation  accuracy 0.3232\n",
      "step 52000 , validation loss : 10.9079\n",
      "step 52100 , training  accuracy 0.233333\n",
      "step 52100 , loss : 2.20015\n",
      "step 52100 , validation  accuracy 0.3256\n",
      "step 52100 , validation loss : 11.1065\n",
      "step 52200 , training  accuracy 0.4\n",
      "step 52200 , loss : 2.16436\n",
      "step 52200 , validation  accuracy 0.3372\n",
      "step 52200 , validation loss : 11.2526\n",
      "step 52300 , training  accuracy 0.4\n",
      "step 52300 , loss : 2.2093\n",
      "step 52300 , validation  accuracy 0.3226\n",
      "step 52300 , validation loss : 9.79296\n",
      "step 52400 , training  accuracy 0.566667\n",
      "step 52400 , loss : 2.14352\n",
      "step 52400 , validation  accuracy 0.332\n",
      "step 52400 , validation loss : 10.8046\n",
      "step 52500 , training  accuracy 0.433333\n",
      "step 52500 , loss : 2.16031\n",
      "step 52500 , validation  accuracy 0.3148\n",
      "step 52500 , validation loss : 10.1043\n",
      "step 52600 , training  accuracy 0.266667\n",
      "step 52600 , loss : 2.17926\n",
      "step 52600 , validation  accuracy 0.3292\n",
      "step 52600 , validation loss : 10.3364\n",
      "step 52700 , training  accuracy 0.366667\n",
      "step 52700 , loss : 2.17706\n",
      "step 52700 , validation  accuracy 0.3216\n",
      "step 52700 , validation loss : 10.3511\n",
      "step 52800 , training  accuracy 0.533333\n",
      "step 52800 , loss : 2.1425\n",
      "step 52800 , validation  accuracy 0.3268\n",
      "step 52800 , validation loss : 10.4108\n",
      "step 52900 , training  accuracy 0.366667\n",
      "step 52900 , loss : 2.18023\n",
      "step 52900 , validation  accuracy 0.3234\n",
      "step 52900 , validation loss : 11.0289\n",
      "step 53000 , training  accuracy 0.366667\n",
      "step 53000 , loss : 2.19255\n",
      "step 53000 , validation  accuracy 0.3258\n",
      "step 53000 , validation loss : 11.2875\n",
      "step 53100 , training  accuracy 0.433333\n",
      "step 53100 , loss : 2.13151\n",
      "step 53100 , validation  accuracy 0.3172\n",
      "step 53100 , validation loss : 9.95794\n",
      "step 53200 , training  accuracy 0.533333\n",
      "step 53200 , loss : 2.12893\n",
      "step 53200 , validation  accuracy 0.312\n",
      "step 53200 , validation loss : 10.718\n",
      "step 53300 , training  accuracy 0.333333\n",
      "step 53300 , loss : 2.20591\n",
      "step 53300 , validation  accuracy 0.3314\n",
      "step 53300 , validation loss : 10.8733\n",
      "step 53400 , training  accuracy 0.366667\n",
      "step 53400 , loss : 2.18667\n",
      "step 53400 , validation  accuracy 0.3232\n",
      "step 53400 , validation loss : 10.3592\n",
      "step 53500 , training  accuracy 0.566667\n",
      "step 53500 , loss : 2.15418\n",
      "step 53500 , validation  accuracy 0.3098\n",
      "step 53500 , validation loss : 9.87171\n",
      "step 53600 , training  accuracy 0.3\n",
      "step 53600 , loss : 2.20895\n",
      "step 53600 , validation  accuracy 0.3066\n",
      "step 53600 , validation loss : 9.96779\n",
      "step 53700 , training  accuracy 0.366667\n",
      "step 53700 , loss : 2.19824\n",
      "step 53700 , validation  accuracy 0.332\n",
      "step 53700 , validation loss : 10.9352\n",
      "step 53800 , training  accuracy 0.366667\n",
      "step 53800 , loss : 2.20029\n",
      "step 53800 , validation  accuracy 0.3146\n",
      "step 53800 , validation loss : 10.5854\n",
      "step 53900 , training  accuracy 0.5\n",
      "step 53900 , loss : 2.15067\n",
      "step 53900 , validation  accuracy 0.3266\n",
      "step 53900 , validation loss : 10.7787\n",
      "step 54000 , training  accuracy 0.4\n",
      "step 54000 , loss : 2.18874\n",
      "step 54000 , validation  accuracy 0.316\n",
      "step 54000 , validation loss : 11.2319\n",
      "step 54100 , training  accuracy 0.433333\n",
      "step 54100 , loss : 2.13773\n",
      "step 54100 , validation  accuracy 0.3098\n",
      "step 54100 , validation loss : 10.7406\n",
      "step 54200 , training  accuracy 0.466667\n",
      "step 54200 , loss : 2.17355\n",
      "step 54200 , validation  accuracy 0.3186\n",
      "step 54200 , validation loss : 10.7416\n",
      "step 54300 , training  accuracy 0.4\n",
      "step 54300 , loss : 2.15753\n",
      "step 54300 , validation  accuracy 0.3204\n",
      "step 54300 , validation loss : 10.5524\n",
      "step 54400 , training  accuracy 0.566667\n",
      "step 54400 , loss : 2.13218\n",
      "step 54400 , validation  accuracy 0.3366\n",
      "step 54400 , validation loss : 11.6779\n",
      "step 54500 , training  accuracy 0.5\n",
      "step 54500 , loss : 2.13884\n",
      "step 54500 , validation  accuracy 0.3146\n",
      "step 54500 , validation loss : 11.4891\n",
      "step 54600 , training  accuracy 0.233333\n",
      "step 54600 , loss : 2.20239\n",
      "step 54600 , validation  accuracy 0.2986\n",
      "step 54600 , validation loss : 10.0139\n",
      "step 54700 , training  accuracy 0.433333\n",
      "step 54700 , loss : 2.17961\n",
      "step 54700 , validation  accuracy 0.332\n",
      "step 54700 , validation loss : 11.5312\n",
      "step 54800 , training  accuracy 0.466667\n",
      "step 54800 , loss : 2.18016\n",
      "step 54800 , validation  accuracy 0.3286\n",
      "step 54800 , validation loss : 11.0004\n",
      "step 54900 , training  accuracy 0.266667\n",
      "step 54900 , loss : 2.24571\n",
      "step 54900 , validation  accuracy 0.3174\n",
      "step 54900 , validation loss : 10.7231\n",
      "step 55000 , training  accuracy 0.333333\n",
      "step 55000 , loss : 2.16281\n",
      "step 55000 , validation  accuracy 0.3156\n",
      "step 55000 , validation loss : 10.4463\n",
      "step 55100 , training  accuracy 0.4\n",
      "step 55100 , loss : 2.14309\n",
      "step 55100 , validation  accuracy 0.3292\n",
      "step 55100 , validation loss : 11.833\n",
      "step 55200 , training  accuracy 0.433333\n",
      "step 55200 , loss : 2.1603\n",
      "step 55200 , validation  accuracy 0.3242\n",
      "step 55200 , validation loss : 11.8267\n",
      "step 55300 , training  accuracy 0.6\n",
      "step 55300 , loss : 2.11387\n",
      "step 55300 , validation  accuracy 0.3322\n",
      "step 55300 , validation loss : 11.8692\n",
      "step 55400 , training  accuracy 0.633333\n",
      "step 55400 , loss : 2.11217\n",
      "step 55400 , validation  accuracy 0.3316\n",
      "step 55400 , validation loss : 11.3317\n",
      "step 55500 , training  accuracy 0.533333\n",
      "step 55500 , loss : 2.13507\n",
      "step 55500 , validation  accuracy 0.3294\n",
      "step 55500 , validation loss : 12.9876\n",
      "step 55600 , training  accuracy 0.366667\n",
      "step 55600 , loss : 2.2014\n",
      "step 55600 , validation  accuracy 0.3244\n",
      "step 55600 , validation loss : 11.4405\n",
      "step 55700 , training  accuracy 0.366667\n",
      "step 55700 , loss : 2.17381\n",
      "step 55700 , validation  accuracy 0.3196\n",
      "step 55700 , validation loss : 10.4043\n",
      "step 55800 , training  accuracy 0.266667\n",
      "step 55800 , loss : 2.22612\n",
      "step 55800 , validation  accuracy 0.3194\n",
      "step 55800 , validation loss : 10.5432\n",
      "step 55900 , training  accuracy 0.533333\n",
      "step 55900 , loss : 2.13352\n",
      "step 55900 , validation  accuracy 0.3338\n",
      "step 55900 , validation loss : 12.8496\n",
      "step 56000 , training  accuracy 0.533333\n",
      "step 56000 , loss : 2.17696\n",
      "step 56000 , validation  accuracy 0.3224\n",
      "step 56000 , validation loss : 10.568\n",
      "step 56100 , training  accuracy 0.433333\n",
      "step 56100 , loss : 2.17748\n",
      "step 56100 , validation  accuracy 0.3194\n",
      "step 56100 , validation loss : 10.8131\n",
      "step 56200 , training  accuracy 0.366667\n",
      "step 56200 , loss : 2.16329\n",
      "step 56200 , validation  accuracy 0.3262\n",
      "step 56200 , validation loss : 11.212\n",
      "step 56300 , training  accuracy 0.466667\n",
      "step 56300 , loss : 2.19803\n",
      "step 56300 , validation  accuracy 0.3216\n",
      "step 56300 , validation loss : 10.6661\n",
      "step 56400 , training  accuracy 0.5\n",
      "step 56400 , loss : 2.1891\n",
      "step 56400 , validation  accuracy 0.3186\n",
      "step 56400 , validation loss : 11.2068\n",
      "step 56500 , training  accuracy 0.6\n",
      "step 56500 , loss : 2.13626\n",
      "step 56500 , validation  accuracy 0.3026\n",
      "step 56500 , validation loss : 10.7467\n",
      "step 56600 , training  accuracy 0.366667\n",
      "step 56600 , loss : 2.15029\n",
      "step 56600 , validation  accuracy 0.32\n",
      "step 56600 , validation loss : 11.0063\n",
      "step 56700 , training  accuracy 0.266667\n",
      "step 56700 , loss : 2.21038\n",
      "step 56700 , validation  accuracy 0.3252\n",
      "step 56700 , validation loss : 11.1737\n",
      "step 56800 , training  accuracy 0.433333\n",
      "step 56800 , loss : 2.15392\n",
      "step 56800 , validation  accuracy 0.3386\n",
      "step 56800 , validation loss : 12.3613\n",
      "step 56900 , training  accuracy 0.533333\n",
      "step 56900 , loss : 2.11051\n",
      "step 56900 , validation  accuracy 0.3372\n",
      "step 56900 , validation loss : 12.4908\n",
      "step 57000 , training  accuracy 0.333333\n",
      "step 57000 , loss : 2.19035\n",
      "step 57000 , validation  accuracy 0.3392\n",
      "step 57000 , validation loss : 11.6038\n",
      "step 57100 , training  accuracy 0.466667\n",
      "step 57100 , loss : 2.16206\n",
      "step 57100 , validation  accuracy 0.3334\n",
      "step 57100 , validation loss : 11.1261\n",
      "step 57200 , training  accuracy 0.3\n",
      "step 57200 , loss : 2.18399\n",
      "step 57200 , validation  accuracy 0.3206\n",
      "step 57200 , validation loss : 10.8649\n",
      "step 57300 , training  accuracy 0.266667\n",
      "step 57300 , loss : 2.22595\n",
      "step 57300 , validation  accuracy 0.3224\n",
      "step 57300 , validation loss : 12.0137\n",
      "step 57400 , training  accuracy 0.533333\n",
      "step 57400 , loss : 2.1135\n",
      "step 57400 , validation  accuracy 0.3076\n",
      "step 57400 , validation loss : 10.5245\n",
      "step 57500 , training  accuracy 0.466667\n",
      "step 57500 , loss : 2.15818\n",
      "step 57500 , validation  accuracy 0.333\n",
      "step 57500 , validation loss : 11.8961\n",
      "step 57600 , training  accuracy 0.5\n",
      "step 57600 , loss : 2.10636\n",
      "step 57600 , validation  accuracy 0.324\n",
      "step 57600 , validation loss : 11.387\n",
      "step 57700 , training  accuracy 0.466667\n",
      "step 57700 , loss : 2.16074\n",
      "step 57700 , validation  accuracy 0.3154\n",
      "step 57700 , validation loss : 12.5462\n",
      "step 57800 , training  accuracy 0.466667\n",
      "step 57800 , loss : 2.18827\n",
      "step 57800 , validation  accuracy 0.3224\n",
      "step 57800 , validation loss : 13.127\n",
      "step 57900 , training  accuracy 0.466667\n",
      "step 57900 , loss : 2.14592\n",
      "step 57900 , validation  accuracy 0.3222\n",
      "step 57900 , validation loss : 11.4948\n",
      "step 58000 , training  accuracy 0.433333\n",
      "step 58000 , loss : 2.1449\n",
      "step 58000 , validation  accuracy 0.3392\n",
      "step 58000 , validation loss : 12.7602\n",
      "step 58100 , training  accuracy 0.433333\n",
      "step 58100 , loss : 2.16396\n",
      "step 58100 , validation  accuracy 0.341\n",
      "step 58100 , validation loss : 13.0781\n",
      "step 58200 , training  accuracy 0.433333\n",
      "step 58200 , loss : 2.19746\n",
      "step 58200 , validation  accuracy 0.3304\n",
      "step 58200 , validation loss : 12.8918\n",
      "step 58300 , training  accuracy 0.4\n",
      "step 58300 , loss : 2.17077\n",
      "step 58300 , validation  accuracy 0.3238\n",
      "step 58300 , validation loss : 12.4226\n",
      "step 58400 , training  accuracy 0.4\n",
      "step 58400 , loss : 2.17636\n",
      "step 58400 , validation  accuracy 0.3322\n",
      "step 58400 , validation loss : 12.3051\n",
      "step 58500 , training  accuracy 0.333333\n",
      "step 58500 , loss : 2.17802\n",
      "step 58500 , validation  accuracy 0.3322\n",
      "step 58500 , validation loss : 12.0405\n",
      "step 58600 , training  accuracy 0.4\n",
      "step 58600 , loss : 2.1372\n",
      "step 58600 , validation  accuracy 0.3314\n",
      "step 58600 , validation loss : 12.0738\n",
      "step 58700 , training  accuracy 0.3\n",
      "step 58700 , loss : 2.17882\n",
      "step 58700 , validation  accuracy 0.3152\n",
      "step 58700 , validation loss : 11.2491\n",
      "step 58800 , training  accuracy 0.433333\n",
      "step 58800 , loss : 2.10695\n",
      "step 58800 , validation  accuracy 0.3292\n",
      "step 58800 , validation loss : 12.6448\n",
      "step 58900 , training  accuracy 0.466667\n",
      "step 58900 , loss : 2.16156\n",
      "step 58900 , validation  accuracy 0.3142\n",
      "step 58900 , validation loss : 11.8281\n",
      "step 59000 , training  accuracy 0.4\n",
      "step 59000 , loss : 2.14646\n",
      "step 59000 , validation  accuracy 0.3388\n",
      "step 59000 , validation loss : 12.7152\n",
      "step 59100 , training  accuracy 0.466667\n",
      "step 59100 , loss : 2.17323\n",
      "step 59100 , validation  accuracy 0.3112\n",
      "step 59100 , validation loss : 11.6354\n",
      "step 59200 , training  accuracy 0.566667\n",
      "step 59200 , loss : 2.09777\n",
      "step 59200 , validation  accuracy 0.3244\n",
      "step 59200 , validation loss : 11.8793\n",
      "step 59300 , training  accuracy 0.6\n",
      "step 59300 , loss : 2.12764\n",
      "step 59300 , validation  accuracy 0.3266\n",
      "step 59300 , validation loss : 11.4637\n",
      "step 59400 , training  accuracy 0.533333\n",
      "step 59400 , loss : 2.10127\n",
      "step 59400 , validation  accuracy 0.3228\n",
      "step 59400 , validation loss : 11.813\n",
      "step 59500 , training  accuracy 0.533333\n",
      "step 59500 , loss : 2.13491\n",
      "step 59500 , validation  accuracy 0.3256\n",
      "step 59500 , validation loss : 12.6978\n",
      "step 59600 , training  accuracy 0.366667\n",
      "step 59600 , loss : 2.13682\n",
      "step 59600 , validation  accuracy 0.2946\n",
      "step 59600 , validation loss : 10.8031\n",
      "step 59700 , training  accuracy 0.6\n",
      "step 59700 , loss : 2.13621\n",
      "step 59700 , validation  accuracy 0.3248\n",
      "step 59700 , validation loss : 11.8771\n",
      "step 59800 , training  accuracy 0.466667\n",
      "step 59800 , loss : 2.1507\n",
      "step 59800 , validation  accuracy 0.3228\n",
      "step 59800 , validation loss : 11.6399\n",
      "step 59900 , training  accuracy 0.533333\n",
      "step 59900 , loss : 2.14776\n",
      "step 59900 , validation  accuracy 0.3152\n",
      "step 59900 , validation loss : 10.8666\n",
      "step 60000 , training  accuracy 0.5\n",
      "step 60000 , loss : 2.15933\n",
      "step 60000 , validation  accuracy 0.3324\n",
      "step 60000 , validation loss : 13.5085\n",
      "step 60100 , training  accuracy 0.266667\n",
      "step 60100 , loss : 2.18097\n",
      "step 60100 , validation  accuracy 0.3054\n",
      "step 60100 , validation loss : 11.5227\n",
      "step 60200 , training  accuracy 0.433333\n",
      "step 60200 , loss : 2.18441\n",
      "step 60200 , validation  accuracy 0.3278\n",
      "step 60200 , validation loss : 12.0969\n",
      "step 60300 , training  accuracy 0.433333\n",
      "step 60300 , loss : 2.17405\n",
      "step 60300 , validation  accuracy 0.311\n",
      "step 60300 , validation loss : 11.4546\n",
      "step 60400 , training  accuracy 0.333333\n",
      "step 60400 , loss : 2.21111\n",
      "step 60400 , validation  accuracy 0.3372\n",
      "step 60400 , validation loss : 13.1707\n",
      "step 60500 , training  accuracy 0.6\n",
      "step 60500 , loss : 2.12594\n",
      "step 60500 , validation  accuracy 0.3206\n",
      "step 60500 , validation loss : 12.4713\n",
      "step 60600 , training  accuracy 0.4\n",
      "step 60600 , loss : 2.18611\n",
      "step 60600 , validation  accuracy 0.3084\n",
      "step 60600 , validation loss : 12.5094\n",
      "step 60700 , training  accuracy 0.3\n",
      "step 60700 , loss : 2.19965\n",
      "step 60700 , validation  accuracy 0.3198\n",
      "step 60700 , validation loss : 11.9862\n",
      "step 60800 , training  accuracy 0.333333\n",
      "step 60800 , loss : 2.19021\n",
      "step 60800 , validation  accuracy 0.3028\n",
      "step 60800 , validation loss : 10.8281\n",
      "step 60900 , training  accuracy 0.5\n",
      "step 60900 , loss : 2.1508\n",
      "step 60900 , validation  accuracy 0.3356\n",
      "step 60900 , validation loss : 13.4766\n",
      "step 61000 , training  accuracy 0.333333\n",
      "step 61000 , loss : 2.17182\n",
      "step 61000 , validation  accuracy 0.3268\n",
      "step 61000 , validation loss : 13.4302\n",
      "step 61100 , training  accuracy 0.5\n",
      "step 61100 , loss : 2.13127\n",
      "step 61100 , validation  accuracy 0.3232\n",
      "step 61100 , validation loss : 12.6719\n",
      "step 61200 , training  accuracy 0.5\n",
      "step 61200 , loss : 2.10622\n",
      "step 61200 , validation  accuracy 0.3362\n",
      "step 61200 , validation loss : 13.2087\n",
      "step 61300 , training  accuracy 0.433333\n",
      "step 61300 , loss : 2.17793\n",
      "step 61300 , validation  accuracy 0.3112\n",
      "step 61300 , validation loss : 11.932\n",
      "step 61400 , training  accuracy 0.5\n",
      "step 61400 , loss : 2.12004\n",
      "step 61400 , validation  accuracy 0.3264\n",
      "step 61400 , validation loss : 12.4927\n",
      "step 61500 , training  accuracy 0.366667\n",
      "step 61500 , loss : 2.17764\n",
      "step 61500 , validation  accuracy 0.312\n",
      "step 61500 , validation loss : 11.8199\n",
      "step 61600 , training  accuracy 0.5\n",
      "step 61600 , loss : 2.15402\n",
      "step 61600 , validation  accuracy 0.3316\n",
      "step 61600 , validation loss : 12.8563\n",
      "step 61700 , training  accuracy 0.533333\n",
      "step 61700 , loss : 2.12189\n",
      "step 61700 , validation  accuracy 0.3228\n",
      "step 61700 , validation loss : 12.6257\n",
      "step 61800 , training  accuracy 0.266667\n",
      "step 61800 , loss : 2.26692\n",
      "step 61800 , validation  accuracy 0.3098\n",
      "step 61800 , validation loss : 12.4882\n",
      "step 61900 , training  accuracy 0.266667\n",
      "step 61900 , loss : 2.18114\n",
      "step 61900 , validation  accuracy 0.3178\n",
      "step 61900 , validation loss : 12.242\n",
      "step 62000 , training  accuracy 0.366667\n",
      "step 62000 , loss : 2.17114\n",
      "step 62000 , validation  accuracy 0.3088\n",
      "step 62000 , validation loss : 12.1975\n",
      "step 62100 , training  accuracy 0.266667\n",
      "step 62100 , loss : 2.17043\n",
      "step 62100 , validation  accuracy 0.2936\n",
      "step 62100 , validation loss : 11.908\n",
      "step 62200 , training  accuracy 0.466667\n",
      "step 62200 , loss : 2.14621\n",
      "step 62200 , validation  accuracy 0.3314\n",
      "step 62200 , validation loss : 14.3047\n",
      "step 62300 , training  accuracy 0.366667\n",
      "step 62300 , loss : 2.16519\n",
      "step 62300 , validation  accuracy 0.3096\n",
      "step 62300 , validation loss : 11.391\n",
      "step 62400 , training  accuracy 0.466667\n",
      "step 62400 , loss : 2.15026\n",
      "step 62400 , validation  accuracy 0.298\n",
      "step 62400 , validation loss : 11.1349\n",
      "step 62500 , training  accuracy 0.3\n",
      "step 62500 , loss : 2.183\n",
      "step 62500 , validation  accuracy 0.3424\n",
      "step 62500 , validation loss : 14.5594\n",
      "step 62600 , training  accuracy 0.466667\n",
      "step 62600 , loss : 2.18077\n",
      "step 62600 , validation  accuracy 0.3122\n",
      "step 62600 , validation loss : 12.0682\n",
      "step 62700 , training  accuracy 0.366667\n",
      "step 62700 , loss : 2.19469\n",
      "step 62700 , validation  accuracy 0.2964\n",
      "step 62700 , validation loss : 11.2919\n",
      "step 62800 , training  accuracy 0.233333\n",
      "step 62800 , loss : 2.20759\n",
      "step 62800 , validation  accuracy 0.3166\n",
      "step 62800 , validation loss : 12.7182\n",
      "step 62900 , training  accuracy 0.6\n",
      "step 62900 , loss : 2.07526\n",
      "step 62900 , validation  accuracy 0.3248\n",
      "step 62900 , validation loss : 11.8773\n",
      "step 63000 , training  accuracy 0.433333\n",
      "step 63000 , loss : 2.14222\n",
      "step 63000 , validation  accuracy 0.3296\n",
      "step 63000 , validation loss : 13.6568\n",
      "step 63100 , training  accuracy 0.333333\n",
      "step 63100 , loss : 2.18294\n",
      "step 63100 , validation  accuracy 0.3302\n",
      "step 63100 , validation loss : 13.3307\n",
      "step 63200 , training  accuracy 0.466667\n",
      "step 63200 , loss : 2.13917\n",
      "step 63200 , validation  accuracy 0.323\n",
      "step 63200 , validation loss : 13.7298\n",
      "step 63300 , training  accuracy 0.533333\n",
      "step 63300 , loss : 2.16065\n",
      "step 63300 , validation  accuracy 0.3272\n",
      "step 63300 , validation loss : 13.9088\n",
      "step 63400 , training  accuracy 0.533333\n",
      "step 63400 , loss : 2.09098\n",
      "step 63400 , validation  accuracy 0.335\n",
      "step 63400 , validation loss : 13.2847\n",
      "step 63500 , training  accuracy 0.4\n",
      "step 63500 , loss : 2.14693\n",
      "step 63500 , validation  accuracy 0.3242\n",
      "step 63500 , validation loss : 14.4551\n",
      "step 63600 , training  accuracy 0.4\n",
      "step 63600 , loss : 2.14443\n",
      "step 63600 , validation  accuracy 0.3126\n",
      "step 63600 , validation loss : 13.0804\n",
      "step 63700 , training  accuracy 0.466667\n",
      "step 63700 , loss : 2.15226\n",
      "step 63700 , validation  accuracy 0.3032\n",
      "step 63700 , validation loss : 12.4196\n",
      "step 63800 , training  accuracy 0.366667\n",
      "step 63800 , loss : 2.18163\n",
      "step 63800 , validation  accuracy 0.3064\n",
      "step 63800 , validation loss : 11.6799\n",
      "step 63900 , training  accuracy 0.333333\n",
      "step 63900 , loss : 2.13964\n",
      "step 63900 , validation  accuracy 0.324\n",
      "step 63900 , validation loss : 13.6481\n",
      "step 64000 , training  accuracy 0.4\n",
      "step 64000 , loss : 2.11563\n",
      "step 64000 , validation  accuracy 0.3196\n",
      "step 64000 , validation loss : 13.472\n",
      "step 64100 , training  accuracy 0.5\n",
      "step 64100 , loss : 2.16329\n",
      "step 64100 , validation  accuracy 0.3134\n",
      "step 64100 , validation loss : 12.0865\n",
      "step 64200 , training  accuracy 0.5\n",
      "step 64200 , loss : 2.17957\n",
      "step 64200 , validation  accuracy 0.3216\n",
      "step 64200 , validation loss : 12.0448\n",
      "step 64300 , training  accuracy 0.266667\n",
      "step 64300 , loss : 2.20942\n",
      "step 64300 , validation  accuracy 0.299\n",
      "step 64300 , validation loss : 11.4088\n",
      "step 64400 , training  accuracy 0.333333\n",
      "step 64400 , loss : 2.21983\n",
      "step 64400 , validation  accuracy 0.332\n",
      "step 64400 , validation loss : 13.2063\n",
      "step 64500 , training  accuracy 0.633333\n",
      "step 64500 , loss : 2.15344\n",
      "step 64500 , validation  accuracy 0.3262\n",
      "step 64500 , validation loss : 12.3818\n",
      "step 64600 , training  accuracy 0.533333\n",
      "step 64600 , loss : 2.12145\n",
      "step 64600 , validation  accuracy 0.3262\n",
      "step 64600 , validation loss : 13.5915\n",
      "step 64700 , training  accuracy 0.3\n",
      "step 64700 , loss : 2.17112\n",
      "step 64700 , validation  accuracy 0.3312\n",
      "step 64700 , validation loss : 13.1405\n",
      "step 64800 , training  accuracy 0.433333\n",
      "step 64800 , loss : 2.14808\n",
      "step 64800 , validation  accuracy 0.3246\n",
      "step 64800 , validation loss : 13.11\n",
      "step 64900 , training  accuracy 0.433333\n",
      "step 64900 , loss : 2.17221\n",
      "step 64900 , validation  accuracy 0.327\n",
      "step 64900 , validation loss : 13.1512\n",
      "step 65000 , training  accuracy 0.433333\n",
      "step 65000 , loss : 2.16171\n",
      "step 65000 , validation  accuracy 0.3098\n",
      "step 65000 , validation loss : 12.1192\n",
      "step 65100 , training  accuracy 0.4\n",
      "step 65100 , loss : 2.14491\n",
      "step 65100 , validation  accuracy 0.317\n",
      "step 65100 , validation loss : 12.6865\n",
      "step 65200 , training  accuracy 0.533333\n",
      "step 65200 , loss : 2.16095\n",
      "step 65200 , validation  accuracy 0.316\n",
      "step 65200 , validation loss : 13.5767\n",
      "step 65300 , training  accuracy 0.4\n",
      "step 65300 , loss : 2.14832\n",
      "step 65300 , validation  accuracy 0.3136\n",
      "step 65300 , validation loss : 13.1896\n",
      "step 65400 , training  accuracy 0.466667\n",
      "step 65400 , loss : 2.18514\n",
      "step 65400 , validation  accuracy 0.3104\n",
      "step 65400 , validation loss : 13.1844\n",
      "step 65500 , training  accuracy 0.6\n",
      "step 65500 , loss : 2.08176\n",
      "step 65500 , validation  accuracy 0.3208\n",
      "step 65500 , validation loss : 14.9844\n",
      "step 65600 , training  accuracy 0.4\n",
      "step 65600 , loss : 2.14909\n",
      "step 65600 , validation  accuracy 0.3286\n",
      "step 65600 , validation loss : 13.8921\n",
      "step 65700 , training  accuracy 0.533333\n",
      "step 65700 , loss : 2.1228\n",
      "step 65700 , validation  accuracy 0.3334\n",
      "step 65700 , validation loss : 14.5311\n",
      "step 65800 , training  accuracy 0.433333\n",
      "step 65800 , loss : 2.19272\n",
      "step 65800 , validation  accuracy 0.3178\n",
      "step 65800 , validation loss : 12.6184\n",
      "step 65900 , training  accuracy 0.533333\n",
      "step 65900 , loss : 2.13453\n",
      "step 65900 , validation  accuracy 0.3122\n",
      "step 65900 , validation loss : 13.4404\n",
      "step 66000 , training  accuracy 0.266667\n",
      "step 66000 , loss : 2.20405\n",
      "step 66000 , validation  accuracy 0.326\n",
      "step 66000 , validation loss : 12.9964\n",
      "step 66100 , training  accuracy 0.5\n",
      "step 66100 , loss : 2.125\n",
      "step 66100 , validation  accuracy 0.3264\n",
      "step 66100 , validation loss : 13.8726\n",
      "step 66200 , training  accuracy 0.6\n",
      "step 66200 , loss : 2.11724\n",
      "step 66200 , validation  accuracy 0.3254\n",
      "step 66200 , validation loss : 14.5671\n",
      "step 66300 , training  accuracy 0.5\n",
      "step 66300 , loss : 2.10992\n",
      "step 66300 , validation  accuracy 0.3208\n",
      "step 66300 , validation loss : 13.1615\n",
      "step 66400 , training  accuracy 0.6\n",
      "step 66400 , loss : 2.09786\n",
      "step 66400 , validation  accuracy 0.3092\n",
      "step 66400 , validation loss : 12.3276\n",
      "step 66500 , training  accuracy 0.333333\n",
      "step 66500 , loss : 2.1817\n",
      "step 66500 , validation  accuracy 0.3068\n",
      "step 66500 , validation loss : 14.5716\n",
      "step 66600 , training  accuracy 0.7\n",
      "step 66600 , loss : 2.07072\n",
      "step 66600 , validation  accuracy 0.3102\n",
      "step 66600 , validation loss : 13.5187\n",
      "step 66700 , training  accuracy 0.5\n",
      "step 66700 , loss : 2.14208\n",
      "step 66700 , validation  accuracy 0.3238\n",
      "step 66700 , validation loss : 13.8838\n",
      "step 66800 , training  accuracy 0.466667\n",
      "step 66800 , loss : 2.13633\n",
      "step 66800 , validation  accuracy 0.326\n",
      "step 66800 , validation loss : 13.9\n",
      "step 66900 , training  accuracy 0.4\n",
      "step 66900 , loss : 2.17821\n",
      "step 66900 , validation  accuracy 0.3128\n",
      "step 66900 , validation loss : 13.3511\n",
      "step 67000 , training  accuracy 0.333333\n",
      "step 67000 , loss : 2.13171\n",
      "step 67000 , validation  accuracy 0.3142\n",
      "step 67000 , validation loss : 12.92\n",
      "step 67100 , training  accuracy 0.566667\n",
      "step 67100 , loss : 2.13733\n",
      "step 67100 , validation  accuracy 0.3136\n",
      "step 67100 , validation loss : 13.5682\n",
      "step 67200 , training  accuracy 0.533333\n",
      "step 67200 , loss : 2.08934\n",
      "step 67200 , validation  accuracy 0.3106\n",
      "step 67200 , validation loss : 13.3237\n",
      "step 67300 , training  accuracy 0.4\n",
      "step 67300 , loss : 2.19326\n",
      "step 67300 , validation  accuracy 0.3198\n",
      "step 67300 , validation loss : 13.7989\n",
      "step 67400 , training  accuracy 0.666667\n",
      "step 67400 , loss : 2.03192\n",
      "step 67400 , validation  accuracy 0.3188\n",
      "step 67400 , validation loss : 13.5645\n",
      "step 67500 , training  accuracy 0.333333\n",
      "step 67500 , loss : 2.18858\n",
      "step 67500 , validation  accuracy 0.315\n",
      "step 67500 , validation loss : 12.8083\n",
      "step 67600 , training  accuracy 0.4\n",
      "step 67600 , loss : 2.14433\n",
      "step 67600 , validation  accuracy 0.305\n",
      "step 67600 , validation loss : 13.2092\n",
      "step 67700 , training  accuracy 0.433333\n",
      "step 67700 , loss : 2.144\n",
      "step 67700 , validation  accuracy 0.3056\n",
      "step 67700 , validation loss : 14.0989\n",
      "step 67800 , training  accuracy 0.433333\n",
      "step 67800 , loss : 2.16858\n",
      "step 67800 , validation  accuracy 0.3044\n",
      "step 67800 , validation loss : 13.6016\n",
      "step 67900 , training  accuracy 0.5\n",
      "step 67900 , loss : 2.18626\n",
      "step 67900 , validation  accuracy 0.3124\n",
      "step 67900 , validation loss : 13.9727\n",
      "step 68000 , training  accuracy 0.5\n",
      "step 68000 , loss : 2.12644\n",
      "step 68000 , validation  accuracy 0.3252\n",
      "step 68000 , validation loss : 14.1232\n",
      "step 68100 , training  accuracy 0.4\n",
      "step 68100 , loss : 2.16948\n",
      "step 68100 , validation  accuracy 0.3154\n",
      "step 68100 , validation loss : 12.7493\n",
      "step 68200 , training  accuracy 0.5\n",
      "step 68200 , loss : 2.10546\n",
      "step 68200 , validation  accuracy 0.32\n",
      "step 68200 , validation loss : 14.4218\n",
      "step 68300 , training  accuracy 0.433333\n",
      "step 68300 , loss : 2.16365\n",
      "step 68300 , validation  accuracy 0.3218\n",
      "step 68300 , validation loss : 13.3414\n",
      "step 68400 , training  accuracy 0.433333\n",
      "step 68400 , loss : 2.1492\n",
      "step 68400 , validation  accuracy 0.31\n",
      "step 68400 , validation loss : 12.9589\n",
      "step 68500 , training  accuracy 0.3\n",
      "step 68500 , loss : 2.15634\n",
      "step 68500 , validation  accuracy 0.3172\n",
      "step 68500 , validation loss : 13.5778\n",
      "step 68600 , training  accuracy 0.666667\n",
      "step 68600 , loss : 2.08584\n",
      "step 68600 , validation  accuracy 0.323\n",
      "step 68600 , validation loss : 14.6341\n",
      "step 68700 , training  accuracy 0.5\n",
      "step 68700 , loss : 2.13999\n",
      "step 68700 , validation  accuracy 0.322\n",
      "step 68700 , validation loss : 14.1853\n",
      "step 68800 , training  accuracy 0.233333\n",
      "step 68800 , loss : 2.23807\n",
      "step 68800 , validation  accuracy 0.2934\n",
      "step 68800 , validation loss : 11.9288\n",
      "step 68900 , training  accuracy 0.8\n",
      "step 68900 , loss : 2.05116\n",
      "step 68900 , validation  accuracy 0.3184\n",
      "step 68900 , validation loss : 13.6758\n",
      "step 69000 , training  accuracy 0.533333\n",
      "step 69000 , loss : 2.12904\n",
      "step 69000 , validation  accuracy 0.3312\n",
      "step 69000 , validation loss : 14.4539\n",
      "step 69100 , training  accuracy 0.366667\n",
      "step 69100 , loss : 2.18467\n",
      "step 69100 , validation  accuracy 0.3156\n",
      "step 69100 , validation loss : 12.6825\n",
      "step 69200 , training  accuracy 0.566667\n",
      "step 69200 , loss : 2.11015\n",
      "step 69200 , validation  accuracy 0.3252\n",
      "step 69200 , validation loss : 13.5576\n",
      "step 69300 , training  accuracy 0.466667\n",
      "step 69300 , loss : 2.12786\n",
      "step 69300 , validation  accuracy 0.3178\n",
      "step 69300 , validation loss : 13.8946\n",
      "step 69400 , training  accuracy 0.6\n",
      "step 69400 , loss : 2.09234\n",
      "step 69400 , validation  accuracy 0.3212\n",
      "step 69400 , validation loss : 13.2087\n",
      "step 69500 , training  accuracy 0.466667\n",
      "step 69500 , loss : 2.14659\n",
      "step 69500 , validation  accuracy 0.3244\n",
      "step 69500 , validation loss : 13.9604\n",
      "step 69600 , training  accuracy 0.533333\n",
      "step 69600 , loss : 2.11706\n",
      "step 69600 , validation  accuracy 0.3318\n",
      "step 69600 , validation loss : 14.9265\n",
      "step 69700 , training  accuracy 0.533333\n",
      "step 69700 , loss : 2.14954\n",
      "step 69700 , validation  accuracy 0.3196\n",
      "step 69700 , validation loss : 13.6539\n",
      "step 69800 , training  accuracy 0.333333\n",
      "step 69800 , loss : 2.15004\n",
      "step 69800 , validation  accuracy 0.33\n",
      "step 69800 , validation loss : 14.578\n",
      "step 69900 , training  accuracy 0.433333\n",
      "step 69900 , loss : 2.1517\n",
      "step 69900 , validation  accuracy 0.3166\n",
      "step 69900 , validation loss : 13.6764\n",
      "step 70000 , training  accuracy 0.533333\n",
      "step 70000 , loss : 2.17382\n",
      "step 70000 , validation  accuracy 0.3262\n",
      "step 70000 , validation loss : 13.5131\n",
      "step 70100 , training  accuracy 0.566667\n",
      "step 70100 , loss : 2.12031\n",
      "step 70100 , validation  accuracy 0.3166\n",
      "step 70100 , validation loss : 13.4084\n",
      "step 70200 , training  accuracy 0.533333\n",
      "step 70200 , loss : 2.12191\n",
      "step 70200 , validation  accuracy 0.3306\n",
      "step 70200 , validation loss : 15.1969\n",
      "step 70300 , training  accuracy 0.5\n",
      "step 70300 , loss : 2.11881\n",
      "step 70300 , validation  accuracy 0.3104\n",
      "step 70300 , validation loss : 13.2409\n",
      "step 70400 , training  accuracy 0.333333\n",
      "step 70400 , loss : 2.22068\n",
      "step 70400 , validation  accuracy 0.3158\n",
      "step 70400 , validation loss : 13.6157\n",
      "step 70500 , training  accuracy 0.3\n",
      "step 70500 , loss : 2.19153\n",
      "step 70500 , validation  accuracy 0.303\n",
      "step 70500 , validation loss : 13.4508\n",
      "step 70600 , training  accuracy 0.333333\n",
      "step 70600 , loss : 2.18163\n",
      "step 70600 , validation  accuracy 0.321\n",
      "step 70600 , validation loss : 14.0428\n",
      "step 70700 , training  accuracy 0.533333\n",
      "step 70700 , loss : 2.12914\n",
      "step 70700 , validation  accuracy 0.3286\n",
      "step 70700 , validation loss : 14.8282\n",
      "step 70800 , training  accuracy 0.4\n",
      "step 70800 , loss : 2.15282\n",
      "step 70800 , validation  accuracy 0.3234\n",
      "step 70800 , validation loss : 14.2132\n",
      "step 70900 , training  accuracy 0.466667\n",
      "step 70900 , loss : 2.15177\n",
      "step 70900 , validation  accuracy 0.3058\n",
      "step 70900 , validation loss : 13.1133\n",
      "step 71000 , training  accuracy 0.466667\n",
      "step 71000 , loss : 2.20891\n",
      "step 71000 , validation  accuracy 0.3262\n",
      "step 71000 , validation loss : 13.9848\n",
      "step 71100 , training  accuracy 0.4\n",
      "step 71100 , loss : 2.15431\n",
      "step 71100 , validation  accuracy 0.3278\n",
      "step 71100 , validation loss : 14.4923\n",
      "step 71200 , training  accuracy 0.433333\n",
      "step 71200 , loss : 2.1704\n",
      "step 71200 , validation  accuracy 0.3274\n",
      "step 71200 , validation loss : 14.5685\n",
      "step 71300 , training  accuracy 0.466667\n",
      "step 71300 , loss : 2.13404\n",
      "step 71300 , validation  accuracy 0.3078\n",
      "step 71300 , validation loss : 12.7864\n",
      "step 71400 , training  accuracy 0.6\n",
      "step 71400 , loss : 2.11366\n",
      "step 71400 , validation  accuracy 0.3272\n",
      "step 71400 , validation loss : 14.2496\n",
      "step 71500 , training  accuracy 0.433333\n",
      "step 71500 , loss : 2.17524\n",
      "step 71500 , validation  accuracy 0.3044\n",
      "step 71500 , validation loss : 14.2203\n",
      "step 71600 , training  accuracy 0.333333\n",
      "step 71600 , loss : 2.16672\n",
      "step 71600 , validation  accuracy 0.3344\n",
      "step 71600 , validation loss : 15.4786\n",
      "step 71700 , training  accuracy 0.4\n",
      "step 71700 , loss : 2.1793\n",
      "step 71700 , validation  accuracy 0.3096\n",
      "step 71700 , validation loss : 13.7367\n",
      "step 71800 , training  accuracy 0.366667\n",
      "step 71800 , loss : 2.18217\n",
      "step 71800 , validation  accuracy 0.333\n",
      "step 71800 , validation loss : 14.8469\n",
      "step 71900 , training  accuracy 0.366667\n",
      "step 71900 , loss : 2.20886\n",
      "step 71900 , validation  accuracy 0.3202\n",
      "step 71900 , validation loss : 13.8608\n",
      "step 72000 , training  accuracy 0.533333\n",
      "step 72000 , loss : 2.12408\n",
      "step 72000 , validation  accuracy 0.3216\n",
      "step 72000 , validation loss : 14.2607\n",
      "step 72100 , training  accuracy 0.5\n",
      "step 72100 , loss : 2.1367\n",
      "step 72100 , validation  accuracy 0.32\n",
      "step 72100 , validation loss : 13.6506\n",
      "step 72200 , training  accuracy 0.3\n",
      "step 72200 , loss : 2.18119\n",
      "step 72200 , validation  accuracy 0.3096\n",
      "step 72200 , validation loss : 13.4665\n",
      "step 72300 , training  accuracy 0.466667\n",
      "step 72300 , loss : 2.12824\n",
      "step 72300 , validation  accuracy 0.3258\n",
      "step 72300 , validation loss : 14.9346\n",
      "step 72400 , training  accuracy 0.266667\n",
      "step 72400 , loss : 2.23768\n",
      "step 72400 , validation  accuracy 0.303\n",
      "step 72400 , validation loss : 13.8797\n",
      "step 72500 , training  accuracy 0.333333\n",
      "step 72500 , loss : 2.16396\n",
      "step 72500 , validation  accuracy 0.306\n",
      "step 72500 , validation loss : 14.381\n",
      "step 72600 , training  accuracy 0.5\n",
      "step 72600 , loss : 2.13308\n",
      "step 72600 , validation  accuracy 0.3194\n",
      "step 72600 , validation loss : 14.6802\n",
      "step 72700 , training  accuracy 0.566667\n",
      "step 72700 , loss : 2.13416\n",
      "step 72700 , validation  accuracy 0.323\n",
      "step 72700 , validation loss : 14.3124\n",
      "step 72800 , training  accuracy 0.5\n",
      "step 72800 , loss : 2.12843\n",
      "step 72800 , validation  accuracy 0.3146\n",
      "step 72800 , validation loss : 14.2263\n",
      "step 72900 , training  accuracy 0.4\n",
      "step 72900 , loss : 2.16988\n",
      "step 72900 , validation  accuracy 0.2938\n",
      "step 72900 , validation loss : 12.8325\n",
      "step 73000 , training  accuracy 0.433333\n",
      "step 73000 , loss : 2.17599\n",
      "step 73000 , validation  accuracy 0.2932\n",
      "step 73000 , validation loss : 13.1309\n",
      "step 73100 , training  accuracy 0.366667\n",
      "step 73100 , loss : 2.15373\n",
      "step 73100 , validation  accuracy 0.3122\n",
      "step 73100 , validation loss : 14.6352\n",
      "step 73200 , training  accuracy 0.433333\n",
      "step 73200 , loss : 2.14286\n",
      "step 73200 , validation  accuracy 0.302\n",
      "step 73200 , validation loss : 13.6171\n",
      "step 73300 , training  accuracy 0.5\n",
      "step 73300 , loss : 2.1013\n",
      "step 73300 , validation  accuracy 0.319\n",
      "step 73300 , validation loss : 14.8419\n",
      "step 73400 , training  accuracy 0.466667\n",
      "step 73400 , loss : 2.14357\n",
      "step 73400 , validation  accuracy 0.3258\n",
      "step 73400 , validation loss : 15.6953\n",
      "step 73500 , training  accuracy 0.7\n",
      "step 73500 , loss : 2.04719\n",
      "step 73500 , validation  accuracy 0.3144\n",
      "step 73500 , validation loss : 14.8708\n",
      "step 73600 , training  accuracy 0.4\n",
      "step 73600 , loss : 2.15294\n",
      "step 73600 , validation  accuracy 0.3086\n",
      "step 73600 , validation loss : 13.4093\n",
      "step 73700 , training  accuracy 0.466667\n",
      "step 73700 , loss : 2.16861\n",
      "step 73700 , validation  accuracy 0.3252\n",
      "step 73700 , validation loss : 14.7755\n",
      "step 73800 , training  accuracy 0.366667\n",
      "step 73800 , loss : 2.16286\n",
      "step 73800 , validation  accuracy 0.3274\n",
      "step 73800 , validation loss : 14.7449\n",
      "step 73900 , training  accuracy 0.433333\n",
      "step 73900 , loss : 2.11926\n",
      "step 73900 , validation  accuracy 0.32\n",
      "step 73900 , validation loss : 15.0102\n",
      "step 74000 , training  accuracy 0.366667\n",
      "step 74000 , loss : 2.13391\n",
      "step 74000 , validation  accuracy 0.3014\n",
      "step 74000 , validation loss : 14.5853\n",
      "step 74100 , training  accuracy 0.5\n",
      "step 74100 , loss : 2.1772\n",
      "step 74100 , validation  accuracy 0.3208\n",
      "step 74100 , validation loss : 14.4593\n",
      "step 74200 , training  accuracy 0.333333\n",
      "step 74200 , loss : 2.22209\n",
      "step 74200 , validation  accuracy 0.3136\n",
      "step 74200 , validation loss : 14.0817\n",
      "step 74300 , training  accuracy 0.4\n",
      "step 74300 , loss : 2.1815\n",
      "step 74300 , validation  accuracy 0.3054\n",
      "step 74300 , validation loss : 14.3449\n",
      "step 74400 , training  accuracy 0.466667\n",
      "step 74400 , loss : 2.10881\n",
      "step 74400 , validation  accuracy 0.3104\n",
      "step 74400 , validation loss : 14.0453\n",
      "step 74500 , training  accuracy 0.633333\n",
      "step 74500 , loss : 2.12243\n",
      "step 74500 , validation  accuracy 0.317\n",
      "step 74500 , validation loss : 14.5162\n",
      "step 74600 , training  accuracy 0.366667\n",
      "step 74600 , loss : 2.15646\n",
      "step 74600 , validation  accuracy 0.3084\n",
      "step 74600 , validation loss : 14.1215\n",
      "step 74700 , training  accuracy 0.366667\n",
      "step 74700 , loss : 2.16691\n",
      "step 74700 , validation  accuracy 0.3254\n",
      "step 74700 , validation loss : 15.3751\n",
      "step 74800 , training  accuracy 0.366667\n",
      "step 74800 , loss : 2.17622\n",
      "step 74800 , validation  accuracy 0.3138\n",
      "step 74800 , validation loss : 14.5133\n",
      "step 74900 , training  accuracy 0.4\n",
      "step 74900 , loss : 2.08331\n",
      "step 74900 , validation  accuracy 0.3208\n",
      "step 74900 , validation loss : 14.5063\n",
      "step 75000 , training  accuracy 0.6\n",
      "step 75000 , loss : 2.09466\n",
      "step 75000 , validation  accuracy 0.327\n",
      "step 75000 , validation loss : 15.0454\n",
      "step 75100 , training  accuracy 0.4\n",
      "step 75100 , loss : 2.12527\n",
      "step 75100 , validation  accuracy 0.3274\n",
      "step 75100 , validation loss : 14.9895\n",
      "step 75200 , training  accuracy 0.5\n",
      "step 75200 , loss : 2.04513\n",
      "step 75200 , validation  accuracy 0.3342\n",
      "step 75200 , validation loss : 16.3681\n",
      "step 75300 , training  accuracy 0.333333\n",
      "step 75300 , loss : 2.15774\n",
      "step 75300 , validation  accuracy 0.3326\n",
      "step 75300 , validation loss : 15.3199\n",
      "step 75400 , training  accuracy 0.5\n",
      "step 75400 , loss : 2.09707\n",
      "step 75400 , validation  accuracy 0.3188\n",
      "step 75400 , validation loss : 15.6271\n",
      "step 75500 , training  accuracy 0.5\n",
      "step 75500 , loss : 2.15101\n",
      "step 75500 , validation  accuracy 0.3146\n",
      "step 75500 , validation loss : 15.075\n",
      "step 75600 , training  accuracy 0.4\n",
      "step 75600 , loss : 2.13376\n",
      "step 75600 , validation  accuracy 0.3204\n",
      "step 75600 , validation loss : 14.0544\n",
      "step 75700 , training  accuracy 0.4\n",
      "step 75700 , loss : 2.15929\n",
      "step 75700 , validation  accuracy 0.3282\n",
      "step 75700 , validation loss : 16.1233\n",
      "step 75800 , training  accuracy 0.5\n",
      "step 75800 , loss : 2.11221\n",
      "step 75800 , validation  accuracy 0.323\n",
      "step 75800 , validation loss : 14.2675\n",
      "step 75900 , training  accuracy 0.466667\n",
      "step 75900 , loss : 2.14163\n",
      "step 75900 , validation  accuracy 0.3086\n",
      "step 75900 , validation loss : 14.1924\n",
      "step 76000 , training  accuracy 0.366667\n",
      "step 76000 , loss : 2.09812\n",
      "step 76000 , validation  accuracy 0.3356\n",
      "step 76000 , validation loss : 16.4927\n",
      "step 76100 , training  accuracy 0.366667\n",
      "step 76100 , loss : 2.1506\n",
      "step 76100 , validation  accuracy 0.3262\n",
      "step 76100 , validation loss : 16.6684\n",
      "step 76200 , training  accuracy 0.466667\n",
      "step 76200 , loss : 2.14994\n",
      "step 76200 , validation  accuracy 0.3232\n",
      "step 76200 , validation loss : 14.3912\n",
      "step 76300 , training  accuracy 0.433333\n",
      "step 76300 , loss : 2.12288\n",
      "step 76300 , validation  accuracy 0.318\n",
      "step 76300 , validation loss : 14.5316\n",
      "step 76400 , training  accuracy 0.466667\n",
      "step 76400 , loss : 2.179\n",
      "step 76400 , validation  accuracy 0.3174\n",
      "step 76400 , validation loss : 14.4937\n",
      "step 76500 , training  accuracy 0.4\n",
      "step 76500 , loss : 2.17622\n",
      "step 76500 , validation  accuracy 0.3012\n",
      "step 76500 , validation loss : 13.6721\n",
      "step 76600 , training  accuracy 0.4\n",
      "step 76600 , loss : 2.16307\n",
      "step 76600 , validation  accuracy 0.3066\n",
      "step 76600 , validation loss : 14.0026\n",
      "step 76700 , training  accuracy 0.466667\n",
      "step 76700 , loss : 2.12126\n",
      "step 76700 , validation  accuracy 0.3242\n",
      "step 76700 , validation loss : 15.2746\n",
      "step 76800 , training  accuracy 0.566667\n",
      "step 76800 , loss : 2.13228\n",
      "step 76800 , validation  accuracy 0.3124\n",
      "step 76800 , validation loss : 14.1214\n",
      "step 76900 , training  accuracy 0.4\n",
      "step 76900 , loss : 2.17327\n",
      "step 76900 , validation  accuracy 0.3182\n",
      "step 76900 , validation loss : 14.4735\n",
      "step 77000 , training  accuracy 0.566667\n",
      "step 77000 , loss : 2.08564\n",
      "step 77000 , validation  accuracy 0.3214\n",
      "step 77000 , validation loss : 16.3045\n",
      "step 77100 , training  accuracy 0.633333\n",
      "step 77100 , loss : 2.12254\n",
      "step 77100 , validation  accuracy 0.3018\n",
      "step 77100 , validation loss : 14.7519\n",
      "step 77200 , training  accuracy 0.466667\n",
      "step 77200 , loss : 2.14815\n",
      "step 77200 , validation  accuracy 0.3196\n",
      "step 77200 , validation loss : 14.8004\n",
      "step 77300 , training  accuracy 0.366667\n",
      "step 77300 , loss : 2.19562\n",
      "step 77300 , validation  accuracy 0.3072\n",
      "step 77300 , validation loss : 13.6718\n",
      "step 77400 , training  accuracy 0.433333\n",
      "step 77400 , loss : 2.13328\n",
      "step 77400 , validation  accuracy 0.3232\n",
      "step 77400 , validation loss : 15.2029\n",
      "step 77500 , training  accuracy 0.466667\n",
      "step 77500 , loss : 2.10812\n",
      "step 77500 , validation  accuracy 0.3226\n",
      "step 77500 , validation loss : 15.7589\n",
      "step 77600 , training  accuracy 0.566667\n",
      "step 77600 , loss : 2.0983\n",
      "step 77600 , validation  accuracy 0.3156\n",
      "step 77600 , validation loss : 14.1031\n",
      "step 77700 , training  accuracy 0.5\n",
      "step 77700 , loss : 2.0743\n",
      "step 77700 , validation  accuracy 0.3262\n",
      "step 77700 , validation loss : 15.0503\n",
      "step 77800 , training  accuracy 0.333333\n",
      "step 77800 , loss : 2.16441\n",
      "step 77800 , validation  accuracy 0.3324\n",
      "step 77800 , validation loss : 16.0412\n",
      "step 77900 , training  accuracy 0.466667\n",
      "step 77900 , loss : 2.14923\n",
      "step 77900 , validation  accuracy 0.318\n",
      "step 77900 , validation loss : 14.2118\n",
      "step 78000 , training  accuracy 0.5\n",
      "step 78000 , loss : 2.15358\n",
      "step 78000 , validation  accuracy 0.3216\n",
      "step 78000 , validation loss : 14.678\n",
      "step 78100 , training  accuracy 0.4\n",
      "step 78100 , loss : 2.19725\n",
      "step 78100 , validation  accuracy 0.3226\n",
      "step 78100 , validation loss : 15.8528\n",
      "step 78200 , training  accuracy 0.333333\n",
      "step 78200 , loss : 2.19535\n",
      "step 78200 , validation  accuracy 0.3148\n",
      "step 78200 , validation loss : 14.4749\n",
      "step 78300 , training  accuracy 0.4\n",
      "step 78300 , loss : 2.17065\n",
      "step 78300 , validation  accuracy 0.3148\n",
      "step 78300 , validation loss : 14.5092\n",
      "step 78400 , training  accuracy 0.4\n",
      "step 78400 , loss : 2.18785\n",
      "step 78400 , validation  accuracy 0.3134\n",
      "step 78400 , validation loss : 14.7865\n",
      "step 78500 , training  accuracy 0.5\n",
      "step 78500 , loss : 2.09692\n",
      "step 78500 , validation  accuracy 0.3238\n",
      "step 78500 , validation loss : 15.9932\n",
      "step 78600 , training  accuracy 0.533333\n",
      "step 78600 , loss : 2.13442\n",
      "step 78600 , validation  accuracy 0.31\n",
      "step 78600 , validation loss : 15.1927\n",
      "step 78700 , training  accuracy 0.433333\n",
      "step 78700 , loss : 2.18222\n",
      "step 78700 , validation  accuracy 0.3206\n",
      "step 78700 , validation loss : 15.1895\n",
      "step 78800 , training  accuracy 0.533333\n",
      "step 78800 , loss : 2.1142\n",
      "step 78800 , validation  accuracy 0.328\n",
      "step 78800 , validation loss : 15.8775\n",
      "step 78900 , training  accuracy 0.566667\n",
      "step 78900 , loss : 2.10834\n",
      "step 78900 , validation  accuracy 0.3232\n",
      "step 78900 , validation loss : 15.9951\n",
      "step 79000 , training  accuracy 0.366667\n",
      "step 79000 , loss : 2.13512\n",
      "step 79000 , validation  accuracy 0.2946\n",
      "step 79000 , validation loss : 14.6072\n",
      "step 79100 , training  accuracy 0.6\n",
      "step 79100 , loss : 2.12204\n",
      "step 79100 , validation  accuracy 0.3094\n",
      "step 79100 , validation loss : 14.9631\n",
      "step 79200 , training  accuracy 0.3\n",
      "step 79200 , loss : 2.16081\n",
      "step 79200 , validation  accuracy 0.3208\n",
      "step 79200 , validation loss : 15.3242\n",
      "step 79300 , training  accuracy 0.3\n",
      "step 79300 , loss : 2.19363\n",
      "step 79300 , validation  accuracy 0.3246\n",
      "step 79300 , validation loss : 15.7982\n",
      "step 79400 , training  accuracy 0.366667\n",
      "step 79400 , loss : 2.19147\n",
      "step 79400 , validation  accuracy 0.3288\n",
      "step 79400 , validation loss : 16.4774\n",
      "step 79500 , training  accuracy 0.333333\n",
      "step 79500 , loss : 2.18356\n",
      "step 79500 , validation  accuracy 0.3126\n",
      "step 79500 , validation loss : 14.6582\n",
      "step 79600 , training  accuracy 0.466667\n",
      "step 79600 , loss : 2.09752\n",
      "step 79600 , validation  accuracy 0.3284\n",
      "step 79600 , validation loss : 15.9371\n",
      "step 79700 , training  accuracy 0.3\n",
      "step 79700 , loss : 2.15396\n",
      "step 79700 , validation  accuracy 0.3368\n",
      "step 79700 , validation loss : 16.6371\n",
      "step 79800 , training  accuracy 0.533333\n",
      "step 79800 , loss : 2.08685\n",
      "step 79800 , validation  accuracy 0.3188\n",
      "step 79800 , validation loss : 15.9328\n",
      "step 79900 , training  accuracy 0.533333\n",
      "step 79900 , loss : 2.0647\n",
      "step 79900 , validation  accuracy 0.3218\n",
      "step 79900 , validation loss : 16.0223\n",
      "step 80000 , training  accuracy 0.433333\n",
      "step 80000 , loss : 2.15946\n",
      "step 80000 , validation  accuracy 0.316\n",
      "step 80000 , validation loss : 15.266\n",
      "step 80100 , training  accuracy 0.4\n",
      "step 80100 , loss : 2.18384\n",
      "step 80100 , validation  accuracy 0.307\n",
      "step 80100 , validation loss : 14.3482\n",
      "step 80200 , training  accuracy 0.5\n",
      "step 80200 , loss : 2.16766\n",
      "step 80200 , validation  accuracy 0.3144\n",
      "step 80200 , validation loss : 15.9765\n",
      "step 80300 , training  accuracy 0.433333\n",
      "step 80300 , loss : 2.12669\n",
      "step 80300 , validation  accuracy 0.313\n",
      "step 80300 , validation loss : 15.4285\n",
      "step 80400 , training  accuracy 0.5\n",
      "step 80400 , loss : 2.13609\n",
      "step 80400 , validation  accuracy 0.3174\n",
      "step 80400 , validation loss : 15.3388\n",
      "step 80500 , training  accuracy 0.6\n",
      "step 80500 , loss : 2.03696\n",
      "step 80500 , validation  accuracy 0.3194\n",
      "step 80500 , validation loss : 15.562\n",
      "step 80600 , training  accuracy 0.5\n",
      "step 80600 , loss : 2.09895\n",
      "step 80600 , validation  accuracy 0.3198\n",
      "step 80600 , validation loss : 14.9803\n",
      "step 80700 , training  accuracy 0.366667\n",
      "step 80700 , loss : 2.13546\n",
      "step 80700 , validation  accuracy 0.318\n",
      "step 80700 , validation loss : 15.8477\n",
      "step 80800 , training  accuracy 0.333333\n",
      "step 80800 , loss : 2.19373\n",
      "step 80800 , validation  accuracy 0.3008\n",
      "step 80800 , validation loss : 14.6174\n",
      "step 80900 , training  accuracy 0.3\n",
      "step 80900 , loss : 2.24603\n",
      "step 80900 , validation  accuracy 0.3082\n",
      "step 80900 , validation loss : 15.2011\n",
      "step 81000 , training  accuracy 0.466667\n",
      "step 81000 , loss : 2.1163\n",
      "step 81000 , validation  accuracy 0.3298\n",
      "step 81000 , validation loss : 17.0619\n",
      "step 81100 , training  accuracy 0.466667\n",
      "step 81100 , loss : 2.1855\n",
      "step 81100 , validation  accuracy 0.3134\n",
      "step 81100 , validation loss : 13.8589\n",
      "step 81200 , training  accuracy 0.533333\n",
      "step 81200 , loss : 2.0796\n",
      "step 81200 , validation  accuracy 0.3222\n",
      "step 81200 , validation loss : 15.9494\n",
      "step 81300 , training  accuracy 0.566667\n",
      "step 81300 , loss : 2.09745\n",
      "step 81300 , validation  accuracy 0.328\n",
      "step 81300 , validation loss : 16.0005\n",
      "step 81400 , training  accuracy 0.533333\n",
      "step 81400 , loss : 2.08566\n",
      "step 81400 , validation  accuracy 0.3364\n",
      "step 81400 , validation loss : 16.6499\n",
      "step 81500 , training  accuracy 0.433333\n",
      "step 81500 , loss : 2.16321\n",
      "step 81500 , validation  accuracy 0.307\n",
      "step 81500 , validation loss : 15.263\n",
      "step 81600 , training  accuracy 0.4\n",
      "step 81600 , loss : 2.17119\n",
      "step 81600 , validation  accuracy 0.3076\n",
      "step 81600 , validation loss : 15.3842\n",
      "step 81700 , training  accuracy 0.333333\n",
      "step 81700 , loss : 2.17338\n",
      "step 81700 , validation  accuracy 0.3224\n",
      "step 81700 , validation loss : 16.2779\n",
      "step 81800 , training  accuracy 0.566667\n",
      "step 81800 , loss : 2.09241\n",
      "step 81800 , validation  accuracy 0.3258\n",
      "step 81800 , validation loss : 15.9209\n",
      "step 81900 , training  accuracy 0.433333\n",
      "step 81900 , loss : 2.13997\n",
      "step 81900 , validation  accuracy 0.2974\n",
      "step 81900 , validation loss : 14.406\n",
      "step 82000 , training  accuracy 0.6\n",
      "step 82000 , loss : 2.10745\n",
      "step 82000 , validation  accuracy 0.3042\n",
      "step 82000 , validation loss : 15.7414\n",
      "step 82100 , training  accuracy 0.6\n",
      "step 82100 , loss : 2.07256\n",
      "step 82100 , validation  accuracy 0.325\n",
      "step 82100 , validation loss : 15.9714\n",
      "step 82200 , training  accuracy 0.6\n",
      "step 82200 , loss : 2.04812\n",
      "step 82200 , validation  accuracy 0.3132\n",
      "step 82200 , validation loss : 15.6991\n",
      "step 82300 , training  accuracy 0.333333\n",
      "step 82300 , loss : 2.15208\n",
      "step 82300 , validation  accuracy 0.3086\n",
      "step 82300 , validation loss : 16.3266\n",
      "step 82400 , training  accuracy 0.433333\n",
      "step 82400 , loss : 2.13545\n",
      "step 82400 , validation  accuracy 0.3102\n",
      "step 82400 , validation loss : 15.5985\n",
      "step 82500 , training  accuracy 0.5\n",
      "step 82500 , loss : 2.12328\n",
      "step 82500 , validation  accuracy 0.3238\n",
      "step 82500 , validation loss : 16.2012\n",
      "step 82600 , training  accuracy 0.533333\n",
      "step 82600 , loss : 2.12521\n",
      "step 82600 , validation  accuracy 0.3062\n",
      "step 82600 , validation loss : 14.921\n",
      "step 82700 , training  accuracy 0.433333\n",
      "step 82700 , loss : 2.18181\n",
      "step 82700 , validation  accuracy 0.3242\n",
      "step 82700 , validation loss : 17.3665\n",
      "step 82800 , training  accuracy 0.333333\n",
      "step 82800 , loss : 2.21684\n",
      "step 82800 , validation  accuracy 0.2874\n",
      "step 82800 , validation loss : 15.2668\n",
      "step 82900 , training  accuracy 0.433333\n",
      "step 82900 , loss : 2.13753\n",
      "step 82900 , validation  accuracy 0.335\n",
      "step 82900 , validation loss : 17.3356\n",
      "step 83000 , training  accuracy 0.5\n",
      "step 83000 , loss : 2.09234\n",
      "step 83000 , validation  accuracy 0.3206\n",
      "step 83000 , validation loss : 17.6308\n",
      "step 83100 , training  accuracy 0.533333\n",
      "step 83100 , loss : 2.12985\n",
      "step 83100 , validation  accuracy 0.315\n",
      "step 83100 , validation loss : 15.1591\n",
      "step 83200 , training  accuracy 0.466667\n",
      "step 83200 , loss : 2.14036\n",
      "step 83200 , validation  accuracy 0.3234\n",
      "step 83200 , validation loss : 16.2784\n",
      "step 83300 , training  accuracy 0.5\n",
      "step 83300 , loss : 2.09043\n",
      "step 83300 , validation  accuracy 0.3206\n",
      "step 83300 , validation loss : 16.5802\n",
      "step 83400 , training  accuracy 0.333333\n",
      "step 83400 , loss : 2.17926\n",
      "step 83400 , validation  accuracy 0.313\n",
      "step 83400 , validation loss : 15.708\n",
      "step 83500 , training  accuracy 0.466667\n",
      "step 83500 , loss : 2.16636\n",
      "step 83500 , validation  accuracy 0.3116\n",
      "step 83500 , validation loss : 15.3913\n",
      "step 83600 , training  accuracy 0.5\n",
      "step 83600 , loss : 2.13446\n",
      "step 83600 , validation  accuracy 0.3188\n",
      "step 83600 , validation loss : 15.3706\n",
      "step 83700 , training  accuracy 0.466667\n",
      "step 83700 , loss : 2.11312\n",
      "step 83700 , validation  accuracy 0.3146\n",
      "step 83700 , validation loss : 15.5866\n",
      "step 83800 , training  accuracy 0.5\n",
      "step 83800 , loss : 2.11606\n",
      "step 83800 , validation  accuracy 0.3\n",
      "step 83800 , validation loss : 14.6722\n",
      "step 83900 , training  accuracy 0.433333\n",
      "step 83900 , loss : 2.14725\n",
      "step 83900 , validation  accuracy 0.3172\n",
      "step 83900 , validation loss : 15.3412\n",
      "step 84000 , training  accuracy 0.433333\n",
      "step 84000 , loss : 2.1563\n",
      "step 84000 , validation  accuracy 0.2978\n",
      "step 84000 , validation loss : 15.1421\n",
      "step 84100 , training  accuracy 0.433333\n",
      "step 84100 , loss : 2.12465\n",
      "step 84100 , validation  accuracy 0.313\n",
      "step 84100 , validation loss : 16.9022\n",
      "step 84200 , training  accuracy 0.366667\n",
      "step 84200 , loss : 2.1442\n",
      "step 84200 , validation  accuracy 0.3102\n",
      "step 84200 , validation loss : 14.6464\n",
      "step 84300 , training  accuracy 0.533333\n",
      "step 84300 , loss : 2.09278\n",
      "step 84300 , validation  accuracy 0.327\n",
      "step 84300 , validation loss : 16.1551\n",
      "step 84400 , training  accuracy 0.533333\n",
      "step 84400 , loss : 2.12233\n",
      "step 84400 , validation  accuracy 0.3202\n",
      "step 84400 , validation loss : 16.7724\n",
      "step 84500 , training  accuracy 0.6\n",
      "step 84500 , loss : 2.11096\n",
      "step 84500 , validation  accuracy 0.3018\n",
      "step 84500 , validation loss : 14.882\n",
      "step 84600 , training  accuracy 0.5\n",
      "step 84600 , loss : 2.12676\n",
      "step 84600 , validation  accuracy 0.3144\n",
      "step 84600 , validation loss : 16.0637\n",
      "step 84700 , training  accuracy 0.333333\n",
      "step 84700 , loss : 2.18064\n",
      "step 84700 , validation  accuracy 0.3342\n",
      "step 84700 , validation loss : 17.0743\n",
      "step 84800 , training  accuracy 0.266667\n",
      "step 84800 , loss : 2.17089\n",
      "step 84800 , validation  accuracy 0.314\n",
      "step 84800 , validation loss : 15.6034\n",
      "step 84900 , training  accuracy 0.5\n",
      "step 84900 , loss : 2.14236\n",
      "step 84900 , validation  accuracy 0.3166\n",
      "step 84900 , validation loss : 15.6287\n",
      "step 85000 , training  accuracy 0.3\n",
      "step 85000 , loss : 2.16556\n",
      "step 85000 , validation  accuracy 0.3248\n",
      "step 85000 , validation loss : 16.9045\n",
      "step 85100 , training  accuracy 0.4\n",
      "step 85100 , loss : 2.18032\n",
      "step 85100 , validation  accuracy 0.321\n",
      "step 85100 , validation loss : 15.8399\n",
      "step 85200 , training  accuracy 0.533333\n",
      "step 85200 , loss : 2.1167\n",
      "step 85200 , validation  accuracy 0.3072\n",
      "step 85200 , validation loss : 15.019\n",
      "step 85300 , training  accuracy 0.333333\n",
      "step 85300 , loss : 2.191\n",
      "step 85300 , validation  accuracy 0.3158\n",
      "step 85300 , validation loss : 16.0503\n",
      "step 85400 , training  accuracy 0.533333\n",
      "step 85400 , loss : 2.11116\n",
      "step 85400 , validation  accuracy 0.3296\n",
      "step 85400 , validation loss : 17.0949\n",
      "step 85500 , training  accuracy 0.533333\n",
      "step 85500 , loss : 2.07933\n",
      "step 85500 , validation  accuracy 0.304\n",
      "step 85500 , validation loss : 14.9017\n",
      "step 85600 , training  accuracy 0.333333\n",
      "step 85600 , loss : 2.17646\n",
      "step 85600 , validation  accuracy 0.3052\n",
      "step 85600 , validation loss : 14.2635\n",
      "step 85700 , training  accuracy 0.5\n",
      "step 85700 , loss : 2.09308\n",
      "step 85700 , validation  accuracy 0.3194\n",
      "step 85700 , validation loss : 16.8403\n",
      "step 85800 , training  accuracy 0.466667\n",
      "step 85800 , loss : 2.12236\n",
      "step 85800 , validation  accuracy 0.3104\n",
      "step 85800 , validation loss : 15.967\n",
      "step 85900 , training  accuracy 0.4\n",
      "step 85900 , loss : 2.19727\n",
      "step 85900 , validation  accuracy 0.3202\n",
      "step 85900 , validation loss : 16.5205\n",
      "step 86000 , training  accuracy 0.533333\n",
      "step 86000 , loss : 2.12179\n",
      "step 86000 , validation  accuracy 0.3206\n",
      "step 86000 , validation loss : 16.3881\n",
      "step 86100 , training  accuracy 0.433333\n",
      "step 86100 , loss : 2.1452\n",
      "step 86100 , validation  accuracy 0.3304\n",
      "step 86100 , validation loss : 16.5632\n",
      "step 86200 , training  accuracy 0.4\n",
      "step 86200 , loss : 2.19233\n",
      "step 86200 , validation  accuracy 0.304\n",
      "step 86200 , validation loss : 14.757\n",
      "step 86300 , training  accuracy 0.4\n",
      "step 86300 , loss : 2.14275\n",
      "step 86300 , validation  accuracy 0.3252\n",
      "step 86300 , validation loss : 17.027\n",
      "step 86400 , training  accuracy 0.566667\n",
      "step 86400 , loss : 2.10114\n",
      "step 86400 , validation  accuracy 0.3252\n",
      "step 86400 , validation loss : 16.3397\n",
      "step 86500 , training  accuracy 0.433333\n",
      "step 86500 , loss : 2.19042\n",
      "step 86500 , validation  accuracy 0.3176\n",
      "step 86500 , validation loss : 17.2705\n",
      "step 86600 , training  accuracy 0.566667\n",
      "step 86600 , loss : 2.08049\n",
      "step 86600 , validation  accuracy 0.3078\n",
      "step 86600 , validation loss : 15.4611\n",
      "step 86700 , training  accuracy 0.4\n",
      "step 86700 , loss : 2.16015\n",
      "step 86700 , validation  accuracy 0.325\n",
      "step 86700 , validation loss : 17.1879\n",
      "step 86800 , training  accuracy 0.5\n",
      "step 86800 , loss : 2.1517\n",
      "step 86800 , validation  accuracy 0.3274\n",
      "step 86800 , validation loss : 16.6262\n",
      "step 86900 , training  accuracy 0.533333\n",
      "step 86900 , loss : 2.05729\n",
      "step 86900 , validation  accuracy 0.3216\n",
      "step 86900 , validation loss : 15.9038\n",
      "step 87000 , training  accuracy 0.466667\n",
      "step 87000 , loss : 2.13595\n",
      "step 87000 , validation  accuracy 0.3224\n",
      "step 87000 , validation loss : 16.4701\n",
      "step 87100 , training  accuracy 0.366667\n",
      "step 87100 , loss : 2.17047\n",
      "step 87100 , validation  accuracy 0.3236\n",
      "step 87100 , validation loss : 16.5572\n",
      "step 87200 , training  accuracy 0.433333\n",
      "step 87200 , loss : 2.18837\n",
      "step 87200 , validation  accuracy 0.318\n",
      "step 87200 , validation loss : 15.987\n",
      "step 87300 , training  accuracy 0.433333\n",
      "step 87300 , loss : 2.1135\n",
      "step 87300 , validation  accuracy 0.317\n",
      "step 87300 , validation loss : 15.9843\n",
      "step 87400 , training  accuracy 0.733333\n",
      "step 87400 , loss : 2.0815\n",
      "step 87400 , validation  accuracy 0.3244\n",
      "step 87400 , validation loss : 15.9468\n",
      "step 87500 , training  accuracy 0.466667\n",
      "step 87500 , loss : 2.10851\n",
      "step 87500 , validation  accuracy 0.329\n",
      "step 87500 , validation loss : 17.2164\n",
      "step 87600 , training  accuracy 0.466667\n",
      "step 87600 , loss : 2.13276\n",
      "step 87600 , validation  accuracy 0.3168\n",
      "step 87600 , validation loss : 15.7219\n",
      "step 87700 , training  accuracy 0.533333\n",
      "step 87700 , loss : 2.13698\n",
      "step 87700 , validation  accuracy 0.3146\n",
      "step 87700 , validation loss : 15.2028\n",
      "step 87800 , training  accuracy 0.433333\n",
      "step 87800 , loss : 2.09795\n",
      "step 87800 , validation  accuracy 0.3152\n",
      "step 87800 , validation loss : 15.964\n",
      "step 87900 , training  accuracy 0.366667\n",
      "step 87900 , loss : 2.19046\n",
      "step 87900 , validation  accuracy 0.3242\n",
      "step 87900 , validation loss : 16.2541\n",
      "step 88000 , training  accuracy 0.4\n",
      "step 88000 , loss : 2.18108\n",
      "step 88000 , validation  accuracy 0.3128\n",
      "step 88000 , validation loss : 15.9468\n",
      "step 88100 , training  accuracy 0.5\n",
      "step 88100 , loss : 2.15864\n",
      "step 88100 , validation  accuracy 0.3052\n",
      "step 88100 , validation loss : 14.8978\n",
      "step 88200 , training  accuracy 0.466667\n",
      "step 88200 , loss : 2.14753\n",
      "step 88200 , validation  accuracy 0.3292\n",
      "step 88200 , validation loss : 17.4163\n",
      "step 88300 , training  accuracy 0.4\n",
      "step 88300 , loss : 2.17461\n",
      "step 88300 , validation  accuracy 0.3194\n",
      "step 88300 , validation loss : 16.0224\n",
      "step 88400 , training  accuracy 0.4\n",
      "step 88400 , loss : 2.17826\n",
      "step 88400 , validation  accuracy 0.3246\n",
      "step 88400 , validation loss : 16.0034\n",
      "step 88500 , training  accuracy 0.533333\n",
      "step 88500 , loss : 2.08344\n",
      "step 88500 , validation  accuracy 0.3052\n",
      "step 88500 , validation loss : 15.9713\n",
      "step 88600 , training  accuracy 0.466667\n",
      "step 88600 , loss : 2.11394\n",
      "step 88600 , validation  accuracy 0.3158\n",
      "step 88600 , validation loss : 15.7572\n",
      "step 88700 , training  accuracy 0.633333\n",
      "step 88700 , loss : 2.0513\n",
      "step 88700 , validation  accuracy 0.3278\n",
      "step 88700 , validation loss : 16.4512\n",
      "step 88800 , training  accuracy 0.366667\n",
      "step 88800 , loss : 2.16322\n",
      "step 88800 , validation  accuracy 0.3118\n",
      "step 88800 , validation loss : 15.7337\n",
      "step 88900 , training  accuracy 0.333333\n",
      "step 88900 , loss : 2.17221\n",
      "step 88900 , validation  accuracy 0.3062\n",
      "step 88900 , validation loss : 16.0429\n",
      "step 89000 , training  accuracy 0.366667\n",
      "step 89000 , loss : 2.17001\n",
      "step 89000 , validation  accuracy 0.3322\n",
      "step 89000 , validation loss : 17.0649\n",
      "step 89100 , training  accuracy 0.566667\n",
      "step 89100 , loss : 2.11782\n",
      "step 89100 , validation  accuracy 0.331\n",
      "step 89100 , validation loss : 16.8981\n",
      "step 89200 , training  accuracy 0.466667\n",
      "step 89200 , loss : 2.13729\n",
      "step 89200 , validation  accuracy 0.323\n",
      "step 89200 , validation loss : 16.6876\n",
      "step 89300 , training  accuracy 0.466667\n",
      "step 89300 , loss : 2.09513\n",
      "step 89300 , validation  accuracy 0.3138\n",
      "step 89300 , validation loss : 16.4944\n",
      "step 89400 , training  accuracy 0.466667\n",
      "step 89400 , loss : 2.07622\n",
      "step 89400 , validation  accuracy 0.323\n",
      "step 89400 , validation loss : 16.8577\n",
      "step 89500 , training  accuracy 0.4\n",
      "step 89500 , loss : 2.09329\n",
      "step 89500 , validation  accuracy 0.3188\n",
      "step 89500 , validation loss : 18.1445\n",
      "step 89600 , training  accuracy 0.333333\n",
      "step 89600 , loss : 2.17863\n",
      "step 89600 , validation  accuracy 0.3256\n",
      "step 89600 , validation loss : 16.9108\n",
      "step 89700 , training  accuracy 0.6\n",
      "step 89700 , loss : 2.10623\n",
      "step 89700 , validation  accuracy 0.3226\n",
      "step 89700 , validation loss : 16.0262\n",
      "step 89800 , training  accuracy 0.466667\n",
      "step 89800 , loss : 2.14252\n",
      "step 89800 , validation  accuracy 0.3228\n",
      "step 89800 , validation loss : 16.227\n",
      "step 89900 , training  accuracy 0.666667\n",
      "step 89900 , loss : 2.05379\n",
      "step 89900 , validation  accuracy 0.3274\n",
      "step 89900 , validation loss : 16.7073\n",
      "step 90000 , training  accuracy 0.466667\n",
      "step 90000 , loss : 2.1914\n",
      "step 90000 , validation  accuracy 0.2898\n",
      "step 90000 , validation loss : 15.3123\n",
      "step 90100 , training  accuracy 0.533333\n",
      "step 90100 , loss : 2.10787\n",
      "step 90100 , validation  accuracy 0.3214\n",
      "step 90100 , validation loss : 16.3591\n",
      "step 90200 , training  accuracy 0.6\n",
      "step 90200 , loss : 2.02706\n",
      "step 90200 , validation  accuracy 0.328\n",
      "step 90200 , validation loss : 16.7118\n",
      "step 90300 , training  accuracy 0.5\n",
      "step 90300 , loss : 2.14551\n",
      "step 90300 , validation  accuracy 0.3296\n",
      "step 90300 , validation loss : 17.1129\n",
      "step 90400 , training  accuracy 0.433333\n",
      "step 90400 , loss : 2.19056\n",
      "step 90400 , validation  accuracy 0.3132\n",
      "step 90400 , validation loss : 16.5827\n",
      "step 90500 , training  accuracy 0.433333\n",
      "step 90500 , loss : 2.14217\n",
      "step 90500 , validation  accuracy 0.317\n",
      "step 90500 , validation loss : 16.2686\n",
      "step 90600 , training  accuracy 0.6\n",
      "step 90600 , loss : 2.06263\n",
      "step 90600 , validation  accuracy 0.3186\n",
      "step 90600 , validation loss : 16.3532\n",
      "step 90700 , training  accuracy 0.366667\n",
      "step 90700 , loss : 2.20475\n",
      "step 90700 , validation  accuracy 0.3258\n",
      "step 90700 , validation loss : 16.346\n",
      "step 90800 , training  accuracy 0.633333\n",
      "step 90800 , loss : 2.04511\n",
      "step 90800 , validation  accuracy 0.3168\n",
      "step 90800 , validation loss : 16.239\n",
      "step 90900 , training  accuracy 0.5\n",
      "step 90900 , loss : 2.10426\n",
      "step 90900 , validation  accuracy 0.3228\n",
      "step 90900 , validation loss : 17.268\n",
      "step 91000 , training  accuracy 0.4\n",
      "step 91000 , loss : 2.11327\n",
      "step 91000 , validation  accuracy 0.3084\n",
      "step 91000 , validation loss : 16.155\n",
      "step 91100 , training  accuracy 0.533333\n",
      "step 91100 , loss : 2.12614\n",
      "step 91100 , validation  accuracy 0.318\n",
      "step 91100 , validation loss : 16.5663\n",
      "step 91200 , training  accuracy 0.5\n",
      "step 91200 , loss : 2.09554\n",
      "step 91200 , validation  accuracy 0.3338\n",
      "step 91200 , validation loss : 17.8109\n",
      "step 91300 , training  accuracy 0.433333\n",
      "step 91300 , loss : 2.13759\n",
      "step 91300 , validation  accuracy 0.3148\n",
      "step 91300 , validation loss : 16.2828\n",
      "step 91400 , training  accuracy 0.566667\n",
      "step 91400 , loss : 2.08894\n",
      "step 91400 , validation  accuracy 0.322\n",
      "step 91400 , validation loss : 16.3285\n",
      "step 91500 , training  accuracy 0.633333\n",
      "step 91500 , loss : 2.10821\n",
      "step 91500 , validation  accuracy 0.3074\n",
      "step 91500 , validation loss : 15.4895\n",
      "step 91600 , training  accuracy 0.366667\n",
      "step 91600 , loss : 2.16557\n",
      "step 91600 , validation  accuracy 0.3238\n",
      "step 91600 , validation loss : 17.0364\n",
      "step 91700 , training  accuracy 0.6\n",
      "step 91700 , loss : 2.10392\n",
      "step 91700 , validation  accuracy 0.3332\n",
      "step 91700 , validation loss : 17.7374\n",
      "step 91800 , training  accuracy 0.6\n",
      "step 91800 , loss : 2.04422\n",
      "step 91800 , validation  accuracy 0.3142\n",
      "step 91800 , validation loss : 17.0358\n",
      "step 91900 , training  accuracy 0.533333\n",
      "step 91900 , loss : 2.09092\n",
      "step 91900 , validation  accuracy 0.309\n",
      "step 91900 , validation loss : 15.5304\n",
      "step 92000 , training  accuracy 0.533333\n",
      "step 92000 , loss : 2.07587\n",
      "step 92000 , validation  accuracy 0.3166\n",
      "step 92000 , validation loss : 17.7597\n",
      "step 92100 , training  accuracy 0.6\n",
      "step 92100 , loss : 2.09764\n",
      "step 92100 , validation  accuracy 0.3094\n",
      "step 92100 , validation loss : 15.9491\n",
      "step 92200 , training  accuracy 0.533333\n",
      "step 92200 , loss : 2.1254\n",
      "step 92200 , validation  accuracy 0.3114\n",
      "step 92200 , validation loss : 17.3637\n",
      "step 92300 , training  accuracy 0.7\n",
      "step 92300 , loss : 2.06456\n",
      "step 92300 , validation  accuracy 0.3262\n",
      "step 92300 , validation loss : 17.4023\n",
      "step 92400 , training  accuracy 0.433333\n",
      "step 92400 , loss : 2.1283\n",
      "step 92400 , validation  accuracy 0.3296\n",
      "step 92400 , validation loss : 17.5528\n",
      "step 92500 , training  accuracy 0.366667\n",
      "step 92500 , loss : 2.16771\n",
      "step 92500 , validation  accuracy 0.3176\n",
      "step 92500 , validation loss : 16.9218\n",
      "step 92600 , training  accuracy 0.533333\n",
      "step 92600 , loss : 2.11836\n",
      "step 92600 , validation  accuracy 0.2962\n",
      "step 92600 , validation loss : 16.0381\n",
      "step 92700 , training  accuracy 0.5\n",
      "step 92700 , loss : 2.17134\n",
      "step 92700 , validation  accuracy 0.3128\n",
      "step 92700 , validation loss : 15.7442\n",
      "step 92800 , training  accuracy 0.366667\n",
      "step 92800 , loss : 2.18475\n",
      "step 92800 , validation  accuracy 0.3236\n",
      "step 92800 , validation loss : 17.5144\n",
      "step 92900 , training  accuracy 0.566667\n",
      "step 92900 , loss : 2.06801\n",
      "step 92900 , validation  accuracy 0.3302\n",
      "step 92900 , validation loss : 17.8317\n",
      "step 93000 , training  accuracy 0.533333\n",
      "step 93000 , loss : 2.11298\n",
      "step 93000 , validation  accuracy 0.3298\n",
      "step 93000 , validation loss : 17.0543\n",
      "step 93100 , training  accuracy 0.6\n",
      "step 93100 , loss : 2.1308\n",
      "step 93100 , validation  accuracy 0.3082\n",
      "step 93100 , validation loss : 16.9207\n",
      "step 93200 , training  accuracy 0.533333\n",
      "step 93200 , loss : 2.11375\n",
      "step 93200 , validation  accuracy 0.3324\n",
      "step 93200 , validation loss : 18.0169\n",
      "step 93300 , training  accuracy 0.366667\n",
      "step 93300 , loss : 2.1808\n",
      "step 93300 , validation  accuracy 0.3158\n",
      "step 93300 , validation loss : 16.2436\n",
      "step 93400 , training  accuracy 0.433333\n",
      "step 93400 , loss : 2.18588\n",
      "step 93400 , validation  accuracy 0.3232\n",
      "step 93400 , validation loss : 17.6084\n",
      "step 93500 , training  accuracy 0.366667\n",
      "step 93500 , loss : 2.19526\n",
      "step 93500 , validation  accuracy 0.3144\n",
      "step 93500 , validation loss : 16.9891\n",
      "step 93600 , training  accuracy 0.5\n",
      "step 93600 , loss : 2.1315\n",
      "step 93600 , validation  accuracy 0.3104\n",
      "step 93600 , validation loss : 16.4634\n",
      "step 93700 , training  accuracy 0.4\n",
      "step 93700 , loss : 2.15896\n",
      "step 93700 , validation  accuracy 0.3216\n",
      "step 93700 , validation loss : 17.1763\n",
      "step 93800 , training  accuracy 0.433333\n",
      "step 93800 , loss : 2.16387\n",
      "step 93800 , validation  accuracy 0.3042\n",
      "step 93800 , validation loss : 15.54\n",
      "step 93900 , training  accuracy 0.6\n",
      "step 93900 , loss : 2.05921\n",
      "step 93900 , validation  accuracy 0.3018\n",
      "step 93900 , validation loss : 17.3155\n",
      "step 94000 , training  accuracy 0.566667\n",
      "step 94000 , loss : 2.10966\n",
      "step 94000 , validation  accuracy 0.2994\n",
      "step 94000 , validation loss : 16.6655\n",
      "step 94100 , training  accuracy 0.6\n",
      "step 94100 , loss : 2.10564\n",
      "step 94100 , validation  accuracy 0.3104\n",
      "step 94100 , validation loss : 17.4727\n",
      "step 94200 , training  accuracy 0.366667\n",
      "step 94200 , loss : 2.11546\n",
      "step 94200 , validation  accuracy 0.3066\n",
      "step 94200 , validation loss : 18.3039\n",
      "step 94300 , training  accuracy 0.566667\n",
      "step 94300 , loss : 2.11098\n",
      "step 94300 , validation  accuracy 0.2896\n",
      "step 94300 , validation loss : 15.706\n",
      "step 94400 , training  accuracy 0.4\n",
      "step 94400 , loss : 2.14495\n",
      "step 94400 , validation  accuracy 0.3124\n",
      "step 94400 , validation loss : 16.6452\n",
      "step 94500 , training  accuracy 0.533333\n",
      "step 94500 , loss : 2.09665\n",
      "step 94500 , validation  accuracy 0.3306\n",
      "step 94500 , validation loss : 19.6573\n",
      "step 94600 , training  accuracy 0.566667\n",
      "step 94600 , loss : 2.10848\n",
      "step 94600 , validation  accuracy 0.3102\n",
      "step 94600 , validation loss : 16.034\n",
      "step 94700 , training  accuracy 0.533333\n",
      "step 94700 , loss : 2.1408\n",
      "step 94700 , validation  accuracy 0.31\n",
      "step 94700 , validation loss : 16.6579\n",
      "step 94800 , training  accuracy 0.466667\n",
      "step 94800 , loss : 2.16506\n",
      "step 94800 , validation  accuracy 0.321\n",
      "step 94800 , validation loss : 17.1974\n",
      "step 94900 , training  accuracy 0.666667\n",
      "step 94900 , loss : 2.0856\n",
      "step 94900 , validation  accuracy 0.3168\n",
      "step 94900 , validation loss : 17.3331\n",
      "step 95000 , training  accuracy 0.4\n",
      "step 95000 , loss : 2.17269\n",
      "step 95000 , validation  accuracy 0.3132\n",
      "step 95000 , validation loss : 17.5445\n",
      "step 95100 , training  accuracy 0.5\n",
      "step 95100 , loss : 2.11934\n",
      "step 95100 , validation  accuracy 0.318\n",
      "step 95100 , validation loss : 16.6072\n",
      "step 95200 , training  accuracy 0.5\n",
      "step 95200 , loss : 2.06799\n",
      "step 95200 , validation  accuracy 0.3226\n",
      "step 95200 , validation loss : 17.7633\n",
      "step 95300 , training  accuracy 0.466667\n",
      "step 95300 , loss : 2.09374\n",
      "step 95300 , validation  accuracy 0.32\n",
      "step 95300 , validation loss : 16.5578\n",
      "step 95400 , training  accuracy 0.533333\n",
      "step 95400 , loss : 2.09852\n",
      "step 95400 , validation  accuracy 0.3252\n",
      "step 95400 , validation loss : 17.1719\n",
      "step 95500 , training  accuracy 0.6\n",
      "step 95500 , loss : 2.07044\n",
      "step 95500 , validation  accuracy 0.3216\n",
      "step 95500 , validation loss : 17.4525\n",
      "step 95600 , training  accuracy 0.4\n",
      "step 95600 , loss : 2.18127\n",
      "step 95600 , validation  accuracy 0.3146\n",
      "step 95600 , validation loss : 16.4343\n",
      "step 95700 , training  accuracy 0.466667\n",
      "step 95700 , loss : 2.10877\n",
      "step 95700 , validation  accuracy 0.3196\n",
      "step 95700 , validation loss : 17.3987\n",
      "step 95800 , training  accuracy 0.5\n",
      "step 95800 , loss : 2.16625\n",
      "step 95800 , validation  accuracy 0.3196\n",
      "step 95800 , validation loss : 18.2968\n",
      "step 95900 , training  accuracy 0.5\n",
      "step 95900 , loss : 2.1018\n",
      "step 95900 , validation  accuracy 0.3018\n",
      "step 95900 , validation loss : 15.8823\n",
      "step 96000 , training  accuracy 0.6\n",
      "step 96000 , loss : 2.1067\n",
      "step 96000 , validation  accuracy 0.3094\n",
      "step 96000 , validation loss : 16.7748\n",
      "step 96100 , training  accuracy 0.533333\n",
      "step 96100 , loss : 2.12703\n",
      "step 96100 , validation  accuracy 0.2986\n",
      "step 96100 , validation loss : 17.0406\n",
      "step 96200 , training  accuracy 0.266667\n",
      "step 96200 , loss : 2.1623\n",
      "step 96200 , validation  accuracy 0.3242\n",
      "step 96200 , validation loss : 17.444\n",
      "step 96300 , training  accuracy 0.5\n",
      "step 96300 , loss : 2.11602\n",
      "step 96300 , validation  accuracy 0.3256\n",
      "step 96300 , validation loss : 17.7879\n",
      "step 96400 , training  accuracy 0.466667\n",
      "step 96400 , loss : 2.07946\n",
      "step 96400 , validation  accuracy 0.3156\n",
      "step 96400 , validation loss : 17.3874\n",
      "step 96500 , training  accuracy 0.433333\n",
      "step 96500 , loss : 2.15192\n",
      "step 96500 , validation  accuracy 0.3264\n",
      "step 96500 , validation loss : 17.873\n",
      "step 96600 , training  accuracy 0.466667\n",
      "step 96600 , loss : 2.18687\n",
      "step 96600 , validation  accuracy 0.3198\n",
      "step 96600 , validation loss : 16.5704\n",
      "step 96700 , training  accuracy 0.466667\n",
      "step 96700 , loss : 2.08359\n",
      "step 96700 , validation  accuracy 0.3084\n",
      "step 96700 , validation loss : 16.0335\n",
      "step 96800 , training  accuracy 0.333333\n",
      "step 96800 , loss : 2.20769\n",
      "step 96800 , validation  accuracy 0.3126\n",
      "step 96800 , validation loss : 17.0459\n",
      "step 96900 , training  accuracy 0.4\n",
      "step 96900 , loss : 2.10622\n",
      "step 96900 , validation  accuracy 0.3132\n",
      "step 96900 , validation loss : 17.7037\n",
      "step 97000 , training  accuracy 0.5\n",
      "step 97000 , loss : 2.1194\n",
      "step 97000 , validation  accuracy 0.3224\n",
      "step 97000 , validation loss : 17.0392\n",
      "step 97100 , training  accuracy 0.5\n",
      "step 97100 , loss : 2.17553\n",
      "step 97100 , validation  accuracy 0.3044\n",
      "step 97100 , validation loss : 16.1936\n",
      "step 97200 , training  accuracy 0.566667\n",
      "step 97200 , loss : 2.07636\n",
      "step 97200 , validation  accuracy 0.3158\n",
      "step 97200 , validation loss : 17.5712\n",
      "step 97300 , training  accuracy 0.466667\n",
      "step 97300 , loss : 2.12402\n",
      "step 97300 , validation  accuracy 0.3262\n",
      "step 97300 , validation loss : 18.5679\n",
      "step 97400 , training  accuracy 0.666667\n",
      "step 97400 , loss : 2.10315\n",
      "step 97400 , validation  accuracy 0.3176\n",
      "step 97400 , validation loss : 17.7178\n",
      "step 97500 , training  accuracy 0.566667\n",
      "step 97500 , loss : 2.12696\n",
      "step 97500 , validation  accuracy 0.297\n",
      "step 97500 , validation loss : 16.7641\n",
      "step 97600 , training  accuracy 0.6\n",
      "step 97600 , loss : 2.01695\n",
      "step 97600 , validation  accuracy 0.3078\n",
      "step 97600 , validation loss : 18.6073\n",
      "step 97700 , training  accuracy 0.5\n",
      "step 97700 , loss : 2.08308\n",
      "step 97700 , validation  accuracy 0.3184\n",
      "step 97700 , validation loss : 17.7207\n",
      "step 97800 , training  accuracy 0.433333\n",
      "step 97800 , loss : 2.14529\n",
      "step 97800 , validation  accuracy 0.2994\n",
      "step 97800 , validation loss : 16.1473\n",
      "step 97900 , training  accuracy 0.4\n",
      "step 97900 , loss : 2.14691\n",
      "step 97900 , validation  accuracy 0.3034\n",
      "step 97900 , validation loss : 16.1654\n",
      "step 98000 , training  accuracy 0.533333\n",
      "step 98000 , loss : 2.14174\n",
      "step 98000 , validation  accuracy 0.2934\n",
      "step 98000 , validation loss : 16.9556\n",
      "step 98100 , training  accuracy 0.5\n",
      "step 98100 , loss : 2.13069\n",
      "step 98100 , validation  accuracy 0.323\n",
      "step 98100 , validation loss : 18.2817\n",
      "step 98200 , training  accuracy 0.5\n",
      "step 98200 , loss : 2.10228\n",
      "step 98200 , validation  accuracy 0.3172\n",
      "step 98200 , validation loss : 18.0432\n",
      "step 98300 , training  accuracy 0.466667\n",
      "step 98300 , loss : 2.18639\n",
      "step 98300 , validation  accuracy 0.3124\n",
      "step 98300 , validation loss : 17.0964\n",
      "step 98400 , training  accuracy 0.5\n",
      "step 98400 , loss : 2.11623\n",
      "step 98400 , validation  accuracy 0.3322\n",
      "step 98400 , validation loss : 18.7822\n",
      "step 98500 , training  accuracy 0.4\n",
      "step 98500 , loss : 2.13062\n",
      "step 98500 , validation  accuracy 0.3172\n",
      "step 98500 , validation loss : 17.2738\n",
      "step 98600 , training  accuracy 0.4\n",
      "step 98600 , loss : 2.16661\n",
      "step 98600 , validation  accuracy 0.3098\n",
      "step 98600 , validation loss : 16.6687\n",
      "step 98700 , training  accuracy 0.666667\n",
      "step 98700 , loss : 2.08762\n",
      "step 98700 , validation  accuracy 0.3054\n",
      "step 98700 , validation loss : 16.6146\n",
      "step 98800 , training  accuracy 0.5\n",
      "step 98800 , loss : 2.11445\n",
      "step 98800 , validation  accuracy 0.3184\n",
      "step 98800 , validation loss : 17.1448\n",
      "step 98900 , training  accuracy 0.466667\n",
      "step 98900 , loss : 2.16198\n",
      "step 98900 , validation  accuracy 0.2924\n",
      "step 98900 , validation loss : 15.5114\n",
      "step 99000 , training  accuracy 0.4\n",
      "step 99000 , loss : 2.17415\n",
      "step 99000 , validation  accuracy 0.2866\n",
      "step 99000 , validation loss : 16.3995\n",
      "step 99100 , training  accuracy 0.633333\n",
      "step 99100 , loss : 2.08043\n",
      "step 99100 , validation  accuracy 0.3052\n",
      "step 99100 , validation loss : 16.2381\n",
      "step 99200 , training  accuracy 0.5\n",
      "step 99200 , loss : 2.11489\n",
      "step 99200 , validation  accuracy 0.3226\n",
      "step 99200 , validation loss : 17.4261\n",
      "step 99300 , training  accuracy 0.6\n",
      "step 99300 , loss : 2.04722\n",
      "step 99300 , validation  accuracy 0.3142\n",
      "step 99300 , validation loss : 18.1919\n",
      "step 99400 , training  accuracy 0.6\n",
      "step 99400 , loss : 2.09977\n",
      "step 99400 , validation  accuracy 0.3116\n",
      "step 99400 , validation loss : 16.0181\n",
      "step 99500 , training  accuracy 0.466667\n",
      "step 99500 , loss : 2.14925\n",
      "step 99500 , validation  accuracy 0.315\n",
      "step 99500 , validation loss : 16.9037\n",
      "step 99600 , training  accuracy 0.5\n",
      "step 99600 , loss : 2.14614\n",
      "step 99600 , validation  accuracy 0.3214\n",
      "step 99600 , validation loss : 17.1297\n",
      "step 99700 , training  accuracy 0.766667\n",
      "step 99700 , loss : 2.04539\n",
      "step 99700 , validation  accuracy 0.3336\n",
      "step 99700 , validation loss : 18.9546\n",
      "step 99800 , training  accuracy 0.366667\n",
      "step 99800 , loss : 2.2067\n",
      "step 99800 , validation  accuracy 0.2996\n",
      "step 99800 , validation loss : 17.1397\n",
      "step 99900 , training  accuracy 0.633333\n",
      "step 99900 , loss : 2.03873\n",
      "step 99900 , validation  accuracy 0.3238\n",
      "step 99900 , validation loss : 18.6753\n",
      "step 100000 , training  accuracy 0.333333\n",
      "step 100000 , loss : 2.19597\n",
      "step 100000 , validation  accuracy 0.3264\n",
      "step 100000 , validation loss : 17.6461\n",
      "step 100100 , training  accuracy 0.5\n",
      "step 100100 , loss : 2.14095\n",
      "step 100100 , validation  accuracy 0.316\n",
      "step 100100 , validation loss : 17.0776\n",
      "step 100200 , training  accuracy 0.433333\n",
      "step 100200 , loss : 2.12807\n",
      "step 100200 , validation  accuracy 0.3148\n",
      "step 100200 , validation loss : 17.3257\n",
      "step 100300 , training  accuracy 0.4\n",
      "step 100300 , loss : 2.14577\n",
      "step 100300 , validation  accuracy 0.3264\n",
      "step 100300 , validation loss : 17.904\n",
      "step 100400 , training  accuracy 0.6\n",
      "step 100400 , loss : 2.08379\n",
      "step 100400 , validation  accuracy 0.319\n",
      "step 100400 , validation loss : 17.7247\n",
      "step 100500 , training  accuracy 0.666667\n",
      "step 100500 , loss : 2.04486\n",
      "step 100500 , validation  accuracy 0.3138\n",
      "step 100500 , validation loss : 18.641\n",
      "step 100600 , training  accuracy 0.533333\n",
      "step 100600 , loss : 2.14001\n",
      "step 100600 , validation  accuracy 0.318\n",
      "step 100600 , validation loss : 16.8729\n",
      "step 100700 , training  accuracy 0.366667\n",
      "step 100700 , loss : 2.15777\n",
      "step 100700 , validation  accuracy 0.3276\n",
      "step 100700 , validation loss : 18.0257\n",
      "step 100800 , training  accuracy 0.466667\n",
      "step 100800 , loss : 2.12534\n",
      "step 100800 , validation  accuracy 0.31\n",
      "step 100800 , validation loss : 16.4461\n",
      "step 100900 , training  accuracy 0.5\n",
      "step 100900 , loss : 2.09375\n",
      "step 100900 , validation  accuracy 0.3294\n",
      "step 100900 , validation loss : 18.0747\n",
      "step 101000 , training  accuracy 0.466667\n",
      "step 101000 , loss : 2.12892\n",
      "step 101000 , validation  accuracy 0.3222\n",
      "step 101000 , validation loss : 18.0877\n",
      "step 101100 , training  accuracy 0.366667\n",
      "step 101100 , loss : 2.21433\n",
      "step 101100 , validation  accuracy 0.323\n",
      "step 101100 , validation loss : 17.7042\n",
      "step 101200 , training  accuracy 0.5\n",
      "step 101200 , loss : 2.0635\n",
      "step 101200 , validation  accuracy 0.3288\n",
      "step 101200 , validation loss : 18.4214\n",
      "step 101300 , training  accuracy 0.7\n",
      "step 101300 , loss : 2.04683\n",
      "step 101300 , validation  accuracy 0.316\n",
      "step 101300 , validation loss : 16.9437\n",
      "step 101400 , training  accuracy 0.5\n",
      "step 101400 , loss : 2.1395\n",
      "step 101400 , validation  accuracy 0.3184\n",
      "step 101400 , validation loss : 17.1349\n",
      "step 101500 , training  accuracy 0.466667\n",
      "step 101500 , loss : 2.13302\n",
      "step 101500 , validation  accuracy 0.3006\n",
      "step 101500 , validation loss : 16.6655\n",
      "step 101600 , training  accuracy 0.333333\n",
      "step 101600 , loss : 2.2379\n",
      "step 101600 , validation  accuracy 0.3062\n",
      "step 101600 , validation loss : 16.4122\n",
      "step 101700 , training  accuracy 0.533333\n",
      "step 101700 , loss : 2.11913\n",
      "step 101700 , validation  accuracy 0.3296\n",
      "step 101700 , validation loss : 19.1716\n",
      "step 101800 , training  accuracy 0.566667\n",
      "step 101800 , loss : 2.1058\n",
      "step 101800 , validation  accuracy 0.3172\n",
      "step 101800 , validation loss : 17.6859\n",
      "step 101900 , training  accuracy 0.566667\n",
      "step 101900 , loss : 2.09643\n",
      "step 101900 , validation  accuracy 0.3258\n",
      "step 101900 , validation loss : 18.8677\n",
      "step 102000 , training  accuracy 0.333333\n",
      "step 102000 , loss : 2.18288\n",
      "step 102000 , validation  accuracy 0.3062\n",
      "step 102000 , validation loss : 17.5875\n",
      "step 102100 , training  accuracy 0.533333\n",
      "step 102100 , loss : 2.11604\n",
      "step 102100 , validation  accuracy 0.3132\n",
      "step 102100 , validation loss : 17.9952\n",
      "step 102200 , training  accuracy 0.433333\n",
      "step 102200 , loss : 2.17117\n",
      "step 102200 , validation  accuracy 0.325\n",
      "step 102200 , validation loss : 18.5931\n",
      "step 102300 , training  accuracy 0.533333\n",
      "step 102300 , loss : 2.09986\n",
      "step 102300 , validation  accuracy 0.323\n",
      "step 102300 , validation loss : 19.0357\n",
      "step 102400 , training  accuracy 0.533333\n",
      "step 102400 , loss : 2.0635\n",
      "step 102400 , validation  accuracy 0.3144\n",
      "step 102400 , validation loss : 17.2993\n",
      "step 102500 , training  accuracy 0.433333\n",
      "step 102500 , loss : 2.13757\n",
      "step 102500 , validation  accuracy 0.313\n",
      "step 102500 , validation loss : 19.1228\n",
      "step 102600 , training  accuracy 0.433333\n",
      "step 102600 , loss : 2.16739\n",
      "step 102600 , validation  accuracy 0.3202\n",
      "step 102600 , validation loss : 19.5169\n",
      "step 102700 , training  accuracy 0.266667\n",
      "step 102700 , loss : 2.21795\n",
      "step 102700 , validation  accuracy 0.3248\n",
      "step 102700 , validation loss : 18.6289\n",
      "step 102800 , training  accuracy 0.533333\n",
      "step 102800 , loss : 2.09043\n",
      "step 102800 , validation  accuracy 0.325\n",
      "step 102800 , validation loss : 18.683\n",
      "step 102900 , training  accuracy 0.333333\n",
      "step 102900 , loss : 2.20037\n",
      "step 102900 , validation  accuracy 0.3182\n",
      "step 102900 , validation loss : 17.5647\n",
      "step 103000 , training  accuracy 0.433333\n",
      "step 103000 , loss : 2.14573\n",
      "step 103000 , validation  accuracy 0.315\n",
      "step 103000 , validation loss : 18.0693\n",
      "step 103100 , training  accuracy 0.466667\n",
      "step 103100 , loss : 2.17594\n",
      "step 103100 , validation  accuracy 0.3208\n",
      "step 103100 , validation loss : 17.248\n",
      "step 103200 , training  accuracy 0.366667\n",
      "step 103200 , loss : 2.15941\n",
      "step 103200 , validation  accuracy 0.3204\n",
      "step 103200 , validation loss : 18.3559\n",
      "step 103300 , training  accuracy 0.533333\n",
      "step 103300 , loss : 2.10749\n",
      "step 103300 , validation  accuracy 0.3094\n",
      "step 103300 , validation loss : 16.878\n",
      "step 103400 , training  accuracy 0.366667\n",
      "step 103400 , loss : 2.21544\n",
      "step 103400 , validation  accuracy 0.3136\n",
      "step 103400 , validation loss : 17.3411\n",
      "step 103500 , training  accuracy 0.466667\n",
      "step 103500 , loss : 2.0975\n",
      "step 103500 , validation  accuracy 0.3064\n",
      "step 103500 , validation loss : 18.3017\n",
      "step 103600 , training  accuracy 0.533333\n",
      "step 103600 , loss : 2.11078\n",
      "step 103600 , validation  accuracy 0.2878\n",
      "step 103600 , validation loss : 16.6966\n",
      "step 103700 , training  accuracy 0.466667\n",
      "step 103700 , loss : 2.13929\n",
      "step 103700 , validation  accuracy 0.2962\n",
      "step 103700 , validation loss : 16.5127\n",
      "step 103800 , training  accuracy 0.366667\n",
      "step 103800 , loss : 2.08706\n",
      "step 103800 , validation  accuracy 0.3216\n",
      "step 103800 , validation loss : 17.6006\n",
      "step 103900 , training  accuracy 0.533333\n",
      "step 103900 , loss : 2.08418\n",
      "step 103900 , validation  accuracy 0.305\n",
      "step 103900 , validation loss : 17.7606\n",
      "step 104000 , training  accuracy 0.6\n",
      "step 104000 , loss : 2.10818\n",
      "step 104000 , validation  accuracy 0.2918\n",
      "step 104000 , validation loss : 17.0231\n",
      "step 104100 , training  accuracy 0.466667\n",
      "step 104100 , loss : 2.11399\n",
      "step 104100 , validation  accuracy 0.3206\n",
      "step 104100 , validation loss : 17.6434\n",
      "step 104200 , training  accuracy 0.4\n",
      "step 104200 , loss : 2.14207\n",
      "step 104200 , validation  accuracy 0.3306\n",
      "step 104200 , validation loss : 18.9074\n",
      "step 104300 , training  accuracy 0.666667\n",
      "step 104300 , loss : 2.07456\n",
      "step 104300 , validation  accuracy 0.3176\n",
      "step 104300 , validation loss : 18.7074\n",
      "step 104400 , training  accuracy 0.8\n",
      "step 104400 , loss : 2.03137\n",
      "step 104400 , validation  accuracy 0.3208\n",
      "step 104400 , validation loss : 18.0844\n",
      "step 104500 , training  accuracy 0.3\n",
      "step 104500 , loss : 2.20282\n",
      "step 104500 , validation  accuracy 0.3102\n",
      "step 104500 , validation loss : 17.5519\n",
      "step 104600 , training  accuracy 0.6\n",
      "step 104600 , loss : 2.08235\n",
      "step 104600 , validation  accuracy 0.3222\n",
      "step 104600 , validation loss : 17.9213\n",
      "step 104700 , training  accuracy 0.533333\n",
      "step 104700 , loss : 2.12924\n",
      "step 104700 , validation  accuracy 0.3288\n",
      "step 104700 , validation loss : 19.1025\n",
      "step 104800 , training  accuracy 0.4\n",
      "step 104800 , loss : 2.15029\n",
      "step 104800 , validation  accuracy 0.3008\n",
      "step 104800 , validation loss : 15.8452\n",
      "step 104900 , training  accuracy 0.466667\n",
      "step 104900 , loss : 2.1572\n",
      "step 104900 , validation  accuracy 0.3148\n",
      "step 104900 , validation loss : 17.223\n",
      "step 105000 , training  accuracy 0.4\n",
      "step 105000 , loss : 2.14076\n",
      "step 105000 , validation  accuracy 0.3226\n",
      "step 105000 , validation loss : 18.8416\n",
      "step 105100 , training  accuracy 0.5\n",
      "step 105100 , loss : 2.12554\n",
      "step 105100 , validation  accuracy 0.3114\n",
      "step 105100 , validation loss : 16.6235\n",
      "step 105200 , training  accuracy 0.433333\n",
      "step 105200 , loss : 2.16019\n",
      "step 105200 , validation  accuracy 0.3142\n",
      "step 105200 , validation loss : 16.942\n",
      "step 105300 , training  accuracy 0.466667\n",
      "step 105300 , loss : 2.11943\n",
      "step 105300 , validation  accuracy 0.3168\n",
      "step 105300 , validation loss : 18.192\n",
      "step 105400 , training  accuracy 0.5\n",
      "step 105400 , loss : 2.11967\n",
      "step 105400 , validation  accuracy 0.3216\n",
      "step 105400 , validation loss : 17.9646\n",
      "step 105500 , training  accuracy 0.333333\n",
      "step 105500 , loss : 2.21061\n",
      "step 105500 , validation  accuracy 0.3156\n",
      "step 105500 , validation loss : 16.8475\n",
      "step 105600 , training  accuracy 0.533333\n",
      "step 105600 , loss : 2.07343\n",
      "step 105600 , validation  accuracy 0.307\n",
      "step 105600 , validation loss : 17.8313\n",
      "step 105700 , training  accuracy 0.333333\n",
      "step 105700 , loss : 2.14394\n",
      "step 105700 , validation  accuracy 0.3244\n",
      "step 105700 , validation loss : 18.0298\n",
      "step 105800 , training  accuracy 0.466667\n",
      "step 105800 , loss : 2.10116\n",
      "step 105800 , validation  accuracy 0.3108\n",
      "step 105800 , validation loss : 16.7917\n",
      "step 105900 , training  accuracy 0.6\n",
      "step 105900 , loss : 2.08429\n",
      "step 105900 , validation  accuracy 0.3164\n",
      "step 105900 , validation loss : 17.2833\n",
      "step 106000 , training  accuracy 0.533333\n",
      "step 106000 , loss : 2.0635\n",
      "step 106000 , validation  accuracy 0.2978\n",
      "step 106000 , validation loss : 17.3093\n",
      "step 106100 , training  accuracy 0.6\n",
      "step 106100 , loss : 2.08113\n",
      "step 106100 , validation  accuracy 0.3304\n",
      "step 106100 , validation loss : 18.8222\n",
      "step 106200 , training  accuracy 0.433333\n",
      "step 106200 , loss : 2.14406\n",
      "step 106200 , validation  accuracy 0.3198\n",
      "step 106200 , validation loss : 18.2125\n",
      "step 106300 , training  accuracy 0.366667\n",
      "step 106300 , loss : 2.15147\n",
      "step 106300 , validation  accuracy 0.3012\n",
      "step 106300 , validation loss : 16.8936\n",
      "step 106400 , training  accuracy 0.466667\n",
      "step 106400 , loss : 2.12272\n",
      "step 106400 , validation  accuracy 0.3298\n",
      "step 106400 , validation loss : 18.3369\n",
      "step 106500 , training  accuracy 0.433333\n",
      "step 106500 , loss : 2.14561\n",
      "step 106500 , validation  accuracy 0.3242\n",
      "step 106500 , validation loss : 18.2624\n",
      "step 106600 , training  accuracy 0.433333\n",
      "step 106600 , loss : 2.11353\n",
      "step 106600 , validation  accuracy 0.3238\n",
      "step 106600 , validation loss : 18.5697\n",
      "step 106700 , training  accuracy 0.333333\n",
      "step 106700 , loss : 2.16794\n",
      "step 106700 , validation  accuracy 0.3264\n",
      "step 106700 , validation loss : 17.5115\n",
      "step 106800 , training  accuracy 0.433333\n",
      "step 106800 , loss : 2.13066\n",
      "step 106800 , validation  accuracy 0.3248\n",
      "step 106800 , validation loss : 18.2469\n",
      "step 106900 , training  accuracy 0.3\n",
      "step 106900 , loss : 2.19191\n",
      "step 106900 , validation  accuracy 0.2858\n",
      "step 106900 , validation loss : 15.971\n",
      "step 107000 , training  accuracy 0.5\n",
      "step 107000 , loss : 2.11122\n",
      "step 107000 , validation  accuracy 0.3298\n",
      "step 107000 , validation loss : 18.5875\n",
      "step 107100 , training  accuracy 0.533333\n",
      "step 107100 , loss : 2.15102\n",
      "step 107100 , validation  accuracy 0.3258\n",
      "step 107100 , validation loss : 18.2276\n",
      "step 107200 , training  accuracy 0.533333\n",
      "step 107200 , loss : 2.13926\n",
      "step 107200 , validation  accuracy 0.3162\n",
      "step 107200 , validation loss : 18.1147\n",
      "step 107300 , training  accuracy 0.633333\n",
      "step 107300 , loss : 2.07852\n",
      "step 107300 , validation  accuracy 0.3048\n",
      "step 107300 , validation loss : 18.7167\n",
      "step 107400 , training  accuracy 0.5\n",
      "step 107400 , loss : 2.07056\n",
      "step 107400 , validation  accuracy 0.3318\n",
      "step 107400 , validation loss : 19.0918\n",
      "step 107500 , training  accuracy 0.5\n",
      "step 107500 , loss : 2.08985\n",
      "step 107500 , validation  accuracy 0.3314\n",
      "step 107500 , validation loss : 19.8452\n",
      "step 107600 , training  accuracy 0.6\n",
      "step 107600 , loss : 2.07921\n",
      "step 107600 , validation  accuracy 0.326\n",
      "step 107600 , validation loss : 18.9359\n",
      "step 107700 , training  accuracy 0.5\n",
      "step 107700 , loss : 2.14488\n",
      "step 107700 , validation  accuracy 0.3166\n",
      "step 107700 , validation loss : 17.8067\n",
      "step 107800 , training  accuracy 0.433333\n",
      "step 107800 , loss : 2.14651\n",
      "step 107800 , validation  accuracy 0.3188\n",
      "step 107800 , validation loss : 17.4338\n",
      "step 107900 , training  accuracy 0.533333\n",
      "step 107900 , loss : 2.16191\n",
      "step 107900 , validation  accuracy 0.321\n",
      "step 107900 , validation loss : 18.5038\n",
      "step 108000 , training  accuracy 0.533333\n",
      "step 108000 , loss : 2.13109\n",
      "step 108000 , validation  accuracy 0.3226\n",
      "step 108000 , validation loss : 17.5122\n",
      "step 108100 , training  accuracy 0.466667\n",
      "step 108100 , loss : 2.16961\n",
      "step 108100 , validation  accuracy 0.3198\n",
      "step 108100 , validation loss : 18.021\n",
      "step 108200 , training  accuracy 0.533333\n",
      "step 108200 , loss : 2.10738\n",
      "step 108200 , validation  accuracy 0.3206\n",
      "step 108200 , validation loss : 19.0371\n",
      "step 108300 , training  accuracy 0.366667\n",
      "step 108300 , loss : 2.18284\n",
      "step 108300 , validation  accuracy 0.3176\n",
      "step 108300 , validation loss : 17.2787\n",
      "step 108400 , training  accuracy 0.7\n",
      "step 108400 , loss : 2.01127\n",
      "step 108400 , validation  accuracy 0.3188\n",
      "step 108400 , validation loss : 17.5676\n",
      "step 108500 , training  accuracy 0.5\n",
      "step 108500 , loss : 2.12346\n",
      "step 108500 , validation  accuracy 0.312\n",
      "step 108500 , validation loss : 18.9893\n",
      "step 108600 , training  accuracy 0.433333\n",
      "step 108600 , loss : 2.12818\n",
      "step 108600 , validation  accuracy 0.3254\n",
      "step 108600 , validation loss : 19.0875\n",
      "step 108700 , training  accuracy 0.733333\n",
      "step 108700 , loss : 2.04092\n",
      "step 108700 , validation  accuracy 0.311\n",
      "step 108700 , validation loss : 17.5098\n",
      "step 108800 , training  accuracy 0.5\n",
      "step 108800 , loss : 2.12908\n",
      "step 108800 , validation  accuracy 0.3288\n",
      "step 108800 , validation loss : 19.9103\n",
      "step 108900 , training  accuracy 0.566667\n",
      "step 108900 , loss : 2.06384\n",
      "step 108900 , validation  accuracy 0.3214\n",
      "step 108900 , validation loss : 18.2908\n",
      "step 109000 , training  accuracy 0.566667\n",
      "step 109000 , loss : 2.08686\n",
      "step 109000 , validation  accuracy 0.3216\n",
      "step 109000 , validation loss : 18.8443\n",
      "step 109100 , training  accuracy 0.533333\n",
      "step 109100 , loss : 2.11568\n",
      "step 109100 , validation  accuracy 0.3148\n",
      "step 109100 , validation loss : 17.6312\n",
      "step 109200 , training  accuracy 0.533333\n",
      "step 109200 , loss : 2.07962\n",
      "step 109200 , validation  accuracy 0.3252\n",
      "step 109200 , validation loss : 19.7329\n",
      "step 109300 , training  accuracy 0.566667\n",
      "step 109300 , loss : 2.10837\n",
      "step 109300 , validation  accuracy 0.3176\n",
      "step 109300 , validation loss : 18.7051\n",
      "step 109400 , training  accuracy 0.266667\n",
      "step 109400 , loss : 2.22913\n",
      "step 109400 , validation  accuracy 0.3098\n",
      "step 109400 , validation loss : 19.2892\n",
      "step 109500 , training  accuracy 0.533333\n",
      "step 109500 , loss : 2.0778\n",
      "step 109500 , validation  accuracy 0.3134\n",
      "step 109500 , validation loss : 19.9657\n",
      "step 109600 , training  accuracy 0.566667\n",
      "step 109600 , loss : 2.10545\n",
      "step 109600 , validation  accuracy 0.3122\n",
      "step 109600 , validation loss : 17.2192\n",
      "step 109700 , training  accuracy 0.666667\n",
      "step 109700 , loss : 2.07922\n",
      "step 109700 , validation  accuracy 0.3194\n",
      "step 109700 , validation loss : 18.2901\n",
      "step 109800 , training  accuracy 0.533333\n",
      "step 109800 , loss : 2.08682\n",
      "step 109800 , validation  accuracy 0.3174\n",
      "step 109800 , validation loss : 18.884\n",
      "step 109900 , training  accuracy 0.533333\n",
      "step 109900 , loss : 2.0708\n",
      "step 109900 , validation  accuracy 0.3064\n",
      "step 109900 , validation loss : 16.9343\n",
      "step 110000 , training  accuracy 0.366667\n",
      "step 110000 , loss : 2.10959\n",
      "step 110000 , validation  accuracy 0.3002\n",
      "step 110000 , validation loss : 17.1152\n",
      "step 110100 , training  accuracy 0.266667\n",
      "step 110100 , loss : 2.16787\n",
      "step 110100 , validation  accuracy 0.3192\n",
      "step 110100 , validation loss : 17.653\n",
      "step 110200 , training  accuracy 0.433333\n",
      "step 110200 , loss : 2.18741\n",
      "step 110200 , validation  accuracy 0.3032\n",
      "step 110200 , validation loss : 17.518\n",
      "step 110300 , training  accuracy 0.533333\n",
      "step 110300 , loss : 2.0983\n",
      "step 110300 , validation  accuracy 0.3252\n",
      "step 110300 , validation loss : 19.0139\n",
      "step 110400 , training  accuracy 0.433333\n",
      "step 110400 , loss : 2.15257\n",
      "step 110400 , validation  accuracy 0.3132\n",
      "step 110400 , validation loss : 17.4988\n",
      "step 110500 , training  accuracy 0.5\n",
      "step 110500 , loss : 2.08962\n",
      "step 110500 , validation  accuracy 0.3116\n",
      "step 110500 , validation loss : 17.1413\n",
      "step 110600 , training  accuracy 0.5\n",
      "step 110600 , loss : 2.13038\n",
      "step 110600 , validation  accuracy 0.3212\n",
      "step 110600 , validation loss : 17.8235\n",
      "step 110700 , training  accuracy 0.533333\n",
      "step 110700 , loss : 2.05281\n",
      "step 110700 , validation  accuracy 0.3186\n",
      "step 110700 , validation loss : 18.4753\n",
      "step 110800 , training  accuracy 0.466667\n",
      "step 110800 , loss : 2.10114\n",
      "step 110800 , validation  accuracy 0.3208\n",
      "step 110800 , validation loss : 18.7396\n",
      "step 110900 , training  accuracy 0.3\n",
      "step 110900 , loss : 2.1768\n",
      "step 110900 , validation  accuracy 0.3112\n",
      "step 110900 , validation loss : 17.875\n",
      "step 111000 , training  accuracy 0.566667\n",
      "step 111000 , loss : 2.09691\n",
      "step 111000 , validation  accuracy 0.3086\n",
      "step 111000 , validation loss : 19.0217\n",
      "step 111100 , training  accuracy 0.466667\n",
      "step 111100 , loss : 2.09514\n",
      "step 111100 , validation  accuracy 0.3092\n",
      "step 111100 , validation loss : 17.6246\n",
      "step 111200 , training  accuracy 0.433333\n",
      "step 111200 , loss : 2.14034\n",
      "step 111200 , validation  accuracy 0.305\n",
      "step 111200 , validation loss : 17.1822\n",
      "step 111300 , training  accuracy 0.5\n",
      "step 111300 , loss : 2.1236\n",
      "step 111300 , validation  accuracy 0.3164\n",
      "step 111300 , validation loss : 18.4665\n",
      "step 111400 , training  accuracy 0.566667\n",
      "step 111400 , loss : 2.1056\n",
      "step 111400 , validation  accuracy 0.3128\n",
      "step 111400 , validation loss : 17.4986\n",
      "step 111500 , training  accuracy 0.366667\n",
      "step 111500 , loss : 2.21224\n",
      "step 111500 , validation  accuracy 0.3024\n",
      "step 111500 , validation loss : 17.5637\n",
      "step 111600 , training  accuracy 0.433333\n",
      "step 111600 , loss : 2.11123\n",
      "step 111600 , validation  accuracy 0.318\n",
      "step 111600 , validation loss : 17.6731\n",
      "step 111700 , training  accuracy 0.566667\n",
      "step 111700 , loss : 2.11821\n",
      "step 111700 , validation  accuracy 0.328\n",
      "step 111700 , validation loss : 20.1181\n",
      "step 111800 , training  accuracy 0.4\n",
      "step 111800 , loss : 2.21576\n",
      "step 111800 , validation  accuracy 0.3074\n",
      "step 111800 , validation loss : 17.7192\n",
      "step 111900 , training  accuracy 0.5\n",
      "step 111900 , loss : 2.15771\n",
      "step 111900 , validation  accuracy 0.319\n",
      "step 111900 , validation loss : 18.2564\n",
      "step 112000 , training  accuracy 0.466667\n",
      "step 112000 , loss : 2.09414\n",
      "step 112000 , validation  accuracy 0.301\n",
      "step 112000 , validation loss : 18.3665\n",
      "step 112100 , training  accuracy 0.5\n",
      "step 112100 , loss : 2.11906\n",
      "step 112100 , validation  accuracy 0.2996\n",
      "step 112100 , validation loss : 17.4297\n",
      "step 112200 , training  accuracy 0.333333\n",
      "step 112200 , loss : 2.14507\n",
      "step 112200 , validation  accuracy 0.3232\n",
      "step 112200 , validation loss : 18.7558\n",
      "step 112300 , training  accuracy 0.5\n",
      "step 112300 , loss : 2.10396\n",
      "step 112300 , validation  accuracy 0.32\n",
      "step 112300 , validation loss : 18.3756\n",
      "step 112400 , training  accuracy 0.366667\n",
      "step 112400 , loss : 2.11591\n",
      "step 112400 , validation  accuracy 0.3246\n",
      "step 112400 , validation loss : 19.243\n",
      "step 112500 , training  accuracy 0.433333\n",
      "step 112500 , loss : 2.12109\n",
      "step 112500 , validation  accuracy 0.319\n",
      "step 112500 , validation loss : 18.5648\n",
      "step 112600 , training  accuracy 0.5\n",
      "step 112600 , loss : 2.12172\n",
      "step 112600 , validation  accuracy 0.3232\n",
      "step 112600 , validation loss : 18.3759\n",
      "step 112700 , training  accuracy 0.3\n",
      "step 112700 , loss : 2.15764\n",
      "step 112700 , validation  accuracy 0.3228\n",
      "step 112700 , validation loss : 18.5598\n",
      "step 112800 , training  accuracy 0.566667\n",
      "step 112800 , loss : 2.12331\n",
      "step 112800 , validation  accuracy 0.3114\n",
      "step 112800 , validation loss : 18.3777\n",
      "step 112900 , training  accuracy 0.633333\n",
      "step 112900 , loss : 2.07623\n",
      "step 112900 , validation  accuracy 0.3122\n",
      "step 112900 , validation loss : 17.6421\n",
      "step 113000 , training  accuracy 0.433333\n",
      "step 113000 , loss : 2.13925\n",
      "step 113000 , validation  accuracy 0.2972\n",
      "step 113000 , validation loss : 18.3802\n",
      "step 113100 , training  accuracy 0.666667\n",
      "step 113100 , loss : 2.01335\n",
      "step 113100 , validation  accuracy 0.3254\n",
      "step 113100 , validation loss : 19.6384\n",
      "step 113200 , training  accuracy 0.333333\n",
      "step 113200 , loss : 2.16526\n",
      "step 113200 , validation  accuracy 0.3162\n",
      "step 113200 , validation loss : 17.6937\n",
      "step 113300 , training  accuracy 0.6\n",
      "step 113300 , loss : 2.06102\n",
      "step 113300 , validation  accuracy 0.3182\n",
      "step 113300 , validation loss : 18.7702\n",
      "step 113400 , training  accuracy 0.4\n",
      "step 113400 , loss : 2.094\n",
      "step 113400 , validation  accuracy 0.3268\n",
      "step 113400 , validation loss : 19.4784\n",
      "step 113500 , training  accuracy 0.566667\n",
      "step 113500 , loss : 2.08048\n",
      "step 113500 , validation  accuracy 0.3214\n",
      "step 113500 , validation loss : 19.6354\n",
      "step 113600 , training  accuracy 0.466667\n",
      "step 113600 , loss : 2.12849\n",
      "step 113600 , validation  accuracy 0.3012\n",
      "step 113600 , validation loss : 17.9664\n",
      "step 113700 , training  accuracy 0.566667\n",
      "step 113700 , loss : 2.1212\n",
      "step 113700 , validation  accuracy 0.3236\n",
      "step 113700 , validation loss : 18.9665\n",
      "step 113800 , training  accuracy 0.6\n",
      "step 113800 , loss : 2.13129\n",
      "step 113800 , validation  accuracy 0.3274\n",
      "step 113800 , validation loss : 19.2492\n",
      "step 113900 , training  accuracy 0.566667\n",
      "step 113900 , loss : 2.03901\n",
      "step 113900 , validation  accuracy 0.2964\n",
      "step 113900 , validation loss : 17.6888\n",
      "step 114000 , training  accuracy 0.466667\n",
      "step 114000 , loss : 2.08398\n",
      "step 114000 , validation  accuracy 0.3266\n",
      "step 114000 , validation loss : 19.7751\n",
      "step 114100 , training  accuracy 0.6\n",
      "step 114100 , loss : 2.08044\n",
      "step 114100 , validation  accuracy 0.3142\n",
      "step 114100 , validation loss : 18.3494\n",
      "step 114200 , training  accuracy 0.4\n",
      "step 114200 , loss : 2.15542\n",
      "step 114200 , validation  accuracy 0.3312\n",
      "step 114200 , validation loss : 20.5532\n",
      "step 114300 , training  accuracy 0.5\n",
      "step 114300 , loss : 2.06937\n",
      "step 114300 , validation  accuracy 0.3216\n",
      "step 114300 , validation loss : 19.2808\n",
      "step 114400 , training  accuracy 0.466667\n",
      "step 114400 , loss : 2.13173\n",
      "step 114400 , validation  accuracy 0.3218\n",
      "step 114400 , validation loss : 18.4464\n",
      "step 114500 , training  accuracy 0.433333\n",
      "step 114500 , loss : 2.13182\n",
      "step 114500 , validation  accuracy 0.312\n",
      "step 114500 , validation loss : 18.4079\n",
      "step 114600 , training  accuracy 0.433333\n",
      "step 114600 , loss : 2.13052\n",
      "step 114600 , validation  accuracy 0.3154\n",
      "step 114600 , validation loss : 17.7711\n",
      "step 114700 , training  accuracy 0.433333\n",
      "step 114700 , loss : 2.17911\n",
      "step 114700 , validation  accuracy 0.299\n",
      "step 114700 , validation loss : 17.1112\n",
      "step 114800 , training  accuracy 0.533333\n",
      "step 114800 , loss : 2.13031\n",
      "step 114800 , validation  accuracy 0.3098\n",
      "step 114800 , validation loss : 18.3738\n",
      "step 114900 , training  accuracy 0.633333\n",
      "step 114900 , loss : 2.06091\n",
      "step 114900 , validation  accuracy 0.306\n",
      "step 114900 , validation loss : 17.409\n",
      "step 115000 , training  accuracy 0.466667\n",
      "step 115000 , loss : 2.15861\n",
      "step 115000 , validation  accuracy 0.3152\n",
      "step 115000 , validation loss : 18.2572\n",
      "step 115100 , training  accuracy 0.433333\n",
      "step 115100 , loss : 2.15947\n",
      "step 115100 , validation  accuracy 0.319\n",
      "step 115100 , validation loss : 18.4964\n",
      "step 115200 , training  accuracy 0.7\n",
      "step 115200 , loss : 2.04562\n",
      "step 115200 , validation  accuracy 0.3108\n",
      "step 115200 , validation loss : 18.116\n",
      "step 115300 , training  accuracy 0.6\n",
      "step 115300 , loss : 2.10016\n",
      "step 115300 , validation  accuracy 0.3174\n",
      "step 115300 , validation loss : 19.3528\n",
      "step 115400 , training  accuracy 0.666667\n",
      "step 115400 , loss : 2.04273\n",
      "step 115400 , validation  accuracy 0.3236\n",
      "step 115400 , validation loss : 18.5942\n",
      "step 115500 , training  accuracy 0.566667\n",
      "step 115500 , loss : 2.06302\n",
      "step 115500 , validation  accuracy 0.3202\n",
      "step 115500 , validation loss : 18.3734\n",
      "step 115600 , training  accuracy 0.466667\n",
      "step 115600 , loss : 2.09864\n",
      "step 115600 , validation  accuracy 0.3196\n",
      "step 115600 , validation loss : 19.0879\n",
      "step 115700 , training  accuracy 0.433333\n",
      "step 115700 , loss : 2.11423\n",
      "step 115700 , validation  accuracy 0.313\n",
      "step 115700 , validation loss : 20.4756\n",
      "step 115800 , training  accuracy 0.5\n",
      "step 115800 , loss : 2.12346\n",
      "step 115800 , validation  accuracy 0.314\n",
      "step 115800 , validation loss : 17.3132\n",
      "step 115900 , training  accuracy 0.433333\n",
      "step 115900 , loss : 2.07737\n",
      "step 115900 , validation  accuracy 0.3218\n",
      "step 115900 , validation loss : 18.9682\n",
      "step 116000 , training  accuracy 0.4\n",
      "step 116000 , loss : 2.13931\n",
      "step 116000 , validation  accuracy 0.3096\n",
      "step 116000 , validation loss : 17.9292\n",
      "step 116100 , training  accuracy 0.5\n",
      "step 116100 , loss : 2.09312\n",
      "step 116100 , validation  accuracy 0.3156\n",
      "step 116100 , validation loss : 18.1549\n",
      "step 116200 , training  accuracy 0.566667\n",
      "step 116200 , loss : 2.10248\n",
      "step 116200 , validation  accuracy 0.3124\n",
      "step 116200 , validation loss : 19.3067\n",
      "step 116300 , training  accuracy 0.433333\n",
      "step 116300 , loss : 2.14427\n",
      "step 116300 , validation  accuracy 0.3222\n",
      "step 116300 , validation loss : 19.3529\n",
      "step 116400 , training  accuracy 0.6\n",
      "step 116400 , loss : 2.06216\n",
      "step 116400 , validation  accuracy 0.3272\n",
      "step 116400 , validation loss : 20.3455\n",
      "step 116500 , training  accuracy 0.633333\n",
      "step 116500 , loss : 2.02672\n",
      "step 116500 , validation  accuracy 0.3064\n",
      "step 116500 , validation loss : 19.2175\n",
      "step 116600 , training  accuracy 0.366667\n",
      "step 116600 , loss : 2.19078\n",
      "step 116600 , validation  accuracy 0.311\n",
      "step 116600 , validation loss : 18.388\n",
      "step 116700 , training  accuracy 0.433333\n",
      "step 116700 , loss : 2.13545\n",
      "step 116700 , validation  accuracy 0.3278\n",
      "step 116700 , validation loss : 20.1001\n",
      "step 116800 , training  accuracy 0.5\n",
      "step 116800 , loss : 2.11994\n",
      "step 116800 , validation  accuracy 0.3262\n",
      "step 116800 , validation loss : 18.9005\n",
      "step 116900 , training  accuracy 0.533333\n",
      "step 116900 , loss : 2.10671\n",
      "step 116900 , validation  accuracy 0.3112\n",
      "step 116900 , validation loss : 19.3676\n",
      "step 117000 , training  accuracy 0.5\n",
      "step 117000 , loss : 2.11552\n",
      "step 117000 , validation  accuracy 0.3124\n",
      "step 117000 , validation loss : 19.8737\n",
      "step 117100 , training  accuracy 0.3\n",
      "step 117100 , loss : 2.13324\n",
      "step 117100 , validation  accuracy 0.2998\n",
      "step 117100 , validation loss : 19.4645\n",
      "step 117200 , training  accuracy 0.466667\n",
      "step 117200 , loss : 2.12545\n",
      "step 117200 , validation  accuracy 0.2952\n",
      "step 117200 , validation loss : 17.1601\n",
      "step 117300 , training  accuracy 0.4\n",
      "step 117300 , loss : 2.12868\n",
      "step 117300 , validation  accuracy 0.3102\n",
      "step 117300 , validation loss : 18.2532\n",
      "step 117400 , training  accuracy 0.466667\n",
      "step 117400 , loss : 2.16927\n",
      "step 117400 , validation  accuracy 0.3014\n",
      "step 117400 , validation loss : 18.5358\n",
      "step 117500 , training  accuracy 0.5\n",
      "step 117500 , loss : 2.11146\n",
      "step 117500 , validation  accuracy 0.3048\n",
      "step 117500 , validation loss : 18.6127\n",
      "step 117600 , training  accuracy 0.433333\n",
      "step 117600 , loss : 2.13347\n",
      "step 117600 , validation  accuracy 0.2952\n",
      "step 117600 , validation loss : 18.4496\n",
      "step 117700 , training  accuracy 0.533333\n",
      "step 117700 , loss : 2.13176\n",
      "step 117700 , validation  accuracy 0.3242\n",
      "step 117700 , validation loss : 19.8307\n",
      "step 117800 , training  accuracy 0.566667\n",
      "step 117800 , loss : 2.09639\n",
      "step 117800 , validation  accuracy 0.2876\n",
      "step 117800 , validation loss : 17.4397\n",
      "step 117900 , training  accuracy 0.5\n",
      "step 117900 , loss : 2.10732\n",
      "step 117900 , validation  accuracy 0.2952\n",
      "step 117900 , validation loss : 17.5024\n",
      "step 118000 , training  accuracy 0.4\n",
      "step 118000 , loss : 2.1583\n",
      "step 118000 , validation  accuracy 0.3038\n",
      "step 118000 , validation loss : 18.0477\n",
      "step 118100 , training  accuracy 0.533333\n",
      "step 118100 , loss : 2.09586\n",
      "step 118100 , validation  accuracy 0.3262\n",
      "step 118100 , validation loss : 19.1461\n",
      "step 118200 , training  accuracy 0.566667\n",
      "step 118200 , loss : 2.05568\n",
      "step 118200 , validation  accuracy 0.3254\n",
      "step 118200 , validation loss : 20.5325\n",
      "step 118300 , training  accuracy 0.566667\n",
      "step 118300 , loss : 2.12627\n",
      "step 118300 , validation  accuracy 0.3252\n",
      "step 118300 , validation loss : 19.1897\n",
      "step 118400 , training  accuracy 0.566667\n",
      "step 118400 , loss : 2.06874\n",
      "step 118400 , validation  accuracy 0.3256\n",
      "step 118400 , validation loss : 19.2823\n",
      "step 118500 , training  accuracy 0.433333\n",
      "step 118500 , loss : 2.11451\n",
      "step 118500 , validation  accuracy 0.293\n",
      "step 118500 , validation loss : 18.3445\n",
      "step 118600 , training  accuracy 0.566667\n",
      "step 118600 , loss : 2.11782\n",
      "step 118600 , validation  accuracy 0.315\n",
      "step 118600 , validation loss : 19.0582\n",
      "step 118700 , training  accuracy 0.566667\n",
      "step 118700 , loss : 2.07158\n",
      "step 118700 , validation  accuracy 0.316\n",
      "step 118700 , validation loss : 18.238\n",
      "step 118800 , training  accuracy 0.533333\n",
      "step 118800 , loss : 2.11742\n",
      "step 118800 , validation  accuracy 0.3298\n",
      "step 118800 , validation loss : 18.5363\n",
      "step 118900 , training  accuracy 0.6\n",
      "step 118900 , loss : 2.06035\n",
      "step 118900 , validation  accuracy 0.3242\n",
      "step 118900 , validation loss : 18.5105\n",
      "step 119000 , training  accuracy 0.466667\n",
      "step 119000 , loss : 2.14808\n",
      "step 119000 , validation  accuracy 0.314\n",
      "step 119000 , validation loss : 19.0077\n",
      "step 119100 , training  accuracy 0.333333\n",
      "step 119100 , loss : 2.20337\n",
      "step 119100 , validation  accuracy 0.3256\n",
      "step 119100 , validation loss : 18.033\n",
      "step 119200 , training  accuracy 0.466667\n",
      "step 119200 , loss : 2.14897\n",
      "step 119200 , validation  accuracy 0.3198\n",
      "step 119200 , validation loss : 18.499\n",
      "step 119300 , training  accuracy 0.566667\n",
      "step 119300 , loss : 2.09043\n",
      "step 119300 , validation  accuracy 0.2952\n",
      "step 119300 , validation loss : 17.2806\n",
      "step 119400 , training  accuracy 0.4\n",
      "step 119400 , loss : 2.177\n",
      "step 119400 , validation  accuracy 0.3244\n",
      "step 119400 , validation loss : 19.2746\n",
      "step 119500 , training  accuracy 0.6\n",
      "step 119500 , loss : 2.06871\n",
      "step 119500 , validation  accuracy 0.3144\n",
      "step 119500 , validation loss : 20.4233\n",
      "step 119600 , training  accuracy 0.566667\n",
      "step 119600 , loss : 2.06933\n",
      "step 119600 , validation  accuracy 0.3152\n",
      "step 119600 , validation loss : 18.649\n",
      "step 119700 , training  accuracy 0.5\n",
      "step 119700 , loss : 2.10262\n",
      "step 119700 , validation  accuracy 0.3102\n",
      "step 119700 , validation loss : 18.2334\n",
      "step 119800 , training  accuracy 0.566667\n",
      "step 119800 , loss : 2.0667\n",
      "step 119800 , validation  accuracy 0.3148\n",
      "step 119800 , validation loss : 18.7372\n",
      "step 119900 , training  accuracy 0.3\n",
      "step 119900 , loss : 2.22211\n",
      "step 119900 , validation  accuracy 0.3104\n",
      "step 119900 , validation loss : 18.0162\n",
      "step 120000 , training  accuracy 0.5\n",
      "step 120000 , loss : 2.11427\n",
      "step 120000 , validation  accuracy 0.2868\n",
      "step 120000 , validation loss : 18.2273\n",
      "step 120100 , training  accuracy 0.366667\n",
      "step 120100 , loss : 2.10028\n",
      "step 120100 , validation  accuracy 0.3004\n",
      "step 120100 , validation loss : 18.3218\n",
      "step 120200 , training  accuracy 0.4\n",
      "step 120200 , loss : 2.14308\n",
      "step 120200 , validation  accuracy 0.316\n",
      "step 120200 , validation loss : 18.3467\n",
      "step 120300 , training  accuracy 0.5\n",
      "step 120300 , loss : 2.12525\n",
      "step 120300 , validation  accuracy 0.332\n",
      "step 120300 , validation loss : 19.9687\n",
      "step 120400 , training  accuracy 0.433333\n",
      "step 120400 , loss : 2.16495\n",
      "step 120400 , validation  accuracy 0.3198\n",
      "step 120400 , validation loss : 18.9322\n",
      "step 120500 , training  accuracy 0.466667\n",
      "step 120500 , loss : 2.13578\n",
      "step 120500 , validation  accuracy 0.3252\n",
      "step 120500 , validation loss : 19.6648\n",
      "step 120600 , training  accuracy 0.5\n",
      "step 120600 , loss : 2.11994\n",
      "step 120600 , validation  accuracy 0.3136\n",
      "step 120600 , validation loss : 18.4082\n",
      "step 120700 , training  accuracy 0.666667\n",
      "step 120700 , loss : 2.0018\n",
      "step 120700 , validation  accuracy 0.3304\n",
      "step 120700 , validation loss : 20.118\n",
      "step 120800 , training  accuracy 0.4\n",
      "step 120800 , loss : 2.1635\n",
      "step 120800 , validation  accuracy 0.3172\n",
      "step 120800 , validation loss : 19.0795\n",
      "step 120900 , training  accuracy 0.6\n",
      "step 120900 , loss : 2.05607\n",
      "step 120900 , validation  accuracy 0.3246\n",
      "step 120900 , validation loss : 20.3984\n",
      "step 121000 , training  accuracy 0.6\n",
      "step 121000 , loss : 2.09578\n",
      "step 121000 , validation  accuracy 0.31\n",
      "step 121000 , validation loss : 17.7302\n",
      "step 121100 , training  accuracy 0.433333\n",
      "step 121100 , loss : 2.15942\n",
      "step 121100 , validation  accuracy 0.2952\n",
      "step 121100 , validation loss : 17.5001\n",
      "step 121200 , training  accuracy 0.3\n",
      "step 121200 , loss : 2.18984\n",
      "step 121200 , validation  accuracy 0.3198\n",
      "step 121200 , validation loss : 18.4109\n",
      "step 121300 , training  accuracy 0.433333\n",
      "step 121300 , loss : 2.11326\n",
      "step 121300 , validation  accuracy 0.3164\n",
      "step 121300 , validation loss : 18.8345\n",
      "step 121400 , training  accuracy 0.533333\n",
      "step 121400 , loss : 2.15006\n",
      "step 121400 , validation  accuracy 0.2932\n",
      "step 121400 , validation loss : 17.341\n",
      "step 121500 , training  accuracy 0.466667\n",
      "step 121500 , loss : 2.15987\n",
      "step 121500 , validation  accuracy 0.3006\n",
      "step 121500 , validation loss : 18.8897\n",
      "step 121600 , training  accuracy 0.433333\n",
      "step 121600 , loss : 2.12063\n",
      "step 121600 , validation  accuracy 0.32\n",
      "step 121600 , validation loss : 18.6608\n",
      "step 121700 , training  accuracy 0.5\n",
      "step 121700 , loss : 2.11862\n",
      "step 121700 , validation  accuracy 0.3198\n",
      "step 121700 , validation loss : 18.6218\n",
      "step 121800 , training  accuracy 0.5\n",
      "step 121800 , loss : 2.12483\n",
      "step 121800 , validation  accuracy 0.3142\n",
      "step 121800 , validation loss : 19.4086\n",
      "step 121900 , training  accuracy 0.6\n",
      "step 121900 , loss : 2.05199\n",
      "step 121900 , validation  accuracy 0.3158\n",
      "step 121900 , validation loss : 18.7409\n",
      "step 122000 , training  accuracy 0.4\n",
      "step 122000 , loss : 2.13514\n",
      "step 122000 , validation  accuracy 0.31\n",
      "step 122000 , validation loss : 19.4589\n",
      "step 122100 , training  accuracy 0.5\n",
      "step 122100 , loss : 2.1155\n",
      "step 122100 , validation  accuracy 0.3186\n",
      "step 122100 , validation loss : 19.7763\n",
      "step 122200 , training  accuracy 0.466667\n",
      "step 122200 , loss : 2.19724\n",
      "step 122200 , validation  accuracy 0.3206\n",
      "step 122200 , validation loss : 18.9372\n",
      "step 122300 , training  accuracy 0.5\n",
      "step 122300 , loss : 2.10402\n",
      "step 122300 , validation  accuracy 0.3278\n",
      "step 122300 , validation loss : 19.224\n",
      "step 122400 , training  accuracy 0.533333\n",
      "step 122400 , loss : 2.06918\n",
      "step 122400 , validation  accuracy 0.3156\n",
      "step 122400 , validation loss : 19.609\n",
      "step 122500 , training  accuracy 0.4\n",
      "step 122500 , loss : 2.097\n",
      "step 122500 , validation  accuracy 0.311\n",
      "step 122500 , validation loss : 19.9866\n",
      "step 122600 , training  accuracy 0.366667\n",
      "step 122600 , loss : 2.14099\n",
      "step 122600 , validation  accuracy 0.3144\n",
      "step 122600 , validation loss : 18.2605\n",
      "step 122700 , training  accuracy 0.6\n",
      "step 122700 , loss : 2.05819\n",
      "step 122700 , validation  accuracy 0.323\n",
      "step 122700 , validation loss : 19.0167\n",
      "step 122800 , training  accuracy 0.5\n",
      "step 122800 , loss : 2.12156\n",
      "step 122800 , validation  accuracy 0.2988\n",
      "step 122800 , validation loss : 17.181\n",
      "step 122900 , training  accuracy 0.466667\n",
      "step 122900 , loss : 2.1882\n",
      "step 122900 , validation  accuracy 0.2948\n",
      "step 122900 , validation loss : 17.6953\n",
      "step 123000 , training  accuracy 0.433333\n",
      "step 123000 , loss : 2.15033\n",
      "step 123000 , validation  accuracy 0.3034\n",
      "step 123000 , validation loss : 17.9094\n",
      "step 123100 , training  accuracy 0.3\n",
      "step 123100 , loss : 2.21367\n",
      "step 123100 , validation  accuracy 0.3146\n",
      "step 123100 , validation loss : 19.7568\n",
      "step 123200 , training  accuracy 0.4\n",
      "step 123200 , loss : 2.15564\n",
      "step 123200 , validation  accuracy 0.3294\n",
      "step 123200 , validation loss : 20.3132\n",
      "step 123300 , training  accuracy 0.3\n",
      "step 123300 , loss : 2.21006\n",
      "step 123300 , validation  accuracy 0.3336\n",
      "step 123300 , validation loss : 19.9497\n",
      "step 123400 , training  accuracy 0.566667\n",
      "step 123400 , loss : 2.10148\n",
      "step 123400 , validation  accuracy 0.3104\n",
      "step 123400 , validation loss : 18.5973\n",
      "step 123500 , training  accuracy 0.4\n",
      "step 123500 , loss : 2.16191\n",
      "step 123500 , validation  accuracy 0.3016\n",
      "step 123500 , validation loss : 17.783\n",
      "step 123600 , training  accuracy 0.466667\n",
      "step 123600 , loss : 2.10478\n",
      "step 123600 , validation  accuracy 0.3216\n",
      "step 123600 , validation loss : 19.4291\n",
      "step 123700 , training  accuracy 0.5\n",
      "step 123700 , loss : 2.15807\n",
      "step 123700 , validation  accuracy 0.3142\n",
      "step 123700 , validation loss : 18.1455\n",
      "step 123800 , training  accuracy 0.5\n",
      "step 123800 , loss : 2.11828\n",
      "step 123800 , validation  accuracy 0.3174\n",
      "step 123800 , validation loss : 19.2228\n",
      "step 123900 , training  accuracy 0.6\n",
      "step 123900 , loss : 2.08228\n",
      "step 123900 , validation  accuracy 0.3132\n",
      "step 123900 , validation loss : 18.7117\n",
      "step 124000 , training  accuracy 0.6\n",
      "step 124000 , loss : 2.11308\n",
      "step 124000 , validation  accuracy 0.3134\n",
      "step 124000 , validation loss : 17.7879\n",
      "step 124100 , training  accuracy 0.533333\n",
      "step 124100 , loss : 2.11875\n",
      "step 124100 , validation  accuracy 0.3234\n",
      "step 124100 , validation loss : 19.2819\n",
      "step 124200 , training  accuracy 0.6\n",
      "step 124200 , loss : 2.0655\n",
      "step 124200 , validation  accuracy 0.322\n",
      "step 124200 , validation loss : 19.3183\n",
      "step 124300 , training  accuracy 0.5\n",
      "step 124300 , loss : 2.09816\n",
      "step 124300 , validation  accuracy 0.3198\n",
      "step 124300 , validation loss : 20.15\n",
      "step 124400 , training  accuracy 0.566667\n",
      "step 124400 , loss : 2.06049\n",
      "step 124400 , validation  accuracy 0.301\n",
      "step 124400 , validation loss : 18.6446\n",
      "step 124500 , training  accuracy 0.466667\n",
      "step 124500 , loss : 2.10862\n",
      "step 124500 , validation  accuracy 0.2988\n",
      "step 124500 , validation loss : 19.5776\n",
      "step 124600 , training  accuracy 0.433333\n",
      "step 124600 , loss : 2.14583\n",
      "step 124600 , validation  accuracy 0.3206\n",
      "step 124600 , validation loss : 19.0525\n",
      "step 124700 , training  accuracy 0.5\n",
      "step 124700 , loss : 2.11306\n",
      "step 124700 , validation  accuracy 0.3104\n",
      "step 124700 , validation loss : 17.4121\n",
      "step 124800 , training  accuracy 0.533333\n",
      "step 124800 , loss : 2.08518\n",
      "step 124800 , validation  accuracy 0.3224\n",
      "step 124800 , validation loss : 19.0916\n",
      "step 124900 , training  accuracy 0.5\n",
      "step 124900 , loss : 2.03519\n",
      "step 124900 , validation  accuracy 0.3266\n",
      "step 124900 , validation loss : 19.1389\n",
      "step 125000 , training  accuracy 0.366667\n",
      "step 125000 , loss : 2.11394\n",
      "step 125000 , validation  accuracy 0.3146\n",
      "step 125000 , validation loss : 19.5262\n",
      "step 125100 , training  accuracy 0.533333\n",
      "step 125100 , loss : 2.14261\n",
      "step 125100 , validation  accuracy 0.3216\n",
      "step 125100 , validation loss : 19.8424\n",
      "step 125200 , training  accuracy 0.333333\n",
      "step 125200 , loss : 2.18732\n",
      "step 125200 , validation  accuracy 0.2966\n",
      "step 125200 , validation loss : 17.7519\n",
      "step 125300 , training  accuracy 0.5\n",
      "step 125300 , loss : 2.16176\n",
      "step 125300 , validation  accuracy 0.3204\n",
      "step 125300 , validation loss : 19.7248\n",
      "step 125400 , training  accuracy 0.266667\n",
      "step 125400 , loss : 2.2642\n",
      "step 125400 , validation  accuracy 0.3174\n",
      "step 125400 , validation loss : 18.4151\n",
      "step 125500 , training  accuracy 0.5\n",
      "step 125500 , loss : 2.0647\n",
      "step 125500 , validation  accuracy 0.328\n",
      "step 125500 , validation loss : 19.5132\n",
      "step 125600 , training  accuracy 0.466667\n",
      "step 125600 , loss : 2.15249\n",
      "step 125600 , validation  accuracy 0.3198\n",
      "step 125600 , validation loss : 18.8717\n",
      "step 125700 , training  accuracy 0.366667\n",
      "step 125700 , loss : 2.16496\n",
      "step 125700 , validation  accuracy 0.3098\n",
      "step 125700 , validation loss : 19.0846\n",
      "step 125800 , training  accuracy 0.633333\n",
      "step 125800 , loss : 2.05307\n",
      "step 125800 , validation  accuracy 0.3162\n",
      "step 125800 , validation loss : 18.9484\n",
      "step 125900 , training  accuracy 0.6\n",
      "step 125900 , loss : 2.06337\n",
      "step 125900 , validation  accuracy 0.3058\n",
      "step 125900 , validation loss : 19.2871\n",
      "step 126000 , training  accuracy 0.6\n",
      "step 126000 , loss : 2.00687\n",
      "step 126000 , validation  accuracy 0.322\n",
      "step 126000 , validation loss : 20.9774\n",
      "step 126100 , training  accuracy 0.333333\n",
      "step 126100 , loss : 2.1422\n",
      "step 126100 , validation  accuracy 0.3148\n",
      "step 126100 , validation loss : 18.4409\n",
      "step 126200 , training  accuracy 0.566667\n",
      "step 126200 , loss : 2.09086\n",
      "step 126200 , validation  accuracy 0.322\n",
      "step 126200 , validation loss : 19.5897\n",
      "step 126300 , training  accuracy 0.533333\n",
      "step 126300 , loss : 2.10391\n",
      "step 126300 , validation  accuracy 0.3258\n",
      "step 126300 , validation loss : 21.1341\n",
      "step 126400 , training  accuracy 0.733333\n",
      "step 126400 , loss : 1.99722\n",
      "step 126400 , validation  accuracy 0.2976\n",
      "step 126400 , validation loss : 18.3205\n",
      "step 126500 , training  accuracy 0.533333\n",
      "step 126500 , loss : 2.13108\n",
      "step 126500 , validation  accuracy 0.3004\n",
      "step 126500 , validation loss : 19.0701\n",
      "step 126600 , training  accuracy 0.433333\n",
      "step 126600 , loss : 2.13052\n",
      "step 126600 , validation  accuracy 0.316\n",
      "step 126600 , validation loss : 20.8222\n",
      "step 126700 , training  accuracy 0.566667\n",
      "step 126700 , loss : 2.11279\n",
      "step 126700 , validation  accuracy 0.3198\n",
      "step 126700 , validation loss : 19.9044\n",
      "step 126800 , training  accuracy 0.533333\n",
      "step 126800 , loss : 2.07342\n",
      "step 126800 , validation  accuracy 0.3128\n",
      "step 126800 , validation loss : 18.6448\n",
      "step 126900 , training  accuracy 0.433333\n",
      "step 126900 , loss : 2.16261\n",
      "step 126900 , validation  accuracy 0.306\n",
      "step 126900 , validation loss : 19.1618\n",
      "step 127000 , training  accuracy 0.5\n",
      "step 127000 , loss : 2.11593\n",
      "step 127000 , validation  accuracy 0.3178\n",
      "step 127000 , validation loss : 18.9622\n",
      "step 127100 , training  accuracy 0.266667\n",
      "step 127100 , loss : 2.18243\n",
      "step 127100 , validation  accuracy 0.326\n",
      "step 127100 , validation loss : 19.9867\n",
      "step 127200 , training  accuracy 0.633333\n",
      "step 127200 , loss : 1.99544\n",
      "step 127200 , validation  accuracy 0.3262\n",
      "step 127200 , validation loss : 20.581\n",
      "step 127300 , training  accuracy 0.5\n",
      "step 127300 , loss : 2.12866\n",
      "step 127300 , validation  accuracy 0.2996\n",
      "step 127300 , validation loss : 18.0059\n",
      "step 127400 , training  accuracy 0.666667\n",
      "step 127400 , loss : 2.06321\n",
      "step 127400 , validation  accuracy 0.3256\n",
      "step 127400 , validation loss : 20.0733\n",
      "step 127500 , training  accuracy 0.566667\n",
      "step 127500 , loss : 2.11745\n",
      "step 127500 , validation  accuracy 0.287\n",
      "step 127500 , validation loss : 17.7147\n",
      "step 127600 , training  accuracy 0.533333\n",
      "step 127600 , loss : 2.09499\n",
      "step 127600 , validation  accuracy 0.3078\n",
      "step 127600 , validation loss : 19.5514\n",
      "step 127700 , training  accuracy 0.433333\n",
      "step 127700 , loss : 2.15264\n",
      "step 127700 , validation  accuracy 0.2948\n",
      "step 127700 , validation loss : 19.044\n",
      "step 127800 , training  accuracy 0.566667\n",
      "step 127800 , loss : 2.03455\n",
      "step 127800 , validation  accuracy 0.319\n",
      "step 127800 , validation loss : 20.1821\n",
      "step 127900 , training  accuracy 0.366667\n",
      "step 127900 , loss : 2.15394\n",
      "step 127900 , validation  accuracy 0.322\n",
      "step 127900 , validation loss : 20.2285\n",
      "step 128000 , training  accuracy 0.533333\n",
      "step 128000 , loss : 2.07052\n",
      "step 128000 , validation  accuracy 0.3126\n",
      "step 128000 , validation loss : 20.3497\n",
      "step 128100 , training  accuracy 0.5\n",
      "step 128100 , loss : 2.18148\n",
      "step 128100 , validation  accuracy 0.3152\n",
      "step 128100 , validation loss : 20.0165\n",
      "step 128200 , training  accuracy 0.566667\n",
      "step 128200 , loss : 2.0923\n",
      "step 128200 , validation  accuracy 0.3202\n",
      "step 128200 , validation loss : 19.2198\n",
      "step 128300 , training  accuracy 0.566667\n",
      "step 128300 , loss : 2.05969\n",
      "step 128300 , validation  accuracy 0.3056\n",
      "step 128300 , validation loss : 18.7865\n",
      "step 128400 , training  accuracy 0.5\n",
      "step 128400 , loss : 2.10722\n",
      "step 128400 , validation  accuracy 0.3068\n",
      "step 128400 , validation loss : 19.3867\n",
      "step 128500 , training  accuracy 0.633333\n",
      "step 128500 , loss : 2.10851\n",
      "step 128500 , validation  accuracy 0.315\n",
      "step 128500 , validation loss : 18.9717\n",
      "step 128600 , training  accuracy 0.5\n",
      "step 128600 , loss : 2.12578\n",
      "step 128600 , validation  accuracy 0.3118\n",
      "step 128600 , validation loss : 18.562\n",
      "step 128700 , training  accuracy 0.466667\n",
      "step 128700 , loss : 2.10765\n",
      "step 128700 , validation  accuracy 0.321\n",
      "step 128700 , validation loss : 20.1247\n",
      "step 128800 , training  accuracy 0.566667\n",
      "step 128800 , loss : 2.07669\n",
      "step 128800 , validation  accuracy 0.3256\n",
      "step 128800 , validation loss : 19.4582\n",
      "step 128900 , training  accuracy 0.4\n",
      "step 128900 , loss : 2.1379\n",
      "step 128900 , validation  accuracy 0.3096\n",
      "step 128900 , validation loss : 18.8022\n",
      "step 129000 , training  accuracy 0.433333\n",
      "step 129000 , loss : 2.12876\n",
      "step 129000 , validation  accuracy 0.2928\n",
      "step 129000 , validation loss : 19.203\n",
      "step 129100 , training  accuracy 0.533333\n",
      "step 129100 , loss : 2.10331\n",
      "step 129100 , validation  accuracy 0.31\n",
      "step 129100 , validation loss : 18.8031\n",
      "step 129200 , training  accuracy 0.466667\n",
      "step 129200 , loss : 2.15813\n",
      "step 129200 , validation  accuracy 0.32\n",
      "step 129200 , validation loss : 19.3154\n",
      "step 129300 , training  accuracy 0.666667\n",
      "step 129300 , loss : 2.07185\n",
      "step 129300 , validation  accuracy 0.3204\n",
      "step 129300 , validation loss : 20.4223\n",
      "step 129400 , training  accuracy 0.633333\n",
      "step 129400 , loss : 2.05335\n",
      "step 129400 , validation  accuracy 0.3032\n",
      "step 129400 , validation loss : 19.4435\n",
      "step 129500 , training  accuracy 0.533333\n",
      "step 129500 , loss : 2.09736\n",
      "step 129500 , validation  accuracy 0.297\n",
      "step 129500 , validation loss : 19.9686\n",
      "step 129600 , training  accuracy 0.5\n",
      "step 129600 , loss : 2.11653\n",
      "step 129600 , validation  accuracy 0.3124\n",
      "step 129600 , validation loss : 18.8373\n",
      "step 129700 , training  accuracy 0.4\n",
      "step 129700 , loss : 2.2093\n",
      "step 129700 , validation  accuracy 0.2996\n",
      "step 129700 , validation loss : 18.2037\n",
      "step 129800 , training  accuracy 0.566667\n",
      "step 129800 , loss : 2.11251\n",
      "step 129800 , validation  accuracy 0.3048\n",
      "step 129800 , validation loss : 18.1824\n",
      "step 129900 , training  accuracy 0.466667\n",
      "step 129900 , loss : 2.1403\n",
      "step 129900 , validation  accuracy 0.3046\n",
      "step 129900 , validation loss : 18.2708\n",
      "step 130000 , training  accuracy 0.533333\n",
      "step 130000 , loss : 2.13529\n",
      "step 130000 , validation  accuracy 0.298\n",
      "step 130000 , validation loss : 18.9427\n",
      "step 130100 , training  accuracy 0.533333\n",
      "step 130100 , loss : 2.04353\n",
      "step 130100 , validation  accuracy 0.3232\n",
      "step 130100 , validation loss : 20.1017\n",
      "step 130200 , training  accuracy 0.5\n",
      "step 130200 , loss : 2.12929\n",
      "step 130200 , validation  accuracy 0.3198\n",
      "step 130200 , validation loss : 20.2807\n",
      "step 130300 , training  accuracy 0.433333\n",
      "step 130300 , loss : 2.15784\n",
      "step 130300 , validation  accuracy 0.311\n",
      "step 130300 , validation loss : 19.1796\n",
      "step 130400 , training  accuracy 0.666667\n",
      "step 130400 , loss : 2.02617\n",
      "step 130400 , validation  accuracy 0.3112\n",
      "step 130400 , validation loss : 18.9077\n",
      "step 130500 , training  accuracy 0.533333\n",
      "step 130500 , loss : 2.13741\n",
      "step 130500 , validation  accuracy 0.3052\n",
      "step 130500 , validation loss : 19.8736\n",
      "step 130600 , training  accuracy 0.566667\n",
      "step 130600 , loss : 2.10874\n",
      "step 130600 , validation  accuracy 0.3162\n",
      "step 130600 , validation loss : 19.6252\n",
      "step 130700 , training  accuracy 0.3\n",
      "step 130700 , loss : 2.19124\n",
      "step 130700 , validation  accuracy 0.3192\n",
      "step 130700 , validation loss : 19.1222\n",
      "step 130800 , training  accuracy 0.5\n",
      "step 130800 , loss : 2.10368\n",
      "step 130800 , validation  accuracy 0.3226\n",
      "step 130800 , validation loss : 20.4852\n",
      "step 130900 , training  accuracy 0.533333\n",
      "step 130900 , loss : 2.07117\n",
      "step 130900 , validation  accuracy 0.3094\n",
      "step 130900 , validation loss : 18.9956\n",
      "step 131000 , training  accuracy 0.4\n",
      "step 131000 , loss : 2.15078\n",
      "step 131000 , validation  accuracy 0.3056\n",
      "step 131000 , validation loss : 19.7\n",
      "step 131100 , training  accuracy 0.566667\n",
      "step 131100 , loss : 2.07011\n",
      "step 131100 , validation  accuracy 0.3298\n",
      "step 131100 , validation loss : 19.8494\n",
      "step 131200 , training  accuracy 0.466667\n",
      "step 131200 , loss : 2.12115\n",
      "step 131200 , validation  accuracy 0.312\n",
      "step 131200 , validation loss : 19.5312\n",
      "step 131300 , training  accuracy 0.6\n",
      "step 131300 , loss : 2.05051\n",
      "step 131300 , validation  accuracy 0.3222\n",
      "step 131300 , validation loss : 20.0777\n",
      "step 131400 , training  accuracy 0.7\n",
      "step 131400 , loss : 2.00123\n",
      "step 131400 , validation  accuracy 0.2976\n",
      "step 131400 , validation loss : 17.5854\n",
      "step 131500 , training  accuracy 0.3\n",
      "step 131500 , loss : 2.17319\n",
      "step 131500 , validation  accuracy 0.3062\n",
      "step 131500 , validation loss : 18.5901\n",
      "step 131600 , training  accuracy 0.633333\n",
      "step 131600 , loss : 2.05108\n",
      "step 131600 , validation  accuracy 0.3114\n",
      "step 131600 , validation loss : 19.1997\n",
      "step 131700 , training  accuracy 0.7\n",
      "step 131700 , loss : 1.99027\n",
      "step 131700 , validation  accuracy 0.324\n",
      "step 131700 , validation loss : 20.0706\n",
      "step 131800 , training  accuracy 0.533333\n",
      "step 131800 , loss : 2.10505\n",
      "step 131800 , validation  accuracy 0.3024\n",
      "step 131800 , validation loss : 18.2566\n",
      "step 131900 , training  accuracy 0.5\n",
      "step 131900 , loss : 2.09322\n",
      "step 131900 , validation  accuracy 0.3206\n",
      "step 131900 , validation loss : 20.5117\n",
      "step 132000 , training  accuracy 0.366667\n",
      "step 132000 , loss : 2.163\n",
      "step 132000 , validation  accuracy 0.316\n",
      "step 132000 , validation loss : 19.4767\n",
      "step 132100 , training  accuracy 0.533333\n",
      "step 132100 , loss : 2.066\n",
      "step 132100 , validation  accuracy 0.3186\n",
      "step 132100 , validation loss : 19.3615\n",
      "step 132200 , training  accuracy 0.533333\n",
      "step 132200 , loss : 2.09491\n",
      "step 132200 , validation  accuracy 0.3194\n",
      "step 132200 , validation loss : 18.7251\n",
      "step 132300 , training  accuracy 0.5\n",
      "step 132300 , loss : 2.12255\n",
      "step 132300 , validation  accuracy 0.324\n",
      "step 132300 , validation loss : 20.8664\n",
      "step 132400 , training  accuracy 0.466667\n",
      "step 132400 , loss : 2.10962\n",
      "step 132400 , validation  accuracy 0.3216\n",
      "step 132400 , validation loss : 20.0871\n",
      "step 132500 , training  accuracy 0.6\n",
      "step 132500 , loss : 2.07893\n",
      "step 132500 , validation  accuracy 0.3164\n",
      "step 132500 , validation loss : 20.187\n",
      "step 132600 , training  accuracy 0.5\n",
      "step 132600 , loss : 2.14049\n",
      "step 132600 , validation  accuracy 0.3126\n",
      "step 132600 , validation loss : 19.7766\n",
      "step 132700 , training  accuracy 0.5\n",
      "step 132700 , loss : 2.08722\n",
      "step 132700 , validation  accuracy 0.3136\n",
      "step 132700 , validation loss : 20.3547\n",
      "step 132800 , training  accuracy 0.4\n",
      "step 132800 , loss : 2.14258\n",
      "step 132800 , validation  accuracy 0.3016\n",
      "step 132800 , validation loss : 19.1409\n",
      "step 132900 , training  accuracy 0.4\n",
      "step 132900 , loss : 2.18732\n",
      "step 132900 , validation  accuracy 0.304\n",
      "step 132900 , validation loss : 19.8909\n",
      "step 133000 , training  accuracy 0.5\n",
      "step 133000 , loss : 2.11629\n",
      "step 133000 , validation  accuracy 0.317\n",
      "step 133000 , validation loss : 20.6293\n",
      "step 133100 , training  accuracy 0.366667\n",
      "step 133100 , loss : 2.22724\n",
      "step 133100 , validation  accuracy 0.3078\n",
      "step 133100 , validation loss : 18.8251\n",
      "step 133200 , training  accuracy 0.5\n",
      "step 133200 , loss : 2.13449\n",
      "step 133200 , validation  accuracy 0.3222\n",
      "step 133200 , validation loss : 20.1238\n",
      "step 133300 , training  accuracy 0.6\n",
      "step 133300 , loss : 2.10618\n",
      "step 133300 , validation  accuracy 0.3166\n",
      "step 133300 , validation loss : 20.9972\n",
      "step 133400 , training  accuracy 0.5\n",
      "step 133400 , loss : 2.07289\n",
      "step 133400 , validation  accuracy 0.301\n",
      "step 133400 , validation loss : 19.9841\n",
      "step 133500 , training  accuracy 0.5\n",
      "step 133500 , loss : 2.12474\n",
      "step 133500 , validation  accuracy 0.3102\n",
      "step 133500 , validation loss : 19.7213\n",
      "step 133600 , training  accuracy 0.4\n",
      "step 133600 , loss : 2.16903\n",
      "step 133600 , validation  accuracy 0.3182\n",
      "step 133600 , validation loss : 19.4086\n",
      "step 133700 , training  accuracy 0.4\n",
      "step 133700 , loss : 2.16138\n",
      "step 133700 , validation  accuracy 0.2976\n",
      "step 133700 , validation loss : 19.3977\n",
      "step 133800 , training  accuracy 0.366667\n",
      "step 133800 , loss : 2.14597\n",
      "step 133800 , validation  accuracy 0.3024\n",
      "step 133800 , validation loss : 18.7258\n",
      "step 133900 , training  accuracy 0.533333\n",
      "step 133900 , loss : 2.06376\n",
      "step 133900 , validation  accuracy 0.3274\n",
      "step 133900 , validation loss : 20.7628\n",
      "step 134000 , training  accuracy 0.466667\n",
      "step 134000 , loss : 2.14491\n",
      "step 134000 , validation  accuracy 0.317\n",
      "step 134000 , validation loss : 19.2649\n",
      "step 134100 , training  accuracy 0.533333\n",
      "step 134100 , loss : 2.13781\n",
      "step 134100 , validation  accuracy 0.317\n",
      "step 134100 , validation loss : 18.8849\n",
      "step 134200 , training  accuracy 0.533333\n",
      "step 134200 , loss : 2.13726\n",
      "step 134200 , validation  accuracy 0.3144\n",
      "step 134200 , validation loss : 19.1158\n",
      "step 134300 , training  accuracy 0.366667\n",
      "step 134300 , loss : 2.18632\n",
      "step 134300 , validation  accuracy 0.3024\n",
      "step 134300 , validation loss : 17.9429\n",
      "step 134400 , training  accuracy 0.466667\n",
      "step 134400 , loss : 2.14051\n",
      "step 134400 , validation  accuracy 0.3152\n",
      "step 134400 , validation loss : 19.0981\n",
      "step 134500 , training  accuracy 0.433333\n",
      "step 134500 , loss : 2.18001\n",
      "step 134500 , validation  accuracy 0.304\n",
      "step 134500 , validation loss : 18.5167\n",
      "step 134600 , training  accuracy 0.433333\n",
      "step 134600 , loss : 2.16821\n",
      "step 134600 , validation  accuracy 0.3274\n",
      "step 134600 , validation loss : 19.9114\n",
      "step 134700 , training  accuracy 0.466667\n",
      "step 134700 , loss : 2.12074\n",
      "step 134700 , validation  accuracy 0.293\n",
      "step 134700 , validation loss : 18.6744\n",
      "step 134800 , training  accuracy 0.633333\n",
      "step 134800 , loss : 2.05347\n",
      "step 134800 , validation  accuracy 0.3334\n",
      "step 134800 , validation loss : 21.311\n",
      "step 134900 , training  accuracy 0.4\n",
      "step 134900 , loss : 2.15397\n",
      "step 134900 , validation  accuracy 0.3236\n",
      "step 134900 , validation loss : 20.3438\n",
      "step 135000 , training  accuracy 0.666667\n",
      "step 135000 , loss : 2.03334\n",
      "step 135000 , validation  accuracy 0.3244\n",
      "step 135000 , validation loss : 20.0699\n",
      "step 135100 , training  accuracy 0.466667\n",
      "step 135100 , loss : 2.14275\n",
      "step 135100 , validation  accuracy 0.3124\n",
      "step 135100 , validation loss : 18.9092\n",
      "step 135200 , training  accuracy 0.466667\n",
      "step 135200 , loss : 2.14374\n",
      "step 135200 , validation  accuracy 0.3168\n",
      "step 135200 , validation loss : 20.2606\n",
      "step 135300 , training  accuracy 0.533333\n",
      "step 135300 , loss : 2.08799\n",
      "step 135300 , validation  accuracy 0.3034\n",
      "step 135300 , validation loss : 18.6604\n",
      "step 135400 , training  accuracy 0.4\n",
      "step 135400 , loss : 2.13046\n",
      "step 135400 , validation  accuracy 0.3096\n",
      "step 135400 , validation loss : 18.5727\n",
      "step 135500 , training  accuracy 0.633333\n",
      "step 135500 , loss : 2.04289\n",
      "step 135500 , validation  accuracy 0.3198\n",
      "step 135500 , validation loss : 20.4605\n",
      "step 135600 , training  accuracy 0.4\n",
      "step 135600 , loss : 2.13411\n",
      "step 135600 , validation  accuracy 0.317\n",
      "step 135600 , validation loss : 19.9653\n",
      "step 135700 , training  accuracy 0.5\n",
      "step 135700 , loss : 2.13144\n",
      "step 135700 , validation  accuracy 0.3088\n",
      "step 135700 , validation loss : 19.6999\n",
      "step 135800 , training  accuracy 0.633333\n",
      "step 135800 , loss : 2.06983\n",
      "step 135800 , validation  accuracy 0.3152\n",
      "step 135800 , validation loss : 19.1141\n",
      "step 135900 , training  accuracy 0.433333\n",
      "step 135900 , loss : 2.13737\n",
      "step 135900 , validation  accuracy 0.3164\n",
      "step 135900 , validation loss : 20.3145\n",
      "step 136000 , training  accuracy 0.5\n",
      "step 136000 , loss : 2.09017\n",
      "step 136000 , validation  accuracy 0.3072\n",
      "step 136000 , validation loss : 21.4242\n",
      "step 136100 , training  accuracy 0.466667\n",
      "step 136100 , loss : 2.12902\n",
      "step 136100 , validation  accuracy 0.2974\n",
      "step 136100 , validation loss : 20.0467\n",
      "step 136200 , training  accuracy 0.433333\n",
      "step 136200 , loss : 2.14241\n",
      "step 136200 , validation  accuracy 0.3254\n",
      "step 136200 , validation loss : 20.0638\n",
      "step 136300 , training  accuracy 0.366667\n",
      "step 136300 , loss : 2.14245\n",
      "step 136300 , validation  accuracy 0.3058\n",
      "step 136300 , validation loss : 18.7154\n",
      "step 136400 , training  accuracy 0.533333\n",
      "step 136400 , loss : 2.10983\n",
      "step 136400 , validation  accuracy 0.3244\n",
      "step 136400 , validation loss : 20.4491\n",
      "step 136500 , training  accuracy 0.6\n",
      "step 136500 , loss : 2.02353\n",
      "step 136500 , validation  accuracy 0.3214\n",
      "step 136500 , validation loss : 21.2688\n",
      "step 136600 , training  accuracy 0.5\n",
      "step 136600 , loss : 2.11958\n",
      "step 136600 , validation  accuracy 0.3174\n",
      "step 136600 , validation loss : 19.5702\n",
      "step 136700 , training  accuracy 0.533333\n",
      "step 136700 , loss : 2.0854\n",
      "step 136700 , validation  accuracy 0.3254\n",
      "step 136700 , validation loss : 20.6421\n",
      "step 136800 , training  accuracy 0.366667\n",
      "step 136800 , loss : 2.18879\n",
      "step 136800 , validation  accuracy 0.3196\n",
      "step 136800 , validation loss : 19.7788\n",
      "step 136900 , training  accuracy 0.633333\n",
      "step 136900 , loss : 2.01952\n",
      "step 136900 , validation  accuracy 0.3076\n",
      "step 136900 , validation loss : 20.9294\n",
      "step 137000 , training  accuracy 0.366667\n",
      "step 137000 , loss : 2.14158\n",
      "step 137000 , validation  accuracy 0.2988\n",
      "step 137000 , validation loss : 18.3762\n",
      "step 137100 , training  accuracy 0.4\n",
      "step 137100 , loss : 2.12213\n",
      "step 137100 , validation  accuracy 0.3172\n",
      "step 137100 , validation loss : 20.2274\n",
      "step 137200 , training  accuracy 0.5\n",
      "step 137200 , loss : 2.14992\n",
      "step 137200 , validation  accuracy 0.331\n",
      "step 137200 , validation loss : 20.4068\n",
      "step 137300 , training  accuracy 0.466667\n",
      "step 137300 , loss : 2.13712\n",
      "step 137300 , validation  accuracy 0.318\n",
      "step 137300 , validation loss : 19.8347\n",
      "step 137400 , training  accuracy 0.533333\n",
      "step 137400 , loss : 2.1096\n",
      "step 137400 , validation  accuracy 0.2894\n",
      "step 137400 , validation loss : 18.4145\n",
      "step 137500 , training  accuracy 0.6\n",
      "step 137500 , loss : 2.06782\n",
      "step 137500 , validation  accuracy 0.3266\n",
      "step 137500 , validation loss : 20.1638\n",
      "step 137600 , training  accuracy 0.5\n",
      "step 137600 , loss : 2.11297\n",
      "step 137600 , validation  accuracy 0.3114\n",
      "step 137600 , validation loss : 19.5424\n",
      "step 137700 , training  accuracy 0.4\n",
      "step 137700 , loss : 2.13519\n",
      "step 137700 , validation  accuracy 0.3124\n",
      "step 137700 , validation loss : 19.4583\n",
      "step 137800 , training  accuracy 0.433333\n",
      "step 137800 , loss : 2.11667\n",
      "step 137800 , validation  accuracy 0.3294\n",
      "step 137800 , validation loss : 20.4165\n",
      "step 137900 , training  accuracy 0.566667\n",
      "step 137900 , loss : 2.10397\n",
      "step 137900 , validation  accuracy 0.3252\n",
      "step 137900 , validation loss : 20.5691\n",
      "step 138000 , training  accuracy 0.333333\n",
      "step 138000 , loss : 2.20739\n",
      "step 138000 , validation  accuracy 0.312\n",
      "step 138000 , validation loss : 18.9559\n",
      "step 138100 , training  accuracy 0.433333\n",
      "step 138100 , loss : 2.13511\n",
      "step 138100 , validation  accuracy 0.3114\n",
      "step 138100 , validation loss : 19.4788\n",
      "step 138200 , training  accuracy 0.6\n",
      "step 138200 , loss : 2.06284\n",
      "step 138200 , validation  accuracy 0.3016\n",
      "step 138200 , validation loss : 19.6319\n",
      "step 138300 , training  accuracy 0.566667\n",
      "step 138300 , loss : 2.03191\n",
      "step 138300 , validation  accuracy 0.3222\n",
      "step 138300 , validation loss : 19.7579\n",
      "step 138400 , training  accuracy 0.433333\n",
      "step 138400 , loss : 2.17088\n",
      "step 138400 , validation  accuracy 0.2928\n",
      "step 138400 , validation loss : 17.829\n",
      "step 138500 , training  accuracy 0.566667\n",
      "step 138500 , loss : 2.0913\n",
      "step 138500 , validation  accuracy 0.3196\n",
      "step 138500 , validation loss : 20.6333\n",
      "step 138600 , training  accuracy 0.5\n",
      "step 138600 , loss : 2.10113\n",
      "step 138600 , validation  accuracy 0.3184\n",
      "step 138600 , validation loss : 19.9446\n",
      "step 138700 , training  accuracy 0.533333\n",
      "step 138700 , loss : 2.09296\n",
      "step 138700 , validation  accuracy 0.3324\n",
      "step 138700 , validation loss : 21.9265\n",
      "step 138800 , training  accuracy 0.533333\n",
      "step 138800 , loss : 2.07545\n",
      "step 138800 , validation  accuracy 0.323\n",
      "step 138800 , validation loss : 21.1438\n",
      "step 138900 , training  accuracy 0.5\n",
      "step 138900 , loss : 2.09018\n",
      "step 138900 , validation  accuracy 0.312\n",
      "step 138900 , validation loss : 19.0566\n",
      "step 139000 , training  accuracy 0.7\n",
      "step 139000 , loss : 2.04245\n",
      "step 139000 , validation  accuracy 0.3244\n",
      "step 139000 , validation loss : 20.5039\n",
      "step 139100 , training  accuracy 0.6\n",
      "step 139100 , loss : 2.09448\n",
      "step 139100 , validation  accuracy 0.315\n",
      "step 139100 , validation loss : 19.6745\n",
      "step 139200 , training  accuracy 0.366667\n",
      "step 139200 , loss : 2.13142\n",
      "step 139200 , validation  accuracy 0.3276\n",
      "step 139200 , validation loss : 21.5155\n",
      "step 139300 , training  accuracy 0.5\n",
      "step 139300 , loss : 2.11314\n",
      "step 139300 , validation  accuracy 0.3176\n",
      "step 139300 , validation loss : 20.8276\n",
      "step 139400 , training  accuracy 0.4\n",
      "step 139400 , loss : 2.12804\n",
      "step 139400 , validation  accuracy 0.3166\n",
      "step 139400 , validation loss : 20.1618\n",
      "step 139500 , training  accuracy 0.533333\n",
      "step 139500 , loss : 2.12575\n",
      "step 139500 , validation  accuracy 0.3044\n",
      "step 139500 , validation loss : 19.0926\n",
      "step 139600 , training  accuracy 0.4\n",
      "step 139600 , loss : 2.0877\n",
      "step 139600 , validation  accuracy 0.3118\n",
      "step 139600 , validation loss : 19.7304\n",
      "step 139700 , training  accuracy 0.366667\n",
      "step 139700 , loss : 2.16557\n",
      "step 139700 , validation  accuracy 0.3034\n",
      "step 139700 , validation loss : 18.8153\n",
      "step 139800 , training  accuracy 0.533333\n",
      "step 139800 , loss : 2.16689\n",
      "step 139800 , validation  accuracy 0.2762\n",
      "step 139800 , validation loss : 18.0882\n",
      "step 139900 , training  accuracy 0.666667\n",
      "step 139900 , loss : 2.05162\n",
      "step 139900 , validation  accuracy 0.3138\n",
      "step 139900 , validation loss : 19.512\n",
      "step 140000 , training  accuracy 0.333333\n",
      "step 140000 , loss : 2.1757\n",
      "step 140000 , validation  accuracy 0.2896\n",
      "step 140000 , validation loss : 19.381\n",
      "step 140100 , training  accuracy 0.566667\n",
      "step 140100 , loss : 2.06696\n",
      "step 140100 , validation  accuracy 0.3174\n",
      "step 140100 , validation loss : 19.9307\n",
      "step 140200 , training  accuracy 0.466667\n",
      "step 140200 , loss : 2.10487\n",
      "step 140200 , validation  accuracy 0.2998\n",
      "step 140200 , validation loss : 19.7294\n",
      "step 140300 , training  accuracy 0.666667\n",
      "step 140300 , loss : 2.09238\n",
      "step 140300 , validation  accuracy 0.2868\n",
      "step 140300 , validation loss : 18.7293\n",
      "step 140400 , training  accuracy 0.566667\n",
      "step 140400 , loss : 2.11028\n",
      "step 140400 , validation  accuracy 0.3152\n",
      "step 140400 , validation loss : 19.8528\n",
      "step 140500 , training  accuracy 0.5\n",
      "step 140500 , loss : 2.15259\n",
      "step 140500 , validation  accuracy 0.3174\n",
      "step 140500 , validation loss : 19.9662\n",
      "step 140600 , training  accuracy 0.533333\n",
      "step 140600 , loss : 2.05376\n",
      "step 140600 , validation  accuracy 0.3146\n",
      "step 140600 , validation loss : 20.7973\n",
      "step 140700 , training  accuracy 0.433333\n",
      "step 140700 , loss : 2.2023\n",
      "step 140700 , validation  accuracy 0.294\n",
      "step 140700 , validation loss : 18.3868\n",
      "step 140800 , training  accuracy 0.566667\n",
      "step 140800 , loss : 2.07118\n",
      "step 140800 , validation  accuracy 0.3\n",
      "step 140800 , validation loss : 18.5495\n",
      "step 140900 , training  accuracy 0.466667\n",
      "step 140900 , loss : 2.12771\n",
      "step 140900 , validation  accuracy 0.297\n",
      "step 140900 , validation loss : 19.9188\n",
      "step 141000 , training  accuracy 0.6\n",
      "step 141000 , loss : 2.08029\n",
      "step 141000 , validation  accuracy 0.3132\n",
      "step 141000 , validation loss : 21.1953\n",
      "step 141100 , training  accuracy 0.466667\n",
      "step 141100 , loss : 2.16814\n",
      "step 141100 , validation  accuracy 0.3088\n",
      "step 141100 , validation loss : 19.8278\n",
      "step 141200 , training  accuracy 0.666667\n",
      "step 141200 , loss : 1.99808\n",
      "step 141200 , validation  accuracy 0.3176\n",
      "step 141200 , validation loss : 19.6459\n",
      "step 141300 , training  accuracy 0.5\n",
      "step 141300 , loss : 2.14345\n",
      "step 141300 , validation  accuracy 0.2996\n",
      "step 141300 , validation loss : 19.5545\n",
      "step 141400 , training  accuracy 0.366667\n",
      "step 141400 , loss : 2.16549\n",
      "step 141400 , validation  accuracy 0.3172\n",
      "step 141400 , validation loss : 20.8185\n",
      "step 141500 , training  accuracy 0.633333\n",
      "step 141500 , loss : 2.03142\n",
      "step 141500 , validation  accuracy 0.323\n",
      "step 141500 , validation loss : 21.6539\n",
      "step 141600 , training  accuracy 0.5\n",
      "step 141600 , loss : 2.08447\n",
      "step 141600 , validation  accuracy 0.3156\n",
      "step 141600 , validation loss : 19.9766\n",
      "step 141700 , training  accuracy 0.533333\n",
      "step 141700 , loss : 2.11685\n",
      "step 141700 , validation  accuracy 0.312\n",
      "step 141700 , validation loss : 20.1108\n",
      "step 141800 , training  accuracy 0.5\n",
      "step 141800 , loss : 2.0916\n",
      "step 141800 , validation  accuracy 0.306\n",
      "step 141800 , validation loss : 19.3791\n",
      "step 141900 , training  accuracy 0.566667\n",
      "step 141900 , loss : 2.06347\n",
      "step 141900 , validation  accuracy 0.3066\n",
      "step 141900 , validation loss : 19.2331\n",
      "step 142000 , training  accuracy 0.6\n",
      "step 142000 , loss : 2.02375\n",
      "step 142000 , validation  accuracy 0.3134\n",
      "step 142000 , validation loss : 20.0929\n",
      "step 142100 , training  accuracy 0.466667\n",
      "step 142100 , loss : 2.10847\n",
      "step 142100 , validation  accuracy 0.3016\n",
      "step 142100 , validation loss : 20.2102\n",
      "step 142200 , training  accuracy 0.533333\n",
      "step 142200 , loss : 2.13403\n",
      "step 142200 , validation  accuracy 0.319\n",
      "step 142200 , validation loss : 21.3618\n",
      "step 142300 , training  accuracy 0.6\n",
      "step 142300 , loss : 2.06742\n",
      "step 142300 , validation  accuracy 0.3098\n",
      "step 142300 , validation loss : 19.5449\n",
      "step 142400 , training  accuracy 0.6\n",
      "step 142400 , loss : 2.07915\n",
      "step 142400 , validation  accuracy 0.3142\n",
      "step 142400 , validation loss : 20.1988\n",
      "step 142500 , training  accuracy 0.433333\n",
      "step 142500 , loss : 2.15257\n",
      "step 142500 , validation  accuracy 0.3238\n",
      "step 142500 , validation loss : 22.0635\n",
      "step 142600 , training  accuracy 0.7\n",
      "step 142600 , loss : 2.00834\n",
      "step 142600 , validation  accuracy 0.32\n",
      "step 142600 , validation loss : 20.6802\n",
      "step 142700 , training  accuracy 0.5\n",
      "step 142700 , loss : 2.1156\n",
      "step 142700 , validation  accuracy 0.317\n",
      "step 142700 , validation loss : 20.3173\n",
      "step 142800 , training  accuracy 0.433333\n",
      "step 142800 , loss : 2.13497\n",
      "step 142800 , validation  accuracy 0.2976\n",
      "step 142800 , validation loss : 19.6855\n",
      "step 142900 , training  accuracy 0.566667\n",
      "step 142900 , loss : 2.05962\n",
      "step 142900 , validation  accuracy 0.3262\n",
      "step 142900 , validation loss : 21.562\n",
      "step 143000 , training  accuracy 0.566667\n",
      "step 143000 , loss : 2.09377\n",
      "step 143000 , validation  accuracy 0.322\n",
      "step 143000 , validation loss : 20.6182\n",
      "step 143100 , training  accuracy 0.466667\n",
      "step 143100 , loss : 2.11469\n",
      "step 143100 , validation  accuracy 0.3172\n",
      "step 143100 , validation loss : 20.524\n",
      "step 143200 , training  accuracy 0.633333\n",
      "step 143200 , loss : 2.05829\n",
      "step 143200 , validation  accuracy 0.3108\n",
      "step 143200 , validation loss : 20.663\n",
      "step 143300 , training  accuracy 0.666667\n",
      "step 143300 , loss : 2.01618\n",
      "step 143300 , validation  accuracy 0.3148\n",
      "step 143300 , validation loss : 20.1652\n",
      "step 143400 , training  accuracy 0.466667\n",
      "step 143400 , loss : 2.12183\n",
      "step 143400 , validation  accuracy 0.3192\n",
      "step 143400 , validation loss : 21.1185\n",
      "step 143500 , training  accuracy 0.6\n",
      "step 143500 , loss : 2.05165\n",
      "step 143500 , validation  accuracy 0.3036\n",
      "step 143500 , validation loss : 20.6189\n",
      "step 143600 , training  accuracy 0.6\n",
      "step 143600 , loss : 2.06862\n",
      "step 143600 , validation  accuracy 0.3112\n",
      "step 143600 , validation loss : 19.7389\n",
      "step 143700 , training  accuracy 0.566667\n",
      "step 143700 , loss : 2.05684\n",
      "step 143700 , validation  accuracy 0.3272\n",
      "step 143700 , validation loss : 21.4691\n",
      "step 143800 , training  accuracy 0.5\n",
      "step 143800 , loss : 2.11258\n",
      "step 143800 , validation  accuracy 0.3074\n",
      "step 143800 , validation loss : 19.6442\n",
      "step 143900 , training  accuracy 0.5\n",
      "step 143900 , loss : 2.1019\n",
      "step 143900 , validation  accuracy 0.31\n",
      "step 143900 , validation loss : 19.5496\n",
      "step 144000 , training  accuracy 0.433333\n",
      "step 144000 , loss : 2.13408\n",
      "step 144000 , validation  accuracy 0.3034\n",
      "step 144000 , validation loss : 20.8232\n",
      "step 144100 , training  accuracy 0.433333\n",
      "step 144100 , loss : 2.12064\n",
      "step 144100 , validation  accuracy 0.3136\n",
      "step 144100 , validation loss : 19.8976\n",
      "step 144200 , training  accuracy 0.433333\n",
      "step 144200 , loss : 2.15321\n",
      "step 144200 , validation  accuracy 0.3112\n",
      "step 144200 , validation loss : 19.9948\n",
      "step 144300 , training  accuracy 0.466667\n",
      "step 144300 , loss : 2.12931\n",
      "step 144300 , validation  accuracy 0.3218\n",
      "step 144300 , validation loss : 21.3233\n",
      "step 144400 , training  accuracy 0.466667\n",
      "step 144400 , loss : 2.10464\n",
      "step 144400 , validation  accuracy 0.3034\n",
      "step 144400 , validation loss : 18.8409\n",
      "step 144500 , training  accuracy 0.4\n",
      "step 144500 , loss : 2.11703\n",
      "step 144500 , validation  accuracy 0.309\n",
      "step 144500 , validation loss : 20.9705\n",
      "step 144600 , training  accuracy 0.566667\n",
      "step 144600 , loss : 2.12075\n",
      "step 144600 , validation  accuracy 0.3042\n",
      "step 144600 , validation loss : 19.9208\n",
      "step 144700 , training  accuracy 0.4\n",
      "step 144700 , loss : 2.15602\n",
      "step 144700 , validation  accuracy 0.3142\n",
      "step 144700 , validation loss : 20.5839\n",
      "step 144800 , training  accuracy 0.533333\n",
      "step 144800 , loss : 2.11826\n",
      "step 144800 , validation  accuracy 0.307\n",
      "step 144800 , validation loss : 20.0225\n",
      "step 144900 , training  accuracy 0.533333\n",
      "step 144900 , loss : 2.05814\n",
      "step 144900 , validation  accuracy 0.325\n",
      "step 144900 , validation loss : 21.8355\n",
      "step 145000 , training  accuracy 0.566667\n",
      "step 145000 , loss : 2.07617\n",
      "step 145000 , validation  accuracy 0.3238\n",
      "step 145000 , validation loss : 21.1525\n",
      "step 145100 , training  accuracy 0.633333\n",
      "step 145100 , loss : 2.0544\n",
      "step 145100 , validation  accuracy 0.3172\n",
      "step 145100 , validation loss : 20.6962\n",
      "step 145200 , training  accuracy 0.533333\n",
      "step 145200 , loss : 2.09163\n",
      "step 145200 , validation  accuracy 0.3174\n",
      "step 145200 , validation loss : 20.0575\n",
      "step 145300 , training  accuracy 0.633333\n",
      "step 145300 , loss : 2.02996\n",
      "step 145300 , validation  accuracy 0.3134\n",
      "step 145300 , validation loss : 19.9981\n",
      "step 145400 , training  accuracy 0.566667\n",
      "step 145400 , loss : 2.07459\n",
      "step 145400 , validation  accuracy 0.3282\n",
      "step 145400 , validation loss : 21.4708\n",
      "step 145500 , training  accuracy 0.733333\n",
      "step 145500 , loss : 2.03263\n",
      "step 145500 , validation  accuracy 0.3076\n",
      "step 145500 , validation loss : 20.7079\n",
      "step 145600 , training  accuracy 0.566667\n",
      "step 145600 , loss : 2.0862\n",
      "step 145600 , validation  accuracy 0.3078\n",
      "step 145600 , validation loss : 20.8804\n",
      "step 145700 , training  accuracy 0.4\n",
      "step 145700 , loss : 2.12586\n",
      "step 145700 , validation  accuracy 0.3216\n",
      "step 145700 , validation loss : 21.2956\n",
      "step 145800 , training  accuracy 0.6\n",
      "step 145800 , loss : 2.05665\n",
      "step 145800 , validation  accuracy 0.3266\n",
      "step 145800 , validation loss : 21.2529\n",
      "step 145900 , training  accuracy 0.6\n",
      "step 145900 , loss : 2.13025\n",
      "step 145900 , validation  accuracy 0.307\n",
      "step 145900 , validation loss : 19.7904\n",
      "step 146000 , training  accuracy 0.366667\n",
      "step 146000 , loss : 2.1297\n",
      "step 146000 , validation  accuracy 0.3054\n",
      "step 146000 , validation loss : 20.0336\n",
      "step 146100 , training  accuracy 0.433333\n",
      "step 146100 , loss : 2.11775\n",
      "step 146100 , validation  accuracy 0.3194\n",
      "step 146100 , validation loss : 21.0965\n",
      "step 146200 , training  accuracy 0.566667\n",
      "step 146200 , loss : 2.12202\n",
      "step 146200 , validation  accuracy 0.3244\n",
      "step 146200 , validation loss : 21.4131\n",
      "step 146300 , training  accuracy 0.566667\n",
      "step 146300 , loss : 2.14062\n",
      "step 146300 , validation  accuracy 0.3004\n",
      "step 146300 , validation loss : 19.5995\n",
      "step 146400 , training  accuracy 0.533333\n",
      "step 146400 , loss : 2.08715\n",
      "step 146400 , validation  accuracy 0.3162\n",
      "step 146400 , validation loss : 20.46\n",
      "step 146500 , training  accuracy 0.6\n",
      "step 146500 , loss : 2.08624\n",
      "step 146500 , validation  accuracy 0.3112\n",
      "step 146500 , validation loss : 20.0898\n",
      "step 146600 , training  accuracy 0.333333\n",
      "step 146600 , loss : 2.19007\n",
      "step 146600 , validation  accuracy 0.3092\n",
      "step 146600 , validation loss : 19.8539\n",
      "step 146700 , training  accuracy 0.6\n",
      "step 146700 , loss : 2.07757\n",
      "step 146700 , validation  accuracy 0.3196\n",
      "step 146700 , validation loss : 20.7548\n",
      "step 146800 , training  accuracy 0.533333\n",
      "step 146800 , loss : 2.08559\n",
      "step 146800 , validation  accuracy 0.2932\n",
      "step 146800 , validation loss : 18.6703\n",
      "step 146900 , training  accuracy 0.3\n",
      "step 146900 , loss : 2.1754\n",
      "step 146900 , validation  accuracy 0.3096\n",
      "step 146900 , validation loss : 19.6191\n",
      "step 147000 , training  accuracy 0.6\n",
      "step 147000 , loss : 2.05037\n",
      "step 147000 , validation  accuracy 0.2964\n",
      "step 147000 , validation loss : 21.5684\n",
      "step 147100 , training  accuracy 0.5\n",
      "step 147100 , loss : 2.12745\n",
      "step 147100 , validation  accuracy 0.3156\n",
      "step 147100 , validation loss : 20.7197\n",
      "step 147200 , training  accuracy 0.366667\n",
      "step 147200 , loss : 2.14817\n",
      "step 147200 , validation  accuracy 0.3008\n",
      "step 147200 , validation loss : 19.3682\n",
      "step 147300 , training  accuracy 0.4\n",
      "step 147300 , loss : 2.14144\n",
      "step 147300 , validation  accuracy 0.3224\n",
      "step 147300 , validation loss : 22.1013\n",
      "step 147400 , training  accuracy 0.333333\n",
      "step 147400 , loss : 2.22508\n",
      "step 147400 , validation  accuracy 0.309\n",
      "step 147400 , validation loss : 20.2828\n",
      "step 147500 , training  accuracy 0.6\n",
      "step 147500 , loss : 2.06929\n",
      "step 147500 , validation  accuracy 0.3114\n",
      "step 147500 , validation loss : 21.1493\n",
      "step 147600 , training  accuracy 0.5\n",
      "step 147600 , loss : 2.0931\n",
      "step 147600 , validation  accuracy 0.3238\n",
      "step 147600 , validation loss : 21.7504\n",
      "step 147700 , training  accuracy 0.5\n",
      "step 147700 , loss : 2.09411\n",
      "step 147700 , validation  accuracy 0.3218\n",
      "step 147700 , validation loss : 21.1678\n",
      "step 147800 , training  accuracy 0.566667\n",
      "step 147800 , loss : 2.10776\n",
      "step 147800 , validation  accuracy 0.3172\n",
      "step 147800 , validation loss : 20.7222\n",
      "step 147900 , training  accuracy 0.566667\n",
      "step 147900 , loss : 2.09888\n",
      "step 147900 , validation  accuracy 0.3\n",
      "step 147900 , validation loss : 20.1296\n",
      "step 148000 , training  accuracy 0.466667\n",
      "step 148000 , loss : 2.14336\n",
      "step 148000 , validation  accuracy 0.3016\n",
      "step 148000 , validation loss : 19.2818\n",
      "step 148100 , training  accuracy 0.666667\n",
      "step 148100 , loss : 2.00894\n",
      "step 148100 , validation  accuracy 0.3168\n",
      "step 148100 , validation loss : 21.2742\n",
      "step 148200 , training  accuracy 0.466667\n",
      "step 148200 , loss : 2.13703\n",
      "step 148200 , validation  accuracy 0.3212\n",
      "step 148200 , validation loss : 20.8113\n",
      "step 148300 , training  accuracy 0.6\n",
      "step 148300 , loss : 2.06665\n",
      "step 148300 , validation  accuracy 0.303\n",
      "step 148300 , validation loss : 20.1105\n",
      "step 148400 , training  accuracy 0.633333\n",
      "step 148400 , loss : 2.11463\n",
      "step 148400 , validation  accuracy 0.3034\n",
      "step 148400 , validation loss : 19.2491\n",
      "step 148500 , training  accuracy 0.466667\n",
      "step 148500 , loss : 2.12244\n",
      "step 148500 , validation  accuracy 0.3046\n",
      "step 148500 , validation loss : 19.8494\n",
      "step 148600 , training  accuracy 0.6\n",
      "step 148600 , loss : 2.06562\n",
      "step 148600 , validation  accuracy 0.3162\n",
      "step 148600 , validation loss : 20.4587\n",
      "step 148700 , training  accuracy 0.6\n",
      "step 148700 , loss : 2.04589\n",
      "step 148700 , validation  accuracy 0.3144\n",
      "step 148700 , validation loss : 20.7623\n",
      "step 148800 , training  accuracy 0.533333\n",
      "step 148800 , loss : 2.10333\n",
      "step 148800 , validation  accuracy 0.3258\n",
      "step 148800 , validation loss : 21.8622\n",
      "step 148900 , training  accuracy 0.566667\n",
      "step 148900 , loss : 2.03919\n",
      "step 148900 , validation  accuracy 0.3194\n",
      "step 148900 , validation loss : 21.5706\n",
      "step 149000 , training  accuracy 0.633333\n",
      "step 149000 , loss : 2.07773\n",
      "step 149000 , validation  accuracy 0.3024\n",
      "step 149000 , validation loss : 20.8792\n",
      "step 149100 , training  accuracy 0.433333\n",
      "step 149100 , loss : 2.13699\n",
      "step 149100 , validation  accuracy 0.3146\n",
      "step 149100 , validation loss : 20.4573\n",
      "step 149200 , training  accuracy 0.366667\n",
      "step 149200 , loss : 2.1841\n",
      "step 149200 , validation  accuracy 0.3224\n",
      "step 149200 , validation loss : 21.1873\n",
      "step 149300 , training  accuracy 0.466667\n",
      "step 149300 , loss : 2.1194\n",
      "step 149300 , validation  accuracy 0.3006\n",
      "step 149300 , validation loss : 19.4744\n",
      "step 149400 , training  accuracy 0.566667\n",
      "step 149400 , loss : 2.05933\n",
      "step 149400 , validation  accuracy 0.315\n",
      "step 149400 , validation loss : 20.5171\n",
      "step 149500 , training  accuracy 0.633333\n",
      "step 149500 , loss : 2.05424\n",
      "step 149500 , validation  accuracy 0.319\n",
      "step 149500 , validation loss : 20.9289\n",
      "step 149600 , training  accuracy 0.5\n",
      "step 149600 , loss : 2.16431\n",
      "step 149600 , validation  accuracy 0.3188\n",
      "step 149600 , validation loss : 20.7885\n",
      "step 149700 , training  accuracy 0.433333\n",
      "step 149700 , loss : 2.14202\n",
      "step 149700 , validation  accuracy 0.309\n",
      "step 149700 , validation loss : 19.9896\n",
      "step 149800 , training  accuracy 0.566667\n",
      "step 149800 , loss : 2.09595\n",
      "step 149800 , validation  accuracy 0.3016\n",
      "step 149800 , validation loss : 20.4674\n",
      "step 149900 , training  accuracy 0.6\n",
      "step 149900 , loss : 2.03585\n",
      "step 149900 , validation  accuracy 0.3026\n",
      "step 149900 , validation loss : 21.0795\n",
      "step 150000 , training  accuracy 0.6\n",
      "step 150000 , loss : 1.99645\n",
      "step 150000 , validation  accuracy 0.315\n",
      "step 150000 , validation loss : 20.4898\n",
      "step 150100 , training  accuracy 0.433333\n",
      "step 150100 , loss : 2.14056\n",
      "step 150100 , validation  accuracy 0.3314\n",
      "step 150100 , validation loss : 22.7914\n",
      "step 150200 , training  accuracy 0.5\n",
      "step 150200 , loss : 2.17166\n",
      "step 150200 , validation  accuracy 0.307\n",
      "step 150200 , validation loss : 21.0525\n",
      "step 150300 , training  accuracy 0.5\n",
      "step 150300 , loss : 2.10358\n",
      "step 150300 , validation  accuracy 0.313\n",
      "step 150300 , validation loss : 20.168\n",
      "step 150400 , training  accuracy 0.533333\n",
      "step 150400 , loss : 2.04652\n",
      "step 150400 , validation  accuracy 0.3276\n",
      "step 150400 , validation loss : 22.0334\n",
      "step 150500 , training  accuracy 0.633333\n",
      "step 150500 , loss : 2.07671\n",
      "step 150500 , validation  accuracy 0.3034\n",
      "step 150500 , validation loss : 21.0287\n",
      "step 150600 , training  accuracy 0.466667\n",
      "step 150600 , loss : 2.15509\n",
      "step 150600 , validation  accuracy 0.3228\n",
      "step 150600 , validation loss : 21.3493\n",
      "step 150700 , training  accuracy 0.5\n",
      "step 150700 , loss : 2.1052\n",
      "step 150700 , validation  accuracy 0.3158\n",
      "step 150700 , validation loss : 20.5607\n",
      "step 150800 , training  accuracy 0.633333\n",
      "step 150800 , loss : 2.07361\n",
      "step 150800 , validation  accuracy 0.3066\n",
      "step 150800 , validation loss : 19.9025\n",
      "step 150900 , training  accuracy 0.566667\n",
      "step 150900 , loss : 2.08372\n",
      "step 150900 , validation  accuracy 0.3028\n",
      "step 150900 , validation loss : 19.8136\n",
      "step 151000 , training  accuracy 0.5\n",
      "step 151000 , loss : 2.07063\n",
      "step 151000 , validation  accuracy 0.3064\n",
      "step 151000 , validation loss : 21.0803\n",
      "step 151100 , training  accuracy 0.433333\n",
      "step 151100 , loss : 2.16838\n",
      "step 151100 , validation  accuracy 0.3096\n",
      "step 151100 , validation loss : 20.4\n",
      "step 151200 , training  accuracy 0.5\n",
      "step 151200 , loss : 2.14266\n",
      "step 151200 , validation  accuracy 0.319\n",
      "step 151200 , validation loss : 21.2286\n",
      "step 151300 , training  accuracy 0.533333\n",
      "step 151300 , loss : 2.07982\n",
      "step 151300 , validation  accuracy 0.3118\n",
      "step 151300 , validation loss : 21.2017\n",
      "step 151400 , training  accuracy 0.566667\n",
      "step 151400 , loss : 2.08601\n",
      "step 151400 , validation  accuracy 0.3144\n",
      "step 151400 , validation loss : 21.0828\n",
      "step 151500 , training  accuracy 0.6\n",
      "step 151500 , loss : 2.0889\n",
      "step 151500 , validation  accuracy 0.2934\n",
      "step 151500 , validation loss : 20.7533\n",
      "step 151600 , training  accuracy 0.5\n",
      "step 151600 , loss : 2.06132\n",
      "step 151600 , validation  accuracy 0.314\n",
      "step 151600 , validation loss : 20.2942\n",
      "step 151700 , training  accuracy 0.366667\n",
      "step 151700 , loss : 2.14438\n",
      "step 151700 , validation  accuracy 0.3168\n",
      "step 151700 , validation loss : 22.0655\n",
      "step 151800 , training  accuracy 0.5\n",
      "step 151800 , loss : 2.12011\n",
      "step 151800 , validation  accuracy 0.3048\n",
      "step 151800 , validation loss : 19.4824\n",
      "step 151900 , training  accuracy 0.633333\n",
      "step 151900 , loss : 2.00115\n",
      "step 151900 , validation  accuracy 0.3314\n",
      "step 151900 , validation loss : 22.706\n",
      "step 152000 , training  accuracy 0.366667\n",
      "step 152000 , loss : 2.16495\n",
      "step 152000 , validation  accuracy 0.3082\n",
      "step 152000 , validation loss : 19.396\n",
      "step 152100 , training  accuracy 0.566667\n",
      "step 152100 , loss : 2.0756\n",
      "step 152100 , validation  accuracy 0.314\n",
      "step 152100 , validation loss : 20.682\n",
      "step 152200 , training  accuracy 0.666667\n",
      "step 152200 , loss : 2.0391\n",
      "step 152200 , validation  accuracy 0.3204\n",
      "step 152200 , validation loss : 21.423\n",
      "step 152300 , training  accuracy 0.366667\n",
      "step 152300 , loss : 2.17469\n",
      "step 152300 , validation  accuracy 0.321\n",
      "step 152300 , validation loss : 21.7959\n",
      "step 152400 , training  accuracy 0.5\n",
      "step 152400 , loss : 2.18558\n",
      "step 152400 , validation  accuracy 0.297\n",
      "step 152400 , validation loss : 20.6483\n",
      "step 152500 , training  accuracy 0.366667\n",
      "step 152500 , loss : 2.1522\n",
      "step 152500 , validation  accuracy 0.3116\n",
      "step 152500 , validation loss : 20.4835\n",
      "step 152600 , training  accuracy 0.7\n",
      "step 152600 , loss : 1.99884\n",
      "step 152600 , validation  accuracy 0.2978\n",
      "step 152600 , validation loss : 20.7649\n",
      "step 152700 , training  accuracy 0.533333\n",
      "step 152700 , loss : 2.07808\n",
      "step 152700 , validation  accuracy 0.3166\n",
      "step 152700 , validation loss : 20.6998\n",
      "step 152800 , training  accuracy 0.466667\n",
      "step 152800 , loss : 2.20413\n",
      "step 152800 , validation  accuracy 0.3044\n",
      "step 152800 , validation loss : 20.0255\n",
      "step 152900 , training  accuracy 0.533333\n",
      "step 152900 , loss : 2.06284\n",
      "step 152900 , validation  accuracy 0.3256\n",
      "step 152900 , validation loss : 22.3102\n",
      "step 153000 , training  accuracy 0.633333\n",
      "step 153000 , loss : 2.01606\n",
      "step 153000 , validation  accuracy 0.3162\n",
      "step 153000 , validation loss : 21.9261\n",
      "step 153100 , training  accuracy 0.333333\n",
      "step 153100 , loss : 2.17969\n",
      "step 153100 , validation  accuracy 0.2938\n",
      "step 153100 , validation loss : 18.77\n",
      "step 153200 , training  accuracy 0.4\n",
      "step 153200 , loss : 2.15506\n",
      "step 153200 , validation  accuracy 0.3142\n",
      "step 153200 , validation loss : 20.4609\n",
      "step 153300 , training  accuracy 0.466667\n",
      "step 153300 , loss : 2.0917\n",
      "step 153300 , validation  accuracy 0.3112\n",
      "step 153300 , validation loss : 20.4308\n",
      "step 153400 , training  accuracy 0.433333\n",
      "step 153400 , loss : 2.2378\n",
      "step 153400 , validation  accuracy 0.3094\n",
      "step 153400 , validation loss : 21.2209\n",
      "step 153500 , training  accuracy 0.466667\n",
      "step 153500 , loss : 2.07245\n",
      "step 153500 , validation  accuracy 0.3024\n",
      "step 153500 , validation loss : 20.5613\n",
      "step 153600 , training  accuracy 0.5\n",
      "step 153600 , loss : 2.12692\n",
      "step 153600 , validation  accuracy 0.2942\n",
      "step 153600 , validation loss : 20.0814\n",
      "step 153700 , training  accuracy 0.333333\n",
      "step 153700 , loss : 2.13655\n",
      "step 153700 , validation  accuracy 0.3158\n",
      "step 153700 , validation loss : 21.8972\n",
      "step 153800 , training  accuracy 0.666667\n",
      "step 153800 , loss : 2.07523\n",
      "step 153800 , validation  accuracy 0.3152\n",
      "step 153800 , validation loss : 20.4831\n",
      "step 153900 , training  accuracy 0.5\n",
      "step 153900 , loss : 2.13506\n",
      "step 153900 , validation  accuracy 0.3108\n",
      "step 153900 , validation loss : 21.0343\n",
      "step 154000 , training  accuracy 0.533333\n",
      "step 154000 , loss : 2.10973\n",
      "step 154000 , validation  accuracy 0.3204\n",
      "step 154000 , validation loss : 21.0051\n",
      "step 154100 , training  accuracy 0.566667\n",
      "step 154100 , loss : 2.06656\n",
      "step 154100 , validation  accuracy 0.3146\n",
      "step 154100 , validation loss : 20.715\n",
      "step 154200 , training  accuracy 0.3\n",
      "step 154200 , loss : 2.16861\n",
      "step 154200 , validation  accuracy 0.3026\n",
      "step 154200 , validation loss : 21.3588\n",
      "step 154300 , training  accuracy 0.433333\n",
      "step 154300 , loss : 2.18934\n",
      "step 154300 , validation  accuracy 0.3112\n",
      "step 154300 , validation loss : 20.6251\n",
      "step 154400 , training  accuracy 0.6\n",
      "step 154400 , loss : 2.09738\n",
      "step 154400 , validation  accuracy 0.313\n",
      "step 154400 , validation loss : 20.1885\n",
      "step 154500 , training  accuracy 0.566667\n",
      "step 154500 , loss : 2.0834\n",
      "step 154500 , validation  accuracy 0.3146\n",
      "step 154500 , validation loss : 20.4852\n",
      "step 154600 , training  accuracy 0.566667\n",
      "step 154600 , loss : 2.0647\n",
      "step 154600 , validation  accuracy 0.3238\n",
      "step 154600 , validation loss : 21.279\n",
      "step 154700 , training  accuracy 0.566667\n",
      "step 154700 , loss : 2.07047\n",
      "step 154700 , validation  accuracy 0.3164\n",
      "step 154700 , validation loss : 20.6\n",
      "step 154800 , training  accuracy 0.5\n",
      "step 154800 , loss : 2.09741\n",
      "step 154800 , validation  accuracy 0.3166\n",
      "step 154800 , validation loss : 20.4867\n",
      "step 154900 , training  accuracy 0.566667\n",
      "step 154900 , loss : 2.08278\n",
      "step 154900 , validation  accuracy 0.3218\n",
      "step 154900 , validation loss : 21.6844\n",
      "step 155000 , training  accuracy 0.633333\n",
      "step 155000 , loss : 2.06149\n",
      "step 155000 , validation  accuracy 0.293\n",
      "step 155000 , validation loss : 21.0114\n",
      "step 155100 , training  accuracy 0.566667\n",
      "step 155100 , loss : 2.07185\n",
      "step 155100 , validation  accuracy 0.312\n",
      "step 155100 , validation loss : 21.4378\n",
      "step 155200 , training  accuracy 0.533333\n",
      "step 155200 , loss : 2.14238\n",
      "step 155200 , validation  accuracy 0.31\n",
      "step 155200 , validation loss : 22.0705\n",
      "step 155300 , training  accuracy 0.5\n",
      "step 155300 , loss : 2.05979\n",
      "step 155300 , validation  accuracy 0.3066\n",
      "step 155300 , validation loss : 22.6741\n",
      "step 155400 , training  accuracy 0.533333\n",
      "step 155400 , loss : 2.15009\n",
      "step 155400 , validation  accuracy 0.3074\n",
      "step 155400 , validation loss : 20.3663\n",
      "step 155500 , training  accuracy 0.566667\n",
      "step 155500 , loss : 2.02823\n",
      "step 155500 , validation  accuracy 0.3228\n",
      "step 155500 , validation loss : 22.2378\n",
      "step 155600 , training  accuracy 0.466667\n",
      "step 155600 , loss : 2.11229\n",
      "step 155600 , validation  accuracy 0.2984\n",
      "step 155600 , validation loss : 20.5461\n",
      "step 155700 , training  accuracy 0.533333\n",
      "step 155700 , loss : 2.04033\n",
      "step 155700 , validation  accuracy 0.3106\n",
      "step 155700 , validation loss : 21.3367\n",
      "step 155800 , training  accuracy 0.533333\n",
      "step 155800 , loss : 2.15109\n",
      "step 155800 , validation  accuracy 0.2984\n",
      "step 155800 , validation loss : 21.1313\n",
      "step 155900 , training  accuracy 0.533333\n",
      "step 155900 , loss : 2.09386\n",
      "step 155900 , validation  accuracy 0.3014\n",
      "step 155900 , validation loss : 20.8542\n",
      "step 156000 , training  accuracy 0.533333\n",
      "step 156000 , loss : 2.11898\n",
      "step 156000 , validation  accuracy 0.3052\n",
      "step 156000 , validation loss : 21.6976\n",
      "step 156100 , training  accuracy 0.433333\n",
      "step 156100 , loss : 2.14528\n",
      "step 156100 , validation  accuracy 0.312\n",
      "step 156100 , validation loss : 20.4805\n",
      "step 156200 , training  accuracy 0.733333\n",
      "step 156200 , loss : 1.99607\n",
      "step 156200 , validation  accuracy 0.3186\n",
      "step 156200 , validation loss : 21.3611\n",
      "step 156300 , training  accuracy 0.333333\n",
      "step 156300 , loss : 2.14304\n",
      "step 156300 , validation  accuracy 0.3114\n",
      "step 156300 , validation loss : 20.7293\n",
      "step 156400 , training  accuracy 0.5\n",
      "step 156400 , loss : 2.08612\n",
      "step 156400 , validation  accuracy 0.296\n",
      "step 156400 , validation loss : 20.3236\n",
      "step 156500 , training  accuracy 0.633333\n",
      "step 156500 , loss : 2.01403\n",
      "step 156500 , validation  accuracy 0.31\n",
      "step 156500 , validation loss : 22.591\n",
      "step 156600 , training  accuracy 0.5\n",
      "step 156600 , loss : 2.11284\n",
      "step 156600 , validation  accuracy 0.2978\n",
      "step 156600 , validation loss : 19.8218\n",
      "step 156700 , training  accuracy 0.5\n",
      "step 156700 , loss : 2.11688\n",
      "step 156700 , validation  accuracy 0.3132\n",
      "step 156700 , validation loss : 20.0559\n",
      "step 156800 , training  accuracy 0.5\n",
      "step 156800 , loss : 2.14307\n",
      "step 156800 , validation  accuracy 0.3086\n",
      "step 156800 , validation loss : 20.6564\n",
      "step 156900 , training  accuracy 0.466667\n",
      "step 156900 , loss : 2.12892\n",
      "step 156900 , validation  accuracy 0.315\n",
      "step 156900 , validation loss : 20.9357\n",
      "step 157000 , training  accuracy 0.433333\n",
      "step 157000 , loss : 2.10962\n",
      "step 157000 , validation  accuracy 0.2986\n",
      "step 157000 , validation loss : 20.4856\n",
      "step 157100 , training  accuracy 0.333333\n",
      "step 157100 , loss : 2.20567\n",
      "step 157100 , validation  accuracy 0.3014\n",
      "step 157100 , validation loss : 19.2562\n",
      "step 157200 , training  accuracy 0.7\n",
      "step 157200 , loss : 1.99487\n",
      "step 157200 , validation  accuracy 0.3236\n",
      "step 157200 , validation loss : 21.4037\n",
      "step 157300 , training  accuracy 0.566667\n",
      "step 157300 , loss : 2.09675\n",
      "step 157300 , validation  accuracy 0.329\n",
      "step 157300 , validation loss : 21.9248\n",
      "step 157400 , training  accuracy 0.466667\n",
      "step 157400 , loss : 2.14901\n",
      "step 157400 , validation  accuracy 0.2882\n",
      "step 157400 , validation loss : 18.9681\n",
      "step 157500 , training  accuracy 0.5\n",
      "step 157500 , loss : 2.0926\n",
      "step 157500 , validation  accuracy 0.293\n",
      "step 157500 , validation loss : 19.5529\n",
      "step 157600 , training  accuracy 0.566667\n",
      "step 157600 , loss : 2.07416\n",
      "step 157600 , validation  accuracy 0.3128\n",
      "step 157600 , validation loss : 21.3694\n",
      "step 157700 , training  accuracy 0.533333\n",
      "step 157700 , loss : 2.12738\n",
      "step 157700 , validation  accuracy 0.3286\n",
      "step 157700 , validation loss : 23.4487\n",
      "step 157800 , training  accuracy 0.4\n",
      "step 157800 , loss : 2.18457\n",
      "step 157800 , validation  accuracy 0.295\n",
      "step 157800 , validation loss : 20.5881\n",
      "step 157900 , training  accuracy 0.5\n",
      "step 157900 , loss : 2.15676\n",
      "step 157900 , validation  accuracy 0.2944\n",
      "step 157900 , validation loss : 19.7153\n",
      "step 158000 , training  accuracy 0.6\n",
      "step 158000 , loss : 2.06073\n",
      "step 158000 , validation  accuracy 0.3266\n",
      "step 158000 , validation loss : 21.712\n",
      "step 158100 , training  accuracy 0.633333\n",
      "step 158100 , loss : 2.06923\n",
      "step 158100 , validation  accuracy 0.315\n",
      "step 158100 , validation loss : 21.2644\n",
      "step 158200 , training  accuracy 0.566667\n",
      "step 158200 , loss : 2.12247\n",
      "step 158200 , validation  accuracy 0.3132\n",
      "step 158200 , validation loss : 21.1227\n",
      "step 158300 , training  accuracy 0.6\n",
      "step 158300 , loss : 2.15367\n",
      "step 158300 , validation  accuracy 0.3142\n",
      "step 158300 , validation loss : 20.7453\n",
      "step 158400 , training  accuracy 0.6\n",
      "step 158400 , loss : 2.0917\n",
      "step 158400 , validation  accuracy 0.2836\n",
      "step 158400 , validation loss : 19.4918\n",
      "step 158500 , training  accuracy 0.5\n",
      "step 158500 , loss : 2.14322\n",
      "step 158500 , validation  accuracy 0.3052\n",
      "step 158500 , validation loss : 20.9875\n",
      "step 158600 , training  accuracy 0.433333\n",
      "step 158600 , loss : 2.15108\n",
      "step 158600 , validation  accuracy 0.3152\n",
      "step 158600 , validation loss : 20.7396\n",
      "step 158700 , training  accuracy 0.5\n",
      "step 158700 , loss : 2.17108\n",
      "step 158700 , validation  accuracy 0.3202\n",
      "step 158700 , validation loss : 21.2801\n",
      "step 158800 , training  accuracy 0.566667\n",
      "step 158800 , loss : 2.06619\n",
      "step 158800 , validation  accuracy 0.331\n",
      "step 158800 , validation loss : 22.8525\n",
      "step 158900 , training  accuracy 0.466667\n",
      "step 158900 , loss : 2.16472\n",
      "step 158900 , validation  accuracy 0.301\n",
      "step 158900 , validation loss : 19.8017\n",
      "step 159000 , training  accuracy 0.633333\n",
      "step 159000 , loss : 1.99039\n",
      "step 159000 , validation  accuracy 0.3046\n",
      "step 159000 , validation loss : 22.8995\n",
      "step 159100 , training  accuracy 0.5\n",
      "step 159100 , loss : 2.1126\n",
      "step 159100 , validation  accuracy 0.2994\n",
      "step 159100 , validation loss : 20.8832\n",
      "step 159200 , training  accuracy 0.366667\n",
      "step 159200 , loss : 2.17167\n",
      "step 159200 , validation  accuracy 0.2946\n",
      "step 159200 , validation loss : 20.5166\n",
      "step 159300 , training  accuracy 0.533333\n",
      "step 159300 , loss : 2.1193\n",
      "step 159300 , validation  accuracy 0.3238\n",
      "step 159300 , validation loss : 21.6554\n",
      "step 159400 , training  accuracy 0.5\n",
      "step 159400 , loss : 2.10235\n",
      "step 159400 , validation  accuracy 0.3136\n",
      "step 159400 , validation loss : 20.8269\n",
      "step 159500 , training  accuracy 0.366667\n",
      "step 159500 , loss : 2.16305\n",
      "step 159500 , validation  accuracy 0.2944\n",
      "step 159500 , validation loss : 20.8342\n",
      "step 159600 , training  accuracy 0.6\n",
      "step 159600 , loss : 2.02354\n",
      "step 159600 , validation  accuracy 0.3134\n",
      "step 159600 , validation loss : 22.4139\n",
      "step 159700 , training  accuracy 0.5\n",
      "step 159700 , loss : 2.07926\n",
      "step 159700 , validation  accuracy 0.3006\n",
      "step 159700 , validation loss : 20.965\n",
      "step 159800 , training  accuracy 0.666667\n",
      "step 159800 , loss : 2.02928\n",
      "step 159800 , validation  accuracy 0.3118\n",
      "step 159800 , validation loss : 20.5144\n",
      "step 159900 , training  accuracy 0.533333\n",
      "step 159900 , loss : 2.08837\n",
      "step 159900 , validation  accuracy 0.324\n",
      "step 159900 , validation loss : 21.468\n",
      "step 160000 , training  accuracy 0.433333\n",
      "step 160000 , loss : 2.13886\n",
      "step 160000 , validation  accuracy 0.3\n",
      "step 160000 , validation loss : 20.6408\n",
      "step 160100 , training  accuracy 0.6\n",
      "step 160100 , loss : 2.08439\n",
      "step 160100 , validation  accuracy 0.2974\n",
      "step 160100 , validation loss : 21.1521\n",
      "step 160200 , training  accuracy 0.533333\n",
      "step 160200 , loss : 2.04309\n",
      "step 160200 , validation  accuracy 0.3128\n",
      "step 160200 , validation loss : 20.8411\n",
      "step 160300 , training  accuracy 0.5\n",
      "step 160300 , loss : 2.09717\n",
      "step 160300 , validation  accuracy 0.3202\n",
      "step 160300 , validation loss : 22.3984\n",
      "step 160400 , training  accuracy 0.666667\n",
      "step 160400 , loss : 2.01864\n",
      "step 160400 , validation  accuracy 0.3184\n",
      "step 160400 , validation loss : 21.6776\n",
      "step 160500 , training  accuracy 0.566667\n",
      "step 160500 , loss : 2.06671\n",
      "step 160500 , validation  accuracy 0.3064\n",
      "step 160500 , validation loss : 21.324\n",
      "step 160600 , training  accuracy 0.566667\n",
      "step 160600 , loss : 2.09902\n",
      "step 160600 , validation  accuracy 0.3278\n",
      "step 160600 , validation loss : 21.3165\n",
      "step 160700 , training  accuracy 0.533333\n",
      "step 160700 , loss : 2.11736\n",
      "step 160700 , validation  accuracy 0.3252\n",
      "step 160700 , validation loss : 24.2445\n",
      "step 160800 , training  accuracy 0.566667\n",
      "step 160800 , loss : 2.07795\n",
      "step 160800 , validation  accuracy 0.3074\n",
      "step 160800 , validation loss : 20.7701\n",
      "step 160900 , training  accuracy 0.7\n",
      "step 160900 , loss : 2.09293\n",
      "step 160900 , validation  accuracy 0.315\n",
      "step 160900 , validation loss : 20.6312\n",
      "step 161000 , training  accuracy 0.433333\n",
      "step 161000 , loss : 2.11638\n",
      "step 161000 , validation  accuracy 0.3174\n",
      "step 161000 , validation loss : 23.4426\n",
      "step 161100 , training  accuracy 0.633333\n",
      "step 161100 , loss : 2.05238\n",
      "step 161100 , validation  accuracy 0.3198\n",
      "step 161100 , validation loss : 22.2137\n",
      "step 161200 , training  accuracy 0.433333\n",
      "step 161200 , loss : 2.10416\n",
      "step 161200 , validation  accuracy 0.316\n",
      "step 161200 , validation loss : 21.4454\n",
      "step 161300 , training  accuracy 0.633333\n",
      "step 161300 , loss : 2.05717\n",
      "step 161300 , validation  accuracy 0.3218\n",
      "step 161300 , validation loss : 22.04\n",
      "step 161400 , training  accuracy 0.6\n",
      "step 161400 , loss : 2.04294\n",
      "step 161400 , validation  accuracy 0.304\n",
      "step 161400 , validation loss : 21.5692\n",
      "step 161500 , training  accuracy 0.3\n",
      "step 161500 , loss : 2.17863\n",
      "step 161500 , validation  accuracy 0.295\n",
      "step 161500 , validation loss : 21.015\n",
      "step 161600 , training  accuracy 0.4\n",
      "step 161600 , loss : 2.17941\n",
      "step 161600 , validation  accuracy 0.289\n",
      "step 161600 , validation loss : 20.3741\n",
      "step 161700 , training  accuracy 0.433333\n",
      "step 161700 , loss : 2.13183\n",
      "step 161700 , validation  accuracy 0.3158\n",
      "step 161700 , validation loss : 20.8121\n",
      "step 161800 , training  accuracy 0.5\n",
      "step 161800 , loss : 2.10267\n",
      "step 161800 , validation  accuracy 0.3232\n",
      "step 161800 , validation loss : 21.3929\n",
      "step 161900 , training  accuracy 0.633333\n",
      "step 161900 , loss : 2.04867\n",
      "step 161900 , validation  accuracy 0.3218\n",
      "step 161900 , validation loss : 21.8729\n",
      "step 162000 , training  accuracy 0.533333\n",
      "step 162000 , loss : 2.11695\n",
      "step 162000 , validation  accuracy 0.3034\n",
      "step 162000 , validation loss : 21.8055\n",
      "step 162100 , training  accuracy 0.433333\n",
      "step 162100 , loss : 2.13521\n",
      "step 162100 , validation  accuracy 0.3268\n",
      "step 162100 , validation loss : 22.0809\n",
      "step 162200 , training  accuracy 0.466667\n",
      "step 162200 , loss : 2.12452\n",
      "step 162200 , validation  accuracy 0.3162\n",
      "step 162200 , validation loss : 20.135\n",
      "step 162300 , training  accuracy 0.433333\n",
      "step 162300 , loss : 2.16335\n",
      "step 162300 , validation  accuracy 0.3072\n",
      "step 162300 , validation loss : 20.9806\n",
      "step 162400 , training  accuracy 0.433333\n",
      "step 162400 , loss : 2.14426\n",
      "step 162400 , validation  accuracy 0.323\n",
      "step 162400 , validation loss : 20.9947\n",
      "step 162500 , training  accuracy 0.466667\n",
      "step 162500 , loss : 2.10445\n",
      "step 162500 , validation  accuracy 0.3258\n",
      "step 162500 , validation loss : 22.213\n",
      "step 162600 , training  accuracy 0.6\n",
      "step 162600 , loss : 2.0336\n",
      "step 162600 , validation  accuracy 0.3152\n",
      "step 162600 , validation loss : 21.5609\n",
      "step 162700 , training  accuracy 0.5\n",
      "step 162700 , loss : 2.06525\n",
      "step 162700 , validation  accuracy 0.3204\n",
      "step 162700 , validation loss : 21.9677\n",
      "step 162800 , training  accuracy 0.5\n",
      "step 162800 , loss : 2.12336\n",
      "step 162800 , validation  accuracy 0.32\n",
      "step 162800 , validation loss : 22.2733\n",
      "step 162900 , training  accuracy 0.366667\n",
      "step 162900 , loss : 2.15425\n",
      "step 162900 , validation  accuracy 0.31\n",
      "step 162900 , validation loss : 20.1942\n",
      "step 163000 , training  accuracy 0.5\n",
      "step 163000 , loss : 2.08094\n",
      "step 163000 , validation  accuracy 0.326\n",
      "step 163000 , validation loss : 22.3008\n",
      "step 163100 , training  accuracy 0.4\n",
      "step 163100 , loss : 2.14707\n",
      "step 163100 , validation  accuracy 0.306\n",
      "step 163100 , validation loss : 21.0243\n",
      "step 163200 , training  accuracy 0.566667\n",
      "step 163200 , loss : 2.06062\n",
      "step 163200 , validation  accuracy 0.3192\n",
      "step 163200 , validation loss : 21.2387\n",
      "step 163300 , training  accuracy 0.4\n",
      "step 163300 , loss : 2.06489\n",
      "step 163300 , validation  accuracy 0.3206\n",
      "step 163300 , validation loss : 21.3982\n",
      "step 163400 , training  accuracy 0.533333\n",
      "step 163400 , loss : 2.08047\n",
      "step 163400 , validation  accuracy 0.305\n",
      "step 163400 , validation loss : 20.802\n",
      "step 163500 , training  accuracy 0.566667\n",
      "step 163500 , loss : 2.0658\n",
      "step 163500 , validation  accuracy 0.3052\n",
      "step 163500 , validation loss : 21.2554\n",
      "step 163600 , training  accuracy 0.533333\n",
      "step 163600 , loss : 2.07585\n",
      "step 163600 , validation  accuracy 0.3238\n",
      "step 163600 , validation loss : 21.8309\n",
      "step 163700 , training  accuracy 0.566667\n",
      "step 163700 , loss : 2.05514\n",
      "step 163700 , validation  accuracy 0.3204\n",
      "step 163700 , validation loss : 21.5283\n",
      "step 163800 , training  accuracy 0.566667\n",
      "step 163800 , loss : 2.14245\n",
      "step 163800 , validation  accuracy 0.3018\n",
      "step 163800 , validation loss : 21.4503\n",
      "step 163900 , training  accuracy 0.666667\n",
      "step 163900 , loss : 2.08715\n",
      "step 163900 , validation  accuracy 0.3066\n",
      "step 163900 , validation loss : 21.6083\n",
      "step 164000 , training  accuracy 0.6\n",
      "step 164000 , loss : 2.08255\n",
      "step 164000 , validation  accuracy 0.2982\n",
      "step 164000 , validation loss : 21.3268\n",
      "step 164100 , training  accuracy 0.566667\n",
      "step 164100 , loss : 2.07946\n",
      "step 164100 , validation  accuracy 0.3208\n",
      "step 164100 , validation loss : 21.4852\n",
      "step 164200 , training  accuracy 0.6\n",
      "step 164200 , loss : 2.0753\n",
      "step 164200 , validation  accuracy 0.3084\n",
      "step 164200 , validation loss : 20.2532\n",
      "step 164300 , training  accuracy 0.633333\n",
      "step 164300 , loss : 2.05812\n",
      "step 164300 , validation  accuracy 0.3132\n",
      "step 164300 , validation loss : 20.8092\n",
      "step 164400 , training  accuracy 0.5\n",
      "step 164400 , loss : 2.0968\n",
      "step 164400 , validation  accuracy 0.323\n",
      "step 164400 , validation loss : 22.1543\n",
      "step 164500 , training  accuracy 0.566667\n",
      "step 164500 , loss : 2.08714\n",
      "step 164500 , validation  accuracy 0.3026\n",
      "step 164500 , validation loss : 21.2024\n",
      "step 164600 , training  accuracy 0.433333\n",
      "step 164600 , loss : 2.15653\n",
      "step 164600 , validation  accuracy 0.3058\n",
      "step 164600 , validation loss : 21.4727\n",
      "step 164700 , training  accuracy 0.433333\n",
      "step 164700 , loss : 2.12863\n",
      "step 164700 , validation  accuracy 0.3226\n",
      "step 164700 , validation loss : 22.3685\n",
      "step 164800 , training  accuracy 0.433333\n",
      "step 164800 , loss : 2.18528\n",
      "step 164800 , validation  accuracy 0.3202\n",
      "step 164800 , validation loss : 21.4004\n",
      "step 164900 , training  accuracy 0.433333\n",
      "step 164900 , loss : 2.11796\n",
      "step 164900 , validation  accuracy 0.3184\n",
      "step 164900 , validation loss : 20.7482\n",
      "step 165000 , training  accuracy 0.5\n",
      "step 165000 , loss : 2.10655\n",
      "step 165000 , validation  accuracy 0.2986\n",
      "step 165000 , validation loss : 20.7061\n",
      "step 165100 , training  accuracy 0.366667\n",
      "step 165100 , loss : 2.20466\n",
      "step 165100 , validation  accuracy 0.2918\n",
      "step 165100 , validation loss : 19.1469\n",
      "step 165200 , training  accuracy 0.466667\n",
      "step 165200 , loss : 2.13797\n",
      "step 165200 , validation  accuracy 0.2904\n",
      "step 165200 , validation loss : 21.588\n",
      "step 165300 , training  accuracy 0.6\n",
      "step 165300 , loss : 2.0541\n",
      "step 165300 , validation  accuracy 0.3132\n",
      "step 165300 , validation loss : 21.7951\n",
      "step 165400 , training  accuracy 0.433333\n",
      "step 165400 , loss : 2.15843\n",
      "step 165400 , validation  accuracy 0.3088\n",
      "step 165400 , validation loss : 20.6374\n",
      "step 165500 , training  accuracy 0.6\n",
      "step 165500 , loss : 2.06746\n",
      "step 165500 , validation  accuracy 0.3104\n",
      "step 165500 , validation loss : 21.903\n",
      "step 165600 , training  accuracy 0.666667\n",
      "step 165600 , loss : 2.04321\n",
      "step 165600 , validation  accuracy 0.307\n",
      "step 165600 , validation loss : 21.5184\n",
      "step 165700 , training  accuracy 0.366667\n",
      "step 165700 , loss : 2.15233\n",
      "step 165700 , validation  accuracy 0.3088\n",
      "step 165700 , validation loss : 20.647\n",
      "step 165800 , training  accuracy 0.5\n",
      "step 165800 , loss : 2.09955\n",
      "step 165800 , validation  accuracy 0.3194\n",
      "step 165800 , validation loss : 22.5207\n",
      "step 165900 , training  accuracy 0.666667\n",
      "step 165900 , loss : 2.05667\n",
      "step 165900 , validation  accuracy 0.3206\n",
      "step 165900 , validation loss : 21.6217\n",
      "step 166000 , training  accuracy 0.566667\n",
      "step 166000 , loss : 2.01497\n",
      "step 166000 , validation  accuracy 0.3234\n",
      "step 166000 , validation loss : 22.1012\n",
      "step 166100 , training  accuracy 0.366667\n",
      "step 166100 , loss : 2.1697\n",
      "step 166100 , validation  accuracy 0.3054\n",
      "step 166100 , validation loss : 20.4506\n",
      "step 166200 , training  accuracy 0.633333\n",
      "step 166200 , loss : 2.09629\n",
      "step 166200 , validation  accuracy 0.3076\n",
      "step 166200 , validation loss : 20.1251\n",
      "step 166300 , training  accuracy 0.433333\n",
      "step 166300 , loss : 2.11779\n",
      "step 166300 , validation  accuracy 0.3142\n",
      "step 166300 , validation loss : 21.1371\n",
      "step 166400 , training  accuracy 0.333333\n",
      "step 166400 , loss : 2.16193\n",
      "step 166400 , validation  accuracy 0.3282\n",
      "step 166400 , validation loss : 21.9049\n",
      "step 166500 , training  accuracy 0.566667\n",
      "step 166500 , loss : 2.08483\n",
      "step 166500 , validation  accuracy 0.3006\n",
      "step 166500 , validation loss : 20.4845\n",
      "step 166600 , training  accuracy 0.366667\n",
      "step 166600 , loss : 2.1973\n",
      "step 166600 , validation  accuracy 0.3158\n",
      "step 166600 , validation loss : 22.8136\n",
      "step 166700 , training  accuracy 0.566667\n",
      "step 166700 , loss : 2.10605\n",
      "step 166700 , validation  accuracy 0.317\n",
      "step 166700 , validation loss : 22.6034\n",
      "step 166800 , training  accuracy 0.366667\n",
      "step 166800 , loss : 2.14301\n",
      "step 166800 , validation  accuracy 0.316\n",
      "step 166800 , validation loss : 21.3875\n",
      "step 166900 , training  accuracy 0.633333\n",
      "step 166900 , loss : 2.02122\n",
      "step 166900 , validation  accuracy 0.3282\n",
      "step 166900 , validation loss : 22.3579\n",
      "step 167000 , training  accuracy 0.433333\n",
      "step 167000 , loss : 2.07894\n",
      "step 167000 , validation  accuracy 0.3026\n",
      "step 167000 , validation loss : 21.6033\n",
      "step 167100 , training  accuracy 0.5\n",
      "step 167100 , loss : 2.13918\n",
      "step 167100 , validation  accuracy 0.3188\n",
      "step 167100 , validation loss : 22.0992\n",
      "step 167200 , training  accuracy 0.433333\n",
      "step 167200 , loss : 2.09957\n",
      "step 167200 , validation  accuracy 0.3146\n",
      "step 167200 , validation loss : 22.0271\n",
      "step 167300 , training  accuracy 0.433333\n",
      "step 167300 , loss : 2.09223\n",
      "step 167300 , validation  accuracy 0.325\n",
      "step 167300 , validation loss : 22.4451\n",
      "step 167400 , training  accuracy 0.466667\n",
      "step 167400 , loss : 2.10308\n",
      "step 167400 , validation  accuracy 0.3076\n",
      "step 167400 , validation loss : 22.1269\n",
      "step 167500 , training  accuracy 0.666667\n",
      "step 167500 , loss : 2.01471\n",
      "step 167500 , validation  accuracy 0.314\n",
      "step 167500 , validation loss : 22.4483\n",
      "step 167600 , training  accuracy 0.533333\n",
      "step 167600 , loss : 2.10949\n",
      "step 167600 , validation  accuracy 0.3248\n",
      "step 167600 , validation loss : 22.8554\n",
      "step 167700 , training  accuracy 0.466667\n",
      "step 167700 , loss : 2.1033\n",
      "step 167700 , validation  accuracy 0.3124\n",
      "step 167700 , validation loss : 21.9327\n",
      "step 167800 , training  accuracy 0.633333\n",
      "step 167800 , loss : 2.05149\n",
      "step 167800 , validation  accuracy 0.3214\n",
      "step 167800 , validation loss : 22.2869\n",
      "step 167900 , training  accuracy 0.4\n",
      "step 167900 , loss : 2.17279\n",
      "step 167900 , validation  accuracy 0.3134\n",
      "step 167900 , validation loss : 20.2982\n",
      "step 168000 , training  accuracy 0.533333\n",
      "step 168000 , loss : 2.1467\n",
      "step 168000 , validation  accuracy 0.3088\n",
      "step 168000 , validation loss : 22.4227\n",
      "step 168100 , training  accuracy 0.233333\n",
      "step 168100 , loss : 2.26916\n",
      "step 168100 , validation  accuracy 0.2974\n",
      "step 168100 , validation loss : 19.6516\n",
      "step 168200 , training  accuracy 0.6\n",
      "step 168200 , loss : 2.02215\n",
      "step 168200 , validation  accuracy 0.3204\n",
      "step 168200 , validation loss : 21.7546\n",
      "step 168300 , training  accuracy 0.5\n",
      "step 168300 , loss : 2.07875\n",
      "step 168300 , validation  accuracy 0.3048\n",
      "step 168300 , validation loss : 22.0436\n",
      "step 168400 , training  accuracy 0.4\n",
      "step 168400 , loss : 2.086\n",
      "step 168400 , validation  accuracy 0.325\n",
      "step 168400 , validation loss : 22.1372\n",
      "step 168500 , training  accuracy 0.6\n",
      "step 168500 , loss : 2.10666\n",
      "step 168500 , validation  accuracy 0.323\n",
      "step 168500 , validation loss : 22.595\n",
      "step 168600 , training  accuracy 0.633333\n",
      "step 168600 , loss : 2.02845\n",
      "step 168600 , validation  accuracy 0.3116\n",
      "step 168600 , validation loss : 20.7986\n",
      "step 168700 , training  accuracy 0.633333\n",
      "step 168700 , loss : 2.08733\n",
      "step 168700 , validation  accuracy 0.3188\n",
      "step 168700 , validation loss : 22.3798\n",
      "step 168800 , training  accuracy 0.433333\n",
      "step 168800 , loss : 2.17663\n",
      "step 168800 , validation  accuracy 0.3182\n",
      "step 168800 , validation loss : 22.2498\n",
      "step 168900 , training  accuracy 0.533333\n",
      "step 168900 , loss : 2.08382\n",
      "step 168900 , validation  accuracy 0.314\n",
      "step 168900 , validation loss : 20.8281\n",
      "step 169000 , training  accuracy 0.6\n",
      "step 169000 , loss : 2.11487\n",
      "step 169000 , validation  accuracy 0.3004\n",
      "step 169000 , validation loss : 21.8061\n",
      "step 169100 , training  accuracy 0.566667\n",
      "step 169100 , loss : 2.05068\n",
      "step 169100 , validation  accuracy 0.3066\n",
      "step 169100 , validation loss : 21.5563\n",
      "step 169200 , training  accuracy 0.6\n",
      "step 169200 , loss : 2.07501\n",
      "step 169200 , validation  accuracy 0.3006\n",
      "step 169200 , validation loss : 20.415\n",
      "step 169300 , training  accuracy 0.533333\n",
      "step 169300 , loss : 2.04863\n",
      "step 169300 , validation  accuracy 0.3146\n",
      "step 169300 , validation loss : 21.7459\n",
      "step 169400 , training  accuracy 0.4\n",
      "step 169400 , loss : 2.1718\n",
      "step 169400 , validation  accuracy 0.2792\n",
      "step 169400 , validation loss : 19.8966\n",
      "step 169500 , training  accuracy 0.6\n",
      "step 169500 , loss : 2.05951\n",
      "step 169500 , validation  accuracy 0.3212\n",
      "step 169500 , validation loss : 22.5075\n",
      "step 169600 , training  accuracy 0.433333\n",
      "step 169600 , loss : 2.10685\n",
      "step 169600 , validation  accuracy 0.3004\n",
      "step 169600 , validation loss : 21.0176\n",
      "step 169700 , training  accuracy 0.6\n",
      "step 169700 , loss : 2.03537\n",
      "step 169700 , validation  accuracy 0.311\n",
      "step 169700 , validation loss : 21.5993\n",
      "step 169800 , training  accuracy 0.533333\n",
      "step 169800 , loss : 2.09699\n",
      "step 169800 , validation  accuracy 0.3044\n",
      "step 169800 , validation loss : 20.3578\n",
      "step 169900 , training  accuracy 0.633333\n",
      "step 169900 , loss : 2.01754\n",
      "step 169900 , validation  accuracy 0.323\n",
      "step 169900 , validation loss : 22.6288\n",
      "step 170000 , training  accuracy 0.5\n",
      "step 170000 , loss : 2.11247\n",
      "step 170000 , validation  accuracy 0.32\n",
      "step 170000 , validation loss : 21.8711\n",
      "step 170100 , training  accuracy 0.566667\n",
      "step 170100 , loss : 2.06102\n",
      "step 170100 , validation  accuracy 0.3186\n",
      "step 170100 , validation loss : 22.4369\n",
      "step 170200 , training  accuracy 0.566667\n",
      "step 170200 , loss : 2.13583\n",
      "step 170200 , validation  accuracy 0.3146\n",
      "step 170200 , validation loss : 22.0645\n",
      "step 170300 , training  accuracy 0.433333\n",
      "step 170300 , loss : 2.12469\n",
      "step 170300 , validation  accuracy 0.3036\n",
      "step 170300 , validation loss : 19.8793\n",
      "step 170400 , training  accuracy 0.566667\n",
      "step 170400 , loss : 2.08029\n",
      "step 170400 , validation  accuracy 0.3108\n",
      "step 170400 , validation loss : 20.3797\n",
      "step 170500 , training  accuracy 0.433333\n",
      "step 170500 , loss : 2.16159\n",
      "step 170500 , validation  accuracy 0.2912\n",
      "step 170500 , validation loss : 20.3534\n",
      "step 170600 , training  accuracy 0.566667\n",
      "step 170600 , loss : 2.05735\n",
      "step 170600 , validation  accuracy 0.3122\n",
      "step 170600 , validation loss : 21.3781\n",
      "step 170700 , training  accuracy 0.4\n",
      "step 170700 , loss : 2.13362\n",
      "step 170700 , validation  accuracy 0.3236\n",
      "step 170700 , validation loss : 21.5056\n",
      "step 170800 , training  accuracy 0.566667\n",
      "step 170800 , loss : 2.09939\n",
      "step 170800 , validation  accuracy 0.3122\n",
      "step 170800 , validation loss : 21.6712\n",
      "step 170900 , training  accuracy 0.466667\n",
      "step 170900 , loss : 2.08702\n",
      "step 170900 , validation  accuracy 0.3152\n",
      "step 170900 , validation loss : 21.4429\n",
      "step 171000 , training  accuracy 0.466667\n",
      "step 171000 , loss : 2.08002\n",
      "step 171000 , validation  accuracy 0.3018\n",
      "step 171000 , validation loss : 21.8172\n",
      "step 171100 , training  accuracy 0.666667\n",
      "step 171100 , loss : 2.0582\n",
      "step 171100 , validation  accuracy 0.3202\n",
      "step 171100 , validation loss : 22.009\n",
      "step 171200 , training  accuracy 0.466667\n",
      "step 171200 , loss : 2.1099\n",
      "step 171200 , validation  accuracy 0.3082\n",
      "step 171200 , validation loss : 20.8012\n",
      "step 171300 , training  accuracy 0.566667\n",
      "step 171300 , loss : 2.07761\n",
      "step 171300 , validation  accuracy 0.3174\n",
      "step 171300 , validation loss : 21.8217\n",
      "step 171400 , training  accuracy 0.533333\n",
      "step 171400 , loss : 2.08927\n",
      "step 171400 , validation  accuracy 0.3186\n",
      "step 171400 , validation loss : 22.3725\n",
      "step 171500 , training  accuracy 0.7\n",
      "step 171500 , loss : 1.967\n",
      "step 171500 , validation  accuracy 0.319\n",
      "step 171500 , validation loss : 22.8295\n",
      "step 171600 , training  accuracy 0.633333\n",
      "step 171600 , loss : 2.07842\n",
      "step 171600 , validation  accuracy 0.313\n",
      "step 171600 , validation loss : 20.9098\n",
      "step 171700 , training  accuracy 0.466667\n",
      "step 171700 , loss : 2.11485\n",
      "step 171700 , validation  accuracy 0.3082\n",
      "step 171700 , validation loss : 21.5806\n",
      "step 171800 , training  accuracy 0.466667\n",
      "step 171800 , loss : 2.08759\n",
      "step 171800 , validation  accuracy 0.3152\n",
      "step 171800 , validation loss : 21.7762\n",
      "step 171900 , training  accuracy 0.666667\n",
      "step 171900 , loss : 1.9944\n",
      "step 171900 , validation  accuracy 0.3128\n",
      "step 171900 , validation loss : 22.651\n",
      "step 172000 , training  accuracy 0.533333\n",
      "step 172000 , loss : 2.05845\n",
      "step 172000 , validation  accuracy 0.324\n",
      "step 172000 , validation loss : 22.2835\n",
      "step 172100 , training  accuracy 0.566667\n",
      "step 172100 , loss : 2.12036\n",
      "step 172100 , validation  accuracy 0.3098\n",
      "step 172100 , validation loss : 21.2623\n",
      "step 172200 , training  accuracy 0.6\n",
      "step 172200 , loss : 2.0535\n",
      "step 172200 , validation  accuracy 0.3194\n",
      "step 172200 , validation loss : 22.2362\n",
      "step 172300 , training  accuracy 0.566667\n",
      "step 172300 , loss : 2.06478\n",
      "step 172300 , validation  accuracy 0.3154\n",
      "step 172300 , validation loss : 21.5697\n",
      "step 172400 , training  accuracy 0.7\n",
      "step 172400 , loss : 2.05723\n",
      "step 172400 , validation  accuracy 0.305\n",
      "step 172400 , validation loss : 21.5983\n",
      "step 172500 , training  accuracy 0.333333\n",
      "step 172500 , loss : 2.16969\n",
      "step 172500 , validation  accuracy 0.2952\n",
      "step 172500 , validation loss : 20.733\n",
      "step 172600 , training  accuracy 0.466667\n",
      "step 172600 , loss : 2.14676\n",
      "step 172600 , validation  accuracy 0.3002\n",
      "step 172600 , validation loss : 21.3561\n",
      "step 172700 , training  accuracy 0.433333\n",
      "step 172700 , loss : 2.14104\n",
      "step 172700 , validation  accuracy 0.3198\n",
      "step 172700 , validation loss : 21.5192\n",
      "step 172800 , training  accuracy 0.6\n",
      "step 172800 , loss : 2.11654\n",
      "step 172800 , validation  accuracy 0.324\n",
      "step 172800 , validation loss : 23.1849\n",
      "step 172900 , training  accuracy 0.5\n",
      "step 172900 , loss : 2.08224\n",
      "step 172900 , validation  accuracy 0.3074\n",
      "step 172900 , validation loss : 22.141\n",
      "step 173000 , training  accuracy 0.566667\n",
      "step 173000 , loss : 2.03551\n",
      "step 173000 , validation  accuracy 0.3078\n",
      "step 173000 , validation loss : 21.6214\n",
      "step 173100 , training  accuracy 0.5\n",
      "step 173100 , loss : 2.16699\n",
      "step 173100 , validation  accuracy 0.3018\n",
      "step 173100 , validation loss : 20.6633\n",
      "step 173200 , training  accuracy 0.6\n",
      "step 173200 , loss : 2.0236\n",
      "step 173200 , validation  accuracy 0.3194\n",
      "step 173200 , validation loss : 21.5538\n",
      "step 173300 , training  accuracy 0.5\n",
      "step 173300 , loss : 2.15548\n",
      "step 173300 , validation  accuracy 0.3124\n",
      "step 173300 , validation loss : 21.0759\n",
      "step 173400 , training  accuracy 0.566667\n",
      "step 173400 , loss : 2.05217\n",
      "step 173400 , validation  accuracy 0.313\n",
      "step 173400 , validation loss : 23.1958\n",
      "step 173500 , training  accuracy 0.5\n",
      "step 173500 , loss : 2.0834\n",
      "step 173500 , validation  accuracy 0.3112\n",
      "step 173500 , validation loss : 21.6511\n",
      "step 173600 , training  accuracy 0.533333\n",
      "step 173600 , loss : 2.07466\n",
      "step 173600 , validation  accuracy 0.307\n",
      "step 173600 , validation loss : 21.3567\n",
      "step 173700 , training  accuracy 0.7\n",
      "step 173700 , loss : 1.98051\n",
      "step 173700 , validation  accuracy 0.3202\n",
      "step 173700 , validation loss : 21.9574\n",
      "step 173800 , training  accuracy 0.366667\n",
      "step 173800 , loss : 2.15386\n",
      "step 173800 , validation  accuracy 0.3002\n",
      "step 173800 , validation loss : 20.3412\n",
      "step 173900 , training  accuracy 0.433333\n",
      "step 173900 , loss : 2.1249\n",
      "step 173900 , validation  accuracy 0.3114\n",
      "step 173900 , validation loss : 21.8603\n",
      "step 174000 , training  accuracy 0.466667\n",
      "step 174000 , loss : 2.11767\n",
      "step 174000 , validation  accuracy 0.297\n",
      "step 174000 , validation loss : 21.6607\n",
      "step 174100 , training  accuracy 0.4\n",
      "step 174100 , loss : 2.10442\n",
      "step 174100 , validation  accuracy 0.3176\n",
      "step 174100 , validation loss : 23.3886\n",
      "step 174200 , training  accuracy 0.5\n",
      "step 174200 , loss : 2.14003\n",
      "step 174200 , validation  accuracy 0.2882\n",
      "step 174200 , validation loss : 20.5231\n",
      "step 174300 , training  accuracy 0.533333\n",
      "step 174300 , loss : 2.07959\n",
      "step 174300 , validation  accuracy 0.3206\n",
      "step 174300 , validation loss : 22.214\n",
      "step 174400 , training  accuracy 0.5\n",
      "step 174400 , loss : 2.1371\n",
      "step 174400 , validation  accuracy 0.3034\n",
      "step 174400 , validation loss : 20.8639\n",
      "step 174500 , training  accuracy 0.5\n",
      "step 174500 , loss : 2.06554\n",
      "step 174500 , validation  accuracy 0.3192\n",
      "step 174500 , validation loss : 22.0816\n",
      "step 174600 , training  accuracy 0.4\n",
      "step 174600 , loss : 2.11663\n",
      "step 174600 , validation  accuracy 0.31\n",
      "step 174600 , validation loss : 20.4058\n",
      "step 174700 , training  accuracy 0.333333\n",
      "step 174700 , loss : 2.21722\n",
      "step 174700 , validation  accuracy 0.3096\n",
      "step 174700 , validation loss : 20.7585\n",
      "step 174800 , training  accuracy 0.6\n",
      "step 174800 , loss : 2.1121\n",
      "step 174800 , validation  accuracy 0.3074\n",
      "step 174800 , validation loss : 22.7854\n",
      "step 174900 , training  accuracy 0.633333\n",
      "step 174900 , loss : 2.05146\n",
      "step 174900 , validation  accuracy 0.3116\n",
      "step 174900 , validation loss : 21.3716\n",
      "step 175000 , training  accuracy 0.433333\n",
      "step 175000 , loss : 2.12101\n",
      "step 175000 , validation  accuracy 0.3024\n",
      "step 175000 , validation loss : 21.7707\n",
      "step 175100 , training  accuracy 0.433333\n",
      "step 175100 , loss : 2.13654\n",
      "step 175100 , validation  accuracy 0.3152\n",
      "step 175100 , validation loss : 23.0055\n",
      "step 175200 , training  accuracy 0.6\n",
      "step 175200 , loss : 2.11011\n",
      "step 175200 , validation  accuracy 0.308\n",
      "step 175200 , validation loss : 20.449\n",
      "step 175300 , training  accuracy 0.466667\n",
      "step 175300 , loss : 2.10193\n",
      "step 175300 , validation  accuracy 0.3202\n",
      "step 175300 , validation loss : 22.4801\n",
      "step 175400 , training  accuracy 0.466667\n",
      "step 175400 , loss : 2.17679\n",
      "step 175400 , validation  accuracy 0.2874\n",
      "step 175400 , validation loss : 19.4243\n",
      "step 175500 , training  accuracy 0.6\n",
      "step 175500 , loss : 2.03232\n",
      "step 175500 , validation  accuracy 0.302\n",
      "step 175500 , validation loss : 22.9209\n",
      "step 175600 , training  accuracy 0.5\n",
      "step 175600 , loss : 2.09971\n",
      "step 175600 , validation  accuracy 0.3086\n",
      "step 175600 , validation loss : 20.8891\n",
      "step 175700 , training  accuracy 0.366667\n",
      "step 175700 , loss : 2.12432\n",
      "step 175700 , validation  accuracy 0.3154\n",
      "step 175700 , validation loss : 22.8064\n",
      "step 175800 , training  accuracy 0.566667\n",
      "step 175800 , loss : 2.06351\n",
      "step 175800 , validation  accuracy 0.3138\n",
      "step 175800 , validation loss : 22.4291\n",
      "step 175900 , training  accuracy 0.5\n",
      "step 175900 , loss : 2.10193\n",
      "step 175900 , validation  accuracy 0.3112\n",
      "step 175900 , validation loss : 21.8815\n",
      "step 176000 , training  accuracy 0.4\n",
      "step 176000 , loss : 2.15853\n",
      "step 176000 , validation  accuracy 0.2988\n",
      "step 176000 , validation loss : 21.3051\n",
      "step 176100 , training  accuracy 0.533333\n",
      "step 176100 , loss : 2.13868\n",
      "step 176100 , validation  accuracy 0.313\n",
      "step 176100 , validation loss : 21.6748\n",
      "step 176200 , training  accuracy 0.533333\n",
      "step 176200 , loss : 2.13564\n",
      "step 176200 , validation  accuracy 0.303\n",
      "step 176200 , validation loss : 22.8903\n",
      "step 176300 , training  accuracy 0.566667\n",
      "step 176300 , loss : 2.04323\n",
      "step 176300 , validation  accuracy 0.316\n",
      "step 176300 , validation loss : 22.3291\n",
      "step 176400 , training  accuracy 0.566667\n",
      "step 176400 , loss : 2.10803\n",
      "step 176400 , validation  accuracy 0.314\n",
      "step 176400 , validation loss : 22.1461\n",
      "step 176500 , training  accuracy 0.433333\n",
      "step 176500 , loss : 2.17426\n",
      "step 176500 , validation  accuracy 0.3064\n",
      "step 176500 , validation loss : 20.8798\n",
      "step 176600 , training  accuracy 0.4\n",
      "step 176600 , loss : 2.12274\n",
      "step 176600 , validation  accuracy 0.3042\n",
      "step 176600 , validation loss : 22.0139\n",
      "step 176700 , training  accuracy 0.466667\n",
      "step 176700 , loss : 2.10315\n",
      "step 176700 , validation  accuracy 0.3252\n",
      "step 176700 , validation loss : 23.1065\n",
      "step 176800 , training  accuracy 0.566667\n",
      "step 176800 , loss : 2.08185\n",
      "step 176800 , validation  accuracy 0.3066\n",
      "step 176800 , validation loss : 22.5548\n",
      "step 176900 , training  accuracy 0.6\n",
      "step 176900 , loss : 2.01168\n",
      "step 176900 , validation  accuracy 0.329\n",
      "step 176900 , validation loss : 22.9977\n",
      "step 177000 , training  accuracy 0.4\n",
      "step 177000 , loss : 2.11656\n",
      "step 177000 , validation  accuracy 0.3014\n",
      "step 177000 , validation loss : 23.1897\n",
      "step 177100 , training  accuracy 0.6\n",
      "step 177100 , loss : 1.9996\n",
      "step 177100 , validation  accuracy 0.2978\n",
      "step 177100 , validation loss : 21.5177\n",
      "step 177200 , training  accuracy 0.566667\n",
      "step 177200 , loss : 2.10826\n",
      "step 177200 , validation  accuracy 0.3216\n",
      "step 177200 , validation loss : 23.6676\n",
      "step 177300 , training  accuracy 0.533333\n",
      "step 177300 , loss : 2.04872\n",
      "step 177300 , validation  accuracy 0.3254\n",
      "step 177300 , validation loss : 23.7815\n",
      "step 177400 , training  accuracy 0.466667\n",
      "step 177400 , loss : 2.11702\n",
      "step 177400 , validation  accuracy 0.3222\n",
      "step 177400 , validation loss : 22.1213\n",
      "step 177500 , training  accuracy 0.366667\n",
      "step 177500 , loss : 2.18033\n",
      "step 177500 , validation  accuracy 0.3046\n",
      "step 177500 , validation loss : 21.1621\n",
      "step 177600 , training  accuracy 0.533333\n",
      "step 177600 , loss : 2.13723\n",
      "step 177600 , validation  accuracy 0.309\n",
      "step 177600 , validation loss : 21.6372\n",
      "step 177700 , training  accuracy 0.4\n",
      "step 177700 , loss : 2.18746\n",
      "step 177700 , validation  accuracy 0.3042\n",
      "step 177700 , validation loss : 22.4195\n",
      "step 177800 , training  accuracy 0.5\n",
      "step 177800 , loss : 2.08788\n",
      "step 177800 , validation  accuracy 0.3062\n",
      "step 177800 , validation loss : 21.5522\n",
      "step 177900 , training  accuracy 0.466667\n",
      "step 177900 , loss : 2.09486\n",
      "step 177900 , validation  accuracy 0.3212\n",
      "step 177900 , validation loss : 23.2877\n",
      "step 178000 , training  accuracy 0.4\n",
      "step 178000 , loss : 2.1128\n",
      "step 178000 , validation  accuracy 0.2926\n",
      "step 178000 , validation loss : 20.8279\n",
      "step 178100 , training  accuracy 0.433333\n",
      "step 178100 , loss : 2.15359\n",
      "step 178100 , validation  accuracy 0.2938\n",
      "step 178100 , validation loss : 22.068\n",
      "step 178200 , training  accuracy 0.6\n",
      "step 178200 , loss : 2.04445\n",
      "step 178200 , validation  accuracy 0.303\n",
      "step 178200 , validation loss : 22.2354\n",
      "step 178300 , training  accuracy 0.566667\n",
      "step 178300 , loss : 2.10735\n",
      "step 178300 , validation  accuracy 0.3016\n",
      "step 178300 , validation loss : 21.6627\n",
      "step 178400 , training  accuracy 0.466667\n",
      "step 178400 , loss : 2.11617\n",
      "step 178400 , validation  accuracy 0.3214\n",
      "step 178400 , validation loss : 22.6448\n",
      "step 178500 , training  accuracy 0.4\n",
      "step 178500 , loss : 2.14809\n",
      "step 178500 , validation  accuracy 0.317\n",
      "step 178500 , validation loss : 22.1752\n",
      "step 178600 , training  accuracy 0.266667\n",
      "step 178600 , loss : 2.21289\n",
      "step 178600 , validation  accuracy 0.2986\n",
      "step 178600 , validation loss : 21.5958\n",
      "step 178700 , training  accuracy 0.5\n",
      "step 178700 , loss : 2.13758\n",
      "step 178700 , validation  accuracy 0.3078\n",
      "step 178700 , validation loss : 21.4072\n",
      "step 178800 , training  accuracy 0.533333\n",
      "step 178800 , loss : 2.04801\n",
      "step 178800 , validation  accuracy 0.3176\n",
      "step 178800 , validation loss : 22.2786\n",
      "step 178900 , training  accuracy 0.566667\n",
      "step 178900 , loss : 2.03031\n",
      "step 178900 , validation  accuracy 0.299\n",
      "step 178900 , validation loss : 21.4944\n",
      "step 179000 , training  accuracy 0.633333\n",
      "step 179000 , loss : 2.00652\n",
      "step 179000 , validation  accuracy 0.2982\n",
      "step 179000 , validation loss : 22.218\n",
      "step 179100 , training  accuracy 0.5\n",
      "step 179100 , loss : 2.10473\n",
      "step 179100 , validation  accuracy 0.3208\n",
      "step 179100 , validation loss : 22.2906\n",
      "step 179200 , training  accuracy 0.633333\n",
      "step 179200 , loss : 2.08701\n",
      "step 179200 , validation  accuracy 0.3218\n",
      "step 179200 , validation loss : 21.9017\n",
      "step 179300 , training  accuracy 0.533333\n",
      "step 179300 , loss : 2.03152\n",
      "step 179300 , validation  accuracy 0.2952\n",
      "step 179300 , validation loss : 20.877\n",
      "step 179400 , training  accuracy 0.6\n",
      "step 179400 , loss : 2.05133\n",
      "step 179400 , validation  accuracy 0.3074\n",
      "step 179400 , validation loss : 21.6453\n",
      "step 179500 , training  accuracy 0.6\n",
      "step 179500 , loss : 2.06678\n",
      "step 179500 , validation  accuracy 0.3224\n",
      "step 179500 , validation loss : 23.9074\n",
      "step 179600 , training  accuracy 0.466667\n",
      "step 179600 , loss : 2.14103\n",
      "step 179600 , validation  accuracy 0.3012\n",
      "step 179600 , validation loss : 21.2178\n",
      "step 179700 , training  accuracy 0.633333\n",
      "step 179700 , loss : 2.0155\n",
      "step 179700 , validation  accuracy 0.302\n",
      "step 179700 , validation loss : 22.57\n",
      "step 179800 , training  accuracy 0.566667\n",
      "step 179800 , loss : 2.07654\n",
      "step 179800 , validation  accuracy 0.3092\n",
      "step 179800 , validation loss : 21.3853\n",
      "step 179900 , training  accuracy 0.566667\n",
      "step 179900 , loss : 2.06656\n",
      "step 179900 , validation  accuracy 0.3234\n",
      "step 179900 , validation loss : 23.247\n",
      "step 180000 , training  accuracy 0.366667\n",
      "step 180000 , loss : 2.14443\n",
      "step 180000 , validation  accuracy 0.2952\n",
      "step 180000 , validation loss : 23.0875\n",
      "step 180100 , training  accuracy 0.566667\n",
      "step 180100 , loss : 2.07451\n",
      "step 180100 , validation  accuracy 0.2962\n",
      "step 180100 , validation loss : 20.5111\n",
      "step 180200 , training  accuracy 0.633333\n",
      "step 180200 , loss : 2.0278\n",
      "step 180200 , validation  accuracy 0.3196\n",
      "step 180200 , validation loss : 22.2945\n",
      "step 180300 , training  accuracy 0.366667\n",
      "step 180300 , loss : 2.14542\n",
      "step 180300 , validation  accuracy 0.319\n",
      "step 180300 , validation loss : 23.055\n",
      "step 180400 , training  accuracy 0.366667\n",
      "step 180400 , loss : 2.16537\n",
      "step 180400 , validation  accuracy 0.3096\n",
      "step 180400 , validation loss : 22.068\n",
      "step 180500 , training  accuracy 0.5\n",
      "step 180500 , loss : 2.10842\n",
      "step 180500 , validation  accuracy 0.303\n",
      "step 180500 , validation loss : 22.707\n",
      "step 180600 , training  accuracy 0.533333\n",
      "step 180600 , loss : 2.10098\n",
      "step 180600 , validation  accuracy 0.3008\n",
      "step 180600 , validation loss : 22.9128\n",
      "step 180700 , training  accuracy 0.5\n",
      "step 180700 , loss : 2.05498\n",
      "step 180700 , validation  accuracy 0.307\n",
      "step 180700 , validation loss : 21.0278\n",
      "step 180800 , training  accuracy 0.466667\n",
      "step 180800 , loss : 2.10823\n",
      "step 180800 , validation  accuracy 0.3098\n",
      "step 180800 , validation loss : 21.8065\n",
      "step 180900 , training  accuracy 0.5\n",
      "step 180900 , loss : 2.12561\n",
      "step 180900 , validation  accuracy 0.3106\n",
      "step 180900 , validation loss : 22.2926\n",
      "step 181000 , training  accuracy 0.566667\n",
      "step 181000 , loss : 2.04784\n",
      "step 181000 , validation  accuracy 0.315\n",
      "step 181000 , validation loss : 22.7173\n",
      "step 181100 , training  accuracy 0.433333\n",
      "step 181100 , loss : 2.13777\n",
      "step 181100 , validation  accuracy 0.2796\n",
      "step 181100 , validation loss : 21.8272\n",
      "step 181200 , training  accuracy 0.366667\n",
      "step 181200 , loss : 2.10434\n",
      "step 181200 , validation  accuracy 0.3112\n",
      "step 181200 , validation loss : 22.326\n",
      "step 181300 , training  accuracy 0.633333\n",
      "step 181300 , loss : 2.06847\n",
      "step 181300 , validation  accuracy 0.3152\n",
      "step 181300 , validation loss : 22.7106\n",
      "step 181400 , training  accuracy 0.466667\n",
      "step 181400 , loss : 2.16491\n",
      "step 181400 , validation  accuracy 0.3012\n",
      "step 181400 , validation loss : 21.553\n",
      "step 181500 , training  accuracy 0.533333\n",
      "step 181500 , loss : 2.09661\n",
      "step 181500 , validation  accuracy 0.3044\n",
      "step 181500 , validation loss : 22.0394\n",
      "step 181600 , training  accuracy 0.666667\n",
      "step 181600 , loss : 2.06126\n",
      "step 181600 , validation  accuracy 0.3104\n",
      "step 181600 , validation loss : 21.292\n",
      "step 181700 , training  accuracy 0.466667\n",
      "step 181700 , loss : 2.03798\n",
      "step 181700 , validation  accuracy 0.3058\n",
      "step 181700 , validation loss : 23.1562\n",
      "step 181800 , training  accuracy 0.433333\n",
      "step 181800 , loss : 2.1299\n",
      "step 181800 , validation  accuracy 0.3076\n",
      "step 181800 , validation loss : 21.6176\n",
      "step 181900 , training  accuracy 0.533333\n",
      "step 181900 , loss : 2.06904\n",
      "step 181900 , validation  accuracy 0.3068\n",
      "step 181900 , validation loss : 24.6577\n",
      "step 182000 , training  accuracy 0.466667\n",
      "step 182000 , loss : 2.1181\n",
      "step 182000 , validation  accuracy 0.3186\n",
      "step 182000 , validation loss : 23.8194\n",
      "step 182100 , training  accuracy 0.4\n",
      "step 182100 , loss : 2.15567\n",
      "step 182100 , validation  accuracy 0.3016\n",
      "step 182100 , validation loss : 22.0407\n",
      "step 182200 , training  accuracy 0.5\n",
      "step 182200 , loss : 2.11255\n",
      "step 182200 , validation  accuracy 0.3116\n",
      "step 182200 , validation loss : 22.0428\n",
      "step 182300 , training  accuracy 0.466667\n",
      "step 182300 , loss : 2.0879\n",
      "step 182300 , validation  accuracy 0.3114\n",
      "step 182300 , validation loss : 22.5722\n",
      "step 182400 , training  accuracy 0.566667\n",
      "step 182400 , loss : 2.0356\n",
      "step 182400 , validation  accuracy 0.3016\n",
      "step 182400 , validation loss : 20.6931\n",
      "step 182500 , training  accuracy 0.633333\n",
      "step 182500 , loss : 2.04783\n",
      "step 182500 , validation  accuracy 0.3016\n",
      "step 182500 , validation loss : 23.0044\n",
      "step 182600 , training  accuracy 0.5\n",
      "step 182600 , loss : 2.10526\n",
      "step 182600 , validation  accuracy 0.3004\n",
      "step 182600 , validation loss : 21.646\n",
      "step 182700 , training  accuracy 0.666667\n",
      "step 182700 , loss : 2.04666\n",
      "step 182700 , validation  accuracy 0.315\n",
      "step 182700 , validation loss : 22.3829\n",
      "step 182800 , training  accuracy 0.466667\n",
      "step 182800 , loss : 2.19995\n",
      "step 182800 , validation  accuracy 0.3124\n",
      "step 182800 , validation loss : 22.0687\n",
      "step 182900 , training  accuracy 0.533333\n",
      "step 182900 , loss : 2.0863\n",
      "step 182900 , validation  accuracy 0.3242\n",
      "step 182900 , validation loss : 22.9691\n",
      "step 183000 , training  accuracy 0.466667\n",
      "step 183000 , loss : 2.12966\n",
      "step 183000 , validation  accuracy 0.2938\n",
      "step 183000 , validation loss : 20.4983\n",
      "step 183100 , training  accuracy 0.733333\n",
      "step 183100 , loss : 2.00733\n",
      "step 183100 , validation  accuracy 0.3096\n",
      "step 183100 , validation loss : 22.7697\n",
      "step 183200 , training  accuracy 0.533333\n",
      "step 183200 , loss : 2.06775\n",
      "step 183200 , validation  accuracy 0.3252\n",
      "step 183200 , validation loss : 24.3727\n",
      "step 183300 , training  accuracy 0.733333\n",
      "step 183300 , loss : 2.04183\n",
      "step 183300 , validation  accuracy 0.3182\n",
      "step 183300 , validation loss : 21.9379\n",
      "step 183400 , training  accuracy 0.6\n",
      "step 183400 , loss : 2.07599\n",
      "step 183400 , validation  accuracy 0.2778\n",
      "step 183400 , validation loss : 19.6578\n",
      "step 183500 , training  accuracy 0.6\n",
      "step 183500 , loss : 2.0484\n",
      "step 183500 , validation  accuracy 0.3106\n",
      "step 183500 , validation loss : 22.8801\n",
      "step 183600 , training  accuracy 0.466667\n",
      "step 183600 , loss : 2.17202\n",
      "step 183600 , validation  accuracy 0.3138\n",
      "step 183600 , validation loss : 21.6494\n",
      "step 183700 , training  accuracy 0.666667\n",
      "step 183700 , loss : 2.0505\n",
      "step 183700 , validation  accuracy 0.3138\n",
      "step 183700 , validation loss : 22.2674\n",
      "step 183800 , training  accuracy 0.533333\n",
      "step 183800 , loss : 2.11063\n",
      "step 183800 , validation  accuracy 0.317\n",
      "step 183800 , validation loss : 22.2454\n",
      "step 183900 , training  accuracy 0.633333\n",
      "step 183900 , loss : 2.0204\n",
      "step 183900 , validation  accuracy 0.304\n",
      "step 183900 , validation loss : 22.1687\n",
      "step 184000 , training  accuracy 0.466667\n",
      "step 184000 , loss : 2.13357\n",
      "step 184000 , validation  accuracy 0.315\n",
      "step 184000 , validation loss : 21.5992\n",
      "step 184100 , training  accuracy 0.4\n",
      "step 184100 , loss : 2.16188\n",
      "step 184100 , validation  accuracy 0.316\n",
      "step 184100 , validation loss : 21.3687\n",
      "step 184200 , training  accuracy 0.5\n",
      "step 184200 , loss : 2.07908\n",
      "step 184200 , validation  accuracy 0.323\n",
      "step 184200 , validation loss : 23.3782\n",
      "step 184300 , training  accuracy 0.5\n",
      "step 184300 , loss : 2.17494\n",
      "step 184300 , validation  accuracy 0.2998\n",
      "step 184300 , validation loss : 19.8305\n",
      "step 184400 , training  accuracy 0.433333\n",
      "step 184400 , loss : 2.11333\n",
      "step 184400 , validation  accuracy 0.304\n",
      "step 184400 , validation loss : 22.0663\n",
      "step 184500 , training  accuracy 0.433333\n",
      "step 184500 , loss : 2.17192\n",
      "step 184500 , validation  accuracy 0.2928\n",
      "step 184500 , validation loss : 20.7044\n",
      "step 184600 , training  accuracy 0.466667\n",
      "step 184600 , loss : 2.10084\n",
      "step 184600 , validation  accuracy 0.32\n",
      "step 184600 , validation loss : 24.078\n",
      "step 184700 , training  accuracy 0.566667\n",
      "step 184700 , loss : 2.11039\n",
      "step 184700 , validation  accuracy 0.311\n",
      "step 184700 , validation loss : 21.9069\n",
      "step 184800 , training  accuracy 0.566667\n",
      "step 184800 , loss : 2.08699\n",
      "step 184800 , validation  accuracy 0.3174\n",
      "step 184800 , validation loss : 22.5132\n",
      "step 184900 , training  accuracy 0.433333\n",
      "step 184900 , loss : 2.10131\n",
      "step 184900 , validation  accuracy 0.3104\n",
      "step 184900 , validation loss : 21.7415\n",
      "step 185000 , training  accuracy 0.433333\n",
      "step 185000 , loss : 2.10601\n",
      "step 185000 , validation  accuracy 0.2904\n",
      "step 185000 , validation loss : 21.8768\n",
      "step 185100 , training  accuracy 0.366667\n",
      "step 185100 , loss : 2.17191\n",
      "step 185100 , validation  accuracy 0.3042\n",
      "step 185100 , validation loss : 21.8133\n",
      "step 185200 , training  accuracy 0.533333\n",
      "step 185200 , loss : 2.08105\n",
      "step 185200 , validation  accuracy 0.3194\n",
      "step 185200 , validation loss : 23.5366\n",
      "step 185300 , training  accuracy 0.533333\n",
      "step 185300 , loss : 2.11607\n",
      "step 185300 , validation  accuracy 0.3146\n",
      "step 185300 , validation loss : 21.5893\n",
      "step 185400 , training  accuracy 0.633333\n",
      "step 185400 , loss : 2.04108\n",
      "step 185400 , validation  accuracy 0.3118\n",
      "step 185400 , validation loss : 21.9723\n",
      "step 185500 , training  accuracy 0.466667\n",
      "step 185500 , loss : 2.12242\n",
      "step 185500 , validation  accuracy 0.299\n",
      "step 185500 , validation loss : 21.3954\n",
      "step 185600 , training  accuracy 0.633333\n",
      "step 185600 , loss : 2.03484\n",
      "step 185600 , validation  accuracy 0.2986\n",
      "step 185600 , validation loss : 21.8764\n",
      "step 185700 , training  accuracy 0.3\n",
      "step 185700 , loss : 2.18029\n",
      "step 185700 , validation  accuracy 0.31\n",
      "step 185700 , validation loss : 22.5235\n",
      "step 185800 , training  accuracy 0.633333\n",
      "step 185800 , loss : 2.05206\n",
      "step 185800 , validation  accuracy 0.2964\n",
      "step 185800 , validation loss : 21.8176\n",
      "step 185900 , training  accuracy 0.5\n",
      "step 185900 , loss : 2.07575\n",
      "step 185900 , validation  accuracy 0.2894\n",
      "step 185900 , validation loss : 21.7345\n",
      "step 186000 , training  accuracy 0.433333\n",
      "step 186000 , loss : 2.12052\n",
      "step 186000 , validation  accuracy 0.3046\n",
      "step 186000 , validation loss : 22.8162\n",
      "step 186100 , training  accuracy 0.633333\n",
      "step 186100 , loss : 2.03204\n",
      "step 186100 , validation  accuracy 0.303\n",
      "step 186100 , validation loss : 21.4546\n",
      "step 186200 , training  accuracy 0.433333\n",
      "step 186200 , loss : 2.1331\n",
      "step 186200 , validation  accuracy 0.3136\n",
      "step 186200 , validation loss : 22.4391\n",
      "step 186300 , training  accuracy 0.533333\n",
      "step 186300 , loss : 2.05188\n",
      "step 186300 , validation  accuracy 0.315\n",
      "step 186300 , validation loss : 23.0967\n",
      "step 186400 , training  accuracy 0.466667\n",
      "step 186400 , loss : 2.12193\n",
      "step 186400 , validation  accuracy 0.308\n",
      "step 186400 , validation loss : 21.2254\n",
      "step 186500 , training  accuracy 0.5\n",
      "step 186500 , loss : 2.13242\n",
      "step 186500 , validation  accuracy 0.2914\n",
      "step 186500 , validation loss : 21.6214\n",
      "step 186600 , training  accuracy 0.566667\n",
      "step 186600 , loss : 2.09655\n",
      "step 186600 , validation  accuracy 0.2964\n",
      "step 186600 , validation loss : 21.9914\n",
      "step 186700 , training  accuracy 0.5\n",
      "step 186700 , loss : 2.09697\n",
      "step 186700 , validation  accuracy 0.3088\n",
      "step 186700 , validation loss : 22.1659\n",
      "step 186800 , training  accuracy 0.5\n",
      "step 186800 , loss : 2.12208\n",
      "step 186800 , validation  accuracy 0.2988\n",
      "step 186800 , validation loss : 20.8501\n",
      "step 186900 , training  accuracy 0.6\n",
      "step 186900 , loss : 2.05084\n",
      "step 186900 , validation  accuracy 0.3042\n",
      "step 186900 , validation loss : 21.8677\n",
      "step 187000 , training  accuracy 0.366667\n",
      "step 187000 , loss : 2.19316\n",
      "step 187000 , validation  accuracy 0.2978\n",
      "step 187000 , validation loss : 21.6701\n",
      "step 187100 , training  accuracy 0.433333\n",
      "step 187100 , loss : 2.2032\n",
      "step 187100 , validation  accuracy 0.2762\n",
      "step 187100 , validation loss : 20.6219\n",
      "step 187200 , training  accuracy 0.633333\n",
      "step 187200 , loss : 2.04132\n",
      "step 187200 , validation  accuracy 0.3106\n",
      "step 187200 , validation loss : 21.7638\n",
      "step 187300 , training  accuracy 0.433333\n",
      "step 187300 , loss : 2.117\n",
      "step 187300 , validation  accuracy 0.2898\n",
      "step 187300 , validation loss : 21.3392\n",
      "step 187400 , training  accuracy 0.666667\n",
      "step 187400 , loss : 1.9761\n",
      "step 187400 , validation  accuracy 0.3202\n",
      "step 187400 , validation loss : 22.5982\n",
      "step 187500 , training  accuracy 0.5\n",
      "step 187500 , loss : 2.09526\n",
      "step 187500 , validation  accuracy 0.314\n",
      "step 187500 , validation loss : 22.4209\n",
      "step 187600 , training  accuracy 0.466667\n",
      "step 187600 , loss : 2.12866\n",
      "step 187600 , validation  accuracy 0.3228\n",
      "step 187600 , validation loss : 24.0359\n",
      "step 187700 , training  accuracy 0.4\n",
      "step 187700 , loss : 2.26093\n",
      "step 187700 , validation  accuracy 0.286\n",
      "step 187700 , validation loss : 21.7471\n",
      "step 187800 , training  accuracy 0.566667\n",
      "step 187800 , loss : 2.10392\n",
      "step 187800 , validation  accuracy 0.3056\n",
      "step 187800 , validation loss : 21.4111\n",
      "step 187900 , training  accuracy 0.566667\n",
      "step 187900 , loss : 2.06624\n",
      "step 187900 , validation  accuracy 0.3068\n",
      "step 187900 , validation loss : 21.9228\n",
      "step 188000 , training  accuracy 0.433333\n",
      "step 188000 , loss : 2.09284\n",
      "step 188000 , validation  accuracy 0.3118\n",
      "step 188000 , validation loss : 22.9636\n",
      "step 188100 , training  accuracy 0.633333\n",
      "step 188100 , loss : 2.12372\n",
      "step 188100 , validation  accuracy 0.2954\n",
      "step 188100 , validation loss : 22.2606\n",
      "step 188200 , training  accuracy 0.5\n",
      "step 188200 , loss : 2.09946\n",
      "step 188200 , validation  accuracy 0.3172\n",
      "step 188200 , validation loss : 22.9541\n",
      "step 188300 , training  accuracy 0.566667\n",
      "step 188300 , loss : 2.0984\n",
      "step 188300 , validation  accuracy 0.3102\n",
      "step 188300 , validation loss : 21.5479\n",
      "step 188400 , training  accuracy 0.7\n",
      "step 188400 , loss : 2.01317\n",
      "step 188400 , validation  accuracy 0.3074\n",
      "step 188400 , validation loss : 21.532\n",
      "step 188500 , training  accuracy 0.5\n",
      "step 188500 , loss : 2.07834\n",
      "step 188500 , validation  accuracy 0.3114\n",
      "step 188500 , validation loss : 22.0821\n",
      "step 188600 , training  accuracy 0.466667\n",
      "step 188600 , loss : 2.10792\n",
      "step 188600 , validation  accuracy 0.3212\n",
      "step 188600 , validation loss : 22.6874\n",
      "step 188700 , training  accuracy 0.5\n",
      "step 188700 , loss : 2.12504\n",
      "step 188700 , validation  accuracy 0.3128\n",
      "step 188700 , validation loss : 20.8407\n",
      "step 188800 , training  accuracy 0.6\n",
      "step 188800 , loss : 2.09618\n",
      "step 188800 , validation  accuracy 0.315\n",
      "step 188800 , validation loss : 21.7531\n",
      "step 188900 , training  accuracy 0.533333\n",
      "step 188900 , loss : 2.1542\n",
      "step 188900 , validation  accuracy 0.3094\n",
      "step 188900 , validation loss : 21.0759\n",
      "step 189000 , training  accuracy 0.566667\n",
      "step 189000 , loss : 2.06494\n",
      "step 189000 , validation  accuracy 0.3096\n",
      "step 189000 , validation loss : 21.5147\n",
      "step 189100 , training  accuracy 0.533333\n",
      "step 189100 , loss : 2.06661\n",
      "step 189100 , validation  accuracy 0.3152\n",
      "step 189100 , validation loss : 21.6791\n",
      "step 189200 , training  accuracy 0.5\n",
      "step 189200 , loss : 2.14254\n",
      "step 189200 , validation  accuracy 0.3232\n",
      "step 189200 , validation loss : 23.7874\n",
      "step 189300 , training  accuracy 0.633333\n",
      "step 189300 , loss : 2.04607\n",
      "step 189300 , validation  accuracy 0.3046\n",
      "step 189300 , validation loss : 22.833\n",
      "step 189400 , training  accuracy 0.533333\n",
      "step 189400 , loss : 2.06906\n",
      "step 189400 , validation  accuracy 0.3154\n",
      "step 189400 , validation loss : 22.4692\n",
      "step 189500 , training  accuracy 0.7\n",
      "step 189500 , loss : 2.06011\n",
      "step 189500 , validation  accuracy 0.2976\n",
      "step 189500 , validation loss : 22.639\n",
      "step 189600 , training  accuracy 0.466667\n",
      "step 189600 , loss : 2.13397\n",
      "step 189600 , validation  accuracy 0.3082\n",
      "step 189600 , validation loss : 21.2353\n",
      "step 189700 , training  accuracy 0.5\n",
      "step 189700 , loss : 2.07109\n",
      "step 189700 , validation  accuracy 0.3188\n",
      "step 189700 , validation loss : 22.9475\n",
      "step 189800 , training  accuracy 0.566667\n",
      "step 189800 , loss : 2.14455\n",
      "step 189800 , validation  accuracy 0.3234\n",
      "step 189800 , validation loss : 22.614\n",
      "step 189900 , training  accuracy 0.633333\n",
      "step 189900 , loss : 2.03096\n",
      "step 189900 , validation  accuracy 0.3172\n",
      "step 189900 , validation loss : 22.3094\n",
      "step 190000 , training  accuracy 0.5\n",
      "step 190000 , loss : 2.06734\n",
      "step 190000 , validation  accuracy 0.3144\n",
      "step 190000 , validation loss : 23.0709\n",
      "step 190100 , training  accuracy 0.433333\n",
      "step 190100 , loss : 2.18956\n",
      "step 190100 , validation  accuracy 0.3024\n",
      "step 190100 , validation loss : 22.6735\n",
      "step 190200 , training  accuracy 0.533333\n",
      "step 190200 , loss : 2.08195\n",
      "step 190200 , validation  accuracy 0.3236\n",
      "step 190200 , validation loss : 22.9725\n",
      "step 190300 , training  accuracy 0.466667\n",
      "step 190300 , loss : 2.10842\n",
      "step 190300 , validation  accuracy 0.3184\n",
      "step 190300 , validation loss : 23.0598\n",
      "step 190400 , training  accuracy 0.533333\n",
      "step 190400 , loss : 2.00004\n",
      "step 190400 , validation  accuracy 0.3216\n",
      "step 190400 , validation loss : 23.6871\n",
      "step 190500 , training  accuracy 0.566667\n",
      "step 190500 , loss : 2.07275\n",
      "step 190500 , validation  accuracy 0.3038\n",
      "step 190500 , validation loss : 22.9067\n",
      "step 190600 , training  accuracy 0.666667\n",
      "step 190600 , loss : 2.07041\n",
      "step 190600 , validation  accuracy 0.3078\n",
      "step 190600 , validation loss : 22.2484\n",
      "step 190700 , training  accuracy 0.366667\n",
      "step 190700 , loss : 2.14999\n",
      "step 190700 , validation  accuracy 0.3142\n",
      "step 190700 , validation loss : 22.2908\n",
      "step 190800 , training  accuracy 0.4\n",
      "step 190800 , loss : 2.10538\n",
      "step 190800 , validation  accuracy 0.3146\n",
      "step 190800 , validation loss : 23.2218\n",
      "step 190900 , training  accuracy 0.7\n",
      "step 190900 , loss : 1.97516\n",
      "step 190900 , validation  accuracy 0.3146\n",
      "step 190900 , validation loss : 23.1283\n",
      "step 191000 , training  accuracy 0.433333\n",
      "step 191000 , loss : 2.12824\n",
      "step 191000 , validation  accuracy 0.2938\n",
      "step 191000 , validation loss : 21.8902\n",
      "step 191100 , training  accuracy 0.566667\n",
      "step 191100 , loss : 2.08623\n",
      "step 191100 , validation  accuracy 0.323\n",
      "step 191100 , validation loss : 22.4951\n",
      "step 191200 , training  accuracy 0.366667\n",
      "step 191200 , loss : 2.13586\n",
      "step 191200 , validation  accuracy 0.318\n",
      "step 191200 , validation loss : 22.3374\n",
      "step 191300 , training  accuracy 0.7\n",
      "step 191300 , loss : 2.03377\n",
      "step 191300 , validation  accuracy 0.3166\n",
      "step 191300 , validation loss : 23.1659\n",
      "step 191400 , training  accuracy 0.6\n",
      "step 191400 , loss : 2.06565\n",
      "step 191400 , validation  accuracy 0.3182\n",
      "step 191400 , validation loss : 21.7587\n",
      "step 191500 , training  accuracy 0.633333\n",
      "step 191500 , loss : 2.05001\n",
      "step 191500 , validation  accuracy 0.3202\n",
      "step 191500 , validation loss : 23.5165\n",
      "step 191600 , training  accuracy 0.533333\n",
      "step 191600 , loss : 2.09224\n",
      "step 191600 , validation  accuracy 0.3144\n",
      "step 191600 , validation loss : 21.9242\n",
      "step 191700 , training  accuracy 0.466667\n",
      "step 191700 , loss : 2.07718\n",
      "step 191700 , validation  accuracy 0.3122\n",
      "step 191700 , validation loss : 22.2745\n",
      "step 191800 , training  accuracy 0.466667\n",
      "step 191800 , loss : 2.09654\n",
      "step 191800 , validation  accuracy 0.3182\n",
      "step 191800 , validation loss : 23.2033\n",
      "step 191900 , training  accuracy 0.433333\n",
      "step 191900 , loss : 2.10013\n",
      "step 191900 , validation  accuracy 0.3136\n",
      "step 191900 , validation loss : 23.0393\n",
      "step 192000 , training  accuracy 0.333333\n",
      "step 192000 , loss : 2.2128\n",
      "step 192000 , validation  accuracy 0.2912\n",
      "step 192000 , validation loss : 22.2022\n",
      "step 192100 , training  accuracy 0.433333\n",
      "step 192100 , loss : 2.13421\n",
      "step 192100 , validation  accuracy 0.3164\n",
      "step 192100 , validation loss : 21.3995\n",
      "step 192200 , training  accuracy 0.5\n",
      "step 192200 , loss : 2.09162\n",
      "step 192200 , validation  accuracy 0.313\n",
      "step 192200 , validation loss : 22.6825\n",
      "step 192300 , training  accuracy 0.533333\n",
      "step 192300 , loss : 2.18793\n",
      "step 192300 , validation  accuracy 0.3198\n",
      "step 192300 , validation loss : 22.8264\n",
      "step 192400 , training  accuracy 0.4\n",
      "step 192400 , loss : 2.09436\n",
      "step 192400 , validation  accuracy 0.2994\n",
      "step 192400 , validation loss : 21.7923\n",
      "step 192500 , training  accuracy 0.533333\n",
      "step 192500 , loss : 2.06865\n",
      "step 192500 , validation  accuracy 0.3\n",
      "step 192500 , validation loss : 21.8731\n",
      "step 192600 , training  accuracy 0.5\n",
      "step 192600 , loss : 2.15331\n",
      "step 192600 , validation  accuracy 0.304\n",
      "step 192600 , validation loss : 21.3572\n",
      "step 192700 , training  accuracy 0.5\n",
      "step 192700 , loss : 2.12354\n",
      "step 192700 , validation  accuracy 0.3036\n",
      "step 192700 , validation loss : 22.7794\n",
      "step 192800 , training  accuracy 0.533333\n",
      "step 192800 , loss : 2.06886\n",
      "step 192800 , validation  accuracy 0.311\n",
      "step 192800 , validation loss : 23.2003\n",
      "step 192900 , training  accuracy 0.566667\n",
      "step 192900 , loss : 2.08397\n",
      "step 192900 , validation  accuracy 0.3158\n",
      "step 192900 , validation loss : 22.4435\n",
      "step 193000 , training  accuracy 0.6\n",
      "step 193000 , loss : 2.09146\n",
      "step 193000 , validation  accuracy 0.302\n",
      "step 193000 , validation loss : 22.6948\n",
      "step 193100 , training  accuracy 0.4\n",
      "step 193100 , loss : 2.13635\n",
      "step 193100 , validation  accuracy 0.3034\n",
      "step 193100 , validation loss : 20.7889\n",
      "step 193200 , training  accuracy 0.4\n",
      "step 193200 , loss : 2.09933\n",
      "step 193200 , validation  accuracy 0.3126\n",
      "step 193200 , validation loss : 21.6506\n",
      "step 193300 , training  accuracy 0.733333\n",
      "step 193300 , loss : 2.01172\n",
      "step 193300 , validation  accuracy 0.3234\n",
      "step 193300 , validation loss : 22.2655\n",
      "step 193400 , training  accuracy 0.466667\n",
      "step 193400 , loss : 2.14609\n",
      "step 193400 , validation  accuracy 0.315\n",
      "step 193400 , validation loss : 22.3026\n",
      "step 193500 , training  accuracy 0.466667\n",
      "step 193500 , loss : 2.1021\n",
      "step 193500 , validation  accuracy 0.3074\n",
      "step 193500 , validation loss : 22.8433\n",
      "step 193600 , training  accuracy 0.4\n",
      "step 193600 , loss : 2.16634\n",
      "step 193600 , validation  accuracy 0.3098\n",
      "step 193600 , validation loss : 21.9157\n",
      "step 193700 , training  accuracy 0.533333\n",
      "step 193700 , loss : 2.0893\n",
      "step 193700 , validation  accuracy 0.301\n",
      "step 193700 , validation loss : 21.4488\n",
      "step 193800 , training  accuracy 0.6\n",
      "step 193800 , loss : 2.05675\n",
      "step 193800 , validation  accuracy 0.312\n",
      "step 193800 , validation loss : 21.9986\n",
      "step 193900 , training  accuracy 0.533333\n",
      "step 193900 , loss : 2.04656\n",
      "step 193900 , validation  accuracy 0.3054\n",
      "step 193900 , validation loss : 21.2463\n",
      "step 194000 , training  accuracy 0.4\n",
      "step 194000 , loss : 2.12425\n",
      "step 194000 , validation  accuracy 0.3064\n",
      "step 194000 , validation loss : 21.6005\n",
      "step 194100 , training  accuracy 0.533333\n",
      "step 194100 , loss : 2.13342\n",
      "step 194100 , validation  accuracy 0.3042\n",
      "step 194100 , validation loss : 23.6396\n",
      "step 194200 , training  accuracy 0.466667\n",
      "step 194200 , loss : 2.06441\n",
      "step 194200 , validation  accuracy 0.3152\n",
      "step 194200 , validation loss : 23.0666\n",
      "step 194300 , training  accuracy 0.266667\n",
      "step 194300 , loss : 2.19443\n",
      "step 194300 , validation  accuracy 0.3092\n",
      "step 194300 , validation loss : 23.168\n",
      "step 194400 , training  accuracy 0.533333\n",
      "step 194400 , loss : 2.11938\n",
      "step 194400 , validation  accuracy 0.3148\n",
      "step 194400 , validation loss : 23.4073\n",
      "step 194500 , training  accuracy 0.566667\n",
      "step 194500 , loss : 2.05787\n",
      "step 194500 , validation  accuracy 0.324\n",
      "step 194500 , validation loss : 23.781\n",
      "step 194600 , training  accuracy 0.5\n",
      "step 194600 , loss : 2.19035\n",
      "step 194600 , validation  accuracy 0.2966\n",
      "step 194600 , validation loss : 21.3851\n",
      "step 194700 , training  accuracy 0.7\n",
      "step 194700 , loss : 2.03033\n",
      "step 194700 , validation  accuracy 0.316\n",
      "step 194700 , validation loss : 22.936\n",
      "step 194800 , training  accuracy 0.4\n",
      "step 194800 , loss : 2.12663\n",
      "step 194800 , validation  accuracy 0.314\n",
      "step 194800 , validation loss : 24.2679\n",
      "step 194900 , training  accuracy 0.633333\n",
      "step 194900 , loss : 2.0353\n",
      "step 194900 , validation  accuracy 0.3126\n",
      "step 194900 , validation loss : 23.1266\n",
      "step 195000 , training  accuracy 0.5\n",
      "step 195000 , loss : 2.06828\n",
      "step 195000 , validation  accuracy 0.3078\n",
      "step 195000 , validation loss : 23.2126\n",
      "step 195100 , training  accuracy 0.533333\n",
      "step 195100 , loss : 2.09127\n",
      "step 195100 , validation  accuracy 0.2974\n",
      "step 195100 , validation loss : 22.2665\n",
      "step 195200 , training  accuracy 0.6\n",
      "step 195200 , loss : 2.0748\n",
      "step 195200 , validation  accuracy 0.3142\n",
      "step 195200 , validation loss : 23.462\n",
      "step 195300 , training  accuracy 0.6\n",
      "step 195300 , loss : 2.04798\n",
      "step 195300 , validation  accuracy 0.307\n",
      "step 195300 , validation loss : 23.7406\n",
      "step 195400 , training  accuracy 0.366667\n",
      "step 195400 , loss : 2.11041\n",
      "step 195400 , validation  accuracy 0.315\n",
      "step 195400 , validation loss : 22.6858\n",
      "step 195500 , training  accuracy 0.533333\n",
      "step 195500 , loss : 2.12303\n",
      "step 195500 , validation  accuracy 0.3104\n",
      "step 195500 , validation loss : 22.9627\n",
      "step 195600 , training  accuracy 0.5\n",
      "step 195600 , loss : 2.09648\n",
      "step 195600 , validation  accuracy 0.3086\n",
      "step 195600 , validation loss : 22.3353\n",
      "step 195700 , training  accuracy 0.7\n",
      "step 195700 , loss : 2.01069\n",
      "step 195700 , validation  accuracy 0.3186\n",
      "step 195700 , validation loss : 24.3931\n",
      "step 195800 , training  accuracy 0.533333\n",
      "step 195800 , loss : 2.09419\n",
      "step 195800 , validation  accuracy 0.3178\n",
      "step 195800 , validation loss : 23.782\n",
      "step 195900 , training  accuracy 0.7\n",
      "step 195900 , loss : 2.0268\n",
      "step 195900 , validation  accuracy 0.2924\n",
      "step 195900 , validation loss : 22.0193\n",
      "step 196000 , training  accuracy 0.5\n",
      "step 196000 , loss : 2.07988\n",
      "step 196000 , validation  accuracy 0.3028\n",
      "step 196000 , validation loss : 22.2179\n",
      "step 196100 , training  accuracy 0.7\n",
      "step 196100 , loss : 1.96381\n",
      "step 196100 , validation  accuracy 0.3242\n",
      "step 196100 , validation loss : 25.6042\n",
      "step 196200 , training  accuracy 0.6\n",
      "step 196200 , loss : 2.08767\n",
      "step 196200 , validation  accuracy 0.3102\n",
      "step 196200 , validation loss : 22.9318\n",
      "step 196300 , training  accuracy 0.566667\n",
      "step 196300 , loss : 2.10866\n",
      "step 196300 , validation  accuracy 0.3146\n",
      "step 196300 , validation loss : 22.41\n",
      "step 196400 , training  accuracy 0.533333\n",
      "step 196400 , loss : 2.05211\n",
      "step 196400 , validation  accuracy 0.3086\n",
      "step 196400 , validation loss : 21.8641\n",
      "step 196500 , training  accuracy 0.566667\n",
      "step 196500 , loss : 2.08827\n",
      "step 196500 , validation  accuracy 0.3132\n",
      "step 196500 , validation loss : 23.3066\n",
      "step 196600 , training  accuracy 0.366667\n",
      "step 196600 , loss : 2.14445\n",
      "step 196600 , validation  accuracy 0.3076\n",
      "step 196600 , validation loss : 21.7233\n",
      "step 196700 , training  accuracy 0.4\n",
      "step 196700 , loss : 2.10893\n",
      "step 196700 , validation  accuracy 0.3166\n",
      "step 196700 , validation loss : 22.6007\n",
      "step 196800 , training  accuracy 0.533333\n",
      "step 196800 , loss : 2.07167\n",
      "step 196800 , validation  accuracy 0.3116\n",
      "step 196800 , validation loss : 23.5282\n",
      "step 196900 , training  accuracy 0.433333\n",
      "step 196900 , loss : 2.16164\n",
      "step 196900 , validation  accuracy 0.3052\n",
      "step 196900 , validation loss : 21.4179\n",
      "step 197000 , training  accuracy 0.433333\n",
      "step 197000 , loss : 2.08646\n",
      "step 197000 , validation  accuracy 0.3048\n",
      "step 197000 , validation loss : 23.0485\n",
      "step 197100 , training  accuracy 0.6\n",
      "step 197100 , loss : 2.08892\n",
      "step 197100 , validation  accuracy 0.2984\n",
      "step 197100 , validation loss : 21.0455\n",
      "step 197200 , training  accuracy 0.766667\n",
      "step 197200 , loss : 1.98033\n",
      "step 197200 , validation  accuracy 0.3002\n",
      "step 197200 , validation loss : 22.174\n",
      "step 197300 , training  accuracy 0.5\n",
      "step 197300 , loss : 2.08411\n",
      "step 197300 , validation  accuracy 0.3198\n",
      "step 197300 , validation loss : 22.3511\n",
      "step 197400 , training  accuracy 0.566667\n",
      "step 197400 , loss : 2.06833\n",
      "step 197400 , validation  accuracy 0.3202\n",
      "step 197400 , validation loss : 24.579\n",
      "step 197500 , training  accuracy 0.6\n",
      "step 197500 , loss : 2.06577\n",
      "step 197500 , validation  accuracy 0.298\n",
      "step 197500 , validation loss : 21.7877\n",
      "step 197600 , training  accuracy 0.666667\n",
      "step 197600 , loss : 2.0289\n",
      "step 197600 , validation  accuracy 0.311\n",
      "step 197600 , validation loss : 23.3359\n",
      "step 197700 , training  accuracy 0.6\n",
      "step 197700 , loss : 1.99024\n",
      "step 197700 , validation  accuracy 0.3068\n",
      "step 197700 , validation loss : 23.1744\n",
      "step 197800 , training  accuracy 0.6\n",
      "step 197800 , loss : 2.05601\n",
      "step 197800 , validation  accuracy 0.3216\n",
      "step 197800 , validation loss : 23.4471\n",
      "step 197900 , training  accuracy 0.5\n",
      "step 197900 , loss : 2.10596\n",
      "step 197900 , validation  accuracy 0.3198\n",
      "step 197900 , validation loss : 22.2525\n",
      "step 198000 , training  accuracy 0.566667\n",
      "step 198000 , loss : 2.04998\n",
      "step 198000 , validation  accuracy 0.3166\n",
      "step 198000 , validation loss : 22.8051\n",
      "step 198100 , training  accuracy 0.566667\n",
      "step 198100 , loss : 2.07693\n",
      "step 198100 , validation  accuracy 0.298\n",
      "step 198100 , validation loss : 22.9579\n",
      "step 198200 , training  accuracy 0.4\n",
      "step 198200 , loss : 2.10873\n",
      "step 198200 , validation  accuracy 0.3158\n",
      "step 198200 , validation loss : 23.4915\n",
      "step 198300 , training  accuracy 0.533333\n",
      "step 198300 , loss : 2.11294\n",
      "step 198300 , validation  accuracy 0.3024\n",
      "step 198300 , validation loss : 22.1768\n",
      "step 198400 , training  accuracy 0.366667\n",
      "step 198400 , loss : 2.16726\n",
      "step 198400 , validation  accuracy 0.2878\n",
      "step 198400 , validation loss : 22.7097\n",
      "step 198500 , training  accuracy 0.533333\n",
      "step 198500 , loss : 2.09355\n",
      "step 198500 , validation  accuracy 0.2988\n",
      "step 198500 , validation loss : 24.2449\n",
      "step 198600 , training  accuracy 0.6\n",
      "step 198600 , loss : 2.08536\n",
      "step 198600 , validation  accuracy 0.2966\n",
      "step 198600 , validation loss : 22.7834\n",
      "step 198700 , training  accuracy 0.366667\n",
      "step 198700 , loss : 2.17882\n",
      "step 198700 , validation  accuracy 0.313\n",
      "step 198700 , validation loss : 22.6883\n",
      "step 198800 , training  accuracy 0.733333\n",
      "step 198800 , loss : 2.01368\n",
      "step 198800 , validation  accuracy 0.3104\n",
      "step 198800 , validation loss : 22.7541\n",
      "step 198900 , training  accuracy 0.666667\n",
      "step 198900 , loss : 2.00604\n",
      "step 198900 , validation  accuracy 0.3162\n",
      "step 198900 , validation loss : 23.1149\n",
      "step 199000 , training  accuracy 0.466667\n",
      "step 199000 , loss : 2.1193\n",
      "step 199000 , validation  accuracy 0.303\n",
      "step 199000 , validation loss : 23.0317\n",
      "step 199100 , training  accuracy 0.433333\n",
      "step 199100 , loss : 2.19308\n",
      "step 199100 , validation  accuracy 0.2904\n",
      "step 199100 , validation loss : 21.8991\n",
      "step 199200 , training  accuracy 0.433333\n",
      "step 199200 , loss : 2.15725\n",
      "step 199200 , validation  accuracy 0.307\n",
      "step 199200 , validation loss : 22.0134\n",
      "step 199300 , training  accuracy 0.5\n",
      "step 199300 , loss : 2.0348\n",
      "step 199300 , validation  accuracy 0.317\n",
      "step 199300 , validation loss : 22.7247\n",
      "step 199400 , training  accuracy 0.533333\n",
      "step 199400 , loss : 2.06323\n",
      "step 199400 , validation  accuracy 0.324\n",
      "step 199400 , validation loss : 23.8155\n",
      "step 199500 , training  accuracy 0.466667\n",
      "step 199500 , loss : 2.12059\n",
      "step 199500 , validation  accuracy 0.3228\n",
      "step 199500 , validation loss : 24.2559\n",
      "step 199600 , training  accuracy 0.566667\n",
      "step 199600 , loss : 2.10887\n",
      "step 199600 , validation  accuracy 0.3006\n",
      "step 199600 , validation loss : 21.5386\n",
      "step 199700 , training  accuracy 0.6\n",
      "step 199700 , loss : 2.07257\n",
      "step 199700 , validation  accuracy 0.3038\n",
      "step 199700 , validation loss : 21.5229\n",
      "step 199800 , training  accuracy 0.466667\n",
      "step 199800 , loss : 2.12808\n",
      "step 199800 , validation  accuracy 0.308\n",
      "step 199800 , validation loss : 23.221\n",
      "step 199900 , training  accuracy 0.466667\n",
      "step 199900 , loss : 2.13556\n",
      "step 199900 , validation  accuracy 0.282\n",
      "step 199900 , validation loss : 21.9772\n",
      "step 200000 , training  accuracy 0.566667\n",
      "step 200000 , loss : 2.07652\n",
      "step 200000 , validation  accuracy 0.3086\n",
      "step 200000 , validation loss : 24.4213\n",
      "step 200100 , training  accuracy 0.566667\n",
      "step 200100 , loss : 2.03922\n",
      "step 200100 , validation  accuracy 0.305\n",
      "step 200100 , validation loss : 23.8001\n",
      "step 200200 , training  accuracy 0.466667\n",
      "step 200200 , loss : 2.12316\n",
      "step 200200 , validation  accuracy 0.3174\n",
      "step 200200 , validation loss : 23.2679\n",
      "step 200300 , training  accuracy 0.633333\n",
      "step 200300 , loss : 2.04815\n",
      "step 200300 , validation  accuracy 0.3054\n",
      "step 200300 , validation loss : 23.1027\n",
      "step 200400 , training  accuracy 0.466667\n",
      "step 200400 , loss : 2.11594\n",
      "step 200400 , validation  accuracy 0.3138\n",
      "step 200400 , validation loss : 22.1695\n",
      "step 200500 , training  accuracy 0.733333\n",
      "step 200500 , loss : 2.02675\n",
      "step 200500 , validation  accuracy 0.3132\n",
      "step 200500 , validation loss : 23.9633\n",
      "step 200600 , training  accuracy 0.5\n",
      "step 200600 , loss : 2.10463\n",
      "step 200600 , validation  accuracy 0.3146\n",
      "step 200600 , validation loss : 22.6672\n",
      "step 200700 , training  accuracy 0.566667\n",
      "step 200700 , loss : 2.07139\n",
      "step 200700 , validation  accuracy 0.3168\n",
      "step 200700 , validation loss : 23.2267\n",
      "step 200800 , training  accuracy 0.633333\n",
      "step 200800 , loss : 2.19747\n",
      "step 200800 , validation  accuracy 0.3038\n",
      "step 200800 , validation loss : 23.2885\n",
      "step 200900 , training  accuracy 0.366667\n",
      "step 200900 , loss : 2.21462\n",
      "step 200900 , validation  accuracy 0.3166\n",
      "step 200900 , validation loss : 23.308\n",
      "step 201000 , training  accuracy 0.5\n",
      "step 201000 , loss : 2.09891\n",
      "step 201000 , validation  accuracy 0.2918\n",
      "step 201000 , validation loss : 22.164\n",
      "step 201100 , training  accuracy 0.533333\n",
      "step 201100 , loss : 2.1074\n",
      "step 201100 , validation  accuracy 0.306\n",
      "step 201100 , validation loss : 22.9528\n",
      "step 201200 , training  accuracy 0.333333\n",
      "step 201200 , loss : 2.18779\n",
      "step 201200 , validation  accuracy 0.2884\n",
      "step 201200 , validation loss : 20.5405\n",
      "step 201300 , training  accuracy 0.533333\n",
      "step 201300 , loss : 2.03879\n",
      "step 201300 , validation  accuracy 0.3148\n",
      "step 201300 , validation loss : 23.298\n",
      "step 201400 , training  accuracy 0.733333\n",
      "step 201400 , loss : 1.96061\n",
      "step 201400 , validation  accuracy 0.3178\n",
      "step 201400 , validation loss : 23.7066\n",
      "step 201500 , training  accuracy 0.566667\n",
      "step 201500 , loss : 2.07502\n",
      "step 201500 , validation  accuracy 0.3166\n",
      "step 201500 , validation loss : 23.4827\n",
      "step 201600 , training  accuracy 0.5\n",
      "step 201600 , loss : 2.14216\n",
      "step 201600 , validation  accuracy 0.2926\n",
      "step 201600 , validation loss : 21.7422\n",
      "step 201700 , training  accuracy 0.533333\n",
      "step 201700 , loss : 2.1501\n",
      "step 201700 , validation  accuracy 0.3038\n",
      "step 201700 , validation loss : 21.4413\n",
      "step 201800 , training  accuracy 0.5\n",
      "step 201800 , loss : 2.07142\n",
      "step 201800 , validation  accuracy 0.3124\n",
      "step 201800 , validation loss : 23.684\n",
      "step 201900 , training  accuracy 0.433333\n",
      "step 201900 , loss : 2.15032\n",
      "step 201900 , validation  accuracy 0.32\n",
      "step 201900 , validation loss : 23.8917\n",
      "step 202000 , training  accuracy 0.4\n",
      "step 202000 , loss : 2.14913\n",
      "step 202000 , validation  accuracy 0.3114\n",
      "step 202000 , validation loss : 23.3828\n",
      "step 202100 , training  accuracy 0.4\n",
      "step 202100 , loss : 2.1758\n",
      "step 202100 , validation  accuracy 0.2826\n",
      "step 202100 , validation loss : 21.3082\n",
      "step 202200 , training  accuracy 0.566667\n",
      "step 202200 , loss : 2.05305\n",
      "step 202200 , validation  accuracy 0.3128\n",
      "step 202200 , validation loss : 23.003\n",
      "step 202300 , training  accuracy 0.466667\n",
      "step 202300 , loss : 2.12901\n",
      "step 202300 , validation  accuracy 0.3094\n",
      "step 202300 , validation loss : 23.0315\n",
      "step 202400 , training  accuracy 0.5\n",
      "step 202400 , loss : 2.07769\n",
      "step 202400 , validation  accuracy 0.3182\n",
      "step 202400 , validation loss : 23.9649\n",
      "step 202500 , training  accuracy 0.7\n",
      "step 202500 , loss : 2.05666\n",
      "step 202500 , validation  accuracy 0.2984\n",
      "step 202500 , validation loss : 22.8973\n",
      "step 202600 , training  accuracy 0.466667\n",
      "step 202600 , loss : 2.1103\n",
      "step 202600 , validation  accuracy 0.3214\n",
      "step 202600 , validation loss : 23.226\n",
      "step 202700 , training  accuracy 0.533333\n",
      "step 202700 , loss : 2.11301\n",
      "step 202700 , validation  accuracy 0.3112\n",
      "step 202700 , validation loss : 23.199\n",
      "step 202800 , training  accuracy 0.633333\n",
      "step 202800 , loss : 2.05274\n",
      "step 202800 , validation  accuracy 0.3038\n",
      "step 202800 , validation loss : 22.683\n",
      "step 202900 , training  accuracy 0.433333\n",
      "step 202900 , loss : 2.13755\n",
      "step 202900 , validation  accuracy 0.3034\n",
      "step 202900 , validation loss : 21.3571\n",
      "step 203000 , training  accuracy 0.5\n",
      "step 203000 , loss : 2.08563\n",
      "step 203000 , validation  accuracy 0.3088\n",
      "step 203000 , validation loss : 21.1892\n",
      "step 203100 , training  accuracy 0.333333\n",
      "step 203100 , loss : 2.19212\n",
      "step 203100 , validation  accuracy 0.2932\n",
      "step 203100 , validation loss : 21.8228\n",
      "step 203200 , training  accuracy 0.5\n",
      "step 203200 , loss : 2.09786\n",
      "step 203200 , validation  accuracy 0.3146\n",
      "step 203200 , validation loss : 22.7684\n",
      "step 203300 , training  accuracy 0.4\n",
      "step 203300 , loss : 2.1431\n",
      "step 203300 , validation  accuracy 0.3076\n",
      "step 203300 , validation loss : 22.4898\n",
      "step 203400 , training  accuracy 0.333333\n",
      "step 203400 , loss : 2.17885\n",
      "step 203400 , validation  accuracy 0.307\n",
      "step 203400 , validation loss : 22.2653\n",
      "step 203500 , training  accuracy 0.566667\n",
      "step 203500 , loss : 2.0888\n",
      "step 203500 , validation  accuracy 0.3168\n",
      "step 203500 , validation loss : 23.6861\n",
      "step 203600 , training  accuracy 0.5\n",
      "step 203600 , loss : 2.10763\n",
      "step 203600 , validation  accuracy 0.2972\n",
      "step 203600 , validation loss : 22.4663\n",
      "step 203700 , training  accuracy 0.6\n",
      "step 203700 , loss : 2.06823\n",
      "step 203700 , validation  accuracy 0.3228\n",
      "step 203700 , validation loss : 23.2003\n",
      "step 203800 , training  accuracy 0.6\n",
      "step 203800 , loss : 2.03715\n",
      "step 203800 , validation  accuracy 0.32\n",
      "step 203800 , validation loss : 22.6987\n",
      "step 203900 , training  accuracy 0.566667\n",
      "step 203900 , loss : 2.05903\n",
      "step 203900 , validation  accuracy 0.3106\n",
      "step 203900 , validation loss : 22.7875\n",
      "step 204000 , training  accuracy 0.566667\n",
      "step 204000 , loss : 2.07208\n",
      "step 204000 , validation  accuracy 0.3044\n",
      "step 204000 , validation loss : 23.1846\n",
      "step 204100 , training  accuracy 0.666667\n",
      "step 204100 , loss : 1.99745\n",
      "step 204100 , validation  accuracy 0.3098\n",
      "step 204100 , validation loss : 22.8934\n",
      "step 204200 , training  accuracy 0.466667\n",
      "step 204200 , loss : 2.09233\n",
      "step 204200 , validation  accuracy 0.3156\n",
      "step 204200 , validation loss : 23.5604\n",
      "step 204300 , training  accuracy 0.433333\n",
      "step 204300 , loss : 2.16625\n",
      "step 204300 , validation  accuracy 0.3094\n",
      "step 204300 , validation loss : 22.0419\n",
      "step 204400 , training  accuracy 0.533333\n",
      "step 204400 , loss : 2.14441\n",
      "step 204400 , validation  accuracy 0.3128\n",
      "step 204400 , validation loss : 23.6653\n",
      "step 204500 , training  accuracy 0.6\n",
      "step 204500 , loss : 2.11703\n",
      "step 204500 , validation  accuracy 0.3122\n",
      "step 204500 , validation loss : 23.9396\n",
      "step 204600 , training  accuracy 0.466667\n",
      "step 204600 , loss : 2.12633\n",
      "step 204600 , validation  accuracy 0.2982\n",
      "step 204600 , validation loss : 21.9751\n",
      "step 204700 , training  accuracy 0.5\n",
      "step 204700 , loss : 2.04058\n",
      "step 204700 , validation  accuracy 0.3078\n",
      "step 204700 , validation loss : 23.5123\n",
      "step 204800 , training  accuracy 0.7\n",
      "step 204800 , loss : 2.02111\n",
      "step 204800 , validation  accuracy 0.3092\n",
      "step 204800 , validation loss : 22.6555\n",
      "step 204900 , training  accuracy 0.533333\n",
      "step 204900 , loss : 2.03626\n",
      "step 204900 , validation  accuracy 0.3134\n",
      "step 204900 , validation loss : 22.2851\n",
      "step 205000 , training  accuracy 0.533333\n",
      "step 205000 , loss : 2.06868\n",
      "step 205000 , validation  accuracy 0.3024\n",
      "step 205000 , validation loss : 22.2102\n",
      "step 205100 , training  accuracy 0.566667\n",
      "step 205100 , loss : 2.06629\n",
      "step 205100 , validation  accuracy 0.3152\n",
      "step 205100 , validation loss : 23.8913\n",
      "step 205200 , training  accuracy 0.6\n",
      "step 205200 , loss : 2.05042\n",
      "step 205200 , validation  accuracy 0.3158\n",
      "step 205200 , validation loss : 23.0466\n",
      "step 205300 , training  accuracy 0.633333\n",
      "step 205300 , loss : 2.07048\n",
      "step 205300 , validation  accuracy 0.3146\n",
      "step 205300 , validation loss : 22.8346\n",
      "step 205400 , training  accuracy 0.433333\n",
      "step 205400 , loss : 2.14072\n",
      "step 205400 , validation  accuracy 0.3122\n",
      "step 205400 , validation loss : 23.5007\n",
      "step 205500 , training  accuracy 0.533333\n",
      "step 205500 , loss : 2.08714\n",
      "step 205500 , validation  accuracy 0.3168\n",
      "step 205500 , validation loss : 22.5696\n",
      "step 205600 , training  accuracy 0.533333\n",
      "step 205600 , loss : 2.07654\n",
      "step 205600 , validation  accuracy 0.3162\n",
      "step 205600 , validation loss : 23.076\n",
      "step 205700 , training  accuracy 0.566667\n",
      "step 205700 , loss : 2.07746\n",
      "step 205700 , validation  accuracy 0.318\n",
      "step 205700 , validation loss : 23.9207\n",
      "step 205800 , training  accuracy 0.666667\n",
      "step 205800 , loss : 2.10972\n",
      "step 205800 , validation  accuracy 0.2962\n",
      "step 205800 , validation loss : 20.9187\n",
      "step 205900 , training  accuracy 0.566667\n",
      "step 205900 , loss : 2.05382\n",
      "step 205900 , validation  accuracy 0.3176\n",
      "step 205900 , validation loss : 23.5667\n",
      "step 206000 , training  accuracy 0.533333\n",
      "step 206000 , loss : 2.0904\n",
      "step 206000 , validation  accuracy 0.308\n",
      "step 206000 , validation loss : 23.1205\n",
      "step 206100 , training  accuracy 0.6\n",
      "step 206100 , loss : 2.07601\n",
      "step 206100 , validation  accuracy 0.307\n",
      "step 206100 , validation loss : 23.1812\n",
      "step 206200 , training  accuracy 0.566667\n",
      "step 206200 , loss : 2.14421\n",
      "step 206200 , validation  accuracy 0.314\n",
      "step 206200 , validation loss : 24.4503\n",
      "step 206300 , training  accuracy 0.6\n",
      "step 206300 , loss : 2.02188\n",
      "step 206300 , validation  accuracy 0.3076\n",
      "step 206300 , validation loss : 22.8631\n",
      "step 206400 , training  accuracy 0.633333\n",
      "step 206400 , loss : 2.00676\n",
      "step 206400 , validation  accuracy 0.297\n",
      "step 206400 , validation loss : 21.7841\n",
      "step 206500 , training  accuracy 0.5\n",
      "step 206500 , loss : 2.08857\n",
      "step 206500 , validation  accuracy 0.2982\n",
      "step 206500 , validation loss : 22.6855\n",
      "step 206600 , training  accuracy 0.566667\n",
      "step 206600 , loss : 2.0689\n",
      "step 206600 , validation  accuracy 0.3246\n",
      "step 206600 , validation loss : 25.5679\n",
      "step 206700 , training  accuracy 0.5\n",
      "step 206700 , loss : 2.06716\n",
      "step 206700 , validation  accuracy 0.3164\n",
      "step 206700 , validation loss : 22.8838\n",
      "step 206800 , training  accuracy 0.666667\n",
      "step 206800 , loss : 2.01566\n",
      "step 206800 , validation  accuracy 0.3232\n",
      "step 206800 , validation loss : 24.4771\n",
      "step 206900 , training  accuracy 0.5\n",
      "step 206900 , loss : 2.13047\n",
      "step 206900 , validation  accuracy 0.3052\n",
      "step 206900 , validation loss : 22.9697\n",
      "step 207000 , training  accuracy 0.466667\n",
      "step 207000 , loss : 2.13867\n",
      "step 207000 , validation  accuracy 0.294\n",
      "step 207000 , validation loss : 22.6054\n",
      "step 207100 , training  accuracy 0.466667\n",
      "step 207100 , loss : 2.10571\n",
      "step 207100 , validation  accuracy 0.3148\n",
      "step 207100 , validation loss : 24.9054\n",
      "step 207200 , training  accuracy 0.5\n",
      "step 207200 , loss : 2.185\n",
      "step 207200 , validation  accuracy 0.2962\n",
      "step 207200 , validation loss : 22.1628\n",
      "step 207300 , training  accuracy 0.533333\n",
      "step 207300 , loss : 2.11426\n",
      "step 207300 , validation  accuracy 0.3222\n",
      "step 207300 , validation loss : 23.513\n",
      "step 207400 , training  accuracy 0.433333\n",
      "step 207400 , loss : 2.16548\n",
      "step 207400 , validation  accuracy 0.3024\n",
      "step 207400 , validation loss : 21.4682\n",
      "step 207500 , training  accuracy 0.633333\n",
      "step 207500 , loss : 2.02658\n",
      "step 207500 , validation  accuracy 0.3158\n",
      "step 207500 , validation loss : 22.9369\n",
      "step 207600 , training  accuracy 0.466667\n",
      "step 207600 , loss : 2.09511\n",
      "step 207600 , validation  accuracy 0.3054\n",
      "step 207600 , validation loss : 24.2664\n",
      "step 207700 , training  accuracy 0.433333\n",
      "step 207700 , loss : 2.1009\n",
      "step 207700 , validation  accuracy 0.3232\n",
      "step 207700 , validation loss : 24.9474\n",
      "step 207800 , training  accuracy 0.5\n",
      "step 207800 , loss : 2.11273\n",
      "step 207800 , validation  accuracy 0.3192\n",
      "step 207800 , validation loss : 24.1144\n",
      "step 207900 , training  accuracy 0.433333\n",
      "step 207900 , loss : 2.16044\n",
      "step 207900 , validation  accuracy 0.3014\n",
      "step 207900 , validation loss : 22.8252\n",
      "step 208000 , training  accuracy 0.633333\n",
      "step 208000 , loss : 2.1011\n",
      "step 208000 , validation  accuracy 0.3006\n",
      "step 208000 , validation loss : 23.073\n",
      "step 208100 , training  accuracy 0.633333\n",
      "step 208100 , loss : 2.00631\n",
      "step 208100 , validation  accuracy 0.3076\n",
      "step 208100 , validation loss : 22.9701\n",
      "step 208200 , training  accuracy 0.533333\n",
      "step 208200 , loss : 2.01582\n",
      "step 208200 , validation  accuracy 0.303\n",
      "step 208200 , validation loss : 22.6726\n",
      "step 208300 , training  accuracy 0.533333\n",
      "step 208300 , loss : 2.06924\n",
      "step 208300 , validation  accuracy 0.293\n",
      "step 208300 , validation loss : 22.7941\n",
      "step 208400 , training  accuracy 0.5\n",
      "step 208400 , loss : 2.05209\n",
      "step 208400 , validation  accuracy 0.316\n",
      "step 208400 , validation loss : 23.2663\n",
      "step 208500 , training  accuracy 0.466667\n",
      "step 208500 , loss : 2.12728\n",
      "step 208500 , validation  accuracy 0.3036\n",
      "step 208500 , validation loss : 23.4544\n",
      "step 208600 , training  accuracy 0.566667\n",
      "step 208600 , loss : 2.06507\n",
      "step 208600 , validation  accuracy 0.3082\n",
      "step 208600 , validation loss : 23.5859\n",
      "step 208700 , training  accuracy 0.733333\n",
      "step 208700 , loss : 1.98542\n",
      "step 208700 , validation  accuracy 0.319\n",
      "step 208700 , validation loss : 24.3246\n",
      "step 208800 , training  accuracy 0.6\n",
      "step 208800 , loss : 2.0807\n",
      "step 208800 , validation  accuracy 0.305\n",
      "step 208800 , validation loss : 22.105\n",
      "step 208900 , training  accuracy 0.466667\n",
      "step 208900 , loss : 2.11396\n",
      "step 208900 , validation  accuracy 0.2928\n",
      "step 208900 , validation loss : 21.6975\n",
      "step 209000 , training  accuracy 0.5\n",
      "step 209000 , loss : 2.08466\n",
      "step 209000 , validation  accuracy 0.31\n",
      "step 209000 , validation loss : 23.0854\n",
      "step 209100 , training  accuracy 0.533333\n",
      "step 209100 , loss : 2.13114\n",
      "step 209100 , validation  accuracy 0.3048\n",
      "step 209100 , validation loss : 23.882\n",
      "step 209200 , training  accuracy 0.433333\n",
      "step 209200 , loss : 2.09453\n",
      "step 209200 , validation  accuracy 0.3054\n",
      "step 209200 , validation loss : 23.8625\n",
      "step 209300 , training  accuracy 0.433333\n",
      "step 209300 , loss : 2.13554\n",
      "step 209300 , validation  accuracy 0.3076\n",
      "step 209300 , validation loss : 23.8063\n",
      "step 209400 , training  accuracy 0.7\n",
      "step 209400 , loss : 2.0613\n",
      "step 209400 , validation  accuracy 0.3026\n",
      "step 209400 , validation loss : 22.107\n",
      "step 209500 , training  accuracy 0.5\n",
      "step 209500 , loss : 2.0957\n",
      "step 209500 , validation  accuracy 0.3078\n",
      "step 209500 , validation loss : 23.1765\n",
      "step 209600 , training  accuracy 0.5\n",
      "step 209600 , loss : 2.12199\n",
      "step 209600 , validation  accuracy 0.3048\n",
      "step 209600 , validation loss : 23.0511\n",
      "step 209700 , training  accuracy 0.6\n",
      "step 209700 , loss : 2.11778\n",
      "step 209700 , validation  accuracy 0.296\n",
      "step 209700 , validation loss : 22.6479\n",
      "step 209800 , training  accuracy 0.566667\n",
      "step 209800 , loss : 2.02975\n",
      "step 209800 , validation  accuracy 0.3178\n",
      "step 209800 , validation loss : 23.6681\n",
      "step 209900 , training  accuracy 0.566667\n",
      "step 209900 , loss : 2.06655\n",
      "step 209900 , validation  accuracy 0.3026\n",
      "step 209900 , validation loss : 22.4658\n",
      "step 210000 , training  accuracy 0.533333\n",
      "step 210000 , loss : 2.06497\n",
      "step 210000 , validation  accuracy 0.2994\n",
      "step 210000 , validation loss : 23.2458\n",
      "step 210100 , training  accuracy 0.566667\n",
      "step 210100 , loss : 2.07569\n",
      "step 210100 , validation  accuracy 0.2878\n",
      "step 210100 , validation loss : 20.4716\n",
      "step 210200 , training  accuracy 0.566667\n",
      "step 210200 , loss : 2.04722\n",
      "step 210200 , validation  accuracy 0.299\n",
      "step 210200 , validation loss : 23.3647\n",
      "step 210300 , training  accuracy 0.4\n",
      "step 210300 , loss : 2.11939\n",
      "step 210300 , validation  accuracy 0.3092\n",
      "step 210300 , validation loss : 23.2555\n",
      "step 210400 , training  accuracy 0.533333\n",
      "step 210400 , loss : 2.10037\n",
      "step 210400 , validation  accuracy 0.3108\n",
      "step 210400 , validation loss : 22.2793\n",
      "step 210500 , training  accuracy 0.5\n",
      "step 210500 , loss : 2.12001\n",
      "step 210500 , validation  accuracy 0.3002\n",
      "step 210500 , validation loss : 23.5684\n",
      "step 210600 , training  accuracy 0.633333\n",
      "step 210600 , loss : 2.03267\n",
      "step 210600 , validation  accuracy 0.3076\n",
      "step 210600 , validation loss : 23.1531\n",
      "step 210700 , training  accuracy 0.466667\n",
      "step 210700 , loss : 2.10683\n",
      "step 210700 , validation  accuracy 0.2996\n",
      "step 210700 , validation loss : 23.5157\n",
      "step 210800 , training  accuracy 0.433333\n",
      "step 210800 , loss : 2.14102\n",
      "step 210800 , validation  accuracy 0.2878\n",
      "step 210800 , validation loss : 21.6152\n",
      "step 210900 , training  accuracy 0.633333\n",
      "step 210900 , loss : 2.00333\n",
      "step 210900 , validation  accuracy 0.3086\n",
      "step 210900 , validation loss : 22.6923\n",
      "step 211000 , training  accuracy 0.533333\n",
      "step 211000 , loss : 2.09025\n",
      "step 211000 , validation  accuracy 0.3056\n",
      "step 211000 , validation loss : 23.0485\n",
      "step 211100 , training  accuracy 0.5\n",
      "step 211100 , loss : 2.11104\n",
      "step 211100 , validation  accuracy 0.3026\n",
      "step 211100 , validation loss : 22.1429\n",
      "step 211200 , training  accuracy 0.633333\n",
      "step 211200 , loss : 2.06282\n",
      "step 211200 , validation  accuracy 0.3152\n",
      "step 211200 , validation loss : 23.8846\n",
      "step 211300 , training  accuracy 0.566667\n",
      "step 211300 , loss : 2.03285\n",
      "step 211300 , validation  accuracy 0.3282\n",
      "step 211300 , validation loss : 26.0967\n",
      "step 211400 , training  accuracy 0.5\n",
      "step 211400 , loss : 2.12624\n",
      "step 211400 , validation  accuracy 0.3074\n",
      "step 211400 , validation loss : 23.6637\n",
      "step 211500 , training  accuracy 0.433333\n",
      "step 211500 , loss : 2.11344\n",
      "step 211500 , validation  accuracy 0.3202\n",
      "step 211500 , validation loss : 24.2864\n",
      "step 211600 , training  accuracy 0.566667\n",
      "step 211600 , loss : 2.10112\n",
      "step 211600 , validation  accuracy 0.3084\n",
      "step 211600 , validation loss : 22.2362\n",
      "step 211700 , training  accuracy 0.433333\n",
      "step 211700 , loss : 2.09626\n",
      "step 211700 , validation  accuracy 0.324\n",
      "step 211700 , validation loss : 25.029\n",
      "step 211800 , training  accuracy 0.5\n",
      "step 211800 , loss : 2.1767\n",
      "step 211800 , validation  accuracy 0.308\n",
      "step 211800 , validation loss : 22.7733\n",
      "step 211900 , training  accuracy 0.733333\n",
      "step 211900 , loss : 2.03369\n",
      "step 211900 , validation  accuracy 0.3146\n",
      "step 211900 , validation loss : 23.8626\n",
      "step 212000 , training  accuracy 0.433333\n",
      "step 212000 , loss : 2.14314\n",
      "step 212000 , validation  accuracy 0.2934\n",
      "step 212000 , validation loss : 24.3875\n",
      "step 212100 , training  accuracy 0.6\n",
      "step 212100 , loss : 2.0665\n",
      "step 212100 , validation  accuracy 0.3192\n",
      "step 212100 , validation loss : 25.0136\n",
      "step 212200 , training  accuracy 0.566667\n",
      "step 212200 , loss : 2.11524\n",
      "step 212200 , validation  accuracy 0.3094\n",
      "step 212200 , validation loss : 22.6155\n",
      "step 212300 , training  accuracy 0.5\n",
      "step 212300 , loss : 2.08562\n",
      "step 212300 , validation  accuracy 0.3022\n",
      "step 212300 , validation loss : 22.8524\n",
      "step 212400 , training  accuracy 0.6\n",
      "step 212400 , loss : 2.02341\n",
      "step 212400 , validation  accuracy 0.3\n",
      "step 212400 , validation loss : 22.8652\n",
      "step 212500 , training  accuracy 0.6\n",
      "step 212500 , loss : 2.09183\n",
      "step 212500 , validation  accuracy 0.3056\n",
      "step 212500 , validation loss : 23.6345\n",
      "step 212600 , training  accuracy 0.533333\n",
      "step 212600 , loss : 2.05563\n",
      "step 212600 , validation  accuracy 0.3118\n",
      "step 212600 , validation loss : 23.8382\n",
      "step 212700 , training  accuracy 0.5\n",
      "step 212700 , loss : 2.06599\n",
      "step 212700 , validation  accuracy 0.3222\n",
      "step 212700 , validation loss : 25.0098\n",
      "step 212800 , training  accuracy 0.5\n",
      "step 212800 , loss : 2.07058\n",
      "step 212800 , validation  accuracy 0.3236\n",
      "step 212800 , validation loss : 25.0945\n",
      "step 212900 , training  accuracy 0.566667\n",
      "step 212900 , loss : 2.12432\n",
      "step 212900 , validation  accuracy 0.3152\n",
      "step 212900 , validation loss : 24.1873\n",
      "step 213000 , training  accuracy 0.4\n",
      "step 213000 , loss : 2.13654\n",
      "step 213000 , validation  accuracy 0.3206\n",
      "step 213000 , validation loss : 23.6971\n",
      "step 213100 , training  accuracy 0.466667\n",
      "step 213100 , loss : 2.10222\n",
      "step 213100 , validation  accuracy 0.3028\n",
      "step 213100 , validation loss : 21.9607\n",
      "step 213200 , training  accuracy 0.5\n",
      "step 213200 , loss : 2.09806\n",
      "step 213200 , validation  accuracy 0.3006\n",
      "step 213200 , validation loss : 22.3606\n",
      "step 213300 , training  accuracy 0.4\n",
      "step 213300 , loss : 2.16598\n",
      "step 213300 , validation  accuracy 0.2932\n",
      "step 213300 , validation loss : 21.9951\n",
      "step 213400 , training  accuracy 0.566667\n",
      "step 213400 , loss : 2.11868\n",
      "step 213400 , validation  accuracy 0.2962\n",
      "step 213400 , validation loss : 21.6704\n",
      "step 213500 , training  accuracy 0.566667\n",
      "step 213500 , loss : 2.05973\n",
      "step 213500 , validation  accuracy 0.2986\n",
      "step 213500 , validation loss : 23.2644\n",
      "step 213600 , training  accuracy 0.566667\n",
      "step 213600 , loss : 2.09269\n",
      "step 213600 , validation  accuracy 0.3136\n",
      "step 213600 , validation loss : 25.3128\n",
      "step 213700 , training  accuracy 0.533333\n",
      "step 213700 , loss : 2.09702\n",
      "step 213700 , validation  accuracy 0.3098\n",
      "step 213700 , validation loss : 24.7602\n",
      "step 213800 , training  accuracy 0.3\n",
      "step 213800 , loss : 2.18099\n",
      "step 213800 , validation  accuracy 0.309\n",
      "step 213800 , validation loss : 24.7844\n",
      "step 213900 , training  accuracy 0.566667\n",
      "step 213900 , loss : 2.03341\n",
      "step 213900 , validation  accuracy 0.3158\n",
      "step 213900 , validation loss : 23.0389\n",
      "step 214000 , training  accuracy 0.333333\n",
      "step 214000 , loss : 2.12804\n",
      "step 214000 , validation  accuracy 0.3056\n",
      "step 214000 , validation loss : 24.5389\n",
      "step 214100 , training  accuracy 0.433333\n",
      "step 214100 , loss : 2.08483\n",
      "step 214100 , validation  accuracy 0.2924\n",
      "step 214100 , validation loss : 23.3612\n",
      "step 214200 , training  accuracy 0.533333\n",
      "step 214200 , loss : 2.06818\n",
      "step 214200 , validation  accuracy 0.3172\n",
      "step 214200 , validation loss : 24.2063\n",
      "step 214300 , training  accuracy 0.4\n",
      "step 214300 , loss : 2.21211\n",
      "step 214300 , validation  accuracy 0.3032\n",
      "step 214300 , validation loss : 21.7261\n",
      "step 214400 , training  accuracy 0.566667\n",
      "step 214400 , loss : 2.06273\n",
      "step 214400 , validation  accuracy 0.294\n",
      "step 214400 , validation loss : 21.752\n",
      "step 214500 , training  accuracy 0.566667\n",
      "step 214500 , loss : 2.00208\n",
      "step 214500 , validation  accuracy 0.3224\n",
      "step 214500 , validation loss : 23.4418\n",
      "step 214600 , training  accuracy 0.633333\n",
      "step 214600 , loss : 2.05403\n",
      "step 214600 , validation  accuracy 0.3052\n",
      "step 214600 , validation loss : 21.7775\n",
      "step 214700 , training  accuracy 0.566667\n",
      "step 214700 , loss : 2.10049\n",
      "step 214700 , validation  accuracy 0.3114\n",
      "step 214700 , validation loss : 22.8002\n",
      "step 214800 , training  accuracy 0.766667\n",
      "step 214800 , loss : 2.01258\n",
      "step 214800 , validation  accuracy 0.3194\n",
      "step 214800 , validation loss : 24.207\n",
      "step 214900 , training  accuracy 0.5\n",
      "step 214900 , loss : 2.13353\n",
      "step 214900 , validation  accuracy 0.31\n",
      "step 214900 , validation loss : 23.359\n",
      "step 215000 , training  accuracy 0.533333\n",
      "step 215000 , loss : 2.11045\n",
      "step 215000 , validation  accuracy 0.2898\n",
      "step 215000 , validation loss : 22.8276\n",
      "step 215100 , training  accuracy 0.633333\n",
      "step 215100 , loss : 2.07163\n",
      "step 215100 , validation  accuracy 0.3078\n",
      "step 215100 , validation loss : 22.7231\n",
      "step 215200 , training  accuracy 0.533333\n",
      "step 215200 , loss : 2.10745\n",
      "step 215200 , validation  accuracy 0.3202\n",
      "step 215200 , validation loss : 24.8468\n",
      "step 215300 , training  accuracy 0.6\n",
      "step 215300 , loss : 2.04859\n",
      "step 215300 , validation  accuracy 0.3126\n",
      "step 215300 , validation loss : 22.9614\n",
      "step 215400 , training  accuracy 0.666667\n",
      "step 215400 , loss : 2.08196\n",
      "step 215400 , validation  accuracy 0.312\n",
      "step 215400 , validation loss : 22.9445\n",
      "step 215500 , training  accuracy 0.5\n",
      "step 215500 , loss : 2.11224\n",
      "step 215500 , validation  accuracy 0.3026\n",
      "step 215500 , validation loss : 24.0686\n",
      "step 215600 , training  accuracy 0.533333\n",
      "step 215600 , loss : 2.07655\n",
      "step 215600 , validation  accuracy 0.309\n",
      "step 215600 , validation loss : 23.2463\n",
      "step 215700 , training  accuracy 0.533333\n",
      "step 215700 , loss : 2.07814\n",
      "step 215700 , validation  accuracy 0.299\n",
      "step 215700 , validation loss : 23.2433\n",
      "step 215800 , training  accuracy 0.533333\n",
      "step 215800 , loss : 2.06099\n",
      "step 215800 , validation  accuracy 0.294\n",
      "step 215800 , validation loss : 24.0199\n",
      "step 215900 , training  accuracy 0.5\n",
      "step 215900 , loss : 2.11301\n",
      "step 215900 , validation  accuracy 0.3034\n",
      "step 215900 , validation loss : 22.6539\n",
      "step 216000 , training  accuracy 0.366667\n",
      "step 216000 , loss : 2.15277\n",
      "step 216000 , validation  accuracy 0.3\n",
      "step 216000 , validation loss : 24.5572\n",
      "step 216100 , training  accuracy 0.533333\n",
      "step 216100 , loss : 2.14462\n",
      "step 216100 , validation  accuracy 0.2988\n",
      "step 216100 , validation loss : 22.9023\n",
      "step 216200 , training  accuracy 0.533333\n",
      "step 216200 , loss : 2.04396\n",
      "step 216200 , validation  accuracy 0.3048\n",
      "step 216200 , validation loss : 23.8761\n",
      "step 216300 , training  accuracy 0.4\n",
      "step 216300 , loss : 2.15745\n",
      "step 216300 , validation  accuracy 0.2992\n",
      "step 216300 , validation loss : 21.6901\n",
      "step 216400 , training  accuracy 0.533333\n",
      "step 216400 , loss : 2.07293\n",
      "step 216400 , validation  accuracy 0.3162\n",
      "step 216400 , validation loss : 23.8833\n",
      "step 216500 , training  accuracy 0.633333\n",
      "step 216500 , loss : 2.05596\n",
      "step 216500 , validation  accuracy 0.3042\n",
      "step 216500 , validation loss : 22.9087\n",
      "step 216600 , training  accuracy 0.633333\n",
      "step 216600 , loss : 2.05577\n",
      "step 216600 , validation  accuracy 0.303\n",
      "step 216600 , validation loss : 23.8106\n",
      "step 216700 , training  accuracy 0.533333\n",
      "step 216700 , loss : 2.057\n",
      "step 216700 , validation  accuracy 0.3044\n",
      "step 216700 , validation loss : 22.7229\n",
      "step 216800 , training  accuracy 0.6\n",
      "step 216800 , loss : 2.09627\n",
      "step 216800 , validation  accuracy 0.31\n",
      "step 216800 , validation loss : 23.8719\n",
      "step 216900 , training  accuracy 0.566667\n",
      "step 216900 , loss : 2.04757\n",
      "step 216900 , validation  accuracy 0.3004\n",
      "step 216900 , validation loss : 23.4886\n",
      "step 217000 , training  accuracy 0.733333\n",
      "step 217000 , loss : 2.01883\n",
      "step 217000 , validation  accuracy 0.2862\n",
      "step 217000 , validation loss : 22.5785\n",
      "step 217100 , training  accuracy 0.366667\n",
      "step 217100 , loss : 2.18427\n",
      "step 217100 , validation  accuracy 0.2946\n",
      "step 217100 , validation loss : 24.7778\n",
      "step 217200 , training  accuracy 0.4\n",
      "step 217200 , loss : 2.13423\n",
      "step 217200 , validation  accuracy 0.3026\n",
      "step 217200 , validation loss : 24.5218\n",
      "step 217300 , training  accuracy 0.466667\n",
      "step 217300 , loss : 2.10921\n",
      "step 217300 , validation  accuracy 0.3076\n",
      "step 217300 , validation loss : 23.1598\n",
      "step 217400 , training  accuracy 0.566667\n",
      "step 217400 , loss : 2.07548\n",
      "step 217400 , validation  accuracy 0.3126\n",
      "step 217400 , validation loss : 23.3213\n",
      "step 217500 , training  accuracy 0.666667\n",
      "step 217500 , loss : 1.99831\n",
      "step 217500 , validation  accuracy 0.31\n",
      "step 217500 , validation loss : 23.6895\n",
      "step 217600 , training  accuracy 0.666667\n",
      "step 217600 , loss : 1.99998\n",
      "step 217600 , validation  accuracy 0.3076\n",
      "step 217600 , validation loss : 24.0622\n",
      "step 217700 , training  accuracy 0.5\n",
      "step 217700 , loss : 2.157\n",
      "step 217700 , validation  accuracy 0.2922\n",
      "step 217700 , validation loss : 23.0059\n",
      "step 217800 , training  accuracy 0.566667\n",
      "step 217800 , loss : 2.07114\n",
      "step 217800 , validation  accuracy 0.3134\n",
      "step 217800 , validation loss : 22.9111\n",
      "step 217900 , training  accuracy 0.666667\n",
      "step 217900 , loss : 2.05424\n",
      "step 217900 , validation  accuracy 0.319\n",
      "step 217900 , validation loss : 23.7705\n",
      "step 218000 , training  accuracy 0.6\n",
      "step 218000 , loss : 2.05464\n",
      "step 218000 , validation  accuracy 0.314\n",
      "step 218000 , validation loss : 22.548\n",
      "step 218100 , training  accuracy 0.533333\n",
      "step 218100 , loss : 2.07542\n",
      "step 218100 , validation  accuracy 0.2948\n",
      "step 218100 , validation loss : 23.0442\n",
      "step 218200 , training  accuracy 0.6\n",
      "step 218200 , loss : 2.08994\n",
      "step 218200 , validation  accuracy 0.3114\n",
      "step 218200 , validation loss : 24.9454\n",
      "step 218300 , training  accuracy 0.633333\n",
      "step 218300 , loss : 2.06094\n",
      "step 218300 , validation  accuracy 0.3068\n",
      "step 218300 , validation loss : 22.1744\n",
      "step 218400 , training  accuracy 0.566667\n",
      "step 218400 , loss : 2.1209\n",
      "step 218400 , validation  accuracy 0.3096\n",
      "step 218400 , validation loss : 22.9698\n",
      "step 218500 , training  accuracy 0.7\n",
      "step 218500 , loss : 1.97502\n",
      "step 218500 , validation  accuracy 0.3096\n",
      "step 218500 , validation loss : 24.6303\n",
      "step 218600 , training  accuracy 0.5\n",
      "step 218600 , loss : 2.10892\n",
      "step 218600 , validation  accuracy 0.3088\n",
      "step 218600 , validation loss : 24.5239\n",
      "step 218700 , training  accuracy 0.5\n",
      "step 218700 , loss : 2.10444\n",
      "step 218700 , validation  accuracy 0.3022\n",
      "step 218700 , validation loss : 22.9111\n",
      "step 218800 , training  accuracy 0.433333\n",
      "step 218800 , loss : 2.11429\n",
      "step 218800 , validation  accuracy 0.3162\n",
      "step 218800 , validation loss : 24.0865\n",
      "step 218900 , training  accuracy 0.666667\n",
      "step 218900 , loss : 1.9917\n",
      "step 218900 , validation  accuracy 0.3024\n",
      "step 218900 , validation loss : 22.8517\n",
      "step 219000 , training  accuracy 0.6\n",
      "step 219000 , loss : 2.06559\n",
      "step 219000 , validation  accuracy 0.3152\n",
      "step 219000 , validation loss : 24.2833\n",
      "step 219100 , training  accuracy 0.666667\n",
      "step 219100 , loss : 1.95682\n",
      "step 219100 , validation  accuracy 0.3146\n",
      "step 219100 , validation loss : 25.275\n",
      "step 219200 , training  accuracy 0.533333\n",
      "step 219200 , loss : 2.13019\n",
      "step 219200 , validation  accuracy 0.303\n",
      "step 219200 , validation loss : 22.372\n",
      "step 219300 , training  accuracy 0.466667\n",
      "step 219300 , loss : 2.14133\n",
      "step 219300 , validation  accuracy 0.3156\n",
      "step 219300 , validation loss : 23.8585\n",
      "step 219400 , training  accuracy 0.5\n",
      "step 219400 , loss : 2.12125\n",
      "step 219400 , validation  accuracy 0.2996\n",
      "step 219400 , validation loss : 23.2979\n",
      "step 219500 , training  accuracy 0.6\n",
      "step 219500 , loss : 2.06389\n",
      "step 219500 , validation  accuracy 0.291\n",
      "step 219500 , validation loss : 22.9133\n",
      "step 219600 , training  accuracy 0.6\n",
      "step 219600 , loss : 2.05103\n",
      "step 219600 , validation  accuracy 0.3188\n",
      "step 219600 , validation loss : 24.6582\n",
      "step 219700 , training  accuracy 0.533333\n",
      "step 219700 , loss : 2.12561\n",
      "step 219700 , validation  accuracy 0.3152\n",
      "step 219700 , validation loss : 24.0896\n",
      "step 219800 , training  accuracy 0.5\n",
      "step 219800 , loss : 2.11592\n",
      "step 219800 , validation  accuracy 0.2988\n",
      "step 219800 , validation loss : 24.3063\n",
      "step 219900 , training  accuracy 0.7\n",
      "step 219900 , loss : 1.97876\n",
      "step 219900 , validation  accuracy 0.3124\n",
      "step 219900 , validation loss : 24.2747\n",
      "step 220000 , training  accuracy 0.533333\n",
      "step 220000 , loss : 2.08574\n",
      "step 220000 , validation  accuracy 0.285\n",
      "step 220000 , validation loss : 21.9978\n",
      "step 220100 , training  accuracy 0.433333\n",
      "step 220100 , loss : 2.14011\n",
      "step 220100 , validation  accuracy 0.313\n",
      "step 220100 , validation loss : 24.071\n",
      "step 220200 , training  accuracy 0.533333\n",
      "step 220200 , loss : 2.07859\n",
      "step 220200 , validation  accuracy 0.304\n",
      "step 220200 , validation loss : 24.1811\n",
      "step 220300 , training  accuracy 0.333333\n",
      "step 220300 , loss : 2.18721\n",
      "step 220300 , validation  accuracy 0.2948\n",
      "step 220300 , validation loss : 24.0142\n",
      "step 220400 , training  accuracy 0.4\n",
      "step 220400 , loss : 2.13842\n",
      "step 220400 , validation  accuracy 0.3062\n",
      "step 220400 , validation loss : 23.2236\n",
      "step 220500 , training  accuracy 0.533333\n",
      "step 220500 , loss : 2.09544\n",
      "step 220500 , validation  accuracy 0.3036\n",
      "step 220500 , validation loss : 22.644\n",
      "step 220600 , training  accuracy 0.466667\n",
      "step 220600 , loss : 2.12237\n",
      "step 220600 , validation  accuracy 0.311\n",
      "step 220600 , validation loss : 22.9943\n",
      "step 220700 , training  accuracy 0.366667\n",
      "step 220700 , loss : 2.10181\n",
      "step 220700 , validation  accuracy 0.3224\n",
      "step 220700 , validation loss : 25.76\n",
      "step 220800 , training  accuracy 0.333333\n",
      "step 220800 , loss : 2.20052\n",
      "step 220800 , validation  accuracy 0.3104\n",
      "step 220800 , validation loss : 23.6716\n",
      "step 220900 , training  accuracy 0.433333\n",
      "step 220900 , loss : 2.16756\n",
      "step 220900 , validation  accuracy 0.3044\n",
      "step 220900 , validation loss : 22.6943\n",
      "step 221000 , training  accuracy 0.633333\n",
      "step 221000 , loss : 2.02752\n",
      "step 221000 , validation  accuracy 0.3072\n",
      "step 221000 , validation loss : 24.2156\n",
      "step 221100 , training  accuracy 0.5\n",
      "step 221100 , loss : 2.11806\n",
      "step 221100 , validation  accuracy 0.319\n",
      "step 221100 , validation loss : 23.4012\n",
      "step 221200 , training  accuracy 0.533333\n",
      "step 221200 , loss : 2.13049\n",
      "step 221200 , validation  accuracy 0.31\n",
      "step 221200 , validation loss : 24.1916\n",
      "step 221300 , training  accuracy 0.466667\n",
      "step 221300 , loss : 2.09177\n",
      "step 221300 , validation  accuracy 0.3042\n",
      "step 221300 , validation loss : 22.5662\n",
      "step 221400 , training  accuracy 0.666667\n",
      "step 221400 , loss : 2.04616\n",
      "step 221400 , validation  accuracy 0.3026\n",
      "step 221400 , validation loss : 22.9384\n",
      "step 221500 , training  accuracy 0.5\n",
      "step 221500 , loss : 2.09571\n",
      "step 221500 , validation  accuracy 0.2984\n",
      "step 221500 , validation loss : 23.4353\n",
      "step 221600 , training  accuracy 0.7\n",
      "step 221600 , loss : 2.0606\n",
      "step 221600 , validation  accuracy 0.312\n",
      "step 221600 , validation loss : 24.1354\n",
      "step 221700 , training  accuracy 0.533333\n",
      "step 221700 , loss : 2.12564\n",
      "step 221700 , validation  accuracy 0.3036\n",
      "step 221700 , validation loss : 22.9834\n",
      "step 221800 , training  accuracy 0.5\n",
      "step 221800 , loss : 2.02164\n",
      "step 221800 , validation  accuracy 0.3048\n",
      "step 221800 , validation loss : 23.8254\n",
      "step 221900 , training  accuracy 0.633333\n",
      "step 221900 , loss : 2.0752\n",
      "step 221900 , validation  accuracy 0.313\n",
      "step 221900 , validation loss : 23.5884\n",
      "step 222000 , training  accuracy 0.566667\n",
      "step 222000 , loss : 2.03384\n",
      "step 222000 , validation  accuracy 0.3132\n",
      "step 222000 , validation loss : 25.0747\n",
      "step 222100 , training  accuracy 0.6\n",
      "step 222100 , loss : 2.07929\n",
      "step 222100 , validation  accuracy 0.3104\n",
      "step 222100 , validation loss : 23.5147\n",
      "step 222200 , training  accuracy 0.666667\n",
      "step 222200 , loss : 2.02726\n",
      "step 222200 , validation  accuracy 0.3178\n",
      "step 222200 , validation loss : 25.3513\n",
      "step 222300 , training  accuracy 0.333333\n",
      "step 222300 , loss : 2.10195\n",
      "step 222300 , validation  accuracy 0.303\n",
      "step 222300 , validation loss : 23.3427\n",
      "step 222400 , training  accuracy 0.566667\n",
      "step 222400 , loss : 2.0348\n",
      "step 222400 , validation  accuracy 0.3138\n",
      "step 222400 , validation loss : 24.3731\n",
      "step 222500 , training  accuracy 0.533333\n",
      "step 222500 , loss : 2.07906\n",
      "step 222500 , validation  accuracy 0.2914\n",
      "step 222500 , validation loss : 23.3432\n",
      "step 222600 , training  accuracy 0.566667\n",
      "step 222600 , loss : 2.07641\n",
      "step 222600 , validation  accuracy 0.3028\n",
      "step 222600 , validation loss : 22.2955\n",
      "step 222700 , training  accuracy 0.833333\n",
      "step 222700 , loss : 1.98481\n",
      "step 222700 , validation  accuracy 0.299\n",
      "step 222700 , validation loss : 23.3254\n",
      "step 222800 , training  accuracy 0.5\n",
      "step 222800 , loss : 2.12425\n",
      "step 222800 , validation  accuracy 0.3088\n",
      "step 222800 , validation loss : 23.1946\n",
      "step 222900 , training  accuracy 0.6\n",
      "step 222900 , loss : 2.02382\n",
      "step 222900 , validation  accuracy 0.3182\n",
      "step 222900 , validation loss : 24.0829\n",
      "step 223000 , training  accuracy 0.533333\n",
      "step 223000 , loss : 2.05966\n",
      "step 223000 , validation  accuracy 0.3164\n",
      "step 223000 , validation loss : 25.6226\n",
      "step 223100 , training  accuracy 0.533333\n",
      "step 223100 , loss : 2.05209\n",
      "step 223100 , validation  accuracy 0.3066\n",
      "step 223100 , validation loss : 22.9009\n",
      "step 223200 , training  accuracy 0.566667\n",
      "step 223200 , loss : 2.03797\n",
      "step 223200 , validation  accuracy 0.3068\n",
      "step 223200 , validation loss : 23.5006\n",
      "step 223300 , training  accuracy 0.666667\n",
      "step 223300 , loss : 1.98691\n",
      "step 223300 , validation  accuracy 0.3154\n",
      "step 223300 , validation loss : 25.5484\n",
      "step 223400 , training  accuracy 0.433333\n",
      "step 223400 , loss : 2.13686\n",
      "step 223400 , validation  accuracy 0.3116\n",
      "step 223400 , validation loss : 22.4515\n",
      "step 223500 , training  accuracy 0.666667\n",
      "step 223500 , loss : 2.01917\n",
      "step 223500 , validation  accuracy 0.3038\n",
      "step 223500 , validation loss : 23.527\n",
      "step 223600 , training  accuracy 0.6\n",
      "step 223600 , loss : 2.06462\n",
      "step 223600 , validation  accuracy 0.3118\n",
      "step 223600 , validation loss : 23.5221\n",
      "step 223700 , training  accuracy 0.7\n",
      "step 223700 , loss : 1.98056\n",
      "step 223700 , validation  accuracy 0.3062\n",
      "step 223700 , validation loss : 22.4192\n",
      "step 223800 , training  accuracy 0.6\n",
      "step 223800 , loss : 2.07835\n",
      "step 223800 , validation  accuracy 0.2984\n",
      "step 223800 , validation loss : 22.7017\n",
      "step 223900 , training  accuracy 0.6\n",
      "step 223900 , loss : 2.06877\n",
      "step 223900 , validation  accuracy 0.3168\n",
      "step 223900 , validation loss : 22.9714\n",
      "step 224000 , training  accuracy 0.566667\n",
      "step 224000 , loss : 2.07712\n",
      "step 224000 , validation  accuracy 0.3008\n",
      "step 224000 , validation loss : 24.2276\n",
      "step 224100 , training  accuracy 0.533333\n",
      "step 224100 , loss : 2.04567\n",
      "step 224100 , validation  accuracy 0.303\n",
      "step 224100 , validation loss : 23.2419\n",
      "step 224200 , training  accuracy 0.466667\n",
      "step 224200 , loss : 2.12597\n",
      "step 224200 , validation  accuracy 0.3042\n",
      "step 224200 , validation loss : 25.502\n",
      "step 224300 , training  accuracy 0.633333\n",
      "step 224300 , loss : 1.96173\n",
      "step 224300 , validation  accuracy 0.3168\n",
      "step 224300 , validation loss : 24.1218\n",
      "step 224400 , training  accuracy 0.5\n",
      "step 224400 , loss : 2.0918\n",
      "step 224400 , validation  accuracy 0.3142\n",
      "step 224400 , validation loss : 24.2224\n",
      "step 224500 , training  accuracy 0.5\n",
      "step 224500 , loss : 2.11777\n",
      "step 224500 , validation  accuracy 0.322\n",
      "step 224500 , validation loss : 24.0676\n",
      "step 224600 , training  accuracy 0.6\n",
      "step 224600 , loss : 2.09818\n",
      "step 224600 , validation  accuracy 0.306\n",
      "step 224600 , validation loss : 23.6758\n",
      "step 224700 , training  accuracy 0.366667\n",
      "step 224700 , loss : 2.18217\n",
      "step 224700 , validation  accuracy 0.3158\n",
      "step 224700 , validation loss : 23.1957\n",
      "step 224800 , training  accuracy 0.466667\n",
      "step 224800 , loss : 2.12463\n",
      "step 224800 , validation  accuracy 0.3032\n",
      "step 224800 , validation loss : 23.6241\n",
      "step 224900 , training  accuracy 0.433333\n",
      "step 224900 , loss : 2.13884\n",
      "step 224900 , validation  accuracy 0.308\n",
      "step 224900 , validation loss : 23.7356\n",
      "step 225000 , training  accuracy 0.533333\n",
      "step 225000 , loss : 2.08943\n",
      "step 225000 , validation  accuracy 0.3104\n",
      "step 225000 , validation loss : 24.0492\n",
      "step 225100 , training  accuracy 0.433333\n",
      "step 225100 , loss : 2.17885\n",
      "step 225100 , validation  accuracy 0.291\n",
      "step 225100 , validation loss : 23.2307\n",
      "step 225200 , training  accuracy 0.733333\n",
      "step 225200 , loss : 2.0277\n",
      "step 225200 , validation  accuracy 0.3048\n",
      "step 225200 , validation loss : 23.7775\n",
      "step 225300 , training  accuracy 0.4\n",
      "step 225300 , loss : 2.12365\n",
      "step 225300 , validation  accuracy 0.3032\n",
      "step 225300 , validation loss : 24.5646\n",
      "step 225400 , training  accuracy 0.633333\n",
      "step 225400 , loss : 2.05847\n",
      "step 225400 , validation  accuracy 0.3108\n",
      "step 225400 , validation loss : 25.9228\n",
      "step 225500 , training  accuracy 0.633333\n",
      "step 225500 , loss : 2.03454\n",
      "step 225500 , validation  accuracy 0.2998\n",
      "step 225500 , validation loss : 23.4741\n",
      "step 225600 , training  accuracy 0.566667\n",
      "step 225600 , loss : 2.08455\n",
      "step 225600 , validation  accuracy 0.2954\n",
      "step 225600 , validation loss : 22.2132\n",
      "step 225700 , training  accuracy 0.533333\n",
      "step 225700 , loss : 2.03472\n",
      "step 225700 , validation  accuracy 0.313\n",
      "step 225700 , validation loss : 23.9861\n",
      "step 225800 , training  accuracy 0.6\n",
      "step 225800 , loss : 2.09054\n",
      "step 225800 , validation  accuracy 0.3062\n",
      "step 225800 , validation loss : 23.4471\n",
      "step 225900 , training  accuracy 0.7\n",
      "step 225900 , loss : 2.02599\n",
      "step 225900 , validation  accuracy 0.3136\n",
      "step 225900 , validation loss : 23.2348\n",
      "step 226000 , training  accuracy 0.733333\n",
      "step 226000 , loss : 1.94417\n",
      "step 226000 , validation  accuracy 0.3\n",
      "step 226000 , validation loss : 23.9089\n",
      "step 226100 , training  accuracy 0.566667\n",
      "step 226100 , loss : 2.10335\n",
      "step 226100 , validation  accuracy 0.2986\n",
      "step 226100 , validation loss : 22.6467\n",
      "step 226200 , training  accuracy 0.433333\n",
      "step 226200 , loss : 2.12486\n",
      "step 226200 , validation  accuracy 0.287\n",
      "step 226200 , validation loss : 22.9238\n",
      "step 226300 , training  accuracy 0.633333\n",
      "step 226300 , loss : 2.01342\n",
      "step 226300 , validation  accuracy 0.3168\n",
      "step 226300 , validation loss : 24.2157\n",
      "step 226400 , training  accuracy 0.333333\n",
      "step 226400 , loss : 2.23104\n",
      "step 226400 , validation  accuracy 0.3144\n",
      "step 226400 , validation loss : 24.3063\n",
      "step 226500 , training  accuracy 0.666667\n",
      "step 226500 , loss : 2.02834\n",
      "step 226500 , validation  accuracy 0.3092\n",
      "step 226500 , validation loss : 25.1035\n",
      "step 226600 , training  accuracy 0.633333\n",
      "step 226600 , loss : 2.06017\n",
      "step 226600 , validation  accuracy 0.3076\n",
      "step 226600 , validation loss : 22.7594\n",
      "step 226700 , training  accuracy 0.6\n",
      "step 226700 , loss : 2.11849\n",
      "step 226700 , validation  accuracy 0.2916\n",
      "step 226700 , validation loss : 23.0012\n",
      "step 226800 , training  accuracy 0.766667\n",
      "step 226800 , loss : 1.93403\n",
      "step 226800 , validation  accuracy 0.3176\n",
      "step 226800 , validation loss : 24.478\n",
      "step 226900 , training  accuracy 0.4\n",
      "step 226900 , loss : 2.10584\n",
      "step 226900 , validation  accuracy 0.312\n",
      "step 226900 , validation loss : 24.6765\n",
      "step 227000 , training  accuracy 0.533333\n",
      "step 227000 , loss : 2.07756\n",
      "step 227000 , validation  accuracy 0.3066\n",
      "step 227000 , validation loss : 24.6351\n",
      "step 227100 , training  accuracy 0.6\n",
      "step 227100 , loss : 2.06278\n",
      "step 227100 , validation  accuracy 0.307\n",
      "step 227100 , validation loss : 23.2974\n",
      "step 227200 , training  accuracy 0.5\n",
      "step 227200 , loss : 2.06767\n",
      "step 227200 , validation  accuracy 0.3212\n",
      "step 227200 , validation loss : 24.4627\n",
      "step 227300 , training  accuracy 0.533333\n",
      "step 227300 , loss : 2.1555\n",
      "step 227300 , validation  accuracy 0.296\n",
      "step 227300 , validation loss : 21.8623\n",
      "step 227400 , training  accuracy 0.566667\n",
      "step 227400 , loss : 2.10361\n",
      "step 227400 , validation  accuracy 0.312\n",
      "step 227400 , validation loss : 24.3738\n",
      "step 227500 , training  accuracy 0.466667\n",
      "step 227500 , loss : 2.07647\n",
      "step 227500 , validation  accuracy 0.3064\n",
      "step 227500 , validation loss : 23.3625\n",
      "step 227600 , training  accuracy 0.566667\n",
      "step 227600 , loss : 2.05934\n",
      "step 227600 , validation  accuracy 0.3084\n",
      "step 227600 , validation loss : 23.6131\n",
      "step 227700 , training  accuracy 0.5\n",
      "step 227700 , loss : 2.08053\n",
      "step 227700 , validation  accuracy 0.298\n",
      "step 227700 , validation loss : 23.5684\n",
      "step 227800 , training  accuracy 0.533333\n",
      "step 227800 , loss : 2.03341\n",
      "step 227800 , validation  accuracy 0.314\n",
      "step 227800 , validation loss : 23.0455\n",
      "step 227900 , training  accuracy 0.466667\n",
      "step 227900 , loss : 2.13458\n",
      "step 227900 , validation  accuracy 0.3078\n",
      "step 227900 , validation loss : 22.2984\n",
      "step 228000 , training  accuracy 0.433333\n",
      "step 228000 , loss : 2.0475\n",
      "step 228000 , validation  accuracy 0.3156\n",
      "step 228000 , validation loss : 23.7811\n",
      "step 228100 , training  accuracy 0.433333\n",
      "step 228100 , loss : 2.12008\n",
      "step 228100 , validation  accuracy 0.3162\n",
      "step 228100 , validation loss : 23.7992\n",
      "step 228200 , training  accuracy 0.5\n",
      "step 228200 , loss : 2.08579\n",
      "step 228200 , validation  accuracy 0.31\n",
      "step 228200 , validation loss : 23.0501\n",
      "step 228300 , training  accuracy 0.533333\n",
      "step 228300 , loss : 2.0601\n",
      "step 228300 , validation  accuracy 0.31\n",
      "step 228300 , validation loss : 25.5057\n",
      "step 228400 , training  accuracy 0.633333\n",
      "step 228400 , loss : 2.08068\n",
      "step 228400 , validation  accuracy 0.3074\n",
      "step 228400 , validation loss : 22.5164\n",
      "step 228500 , training  accuracy 0.566667\n",
      "step 228500 , loss : 2.0902\n",
      "step 228500 , validation  accuracy 0.3152\n",
      "step 228500 , validation loss : 24.7506\n",
      "step 228600 , training  accuracy 0.6\n",
      "step 228600 , loss : 2.03604\n",
      "step 228600 , validation  accuracy 0.3106\n",
      "step 228600 , validation loss : 24.2294\n",
      "step 228700 , training  accuracy 0.566667\n",
      "step 228700 , loss : 2.07179\n",
      "step 228700 , validation  accuracy 0.3064\n",
      "step 228700 , validation loss : 24.1717\n",
      "step 228800 , training  accuracy 0.633333\n",
      "step 228800 , loss : 2.13494\n",
      "step 228800 , validation  accuracy 0.313\n",
      "step 228800 , validation loss : 25.0298\n",
      "step 228900 , training  accuracy 0.466667\n",
      "step 228900 , loss : 2.1153\n",
      "step 228900 , validation  accuracy 0.3118\n",
      "step 228900 , validation loss : 25.7176\n",
      "step 229000 , training  accuracy 0.633333\n",
      "step 229000 , loss : 2.01556\n",
      "step 229000 , validation  accuracy 0.3134\n",
      "step 229000 , validation loss : 24.7203\n",
      "step 229100 , training  accuracy 0.533333\n",
      "step 229100 , loss : 2.09898\n",
      "step 229100 , validation  accuracy 0.296\n",
      "step 229100 , validation loss : 22.4012\n",
      "step 229200 , training  accuracy 0.666667\n",
      "step 229200 , loss : 2.06992\n",
      "step 229200 , validation  accuracy 0.3104\n",
      "step 229200 , validation loss : 24.014\n",
      "step 229300 , training  accuracy 0.5\n",
      "step 229300 , loss : 2.11321\n",
      "step 229300 , validation  accuracy 0.3062\n",
      "step 229300 , validation loss : 22.633\n",
      "step 229400 , training  accuracy 0.433333\n",
      "step 229400 , loss : 2.12219\n",
      "step 229400 , validation  accuracy 0.3104\n",
      "step 229400 , validation loss : 23.8918\n",
      "step 229500 , training  accuracy 0.533333\n",
      "step 229500 , loss : 2.07414\n",
      "step 229500 , validation  accuracy 0.3028\n",
      "step 229500 , validation loss : 23.1773\n",
      "step 229600 , training  accuracy 0.433333\n",
      "step 229600 , loss : 2.0801\n",
      "step 229600 , validation  accuracy 0.307\n",
      "step 229600 , validation loss : 24.1481\n",
      "step 229700 , training  accuracy 0.533333\n",
      "step 229700 , loss : 2.12289\n",
      "step 229700 , validation  accuracy 0.3042\n",
      "step 229700 , validation loss : 23.6809\n",
      "step 229800 , training  accuracy 0.533333\n",
      "step 229800 , loss : 2.07331\n",
      "step 229800 , validation  accuracy 0.3052\n",
      "step 229800 , validation loss : 23.5189\n",
      "step 229900 , training  accuracy 0.7\n",
      "step 229900 , loss : 2.04225\n",
      "step 229900 , validation  accuracy 0.31\n",
      "step 229900 , validation loss : 23.934\n",
      "step 230000 , training  accuracy 0.533333\n",
      "step 230000 , loss : 2.04832\n",
      "step 230000 , validation  accuracy 0.3122\n",
      "step 230000 , validation loss : 24.9681\n",
      "step 230100 , training  accuracy 0.4\n",
      "step 230100 , loss : 2.14578\n",
      "step 230100 , validation  accuracy 0.2962\n",
      "step 230100 , validation loss : 24.2424\n",
      "step 230200 , training  accuracy 0.6\n",
      "step 230200 , loss : 2.06772\n",
      "step 230200 , validation  accuracy 0.3052\n",
      "step 230200 , validation loss : 23.2995\n",
      "step 230300 , training  accuracy 0.5\n",
      "step 230300 , loss : 2.13194\n",
      "step 230300 , validation  accuracy 0.3032\n",
      "step 230300 , validation loss : 23.3086\n",
      "step 230400 , training  accuracy 0.666667\n",
      "step 230400 , loss : 1.9784\n",
      "step 230400 , validation  accuracy 0.2952\n",
      "step 230400 , validation loss : 24.1136\n",
      "step 230500 , training  accuracy 0.6\n",
      "step 230500 , loss : 2.04163\n",
      "step 230500 , validation  accuracy 0.3046\n",
      "step 230500 , validation loss : 24.1006\n",
      "step 230600 , training  accuracy 0.533333\n",
      "step 230600 , loss : 2.10135\n",
      "step 230600 , validation  accuracy 0.308\n",
      "step 230600 , validation loss : 24.1919\n",
      "step 230700 , training  accuracy 0.6\n",
      "step 230700 , loss : 1.99649\n",
      "step 230700 , validation  accuracy 0.322\n",
      "step 230700 , validation loss : 24.2555\n",
      "step 230800 , training  accuracy 0.633333\n",
      "step 230800 , loss : 2.01902\n",
      "step 230800 , validation  accuracy 0.3176\n",
      "step 230800 , validation loss : 24.4202\n",
      "step 230900 , training  accuracy 0.6\n",
      "step 230900 , loss : 2.06986\n",
      "step 230900 , validation  accuracy 0.3194\n",
      "step 230900 , validation loss : 23.625\n",
      "step 231000 , training  accuracy 0.566667\n",
      "step 231000 , loss : 2.01395\n",
      "step 231000 , validation  accuracy 0.2984\n",
      "step 231000 , validation loss : 24.4072\n",
      "step 231100 , training  accuracy 0.4\n",
      "step 231100 , loss : 2.14153\n",
      "step 231100 , validation  accuracy 0.3042\n",
      "step 231100 , validation loss : 22.8187\n",
      "step 231200 , training  accuracy 0.433333\n",
      "step 231200 , loss : 2.10501\n",
      "step 231200 , validation  accuracy 0.3086\n",
      "step 231200 , validation loss : 22.8447\n",
      "step 231300 , training  accuracy 0.6\n",
      "step 231300 , loss : 1.98887\n",
      "step 231300 , validation  accuracy 0.3226\n",
      "step 231300 , validation loss : 25.8254\n",
      "step 231400 , training  accuracy 0.633333\n",
      "step 231400 , loss : 2.03656\n",
      "step 231400 , validation  accuracy 0.322\n",
      "step 231400 , validation loss : 24.9854\n",
      "step 231500 , training  accuracy 0.5\n",
      "step 231500 , loss : 2.08294\n",
      "step 231500 , validation  accuracy 0.3104\n",
      "step 231500 , validation loss : 23.8263\n",
      "step 231600 , training  accuracy 0.433333\n",
      "step 231600 , loss : 2.15547\n",
      "step 231600 , validation  accuracy 0.3024\n",
      "step 231600 , validation loss : 22.1257\n",
      "step 231700 , training  accuracy 0.533333\n",
      "step 231700 , loss : 2.07564\n",
      "step 231700 , validation  accuracy 0.3124\n",
      "step 231700 , validation loss : 24.3941\n",
      "step 231800 , training  accuracy 0.566667\n",
      "step 231800 , loss : 2.04671\n",
      "step 231800 , validation  accuracy 0.3026\n",
      "step 231800 , validation loss : 22.5782\n",
      "step 231900 , training  accuracy 0.666667\n",
      "step 231900 , loss : 2.0429\n",
      "step 231900 , validation  accuracy 0.2998\n",
      "step 231900 , validation loss : 24.0705\n",
      "step 232000 , training  accuracy 0.466667\n",
      "step 232000 , loss : 2.11989\n",
      "step 232000 , validation  accuracy 0.303\n",
      "step 232000 , validation loss : 25.1065\n",
      "step 232100 , training  accuracy 0.566667\n",
      "step 232100 , loss : 2.10009\n",
      "step 232100 , validation  accuracy 0.2904\n",
      "step 232100 , validation loss : 23.6607\n",
      "step 232200 , training  accuracy 0.666667\n",
      "step 232200 , loss : 2.02949\n",
      "step 232200 , validation  accuracy 0.302\n",
      "step 232200 , validation loss : 23.3906\n",
      "step 232300 , training  accuracy 0.533333\n",
      "step 232300 , loss : 2.13541\n",
      "step 232300 , validation  accuracy 0.303\n",
      "step 232300 , validation loss : 23.2824\n",
      "step 232400 , training  accuracy 0.566667\n",
      "step 232400 , loss : 2.01353\n",
      "step 232400 , validation  accuracy 0.3124\n",
      "step 232400 , validation loss : 25.8273\n",
      "step 232500 , training  accuracy 0.666667\n",
      "step 232500 , loss : 2.0473\n",
      "step 232500 , validation  accuracy 0.3088\n",
      "step 232500 , validation loss : 25.3585\n",
      "step 232600 , training  accuracy 0.5\n",
      "step 232600 , loss : 2.08472\n",
      "step 232600 , validation  accuracy 0.3152\n",
      "step 232600 , validation loss : 24.3937\n",
      "step 232700 , training  accuracy 0.633333\n",
      "step 232700 , loss : 2.06661\n",
      "step 232700 , validation  accuracy 0.3194\n",
      "step 232700 , validation loss : 25.8249\n",
      "step 232800 , training  accuracy 0.533333\n",
      "step 232800 , loss : 2.09336\n",
      "step 232800 , validation  accuracy 0.2972\n",
      "step 232800 , validation loss : 23.8488\n",
      "step 232900 , training  accuracy 0.433333\n",
      "step 232900 , loss : 2.09571\n",
      "step 232900 , validation  accuracy 0.314\n",
      "step 232900 , validation loss : 23.596\n",
      "step 233000 , training  accuracy 0.6\n",
      "step 233000 , loss : 2.06973\n",
      "step 233000 , validation  accuracy 0.317\n",
      "step 233000 , validation loss : 25.8333\n",
      "step 233100 , training  accuracy 0.466667\n",
      "step 233100 , loss : 2.12423\n",
      "step 233100 , validation  accuracy 0.2882\n",
      "step 233100 , validation loss : 22.5733\n",
      "step 233200 , training  accuracy 0.566667\n",
      "step 233200 , loss : 2.03589\n",
      "step 233200 , validation  accuracy 0.311\n",
      "step 233200 , validation loss : 24.6498\n",
      "step 233300 , training  accuracy 0.6\n",
      "step 233300 , loss : 2.02293\n",
      "step 233300 , validation  accuracy 0.3132\n",
      "step 233300 , validation loss : 24.1113\n",
      "step 233400 , training  accuracy 0.6\n",
      "step 233400 , loss : 2.07446\n",
      "step 233400 , validation  accuracy 0.2862\n",
      "step 233400 , validation loss : 22.5343\n",
      "step 233500 , training  accuracy 0.366667\n",
      "step 233500 , loss : 2.16187\n",
      "step 233500 , validation  accuracy 0.3018\n",
      "step 233500 , validation loss : 23.4765\n",
      "step 233600 , training  accuracy 0.533333\n",
      "step 233600 , loss : 2.15049\n",
      "step 233600 , validation  accuracy 0.2974\n",
      "step 233600 , validation loss : 23.7956\n",
      "step 233700 , training  accuracy 0.5\n",
      "step 233700 , loss : 2.07833\n",
      "step 233700 , validation  accuracy 0.3048\n",
      "step 233700 , validation loss : 23.4763\n",
      "step 233800 , training  accuracy 0.433333\n",
      "step 233800 , loss : 2.1367\n",
      "step 233800 , validation  accuracy 0.3092\n",
      "step 233800 , validation loss : 23.4704\n",
      "step 233900 , training  accuracy 0.666667\n",
      "step 233900 , loss : 2.02918\n",
      "step 233900 , validation  accuracy 0.3094\n",
      "step 233900 , validation loss : 22.6036\n",
      "step 234000 , training  accuracy 0.5\n",
      "step 234000 , loss : 2.09526\n",
      "step 234000 , validation  accuracy 0.3086\n",
      "step 234000 , validation loss : 23.151\n",
      "step 234100 , training  accuracy 0.666667\n",
      "step 234100 , loss : 2.04214\n",
      "step 234100 , validation  accuracy 0.2992\n",
      "step 234100 , validation loss : 22.7404\n",
      "step 234200 , training  accuracy 0.733333\n",
      "step 234200 , loss : 2.00518\n",
      "step 234200 , validation  accuracy 0.3088\n",
      "step 234200 , validation loss : 26.5089\n",
      "step 234300 , training  accuracy 0.533333\n",
      "step 234300 , loss : 2.1023\n",
      "step 234300 , validation  accuracy 0.296\n",
      "step 234300 , validation loss : 21.2352\n",
      "step 234400 , training  accuracy 0.633333\n",
      "step 234400 , loss : 2.04601\n",
      "step 234400 , validation  accuracy 0.2958\n",
      "step 234400 , validation loss : 21.846\n",
      "step 234500 , training  accuracy 0.5\n",
      "step 234500 , loss : 2.09966\n",
      "step 234500 , validation  accuracy 0.3102\n",
      "step 234500 , validation loss : 22.4528\n",
      "step 234600 , training  accuracy 0.466667\n",
      "step 234600 , loss : 2.14305\n",
      "step 234600 , validation  accuracy 0.293\n",
      "step 234600 , validation loss : 22.5661\n",
      "step 234700 , training  accuracy 0.833333\n",
      "step 234700 , loss : 1.9578\n",
      "step 234700 , validation  accuracy 0.3074\n",
      "step 234700 , validation loss : 23.8242\n",
      "step 234800 , training  accuracy 0.466667\n",
      "step 234800 , loss : 2.115\n",
      "step 234800 , validation  accuracy 0.3022\n",
      "step 234800 , validation loss : 22.3813\n",
      "step 234900 , training  accuracy 0.566667\n",
      "step 234900 , loss : 2.06226\n",
      "step 234900 , validation  accuracy 0.313\n",
      "step 234900 , validation loss : 23.0728\n",
      "step 235000 , training  accuracy 0.6\n",
      "step 235000 , loss : 2.0535\n",
      "step 235000 , validation  accuracy 0.308\n",
      "step 235000 , validation loss : 24.6232\n",
      "step 235100 , training  accuracy 0.566667\n",
      "step 235100 , loss : 2.09065\n",
      "step 235100 , validation  accuracy 0.29\n",
      "step 235100 , validation loss : 22.974\n",
      "step 235200 , training  accuracy 0.533333\n",
      "step 235200 , loss : 2.11617\n",
      "step 235200 , validation  accuracy 0.313\n",
      "step 235200 , validation loss : 22.5436\n",
      "step 235300 , training  accuracy 0.533333\n",
      "step 235300 , loss : 2.14878\n",
      "step 235300 , validation  accuracy 0.3086\n",
      "step 235300 , validation loss : 23.5212\n",
      "step 235400 , training  accuracy 0.566667\n",
      "step 235400 , loss : 2.04494\n",
      "step 235400 , validation  accuracy 0.302\n",
      "step 235400 , validation loss : 23.3737\n",
      "step 235500 , training  accuracy 0.566667\n",
      "step 235500 , loss : 2.05347\n",
      "step 235500 , validation  accuracy 0.296\n",
      "step 235500 , validation loss : 23.2374\n",
      "step 235600 , training  accuracy 0.6\n",
      "step 235600 , loss : 2.07391\n",
      "step 235600 , validation  accuracy 0.2998\n",
      "step 235600 , validation loss : 24.8985\n",
      "step 235700 , training  accuracy 0.566667\n",
      "step 235700 , loss : 2.06171\n",
      "step 235700 , validation  accuracy 0.3074\n",
      "step 235700 , validation loss : 26.2448\n",
      "step 235800 , training  accuracy 0.533333\n",
      "step 235800 , loss : 2.04319\n",
      "step 235800 , validation  accuracy 0.3098\n",
      "step 235800 , validation loss : 23.7135\n",
      "step 235900 , training  accuracy 0.433333\n",
      "step 235900 , loss : 2.09934\n",
      "step 235900 , validation  accuracy 0.3148\n",
      "step 235900 , validation loss : 25.1426\n",
      "step 236000 , training  accuracy 0.4\n",
      "step 236000 , loss : 2.16402\n",
      "step 236000 , validation  accuracy 0.3028\n",
      "step 236000 , validation loss : 22.1268\n",
      "step 236100 , training  accuracy 0.533333\n",
      "step 236100 , loss : 2.0594\n",
      "step 236100 , validation  accuracy 0.3092\n",
      "step 236100 , validation loss : 24.3634\n",
      "step 236200 , training  accuracy 0.6\n",
      "step 236200 , loss : 2.06092\n",
      "step 236200 , validation  accuracy 0.3204\n",
      "step 236200 , validation loss : 24.3584\n",
      "step 236300 , training  accuracy 0.6\n",
      "step 236300 , loss : 2.05758\n",
      "step 236300 , validation  accuracy 0.3146\n",
      "step 236300 , validation loss : 22.7952\n",
      "step 236400 , training  accuracy 0.566667\n",
      "step 236400 , loss : 2.11469\n",
      "step 236400 , validation  accuracy 0.3076\n",
      "step 236400 , validation loss : 23.3348\n",
      "step 236500 , training  accuracy 0.566667\n",
      "step 236500 , loss : 2.07536\n",
      "step 236500 , validation  accuracy 0.2938\n",
      "step 236500 , validation loss : 22.7861\n",
      "step 236600 , training  accuracy 0.5\n",
      "step 236600 , loss : 2.08138\n",
      "step 236600 , validation  accuracy 0.3138\n",
      "step 236600 , validation loss : 23.5512\n",
      "step 236700 , training  accuracy 0.466667\n",
      "step 236700 , loss : 2.13814\n",
      "step 236700 , validation  accuracy 0.3194\n",
      "step 236700 , validation loss : 22.9753\n",
      "step 236800 , training  accuracy 0.566667\n",
      "step 236800 , loss : 2.06181\n",
      "step 236800 , validation  accuracy 0.3058\n",
      "step 236800 , validation loss : 23.1288\n",
      "step 236900 , training  accuracy 0.5\n",
      "step 236900 , loss : 2.1347\n",
      "step 236900 , validation  accuracy 0.3022\n",
      "step 236900 , validation loss : 22.6213\n",
      "step 237000 , training  accuracy 0.566667\n",
      "step 237000 , loss : 2.09438\n",
      "step 237000 , validation  accuracy 0.3146\n",
      "step 237000 , validation loss : 24.2763\n",
      "step 237100 , training  accuracy 0.566667\n",
      "step 237100 , loss : 2.00665\n",
      "step 237100 , validation  accuracy 0.3142\n",
      "step 237100 , validation loss : 25.271\n",
      "step 237200 , training  accuracy 0.633333\n",
      "step 237200 , loss : 2.06011\n",
      "step 237200 , validation  accuracy 0.3054\n",
      "step 237200 , validation loss : 24.1923\n",
      "step 237300 , training  accuracy 0.566667\n",
      "step 237300 , loss : 2.10712\n",
      "step 237300 , validation  accuracy 0.3074\n",
      "step 237300 , validation loss : 23.5386\n",
      "step 237400 , training  accuracy 0.533333\n",
      "step 237400 , loss : 2.06574\n",
      "step 237400 , validation  accuracy 0.2938\n",
      "step 237400 , validation loss : 23.2402\n",
      "step 237500 , training  accuracy 0.366667\n",
      "step 237500 , loss : 2.12795\n",
      "step 237500 , validation  accuracy 0.2952\n",
      "step 237500 , validation loss : 23.0233\n",
      "step 237600 , training  accuracy 0.466667\n",
      "step 237600 , loss : 2.11642\n",
      "step 237600 , validation  accuracy 0.3142\n",
      "step 237600 , validation loss : 25.3016\n",
      "step 237700 , training  accuracy 0.4\n",
      "step 237700 , loss : 2.18972\n",
      "step 237700 , validation  accuracy 0.304\n",
      "step 237700 , validation loss : 22.7511\n",
      "step 237800 , training  accuracy 0.6\n",
      "step 237800 , loss : 2.0134\n",
      "step 237800 , validation  accuracy 0.3116\n",
      "step 237800 , validation loss : 23.3404\n",
      "step 237900 , training  accuracy 0.666667\n",
      "step 237900 , loss : 2.00472\n",
      "step 237900 , validation  accuracy 0.3058\n",
      "step 237900 , validation loss : 24.6978\n",
      "step 238000 , training  accuracy 0.466667\n",
      "step 238000 , loss : 2.16116\n",
      "step 238000 , validation  accuracy 0.309\n",
      "step 238000 , validation loss : 24.2987\n",
      "step 238100 , training  accuracy 0.6\n",
      "step 238100 , loss : 2.05723\n",
      "step 238100 , validation  accuracy 0.2978\n",
      "step 238100 , validation loss : 22.302\n",
      "step 238200 , training  accuracy 0.633333\n",
      "step 238200 , loss : 1.99371\n",
      "step 238200 , validation  accuracy 0.3158\n",
      "step 238200 , validation loss : 24.1709\n",
      "step 238300 , training  accuracy 0.6\n",
      "step 238300 , loss : 2.02766\n",
      "step 238300 , validation  accuracy 0.3014\n",
      "step 238300 , validation loss : 22.6695\n",
      "step 238400 , training  accuracy 0.7\n",
      "step 238400 , loss : 1.99076\n",
      "step 238400 , validation  accuracy 0.3108\n",
      "step 238400 , validation loss : 22.9635\n",
      "step 238500 , training  accuracy 0.533333\n",
      "step 238500 , loss : 2.06785\n",
      "step 238500 , validation  accuracy 0.3088\n",
      "step 238500 , validation loss : 23.7898\n",
      "step 238600 , training  accuracy 0.4\n",
      "step 238600 , loss : 2.1749\n",
      "step 238600 , validation  accuracy 0.2972\n",
      "step 238600 , validation loss : 22.8474\n",
      "step 238700 , training  accuracy 0.466667\n",
      "step 238700 , loss : 2.10065\n",
      "step 238700 , validation  accuracy 0.3146\n",
      "step 238700 , validation loss : 24.1638\n",
      "step 238800 , training  accuracy 0.5\n",
      "step 238800 , loss : 2.07076\n",
      "step 238800 , validation  accuracy 0.313\n",
      "step 238800 , validation loss : 23.8359\n",
      "step 238900 , training  accuracy 0.333333\n",
      "step 238900 , loss : 2.15392\n",
      "step 238900 , validation  accuracy 0.3072\n",
      "step 238900 , validation loss : 23.4597\n",
      "step 239000 , training  accuracy 0.6\n",
      "step 239000 , loss : 2.02196\n",
      "step 239000 , validation  accuracy 0.3194\n",
      "step 239000 , validation loss : 24.5549\n",
      "step 239100 , training  accuracy 0.266667\n",
      "step 239100 , loss : 2.18902\n",
      "step 239100 , validation  accuracy 0.3022\n",
      "step 239100 , validation loss : 23.4784\n",
      "step 239200 , training  accuracy 0.566667\n",
      "step 239200 , loss : 2.04444\n",
      "step 239200 , validation  accuracy 0.3138\n",
      "step 239200 , validation loss : 24.2942\n",
      "step 239300 , training  accuracy 0.533333\n",
      "step 239300 , loss : 2.12791\n",
      "step 239300 , validation  accuracy 0.306\n",
      "step 239300 , validation loss : 23.7914\n",
      "step 239400 , training  accuracy 0.466667\n",
      "step 239400 , loss : 2.1693\n",
      "step 239400 , validation  accuracy 0.3138\n",
      "step 239400 , validation loss : 25.6732\n",
      "step 239500 , training  accuracy 0.6\n",
      "step 239500 , loss : 2.08617\n",
      "step 239500 , validation  accuracy 0.2878\n",
      "step 239500 , validation loss : 22.8191\n",
      "step 239600 , training  accuracy 0.433333\n",
      "step 239600 , loss : 2.08497\n",
      "step 239600 , validation  accuracy 0.315\n",
      "step 239600 , validation loss : 22.7851\n",
      "step 239700 , training  accuracy 0.5\n",
      "step 239700 , loss : 2.09139\n",
      "step 239700 , validation  accuracy 0.308\n",
      "step 239700 , validation loss : 23.1493\n",
      "step 239800 , training  accuracy 0.566667\n",
      "step 239800 , loss : 2.09785\n",
      "step 239800 , validation  accuracy 0.2956\n",
      "step 239800 , validation loss : 22.4621\n",
      "step 239900 , training  accuracy 0.6\n",
      "step 239900 , loss : 2.05108\n",
      "step 239900 , validation  accuracy 0.3044\n",
      "step 239900 , validation loss : 23.9427\n",
      "step 240000 , training  accuracy 0.533333\n",
      "step 240000 , loss : 2.09327\n",
      "step 240000 , validation  accuracy 0.3114\n",
      "step 240000 , validation loss : 22.8485\n",
      "step 240100 , training  accuracy 0.5\n",
      "step 240100 , loss : 2.03956\n",
      "step 240100 , validation  accuracy 0.3062\n",
      "step 240100 , validation loss : 23.2731\n",
      "step 240200 , training  accuracy 0.5\n",
      "step 240200 , loss : 2.08499\n",
      "step 240200 , validation  accuracy 0.3006\n",
      "step 240200 , validation loss : 23.6934\n",
      "step 240300 , training  accuracy 0.733333\n",
      "step 240300 , loss : 2.00788\n",
      "step 240300 , validation  accuracy 0.3136\n",
      "step 240300 , validation loss : 26.4402\n",
      "step 240400 , training  accuracy 0.566667\n",
      "step 240400 , loss : 2.06867\n",
      "step 240400 , validation  accuracy 0.2882\n",
      "step 240400 , validation loss : 23.9348\n",
      "step 240500 , training  accuracy 0.533333\n",
      "step 240500 , loss : 2.10741\n",
      "step 240500 , validation  accuracy 0.307\n",
      "step 240500 , validation loss : 24.9707\n",
      "step 240600 , training  accuracy 0.466667\n",
      "step 240600 , loss : 2.07046\n",
      "step 240600 , validation  accuracy 0.3018\n",
      "step 240600 , validation loss : 23.6425\n",
      "step 240700 , training  accuracy 0.466667\n",
      "step 240700 , loss : 2.10273\n",
      "step 240700 , validation  accuracy 0.3116\n",
      "step 240700 , validation loss : 23.2827\n",
      "step 240800 , training  accuracy 0.5\n",
      "step 240800 , loss : 2.06626\n",
      "step 240800 , validation  accuracy 0.315\n",
      "step 240800 , validation loss : 24.2929\n",
      "step 240900 , training  accuracy 0.633333\n",
      "step 240900 , loss : 2.0318\n",
      "step 240900 , validation  accuracy 0.3004\n",
      "step 240900 , validation loss : 22.6712\n",
      "step 241000 , training  accuracy 0.633333\n",
      "step 241000 , loss : 2.04338\n",
      "step 241000 , validation  accuracy 0.3076\n",
      "step 241000 , validation loss : 23.0099\n",
      "step 241100 , training  accuracy 0.466667\n",
      "step 241100 , loss : 2.1252\n",
      "step 241100 , validation  accuracy 0.3044\n",
      "step 241100 , validation loss : 23.4173\n",
      "step 241200 , training  accuracy 0.7\n",
      "step 241200 , loss : 2.00854\n",
      "step 241200 , validation  accuracy 0.31\n",
      "step 241200 , validation loss : 23.466\n",
      "step 241300 , training  accuracy 0.4\n",
      "step 241300 , loss : 2.18509\n",
      "step 241300 , validation  accuracy 0.307\n",
      "step 241300 , validation loss : 23.5536\n",
      "step 241400 , training  accuracy 0.5\n",
      "step 241400 , loss : 2.07451\n",
      "step 241400 , validation  accuracy 0.2926\n",
      "step 241400 , validation loss : 21.4072\n",
      "step 241500 , training  accuracy 0.566667\n",
      "step 241500 , loss : 2.03426\n",
      "step 241500 , validation  accuracy 0.3158\n",
      "step 241500 , validation loss : 23.8661\n",
      "step 241600 , training  accuracy 0.633333\n",
      "step 241600 , loss : 2.04766\n",
      "step 241600 , validation  accuracy 0.3106\n",
      "step 241600 , validation loss : 24.3633\n",
      "step 241700 , training  accuracy 0.533333\n",
      "step 241700 , loss : 2.07519\n",
      "step 241700 , validation  accuracy 0.293\n",
      "step 241700 , validation loss : 22.4674\n",
      "step 241800 , training  accuracy 0.566667\n",
      "step 241800 , loss : 2.09549\n",
      "step 241800 , validation  accuracy 0.2976\n",
      "step 241800 , validation loss : 22.7035\n",
      "step 241900 , training  accuracy 0.633333\n",
      "step 241900 , loss : 2.03882\n",
      "step 241900 , validation  accuracy 0.308\n",
      "step 241900 , validation loss : 23.7225\n",
      "step 242000 , training  accuracy 0.466667\n",
      "step 242000 , loss : 2.11937\n",
      "step 242000 , validation  accuracy 0.3012\n",
      "step 242000 , validation loss : 24.0665\n",
      "step 242100 , training  accuracy 0.633333\n",
      "step 242100 , loss : 2.02589\n",
      "step 242100 , validation  accuracy 0.3014\n",
      "step 242100 , validation loss : 23.49\n",
      "step 242200 , training  accuracy 0.533333\n",
      "step 242200 , loss : 2.12446\n",
      "step 242200 , validation  accuracy 0.3112\n",
      "step 242200 , validation loss : 23.7089\n",
      "step 242300 , training  accuracy 0.6\n",
      "step 242300 , loss : 2.09977\n",
      "step 242300 , validation  accuracy 0.3078\n",
      "step 242300 , validation loss : 23.2813\n",
      "step 242400 , training  accuracy 0.633333\n",
      "step 242400 , loss : 2.04761\n",
      "step 242400 , validation  accuracy 0.3114\n",
      "step 242400 , validation loss : 24.0843\n",
      "step 242500 , training  accuracy 0.466667\n",
      "step 242500 , loss : 2.12006\n",
      "step 242500 , validation  accuracy 0.3154\n",
      "step 242500 , validation loss : 24.8009\n",
      "step 242600 , training  accuracy 0.566667\n",
      "step 242600 , loss : 2.06732\n",
      "step 242600 , validation  accuracy 0.3026\n",
      "step 242600 , validation loss : 22.8231\n",
      "step 242700 , training  accuracy 0.4\n",
      "step 242700 , loss : 2.14948\n",
      "step 242700 , validation  accuracy 0.2968\n",
      "step 242700 , validation loss : 23.026\n",
      "step 242800 , training  accuracy 0.4\n",
      "step 242800 , loss : 2.13295\n",
      "step 242800 , validation  accuracy 0.3096\n",
      "step 242800 , validation loss : 24.1763\n",
      "step 242900 , training  accuracy 0.533333\n",
      "step 242900 , loss : 2.05587\n",
      "step 242900 , validation  accuracy 0.3088\n",
      "step 242900 , validation loss : 24.7919\n",
      "step 243000 , training  accuracy 0.566667\n",
      "step 243000 , loss : 2.08169\n",
      "step 243000 , validation  accuracy 0.3066\n",
      "step 243000 , validation loss : 24.5852\n",
      "step 243100 , training  accuracy 0.633333\n",
      "step 243100 , loss : 2.05078\n",
      "step 243100 , validation  accuracy 0.3054\n",
      "step 243100 , validation loss : 24.1745\n",
      "step 243200 , training  accuracy 0.566667\n",
      "step 243200 , loss : 2.06007\n",
      "step 243200 , validation  accuracy 0.3178\n",
      "step 243200 , validation loss : 24.5193\n",
      "step 243300 , training  accuracy 0.5\n",
      "step 243300 , loss : 2.09785\n",
      "step 243300 , validation  accuracy 0.2958\n",
      "step 243300 , validation loss : 23.1743\n",
      "step 243400 , training  accuracy 0.466667\n",
      "step 243400 , loss : 2.11943\n",
      "step 243400 , validation  accuracy 0.3178\n",
      "step 243400 , validation loss : 24.5665\n",
      "step 243500 , training  accuracy 0.633333\n",
      "step 243500 , loss : 2.01548\n",
      "step 243500 , validation  accuracy 0.3116\n",
      "step 243500 , validation loss : 25.6717\n",
      "step 243600 , training  accuracy 0.633333\n",
      "step 243600 , loss : 2.00265\n",
      "step 243600 , validation  accuracy 0.3058\n",
      "step 243600 , validation loss : 24.0042\n",
      "step 243700 , training  accuracy 0.466667\n",
      "step 243700 , loss : 2.09596\n",
      "step 243700 , validation  accuracy 0.2916\n",
      "step 243700 , validation loss : 23.518\n",
      "step 243800 , training  accuracy 0.433333\n",
      "step 243800 , loss : 2.13684\n",
      "step 243800 , validation  accuracy 0.313\n",
      "step 243800 , validation loss : 22.8726\n",
      "step 243900 , training  accuracy 0.633333\n",
      "step 243900 , loss : 1.98272\n",
      "step 243900 , validation  accuracy 0.3122\n",
      "step 243900 , validation loss : 25.5325\n",
      "step 244000 , training  accuracy 0.666667\n",
      "step 244000 , loss : 2.03373\n",
      "step 244000 , validation  accuracy 0.3186\n",
      "step 244000 , validation loss : 24.4917\n",
      "step 244100 , training  accuracy 0.466667\n",
      "step 244100 , loss : 2.09235\n",
      "step 244100 , validation  accuracy 0.3066\n",
      "step 244100 , validation loss : 23.72\n",
      "step 244200 , training  accuracy 0.366667\n",
      "step 244200 , loss : 2.20808\n",
      "step 244200 , validation  accuracy 0.3018\n",
      "step 244200 , validation loss : 23.8569\n",
      "step 244300 , training  accuracy 0.5\n",
      "step 244300 , loss : 2.05002\n",
      "step 244300 , validation  accuracy 0.3174\n",
      "step 244300 , validation loss : 24.1769\n",
      "step 244400 , training  accuracy 0.566667\n",
      "step 244400 , loss : 2.06582\n",
      "step 244400 , validation  accuracy 0.307\n",
      "step 244400 , validation loss : 23.8313\n",
      "step 244500 , training  accuracy 0.433333\n",
      "step 244500 , loss : 2.11301\n",
      "step 244500 , validation  accuracy 0.3102\n",
      "step 244500 , validation loss : 25.5387\n",
      "step 244600 , training  accuracy 0.466667\n",
      "step 244600 , loss : 2.10212\n",
      "step 244600 , validation  accuracy 0.3218\n",
      "step 244600 , validation loss : 26.5746\n",
      "step 244700 , training  accuracy 0.533333\n",
      "step 244700 , loss : 2.06803\n",
      "step 244700 , validation  accuracy 0.3078\n",
      "step 244700 , validation loss : 22.9393\n",
      "step 244800 , training  accuracy 0.466667\n",
      "step 244800 , loss : 2.13026\n",
      "step 244800 , validation  accuracy 0.3168\n",
      "step 244800 , validation loss : 24.1523\n",
      "step 244900 , training  accuracy 0.566667\n",
      "step 244900 , loss : 2.05421\n",
      "step 244900 , validation  accuracy 0.3122\n",
      "step 244900 , validation loss : 23.1124\n",
      "step 245000 , training  accuracy 0.6\n",
      "step 245000 , loss : 2.06168\n",
      "step 245000 , validation  accuracy 0.3068\n",
      "step 245000 , validation loss : 24.3997\n",
      "step 245100 , training  accuracy 0.6\n",
      "step 245100 , loss : 2.03506\n",
      "step 245100 , validation  accuracy 0.3092\n",
      "step 245100 , validation loss : 24.8344\n",
      "step 245200 , training  accuracy 0.6\n",
      "step 245200 , loss : 2.07155\n",
      "step 245200 , validation  accuracy 0.3056\n",
      "step 245200 , validation loss : 23.5062\n",
      "step 245300 , training  accuracy 0.566667\n",
      "step 245300 , loss : 2.06693\n",
      "step 245300 , validation  accuracy 0.3036\n",
      "step 245300 , validation loss : 22.6515\n",
      "step 245400 , training  accuracy 0.533333\n",
      "step 245400 , loss : 2.03507\n",
      "step 245400 , validation  accuracy 0.3188\n",
      "step 245400 , validation loss : 23.4026\n",
      "step 245500 , training  accuracy 0.533333\n",
      "step 245500 , loss : 2.08475\n",
      "step 245500 , validation  accuracy 0.314\n",
      "step 245500 , validation loss : 24.2664\n",
      "step 245600 , training  accuracy 0.6\n",
      "step 245600 , loss : 2.06224\n",
      "step 245600 , validation  accuracy 0.3112\n",
      "step 245600 , validation loss : 25.0131\n",
      "step 245700 , training  accuracy 0.633333\n",
      "step 245700 , loss : 2.04025\n",
      "step 245700 , validation  accuracy 0.307\n",
      "step 245700 , validation loss : 26.0737\n",
      "step 245800 , training  accuracy 0.4\n",
      "step 245800 , loss : 2.1589\n",
      "step 245800 , validation  accuracy 0.3\n",
      "step 245800 , validation loss : 22.5959\n",
      "step 245900 , training  accuracy 0.766667\n",
      "step 245900 , loss : 1.9835\n",
      "step 245900 , validation  accuracy 0.315\n",
      "step 245900 , validation loss : 24.1803\n",
      "step 246000 , training  accuracy 0.466667\n",
      "step 246000 , loss : 2.15341\n",
      "step 246000 , validation  accuracy 0.3156\n",
      "step 246000 , validation loss : 22.1303\n",
      "step 246100 , training  accuracy 0.7\n",
      "step 246100 , loss : 1.99901\n",
      "step 246100 , validation  accuracy 0.3028\n",
      "step 246100 , validation loss : 22.8973\n",
      "step 246200 , training  accuracy 0.5\n",
      "step 246200 , loss : 2.07739\n",
      "step 246200 , validation  accuracy 0.3128\n",
      "step 246200 , validation loss : 24.7931\n",
      "step 246300 , training  accuracy 0.433333\n",
      "step 246300 , loss : 2.16053\n",
      "step 246300 , validation  accuracy 0.305\n",
      "step 246300 , validation loss : 23.2335\n",
      "step 246400 , training  accuracy 0.633333\n",
      "step 246400 , loss : 2.03409\n",
      "step 246400 , validation  accuracy 0.3148\n",
      "step 246400 , validation loss : 23.5426\n",
      "step 246500 , training  accuracy 0.466667\n",
      "step 246500 , loss : 2.08409\n",
      "step 246500 , validation  accuracy 0.3026\n",
      "step 246500 , validation loss : 23.3101\n",
      "step 246600 , training  accuracy 0.433333\n",
      "step 246600 , loss : 2.13364\n",
      "step 246600 , validation  accuracy 0.311\n",
      "step 246600 , validation loss : 23.7692\n",
      "step 246700 , training  accuracy 0.533333\n",
      "step 246700 , loss : 2.08884\n",
      "step 246700 , validation  accuracy 0.3096\n",
      "step 246700 , validation loss : 23.8703\n",
      "step 246800 , training  accuracy 0.566667\n",
      "step 246800 , loss : 2.03101\n",
      "step 246800 , validation  accuracy 0.3152\n",
      "step 246800 , validation loss : 24.2945\n",
      "step 246900 , training  accuracy 0.5\n",
      "step 246900 , loss : 2.04491\n",
      "step 246900 , validation  accuracy 0.321\n",
      "step 246900 , validation loss : 23.7746\n",
      "step 247000 , training  accuracy 0.5\n",
      "step 247000 , loss : 2.10707\n",
      "step 247000 , validation  accuracy 0.31\n",
      "step 247000 , validation loss : 23.7019\n",
      "step 247100 , training  accuracy 0.466667\n",
      "step 247100 , loss : 2.07185\n",
      "step 247100 , validation  accuracy 0.3106\n",
      "step 247100 , validation loss : 24.3256\n",
      "step 247200 , training  accuracy 0.366667\n",
      "step 247200 , loss : 2.11097\n",
      "step 247200 , validation  accuracy 0.302\n",
      "step 247200 , validation loss : 23.9654\n",
      "step 247300 , training  accuracy 0.633333\n",
      "step 247300 , loss : 2.07632\n",
      "step 247300 , validation  accuracy 0.3052\n",
      "step 247300 , validation loss : 22.8382\n",
      "step 247400 , training  accuracy 0.5\n",
      "step 247400 , loss : 2.10314\n",
      "step 247400 , validation  accuracy 0.317\n",
      "step 247400 , validation loss : 24.5049\n",
      "step 247500 , training  accuracy 0.633333\n",
      "step 247500 , loss : 2.03983\n",
      "step 247500 , validation  accuracy 0.314\n",
      "step 247500 , validation loss : 25.1889\n",
      "step 247600 , training  accuracy 0.666667\n",
      "step 247600 , loss : 2.03504\n",
      "step 247600 , validation  accuracy 0.3256\n",
      "step 247600 , validation loss : 24.8056\n",
      "step 247700 , training  accuracy 0.566667\n",
      "step 247700 , loss : 2.04018\n",
      "step 247700 , validation  accuracy 0.3226\n",
      "step 247700 , validation loss : 24.4722\n",
      "step 247800 , training  accuracy 0.5\n",
      "step 247800 , loss : 2.05214\n",
      "step 247800 , validation  accuracy 0.315\n",
      "step 247800 , validation loss : 23.5599\n",
      "step 247900 , training  accuracy 0.6\n",
      "step 247900 , loss : 2.01434\n",
      "step 247900 , validation  accuracy 0.314\n",
      "step 247900 , validation loss : 24.5069\n",
      "step 248000 , training  accuracy 0.466667\n",
      "step 248000 , loss : 2.11072\n",
      "step 248000 , validation  accuracy 0.3054\n",
      "step 248000 , validation loss : 23.1623\n",
      "step 248100 , training  accuracy 0.4\n",
      "step 248100 , loss : 2.1508\n",
      "step 248100 , validation  accuracy 0.323\n",
      "step 248100 , validation loss : 24.2444\n",
      "step 248200 , training  accuracy 0.433333\n",
      "step 248200 , loss : 2.12224\n",
      "step 248200 , validation  accuracy 0.31\n",
      "step 248200 , validation loss : 24.0207\n",
      "step 248300 , training  accuracy 0.5\n",
      "step 248300 , loss : 2.15853\n",
      "step 248300 , validation  accuracy 0.3108\n",
      "step 248300 , validation loss : 23.3265\n",
      "step 248400 , training  accuracy 0.7\n",
      "step 248400 , loss : 1.98386\n",
      "step 248400 , validation  accuracy 0.3124\n",
      "step 248400 , validation loss : 23.0451\n",
      "step 248500 , training  accuracy 0.533333\n",
      "step 248500 , loss : 2.02941\n",
      "step 248500 , validation  accuracy 0.3236\n",
      "step 248500 , validation loss : 23.8537\n",
      "step 248600 , training  accuracy 0.5\n",
      "step 248600 , loss : 2.14152\n",
      "step 248600 , validation  accuracy 0.2958\n",
      "step 248600 , validation loss : 22.4203\n",
      "step 248700 , training  accuracy 0.566667\n",
      "step 248700 , loss : 2.04901\n",
      "step 248700 , validation  accuracy 0.307\n",
      "step 248700 , validation loss : 23.0278\n",
      "step 248800 , training  accuracy 0.533333\n",
      "step 248800 , loss : 2.05949\n",
      "step 248800 , validation  accuracy 0.3086\n",
      "step 248800 , validation loss : 22.2706\n",
      "step 248900 , training  accuracy 0.566667\n",
      "step 248900 , loss : 2.03838\n",
      "step 248900 , validation  accuracy 0.3148\n",
      "step 248900 , validation loss : 24.1489\n",
      "step 249000 , training  accuracy 0.666667\n",
      "step 249000 , loss : 1.9992\n",
      "step 249000 , validation  accuracy 0.324\n",
      "step 249000 , validation loss : 24.3652\n",
      "step 249100 , training  accuracy 0.5\n",
      "step 249100 , loss : 2.03721\n",
      "step 249100 , validation  accuracy 0.302\n",
      "step 249100 , validation loss : 23.3855\n",
      "step 249200 , training  accuracy 0.633333\n",
      "step 249200 , loss : 2.09342\n",
      "step 249200 , validation  accuracy 0.3156\n",
      "step 249200 , validation loss : 23.5428\n",
      "step 249300 , training  accuracy 0.433333\n",
      "step 249300 , loss : 2.12208\n",
      "step 249300 , validation  accuracy 0.3144\n",
      "step 249300 , validation loss : 23.6436\n",
      "step 249400 , training  accuracy 0.533333\n",
      "step 249400 , loss : 2.12606\n",
      "step 249400 , validation  accuracy 0.3092\n",
      "step 249400 , validation loss : 23.2115\n",
      "step 249500 , training  accuracy 0.6\n",
      "step 249500 , loss : 2.00067\n",
      "step 249500 , validation  accuracy 0.3066\n",
      "step 249500 , validation loss : 24.1811\n",
      "step 249600 , training  accuracy 0.433333\n",
      "step 249600 , loss : 2.11272\n",
      "step 249600 , validation  accuracy 0.3074\n",
      "step 249600 , validation loss : 23.7254\n",
      "step 249700 , training  accuracy 0.466667\n",
      "step 249700 , loss : 2.09331\n",
      "step 249700 , validation  accuracy 0.3164\n",
      "step 249700 , validation loss : 23.4977\n",
      "step 249800 , training  accuracy 0.566667\n",
      "step 249800 , loss : 2.0787\n",
      "step 249800 , validation  accuracy 0.312\n",
      "step 249800 , validation loss : 24.4279\n",
      "step 249900 , training  accuracy 0.566667\n",
      "step 249900 , loss : 2.07108\n",
      "step 249900 , validation  accuracy 0.3158\n",
      "step 249900 , validation loss : 23.2609\n",
      "step 250000 , training  accuracy 0.5\n",
      "step 250000 , loss : 2.1365\n",
      "step 250000 , validation  accuracy 0.3108\n",
      "step 250000 , validation loss : 23.3243\n",
      "step 250100 , training  accuracy 0.5\n",
      "step 250100 , loss : 2.09375\n",
      "step 250100 , validation  accuracy 0.3114\n",
      "step 250100 , validation loss : 24.5979\n",
      "step 250200 , training  accuracy 0.466667\n",
      "step 250200 , loss : 2.109\n",
      "step 250200 , validation  accuracy 0.325\n",
      "step 250200 , validation loss : 25.9896\n",
      "step 250300 , training  accuracy 0.7\n",
      "step 250300 , loss : 2.05041\n",
      "step 250300 , validation  accuracy 0.3158\n",
      "step 250300 , validation loss : 25.5661\n",
      "step 250400 , training  accuracy 0.433333\n",
      "step 250400 , loss : 2.07222\n",
      "step 250400 , validation  accuracy 0.316\n",
      "step 250400 , validation loss : 23.9811\n",
      "step 250500 , training  accuracy 0.466667\n",
      "step 250500 , loss : 2.08735\n",
      "step 250500 , validation  accuracy 0.3036\n",
      "step 250500 , validation loss : 24.1954\n",
      "step 250600 , training  accuracy 0.666667\n",
      "step 250600 , loss : 2.03597\n",
      "step 250600 , validation  accuracy 0.3162\n",
      "step 250600 , validation loss : 24.8129\n",
      "step 250700 , training  accuracy 0.5\n",
      "step 250700 , loss : 2.0331\n",
      "step 250700 , validation  accuracy 0.3122\n",
      "step 250700 , validation loss : 24.4158\n",
      "step 250800 , training  accuracy 0.533333\n",
      "step 250800 , loss : 2.11718\n",
      "step 250800 , validation  accuracy 0.3166\n",
      "step 250800 , validation loss : 24.2105\n",
      "step 250900 , training  accuracy 0.5\n",
      "step 250900 , loss : 2.07899\n",
      "step 250900 , validation  accuracy 0.314\n",
      "step 250900 , validation loss : 24.7855\n",
      "step 251000 , training  accuracy 0.5\n",
      "step 251000 , loss : 2.115\n",
      "step 251000 , validation  accuracy 0.2938\n",
      "step 251000 , validation loss : 23.0293\n",
      "step 251100 , training  accuracy 0.433333\n",
      "step 251100 , loss : 2.13731\n",
      "step 251100 , validation  accuracy 0.3016\n",
      "step 251100 , validation loss : 25.6461\n",
      "step 251200 , training  accuracy 0.6\n",
      "step 251200 , loss : 2.09877\n",
      "step 251200 , validation  accuracy 0.299\n",
      "step 251200 , validation loss : 25.5126\n",
      "step 251300 , training  accuracy 0.433333\n",
      "step 251300 , loss : 2.1333\n",
      "step 251300 , validation  accuracy 0.3114\n",
      "step 251300 , validation loss : 23.9282\n",
      "step 251400 , training  accuracy 0.666667\n",
      "step 251400 , loss : 2.0914\n",
      "step 251400 , validation  accuracy 0.3206\n",
      "step 251400 , validation loss : 23.5088\n",
      "step 251500 , training  accuracy 0.566667\n",
      "step 251500 , loss : 2.04044\n",
      "step 251500 , validation  accuracy 0.3108\n",
      "step 251500 , validation loss : 24.3239\n",
      "step 251600 , training  accuracy 0.5\n",
      "step 251600 , loss : 2.10451\n",
      "step 251600 , validation  accuracy 0.3046\n",
      "step 251600 , validation loss : 24.1118\n",
      "step 251700 , training  accuracy 0.366667\n",
      "step 251700 , loss : 2.17309\n",
      "step 251700 , validation  accuracy 0.3144\n",
      "step 251700 , validation loss : 25.1155\n",
      "step 251800 , training  accuracy 0.533333\n",
      "step 251800 , loss : 2.04815\n",
      "step 251800 , validation  accuracy 0.3174\n",
      "step 251800 , validation loss : 24.2763\n",
      "step 251900 , training  accuracy 0.6\n",
      "step 251900 , loss : 2.04254\n",
      "step 251900 , validation  accuracy 0.3158\n",
      "step 251900 , validation loss : 23.8392\n",
      "step 252000 , training  accuracy 0.5\n",
      "step 252000 , loss : 2.04726\n",
      "step 252000 , validation  accuracy 0.3086\n",
      "step 252000 , validation loss : 24.6314\n",
      "step 252100 , training  accuracy 0.466667\n",
      "step 252100 , loss : 2.10969\n",
      "step 252100 , validation  accuracy 0.2982\n",
      "step 252100 , validation loss : 23.0519\n",
      "step 252200 , training  accuracy 0.666667\n",
      "step 252200 , loss : 2.05801\n",
      "step 252200 , validation  accuracy 0.3038\n",
      "step 252200 , validation loss : 23.6995\n",
      "step 252300 , training  accuracy 0.566667\n",
      "step 252300 , loss : 2.12453\n",
      "step 252300 , validation  accuracy 0.3112\n",
      "step 252300 , validation loss : 22.8339\n",
      "step 252400 , training  accuracy 0.633333\n",
      "step 252400 , loss : 1.966\n",
      "step 252400 , validation  accuracy 0.3246\n",
      "step 252400 , validation loss : 24.3467\n",
      "step 252500 , training  accuracy 0.666667\n",
      "step 252500 , loss : 2.02509\n",
      "step 252500 , validation  accuracy 0.3226\n",
      "step 252500 , validation loss : 25.6989\n",
      "step 252600 , training  accuracy 0.6\n",
      "step 252600 , loss : 2.07942\n",
      "step 252600 , validation  accuracy 0.306\n",
      "step 252600 , validation loss : 24.1003\n",
      "step 252700 , training  accuracy 0.466667\n",
      "step 252700 , loss : 2.11597\n",
      "step 252700 , validation  accuracy 0.3144\n",
      "step 252700 , validation loss : 24.8702\n",
      "step 252800 , training  accuracy 0.433333\n",
      "step 252800 , loss : 2.14476\n",
      "step 252800 , validation  accuracy 0.3118\n",
      "step 252800 , validation loss : 24.4196\n",
      "step 252900 , training  accuracy 0.466667\n",
      "step 252900 , loss : 2.11277\n",
      "step 252900 , validation  accuracy 0.3084\n",
      "step 252900 , validation loss : 24.0834\n",
      "step 253000 , training  accuracy 0.566667\n",
      "step 253000 , loss : 2.05698\n",
      "step 253000 , validation  accuracy 0.3242\n",
      "step 253000 , validation loss : 26.4089\n",
      "step 253100 , training  accuracy 0.633333\n",
      "step 253100 , loss : 2.03361\n",
      "step 253100 , validation  accuracy 0.318\n",
      "step 253100 , validation loss : 23.5313\n",
      "step 253200 , training  accuracy 0.5\n",
      "step 253200 , loss : 2.07715\n",
      "step 253200 , validation  accuracy 0.299\n",
      "step 253200 , validation loss : 23.7661\n",
      "step 253300 , training  accuracy 0.5\n",
      "step 253300 , loss : 2.06631\n",
      "step 253300 , validation  accuracy 0.3146\n",
      "step 253300 , validation loss : 25.4753\n",
      "step 253400 , training  accuracy 0.566667\n",
      "step 253400 , loss : 2.05835\n",
      "step 253400 , validation  accuracy 0.3044\n",
      "step 253400 , validation loss : 24.4466\n",
      "step 253500 , training  accuracy 0.433333\n",
      "step 253500 , loss : 2.13083\n",
      "step 253500 , validation  accuracy 0.3014\n",
      "step 253500 , validation loss : 24.9498\n",
      "step 253600 , training  accuracy 0.566667\n",
      "step 253600 , loss : 2.1034\n",
      "step 253600 , validation  accuracy 0.3052\n",
      "step 253600 , validation loss : 23.2789\n",
      "step 253700 , training  accuracy 0.533333\n",
      "step 253700 , loss : 2.06876\n",
      "step 253700 , validation  accuracy 0.3188\n",
      "step 253700 , validation loss : 24.541\n",
      "step 253800 , training  accuracy 0.6\n",
      "step 253800 , loss : 2.02653\n",
      "step 253800 , validation  accuracy 0.3034\n",
      "step 253800 , validation loss : 23.8899\n",
      "step 253900 , training  accuracy 0.8\n",
      "step 253900 , loss : 1.95122\n",
      "step 253900 , validation  accuracy 0.3206\n",
      "step 253900 , validation loss : 23.5927\n",
      "step 254000 , training  accuracy 0.5\n",
      "step 254000 , loss : 2.06928\n",
      "step 254000 , validation  accuracy 0.3016\n",
      "step 254000 , validation loss : 24.4013\n",
      "step 254100 , training  accuracy 0.733333\n",
      "step 254100 , loss : 1.99045\n",
      "step 254100 , validation  accuracy 0.3098\n",
      "step 254100 , validation loss : 24.4034\n",
      "step 254200 , training  accuracy 0.6\n",
      "step 254200 , loss : 2.05414\n",
      "step 254200 , validation  accuracy 0.3172\n",
      "step 254200 , validation loss : 24.4076\n",
      "step 254300 , training  accuracy 0.433333\n",
      "step 254300 , loss : 2.08219\n",
      "step 254300 , validation  accuracy 0.3184\n",
      "step 254300 , validation loss : 24.9803\n",
      "step 254400 , training  accuracy 0.633333\n",
      "step 254400 , loss : 2.04236\n",
      "step 254400 , validation  accuracy 0.2938\n",
      "step 254400 , validation loss : 23.048\n",
      "step 254500 , training  accuracy 0.633333\n",
      "step 254500 , loss : 1.98275\n",
      "step 254500 , validation  accuracy 0.3092\n",
      "step 254500 , validation loss : 25.3053\n",
      "step 254600 , training  accuracy 0.6\n",
      "step 254600 , loss : 2.07953\n",
      "step 254600 , validation  accuracy 0.31\n",
      "step 254600 , validation loss : 25.3142\n",
      "step 254700 , training  accuracy 0.433333\n",
      "step 254700 , loss : 2.07382\n",
      "step 254700 , validation  accuracy 0.3054\n",
      "step 254700 , validation loss : 24.1312\n",
      "step 254800 , training  accuracy 0.566667\n",
      "step 254800 , loss : 2.0532\n",
      "step 254800 , validation  accuracy 0.3058\n",
      "step 254800 , validation loss : 24.5342\n",
      "step 254900 , training  accuracy 0.433333\n",
      "step 254900 , loss : 2.09396\n",
      "step 254900 , validation  accuracy 0.2992\n",
      "step 254900 , validation loss : 23.0576\n",
      "step 255000 , training  accuracy 0.566667\n",
      "step 255000 , loss : 2.05036\n",
      "step 255000 , validation  accuracy 0.2978\n",
      "step 255000 , validation loss : 22.2583\n",
      "step 255100 , training  accuracy 0.466667\n",
      "step 255100 , loss : 2.11522\n",
      "step 255100 , validation  accuracy 0.2914\n",
      "step 255100 , validation loss : 22.1599\n",
      "step 255200 , training  accuracy 0.366667\n",
      "step 255200 , loss : 2.12361\n",
      "step 255200 , validation  accuracy 0.326\n",
      "step 255200 , validation loss : 25.1819\n",
      "step 255300 , training  accuracy 0.6\n",
      "step 255300 , loss : 2.09803\n",
      "step 255300 , validation  accuracy 0.3078\n",
      "step 255300 , validation loss : 22.7408\n",
      "step 255400 , training  accuracy 0.566667\n",
      "step 255400 , loss : 2.07774\n",
      "step 255400 , validation  accuracy 0.3118\n",
      "step 255400 , validation loss : 22.9266\n",
      "step 255500 , training  accuracy 0.566667\n",
      "step 255500 , loss : 2.12795\n",
      "step 255500 , validation  accuracy 0.3004\n",
      "step 255500 , validation loss : 21.6652\n",
      "step 255600 , training  accuracy 0.466667\n",
      "step 255600 , loss : 2.11709\n",
      "step 255600 , validation  accuracy 0.3058\n",
      "step 255600 , validation loss : 22.9458\n",
      "step 255700 , training  accuracy 0.5\n",
      "step 255700 , loss : 2.09678\n",
      "step 255700 , validation  accuracy 0.3134\n",
      "step 255700 , validation loss : 25.0217\n",
      "step 255800 , training  accuracy 0.7\n",
      "step 255800 , loss : 2.04582\n",
      "step 255800 , validation  accuracy 0.2996\n",
      "step 255800 , validation loss : 22.4558\n",
      "step 255900 , training  accuracy 0.566667\n",
      "step 255900 , loss : 2.14521\n",
      "step 255900 , validation  accuracy 0.2938\n",
      "step 255900 , validation loss : 22.8515\n",
      "step 256000 , training  accuracy 0.533333\n",
      "step 256000 , loss : 2.12225\n",
      "step 256000 , validation  accuracy 0.304\n",
      "step 256000 , validation loss : 24.5018\n",
      "step 256100 , training  accuracy 0.6\n",
      "step 256100 , loss : 2.06401\n",
      "step 256100 , validation  accuracy 0.3036\n",
      "step 256100 , validation loss : 24.3168\n",
      "step 256200 , training  accuracy 0.633333\n",
      "step 256200 , loss : 2.07937\n",
      "step 256200 , validation  accuracy 0.3136\n",
      "step 256200 , validation loss : 24.2194\n",
      "step 256300 , training  accuracy 0.633333\n",
      "step 256300 , loss : 2.04958\n",
      "step 256300 , validation  accuracy 0.305\n",
      "step 256300 , validation loss : 23.6149\n",
      "step 256400 , training  accuracy 0.466667\n",
      "step 256400 , loss : 2.1242\n",
      "step 256400 , validation  accuracy 0.3052\n",
      "step 256400 , validation loss : 22.1835\n",
      "step 256500 , training  accuracy 0.4\n",
      "step 256500 , loss : 2.11896\n",
      "step 256500 , validation  accuracy 0.2914\n",
      "step 256500 , validation loss : 21.8067\n",
      "step 256600 , training  accuracy 0.533333\n",
      "step 256600 , loss : 2.07255\n",
      "step 256600 , validation  accuracy 0.307\n",
      "step 256600 , validation loss : 24.1347\n",
      "step 256700 , training  accuracy 0.6\n",
      "step 256700 , loss : 2.03113\n",
      "step 256700 , validation  accuracy 0.312\n",
      "step 256700 , validation loss : 24.7662\n",
      "step 256800 , training  accuracy 0.466667\n",
      "step 256800 , loss : 2.14617\n",
      "step 256800 , validation  accuracy 0.3162\n",
      "step 256800 , validation loss : 24.6913\n",
      "step 256900 , training  accuracy 0.5\n",
      "step 256900 , loss : 2.0791\n",
      "step 256900 , validation  accuracy 0.2978\n",
      "step 256900 , validation loss : 23.3524\n",
      "step 257000 , training  accuracy 0.633333\n",
      "step 257000 , loss : 2.0725\n",
      "step 257000 , validation  accuracy 0.3128\n",
      "step 257000 , validation loss : 24.9132\n",
      "step 257100 , training  accuracy 0.4\n",
      "step 257100 , loss : 2.27254\n",
      "step 257100 , validation  accuracy 0.2854\n",
      "step 257100 , validation loss : 23.8221\n",
      "step 257200 , training  accuracy 0.5\n",
      "step 257200 , loss : 2.09758\n",
      "step 257200 , validation  accuracy 0.3018\n",
      "step 257200 , validation loss : 23.4628\n",
      "step 257300 , training  accuracy 0.566667\n",
      "step 257300 , loss : 2.03529\n",
      "step 257300 , validation  accuracy 0.3128\n",
      "step 257300 , validation loss : 24.1892\n",
      "step 257400 , training  accuracy 0.5\n",
      "step 257400 , loss : 2.14009\n",
      "step 257400 , validation  accuracy 0.2898\n",
      "step 257400 , validation loss : 21.3918\n",
      "step 257500 , training  accuracy 0.466667\n",
      "step 257500 , loss : 2.06516\n",
      "step 257500 , validation  accuracy 0.3062\n",
      "step 257500 , validation loss : 23.1111\n",
      "step 257600 , training  accuracy 0.633333\n",
      "step 257600 , loss : 2.04232\n",
      "step 257600 , validation  accuracy 0.3026\n",
      "step 257600 , validation loss : 24.745\n",
      "step 257700 , training  accuracy 0.633333\n",
      "step 257700 , loss : 1.99907\n",
      "step 257700 , validation  accuracy 0.2984\n",
      "step 257700 , validation loss : 24.7048\n",
      "step 257800 , training  accuracy 0.533333\n",
      "step 257800 , loss : 2.04868\n",
      "step 257800 , validation  accuracy 0.3022\n",
      "step 257800 , validation loss : 23.0496\n",
      "step 257900 , training  accuracy 0.566667\n",
      "step 257900 , loss : 2.07695\n",
      "step 257900 , validation  accuracy 0.2962\n",
      "step 257900 , validation loss : 22.9005\n",
      "step 258000 , training  accuracy 0.5\n",
      "step 258000 , loss : 2.12531\n",
      "step 258000 , validation  accuracy 0.2958\n",
      "step 258000 , validation loss : 22.5788\n",
      "step 258100 , training  accuracy 0.366667\n",
      "step 258100 , loss : 2.18925\n",
      "step 258100 , validation  accuracy 0.3112\n",
      "step 258100 , validation loss : 23.094\n",
      "step 258200 , training  accuracy 0.533333\n",
      "step 258200 , loss : 2.13011\n",
      "step 258200 , validation  accuracy 0.301\n",
      "step 258200 , validation loss : 23.6092\n",
      "step 258300 , training  accuracy 0.633333\n",
      "step 258300 , loss : 2.01257\n",
      "step 258300 , validation  accuracy 0.3102\n",
      "step 258300 , validation loss : 23.8757\n",
      "step 258400 , training  accuracy 0.5\n",
      "step 258400 , loss : 2.11101\n",
      "step 258400 , validation  accuracy 0.303\n",
      "step 258400 , validation loss : 23.2239\n",
      "step 258500 , training  accuracy 0.566667\n",
      "step 258500 , loss : 2.08922\n",
      "step 258500 , validation  accuracy 0.3066\n",
      "step 258500 , validation loss : 24.6542\n",
      "step 258600 , training  accuracy 0.633333\n",
      "step 258600 , loss : 2.09893\n",
      "step 258600 , validation  accuracy 0.3076\n",
      "step 258600 , validation loss : 24.4302\n",
      "step 258700 , training  accuracy 0.566667\n",
      "step 258700 , loss : 2.10189\n",
      "step 258700 , validation  accuracy 0.3068\n",
      "step 258700 , validation loss : 24.0292\n",
      "step 258800 , training  accuracy 0.633333\n",
      "step 258800 , loss : 2.05861\n",
      "step 258800 , validation  accuracy 0.3068\n",
      "step 258800 , validation loss : 24.3988\n",
      "step 258900 , training  accuracy 0.6\n",
      "step 258900 , loss : 1.99981\n",
      "step 258900 , validation  accuracy 0.3156\n",
      "step 258900 , validation loss : 23.8315\n",
      "step 259000 , training  accuracy 0.5\n",
      "step 259000 , loss : 2.07934\n",
      "step 259000 , validation  accuracy 0.2984\n",
      "step 259000 , validation loss : 23.4083\n",
      "step 259100 , training  accuracy 0.533333\n",
      "step 259100 , loss : 2.04966\n",
      "step 259100 , validation  accuracy 0.3124\n",
      "step 259100 , validation loss : 24.7813\n",
      "step 259200 , training  accuracy 0.5\n",
      "step 259200 , loss : 2.08497\n",
      "step 259200 , validation  accuracy 0.3232\n",
      "step 259200 , validation loss : 25.1209\n",
      "step 259300 , training  accuracy 0.6\n",
      "step 259300 , loss : 2.04637\n",
      "step 259300 , validation  accuracy 0.3036\n",
      "step 259300 , validation loss : 24.5959\n",
      "step 259400 , training  accuracy 0.6\n",
      "step 259400 , loss : 2.0299\n",
      "step 259400 , validation  accuracy 0.3018\n",
      "step 259400 , validation loss : 23.7872\n",
      "step 259500 , training  accuracy 0.6\n",
      "step 259500 , loss : 2.05907\n",
      "step 259500 , validation  accuracy 0.317\n",
      "step 259500 , validation loss : 25.6096\n",
      "step 259600 , training  accuracy 0.333333\n",
      "step 259600 , loss : 2.17607\n",
      "step 259600 , validation  accuracy 0.2996\n",
      "step 259600 , validation loss : 23.502\n",
      "step 259700 , training  accuracy 0.533333\n",
      "step 259700 , loss : 2.03679\n",
      "step 259700 , validation  accuracy 0.3056\n",
      "step 259700 , validation loss : 24.0551\n",
      "step 259800 , training  accuracy 0.533333\n",
      "step 259800 , loss : 2.05039\n",
      "step 259800 , validation  accuracy 0.3172\n",
      "step 259800 , validation loss : 23.4607\n",
      "step 259900 , training  accuracy 0.566667\n",
      "step 259900 , loss : 2.14609\n",
      "step 259900 , validation  accuracy 0.3052\n",
      "step 259900 , validation loss : 22.8567\n",
      "step 260000 , training  accuracy 0.633333\n",
      "step 260000 , loss : 2.04946\n",
      "step 260000 , validation  accuracy 0.307\n",
      "step 260000 , validation loss : 25.5331\n",
      "step 260100 , training  accuracy 0.6\n",
      "step 260100 , loss : 2.01569\n",
      "step 260100 , validation  accuracy 0.3202\n",
      "step 260100 , validation loss : 23.2401\n",
      "step 260200 , training  accuracy 0.6\n",
      "step 260200 , loss : 2.06104\n",
      "step 260200 , validation  accuracy 0.3162\n",
      "step 260200 , validation loss : 25.851\n",
      "step 260300 , training  accuracy 0.6\n",
      "step 260300 , loss : 2.07699\n",
      "step 260300 , validation  accuracy 0.315\n",
      "step 260300 , validation loss : 23.7942\n",
      "step 260400 , training  accuracy 0.533333\n",
      "step 260400 , loss : 2.09393\n",
      "step 260400 , validation  accuracy 0.3244\n",
      "step 260400 , validation loss : 23.6127\n",
      "step 260500 , training  accuracy 0.533333\n",
      "step 260500 , loss : 2.06213\n",
      "step 260500 , validation  accuracy 0.307\n",
      "step 260500 , validation loss : 24.0858\n",
      "step 260600 , training  accuracy 0.6\n",
      "step 260600 , loss : 2.05948\n",
      "step 260600 , validation  accuracy 0.3188\n",
      "step 260600 , validation loss : 25.4137\n",
      "step 260700 , training  accuracy 0.566667\n",
      "step 260700 , loss : 2.01284\n",
      "step 260700 , validation  accuracy 0.3096\n",
      "step 260700 , validation loss : 25.0782\n",
      "step 260800 , training  accuracy 0.433333\n",
      "step 260800 , loss : 2.13492\n",
      "step 260800 , validation  accuracy 0.3084\n",
      "step 260800 , validation loss : 23.8442\n",
      "step 260900 , training  accuracy 0.533333\n",
      "step 260900 , loss : 2.01877\n",
      "step 260900 , validation  accuracy 0.31\n",
      "step 260900 , validation loss : 23.7517\n",
      "step 261000 , training  accuracy 0.433333\n",
      "step 261000 , loss : 2.09805\n",
      "step 261000 , validation  accuracy 0.307\n",
      "step 261000 , validation loss : 24.7812\n",
      "step 261100 , training  accuracy 0.466667\n",
      "step 261100 , loss : 2.11477\n",
      "step 261100 , validation  accuracy 0.316\n",
      "step 261100 , validation loss : 25.7134\n",
      "step 261200 , training  accuracy 0.5\n",
      "step 261200 , loss : 2.04183\n",
      "step 261200 , validation  accuracy 0.3072\n",
      "step 261200 , validation loss : 23.552\n",
      "step 261300 , training  accuracy 0.6\n",
      "step 261300 , loss : 2.0709\n",
      "step 261300 , validation  accuracy 0.3154\n",
      "step 261300 , validation loss : 23.8476\n",
      "step 261400 , training  accuracy 0.633333\n",
      "step 261400 , loss : 2.03258\n",
      "step 261400 , validation  accuracy 0.3234\n",
      "step 261400 , validation loss : 25.0973\n",
      "step 261500 , training  accuracy 0.533333\n",
      "step 261500 , loss : 2.11511\n",
      "step 261500 , validation  accuracy 0.3094\n",
      "step 261500 , validation loss : 23.8411\n",
      "step 261600 , training  accuracy 0.6\n",
      "step 261600 , loss : 2.04955\n",
      "step 261600 , validation  accuracy 0.3174\n",
      "step 261600 , validation loss : 25.7937\n",
      "step 261700 , training  accuracy 0.433333\n",
      "step 261700 , loss : 2.11452\n",
      "step 261700 , validation  accuracy 0.3124\n",
      "step 261700 , validation loss : 23.1987\n",
      "step 261800 , training  accuracy 0.6\n",
      "step 261800 , loss : 2.00673\n",
      "step 261800 , validation  accuracy 0.3036\n",
      "step 261800 , validation loss : 23.9722\n",
      "step 261900 , training  accuracy 0.6\n",
      "step 261900 , loss : 2.06346\n",
      "step 261900 , validation  accuracy 0.3136\n",
      "step 261900 , validation loss : 22.5939\n",
      "step 262000 , training  accuracy 0.533333\n",
      "step 262000 , loss : 2.03679\n",
      "step 262000 , validation  accuracy 0.3032\n",
      "step 262000 , validation loss : 23.752\n",
      "step 262100 , training  accuracy 0.566667\n",
      "step 262100 , loss : 2.0208\n",
      "step 262100 , validation  accuracy 0.3158\n",
      "step 262100 , validation loss : 25.9129\n",
      "step 262200 , training  accuracy 0.666667\n",
      "step 262200 , loss : 2.0408\n",
      "step 262200 , validation  accuracy 0.3146\n",
      "step 262200 , validation loss : 24.7564\n",
      "step 262300 , training  accuracy 0.533333\n",
      "step 262300 , loss : 2.06848\n",
      "step 262300 , validation  accuracy 0.311\n",
      "step 262300 , validation loss : 24.2488\n",
      "step 262400 , training  accuracy 0.566667\n",
      "step 262400 , loss : 2.0688\n",
      "step 262400 , validation  accuracy 0.3076\n",
      "step 262400 , validation loss : 23.4102\n",
      "step 262500 , training  accuracy 0.533333\n",
      "step 262500 , loss : 2.06544\n",
      "step 262500 , validation  accuracy 0.2918\n",
      "step 262500 , validation loss : 23.1978\n",
      "step 262600 , training  accuracy 0.566667\n",
      "step 262600 , loss : 2.07139\n",
      "step 262600 , validation  accuracy 0.3124\n",
      "step 262600 , validation loss : 23.1332\n",
      "step 262700 , training  accuracy 0.766667\n",
      "step 262700 , loss : 2.02948\n",
      "step 262700 , validation  accuracy 0.3154\n",
      "step 262700 , validation loss : 22.9501\n",
      "step 262800 , training  accuracy 0.333333\n",
      "step 262800 , loss : 2.1303\n",
      "step 262800 , validation  accuracy 0.3008\n",
      "step 262800 , validation loss : 22.5503\n",
      "step 262900 , training  accuracy 0.566667\n",
      "step 262900 , loss : 2.08065\n",
      "step 262900 , validation  accuracy 0.2888\n",
      "step 262900 , validation loss : 22.6022\n",
      "step 263000 , training  accuracy 0.633333\n",
      "step 263000 , loss : 1.99568\n",
      "step 263000 , validation  accuracy 0.3074\n",
      "step 263000 , validation loss : 24.1649\n",
      "step 263100 , training  accuracy 0.633333\n",
      "step 263100 , loss : 2.04445\n",
      "step 263100 , validation  accuracy 0.3104\n",
      "step 263100 , validation loss : 25.2935\n",
      "step 263200 , training  accuracy 0.533333\n",
      "step 263200 , loss : 2.04622\n",
      "step 263200 , validation  accuracy 0.3194\n",
      "step 263200 , validation loss : 23.6488\n",
      "step 263300 , training  accuracy 0.6\n",
      "step 263300 , loss : 2.11512\n",
      "step 263300 , validation  accuracy 0.3096\n",
      "step 263300 , validation loss : 23.3894\n",
      "step 263400 , training  accuracy 0.566667\n",
      "step 263400 , loss : 2.07442\n",
      "step 263400 , validation  accuracy 0.316\n",
      "step 263400 , validation loss : 25.081\n",
      "step 263500 , training  accuracy 0.466667\n",
      "step 263500 , loss : 2.16843\n",
      "step 263500 , validation  accuracy 0.2988\n",
      "step 263500 , validation loss : 23.2207\n",
      "step 263600 , training  accuracy 0.633333\n",
      "step 263600 , loss : 2.00346\n",
      "step 263600 , validation  accuracy 0.3216\n",
      "step 263600 , validation loss : 26.2201\n",
      "step 263700 , training  accuracy 0.5\n",
      "step 263700 , loss : 2.13439\n",
      "step 263700 , validation  accuracy 0.2952\n",
      "step 263700 , validation loss : 23.4171\n",
      "step 263800 , training  accuracy 0.533333\n",
      "step 263800 , loss : 2.0899\n",
      "step 263800 , validation  accuracy 0.2972\n",
      "step 263800 , validation loss : 23.7314\n",
      "step 263900 , training  accuracy 0.4\n",
      "step 263900 , loss : 2.1543\n",
      "step 263900 , validation  accuracy 0.3218\n",
      "step 263900 , validation loss : 24.7157\n",
      "step 264000 , training  accuracy 0.6\n",
      "step 264000 , loss : 2.0674\n",
      "step 264000 , validation  accuracy 0.3032\n",
      "step 264000 , validation loss : 24.0026\n",
      "step 264100 , training  accuracy 0.566667\n",
      "step 264100 , loss : 2.07016\n",
      "step 264100 , validation  accuracy 0.3016\n",
      "step 264100 , validation loss : 24.1662\n",
      "step 264200 , training  accuracy 0.533333\n",
      "step 264200 , loss : 2.05867\n",
      "step 264200 , validation  accuracy 0.309\n",
      "step 264200 , validation loss : 23.9019\n",
      "step 264300 , training  accuracy 0.6\n",
      "step 264300 , loss : 2.06102\n",
      "step 264300 , validation  accuracy 0.3244\n",
      "step 264300 , validation loss : 24.7132\n",
      "step 264400 , training  accuracy 0.766667\n",
      "step 264400 , loss : 2.01526\n",
      "step 264400 , validation  accuracy 0.3148\n",
      "step 264400 , validation loss : 24.5986\n",
      "step 264500 , training  accuracy 0.566667\n",
      "step 264500 , loss : 2.08974\n",
      "step 264500 , validation  accuracy 0.3074\n",
      "step 264500 , validation loss : 23.8929\n",
      "step 264600 , training  accuracy 0.533333\n",
      "step 264600 , loss : 2.09519\n",
      "step 264600 , validation  accuracy 0.3022\n",
      "step 264600 , validation loss : 23.5835\n",
      "step 264700 , training  accuracy 0.466667\n",
      "step 264700 , loss : 2.07849\n",
      "step 264700 , validation  accuracy 0.3022\n",
      "step 264700 , validation loss : 23.9601\n",
      "step 264800 , training  accuracy 0.5\n",
      "step 264800 , loss : 2.10148\n",
      "step 264800 , validation  accuracy 0.2992\n",
      "step 264800 , validation loss : 22.9846\n",
      "step 264900 , training  accuracy 0.366667\n",
      "step 264900 , loss : 2.17889\n",
      "step 264900 , validation  accuracy 0.3206\n",
      "step 264900 , validation loss : 25.5089\n",
      "step 265000 , training  accuracy 0.5\n",
      "step 265000 , loss : 2.0912\n",
      "step 265000 , validation  accuracy 0.3114\n",
      "step 265000 , validation loss : 25.3932\n",
      "step 265100 , training  accuracy 0.6\n",
      "step 265100 , loss : 2.03956\n",
      "step 265100 , validation  accuracy 0.304\n",
      "step 265100 , validation loss : 22.9319\n",
      "step 265200 , training  accuracy 0.6\n",
      "step 265200 , loss : 2.06412\n",
      "step 265200 , validation  accuracy 0.3102\n",
      "step 265200 , validation loss : 23.7658\n",
      "step 265300 , training  accuracy 0.566667\n",
      "step 265300 , loss : 2.04154\n",
      "step 265300 , validation  accuracy 0.3108\n",
      "step 265300 , validation loss : 24.3395\n",
      "step 265400 , training  accuracy 0.6\n",
      "step 265400 , loss : 2.04128\n",
      "step 265400 , validation  accuracy 0.2946\n",
      "step 265400 , validation loss : 24.175\n",
      "step 265500 , training  accuracy 0.5\n",
      "step 265500 , loss : 2.10387\n",
      "step 265500 , validation  accuracy 0.3178\n",
      "step 265500 , validation loss : 24.8722\n",
      "step 265600 , training  accuracy 0.566667\n",
      "step 265600 , loss : 2.05501\n",
      "step 265600 , validation  accuracy 0.3136\n",
      "step 265600 , validation loss : 24.2462\n",
      "step 265700 , training  accuracy 0.533333\n",
      "step 265700 , loss : 2.04353\n",
      "step 265700 , validation  accuracy 0.3128\n",
      "step 265700 , validation loss : 24.9984\n",
      "step 265800 , training  accuracy 0.633333\n",
      "step 265800 , loss : 2.03323\n",
      "step 265800 , validation  accuracy 0.3052\n",
      "step 265800 , validation loss : 24.0632\n",
      "step 265900 , training  accuracy 0.366667\n",
      "step 265900 , loss : 2.16644\n",
      "step 265900 , validation  accuracy 0.3042\n",
      "step 265900 , validation loss : 22.4866\n",
      "step 266000 , training  accuracy 0.333333\n",
      "step 266000 , loss : 2.15014\n",
      "step 266000 , validation  accuracy 0.289\n",
      "step 266000 , validation loss : 21.1648\n",
      "step 266100 , training  accuracy 0.466667\n",
      "step 266100 , loss : 2.12699\n",
      "step 266100 , validation  accuracy 0.316\n",
      "step 266100 , validation loss : 23.4045\n",
      "step 266200 , training  accuracy 0.633333\n",
      "step 266200 , loss : 2.00696\n",
      "step 266200 , validation  accuracy 0.3126\n",
      "step 266200 , validation loss : 25.1818\n",
      "step 266300 , training  accuracy 0.6\n",
      "step 266300 , loss : 2.00287\n",
      "step 266300 , validation  accuracy 0.3152\n",
      "step 266300 , validation loss : 25.631\n",
      "step 266400 , training  accuracy 0.433333\n",
      "step 266400 , loss : 2.06736\n",
      "step 266400 , validation  accuracy 0.3048\n",
      "step 266400 , validation loss : 24.091\n",
      "step 266500 , training  accuracy 0.633333\n",
      "step 266500 , loss : 2.02644\n",
      "step 266500 , validation  accuracy 0.2956\n",
      "step 266500 , validation loss : 23.7294\n",
      "step 266600 , training  accuracy 0.633333\n",
      "step 266600 , loss : 2.05335\n",
      "step 266600 , validation  accuracy 0.3108\n",
      "step 266600 , validation loss : 23.705\n",
      "step 266700 , training  accuracy 0.566667\n",
      "step 266700 , loss : 2.07116\n",
      "step 266700 , validation  accuracy 0.3112\n",
      "step 266700 , validation loss : 24.5021\n",
      "step 266800 , training  accuracy 0.533333\n",
      "step 266800 , loss : 2.03221\n",
      "step 266800 , validation  accuracy 0.3126\n",
      "step 266800 , validation loss : 23.5775\n",
      "step 266900 , training  accuracy 0.533333\n",
      "step 266900 , loss : 2.13611\n",
      "step 266900 , validation  accuracy 0.304\n",
      "step 266900 , validation loss : 22.5208\n",
      "step 267000 , training  accuracy 0.633333\n",
      "step 267000 , loss : 2.0271\n",
      "step 267000 , validation  accuracy 0.3012\n",
      "step 267000 , validation loss : 23.5191\n",
      "step 267100 , training  accuracy 0.6\n",
      "step 267100 , loss : 2.0601\n",
      "step 267100 , validation  accuracy 0.311\n",
      "step 267100 , validation loss : 24.5679\n",
      "step 267200 , training  accuracy 0.4\n",
      "step 267200 , loss : 2.10826\n",
      "step 267200 , validation  accuracy 0.2954\n",
      "step 267200 , validation loss : 24.2726\n",
      "step 267300 , training  accuracy 0.4\n",
      "step 267300 , loss : 2.15056\n",
      "step 267300 , validation  accuracy 0.3146\n",
      "step 267300 , validation loss : 23.8721\n",
      "step 267400 , training  accuracy 0.633333\n",
      "step 267400 , loss : 2.00067\n",
      "step 267400 , validation  accuracy 0.294\n",
      "step 267400 , validation loss : 24.3479\n",
      "step 267500 , training  accuracy 0.633333\n",
      "step 267500 , loss : 2.01671\n",
      "step 267500 , validation  accuracy 0.3048\n",
      "step 267500 , validation loss : 25.0889\n",
      "step 267600 , training  accuracy 0.433333\n",
      "step 267600 , loss : 2.10313\n",
      "step 267600 , validation  accuracy 0.299\n",
      "step 267600 , validation loss : 23.9714\n",
      "step 267700 , training  accuracy 0.533333\n",
      "step 267700 , loss : 2.10967\n",
      "step 267700 , validation  accuracy 0.3102\n",
      "step 267700 , validation loss : 24.0099\n",
      "step 267800 , training  accuracy 0.666667\n",
      "step 267800 , loss : 2.0302\n",
      "step 267800 , validation  accuracy 0.3038\n",
      "step 267800 , validation loss : 24.0828\n",
      "step 267900 , training  accuracy 0.633333\n",
      "step 267900 , loss : 2.02855\n",
      "step 267900 , validation  accuracy 0.3038\n",
      "step 267900 , validation loss : 24.101\n",
      "step 268000 , training  accuracy 0.4\n",
      "step 268000 , loss : 2.2149\n",
      "step 268000 , validation  accuracy 0.277\n",
      "step 268000 , validation loss : 25.0949\n",
      "step 268100 , training  accuracy 0.633333\n",
      "step 268100 , loss : 2.03782\n",
      "step 268100 , validation  accuracy 0.297\n",
      "step 268100 , validation loss : 22.9907\n",
      "step 268200 , training  accuracy 0.333333\n",
      "step 268200 , loss : 2.1479\n",
      "step 268200 , validation  accuracy 0.3028\n",
      "step 268200 , validation loss : 24.42\n",
      "step 268300 , training  accuracy 0.5\n",
      "step 268300 , loss : 2.12356\n",
      "step 268300 , validation  accuracy 0.3134\n",
      "step 268300 , validation loss : 23.6255\n",
      "step 268400 , training  accuracy 0.5\n",
      "step 268400 , loss : 2.09754\n",
      "step 268400 , validation  accuracy 0.3212\n",
      "step 268400 , validation loss : 24.4843\n",
      "step 268500 , training  accuracy 0.5\n",
      "step 268500 , loss : 2.03738\n",
      "step 268500 , validation  accuracy 0.3164\n",
      "step 268500 , validation loss : 23.9177\n",
      "step 268600 , training  accuracy 0.466667\n",
      "step 268600 , loss : 2.19255\n",
      "step 268600 , validation  accuracy 0.2876\n",
      "step 268600 , validation loss : 20.8022\n",
      "step 268700 , training  accuracy 0.6\n",
      "step 268700 , loss : 2.02772\n",
      "step 268700 , validation  accuracy 0.3022\n",
      "step 268700 , validation loss : 24.749\n",
      "step 268800 , training  accuracy 0.633333\n",
      "step 268800 , loss : 2.04728\n",
      "step 268800 , validation  accuracy 0.3002\n",
      "step 268800 , validation loss : 23.6993\n",
      "step 268900 , training  accuracy 0.4\n",
      "step 268900 , loss : 2.11982\n",
      "step 268900 , validation  accuracy 0.3054\n",
      "step 268900 , validation loss : 24.0731\n",
      "step 269000 , training  accuracy 0.466667\n",
      "step 269000 , loss : 2.11692\n",
      "step 269000 , validation  accuracy 0.3034\n",
      "step 269000 , validation loss : 23.0968\n",
      "step 269100 , training  accuracy 0.6\n",
      "step 269100 , loss : 2.04586\n",
      "step 269100 , validation  accuracy 0.321\n",
      "step 269100 , validation loss : 25.29\n",
      "step 269200 , training  accuracy 0.5\n",
      "step 269200 , loss : 2.11685\n",
      "step 269200 , validation  accuracy 0.3138\n",
      "step 269200 , validation loss : 23.996\n",
      "step 269300 , training  accuracy 0.633333\n",
      "step 269300 , loss : 2.00835\n",
      "step 269300 , validation  accuracy 0.3182\n",
      "step 269300 , validation loss : 24.552\n",
      "step 269400 , training  accuracy 0.633333\n",
      "step 269400 , loss : 2.06004\n",
      "step 269400 , validation  accuracy 0.2992\n",
      "step 269400 , validation loss : 22.4611\n",
      "step 269500 , training  accuracy 0.466667\n",
      "step 269500 , loss : 2.10986\n",
      "step 269500 , validation  accuracy 0.2978\n",
      "step 269500 , validation loss : 24.6249\n",
      "step 269600 , training  accuracy 0.466667\n",
      "step 269600 , loss : 2.10709\n",
      "step 269600 , validation  accuracy 0.309\n",
      "step 269600 , validation loss : 23.6045\n",
      "step 269700 , training  accuracy 0.666667\n",
      "step 269700 , loss : 2.01202\n",
      "step 269700 , validation  accuracy 0.3154\n",
      "step 269700 , validation loss : 24.452\n",
      "step 269800 , training  accuracy 0.666667\n",
      "step 269800 , loss : 2.05676\n",
      "step 269800 , validation  accuracy 0.2998\n",
      "step 269800 , validation loss : 23.2907\n",
      "step 269900 , training  accuracy 0.566667\n",
      "step 269900 , loss : 2.02891\n",
      "step 269900 , validation  accuracy 0.3154\n",
      "step 269900 , validation loss : 23.5358\n",
      "step 270000 , training  accuracy 0.6\n",
      "step 270000 , loss : 2.01195\n",
      "step 270000 , validation  accuracy 0.3032\n",
      "step 270000 , validation loss : 25.026\n",
      "step 270100 , training  accuracy 0.666667\n",
      "step 270100 , loss : 1.99069\n",
      "step 270100 , validation  accuracy 0.3162\n",
      "step 270100 , validation loss : 23.4792\n",
      "step 270200 , training  accuracy 0.5\n",
      "step 270200 , loss : 2.06551\n",
      "step 270200 , validation  accuracy 0.3104\n",
      "step 270200 , validation loss : 23.9875\n",
      "step 270300 , training  accuracy 0.533333\n",
      "step 270300 , loss : 2.05742\n",
      "step 270300 , validation  accuracy 0.3136\n",
      "step 270300 , validation loss : 23.7828\n",
      "step 270400 , training  accuracy 0.466667\n",
      "step 270400 , loss : 2.09661\n",
      "step 270400 , validation  accuracy 0.3064\n",
      "step 270400 , validation loss : 23.6869\n",
      "step 270500 , training  accuracy 0.466667\n",
      "step 270500 , loss : 2.09643\n",
      "step 270500 , validation  accuracy 0.3094\n",
      "step 270500 , validation loss : 24.5303\n",
      "step 270600 , training  accuracy 0.5\n",
      "step 270600 , loss : 2.08321\n",
      "step 270600 , validation  accuracy 0.3048\n",
      "step 270600 , validation loss : 23.4165\n",
      "step 270700 , training  accuracy 0.533333\n",
      "step 270700 , loss : 2.04256\n",
      "step 270700 , validation  accuracy 0.3166\n",
      "step 270700 , validation loss : 24.9908\n",
      "step 270800 , training  accuracy 0.533333\n",
      "step 270800 , loss : 2.10153\n",
      "step 270800 , validation  accuracy 0.319\n",
      "step 270800 , validation loss : 25.3333\n",
      "step 270900 , training  accuracy 0.4\n",
      "step 270900 , loss : 2.16877\n",
      "step 270900 , validation  accuracy 0.3098\n",
      "step 270900 , validation loss : 24.0901\n",
      "step 271000 , training  accuracy 0.633333\n",
      "step 271000 , loss : 2.03216\n",
      "step 271000 , validation  accuracy 0.3032\n",
      "step 271000 , validation loss : 24.7602\n",
      "step 271100 , training  accuracy 0.566667\n",
      "step 271100 , loss : 2.09505\n",
      "step 271100 , validation  accuracy 0.3176\n",
      "step 271100 , validation loss : 27.5357\n",
      "step 271200 , training  accuracy 0.5\n",
      "step 271200 , loss : 2.08651\n",
      "step 271200 , validation  accuracy 0.3058\n",
      "step 271200 , validation loss : 23.9156\n",
      "step 271300 , training  accuracy 0.533333\n",
      "step 271300 , loss : 2.09574\n",
      "step 271300 , validation  accuracy 0.3106\n",
      "step 271300 , validation loss : 22.702\n",
      "step 271400 , training  accuracy 0.633333\n",
      "step 271400 , loss : 2.04214\n",
      "step 271400 , validation  accuracy 0.3132\n",
      "step 271400 , validation loss : 24.041\n",
      "step 271500 , training  accuracy 0.533333\n",
      "step 271500 , loss : 2.06644\n",
      "step 271500 , validation  accuracy 0.326\n",
      "step 271500 , validation loss : 25.5138\n",
      "step 271600 , training  accuracy 0.566667\n",
      "step 271600 , loss : 2.09336\n",
      "step 271600 , validation  accuracy 0.304\n",
      "step 271600 , validation loss : 24.119\n",
      "step 271700 , training  accuracy 0.7\n",
      "step 271700 , loss : 1.97366\n",
      "step 271700 , validation  accuracy 0.3222\n",
      "step 271700 , validation loss : 24.2511\n",
      "step 271800 , training  accuracy 0.566667\n",
      "step 271800 , loss : 2.10381\n",
      "step 271800 , validation  accuracy 0.302\n",
      "step 271800 , validation loss : 23.5761\n",
      "step 271900 , training  accuracy 0.7\n",
      "step 271900 , loss : 1.98692\n",
      "step 271900 , validation  accuracy 0.2984\n",
      "step 271900 , validation loss : 23.1374\n",
      "step 272000 , training  accuracy 0.7\n",
      "step 272000 , loss : 2.0084\n",
      "step 272000 , validation  accuracy 0.3104\n",
      "step 272000 , validation loss : 23.2133\n",
      "step 272100 , training  accuracy 0.5\n",
      "step 272100 , loss : 2.07871\n",
      "step 272100 , validation  accuracy 0.315\n",
      "step 272100 , validation loss : 25.5393\n",
      "step 272200 , training  accuracy 0.366667\n",
      "step 272200 , loss : 2.14185\n",
      "step 272200 , validation  accuracy 0.3104\n",
      "step 272200 , validation loss : 23.9812\n",
      "step 272300 , training  accuracy 0.466667\n",
      "step 272300 , loss : 2.15123\n",
      "step 272300 , validation  accuracy 0.3062\n",
      "step 272300 , validation loss : 25.1388\n",
      "step 272400 , training  accuracy 0.666667\n",
      "step 272400 , loss : 1.98114\n",
      "step 272400 , validation  accuracy 0.3162\n",
      "step 272400 , validation loss : 24.038\n",
      "step 272500 , training  accuracy 0.7\n",
      "step 272500 , loss : 2.02338\n",
      "step 272500 , validation  accuracy 0.3124\n",
      "step 272500 , validation loss : 25.0197\n",
      "step 272600 , training  accuracy 0.366667\n",
      "step 272600 , loss : 2.1644\n",
      "step 272600 , validation  accuracy 0.2896\n",
      "step 272600 , validation loss : 22.2453\n",
      "step 272700 , training  accuracy 0.7\n",
      "step 272700 , loss : 2.01895\n",
      "step 272700 , validation  accuracy 0.309\n",
      "step 272700 , validation loss : 23.0105\n",
      "step 272800 , training  accuracy 0.5\n",
      "step 272800 , loss : 2.10467\n",
      "step 272800 , validation  accuracy 0.3054\n",
      "step 272800 , validation loss : 22.9872\n",
      "step 272900 , training  accuracy 0.633333\n",
      "step 272900 , loss : 2.05751\n",
      "step 272900 , validation  accuracy 0.3088\n",
      "step 272900 , validation loss : 22.5791\n",
      "step 273000 , training  accuracy 0.433333\n",
      "step 273000 , loss : 2.09891\n",
      "step 273000 , validation  accuracy 0.3168\n",
      "step 273000 , validation loss : 25.9365\n",
      "step 273100 , training  accuracy 0.6\n",
      "step 273100 , loss : 2.09376\n",
      "step 273100 , validation  accuracy 0.308\n",
      "step 273100 , validation loss : 23.125\n",
      "step 273200 , training  accuracy 0.466667\n",
      "step 273200 , loss : 2.10481\n",
      "step 273200 , validation  accuracy 0.3124\n",
      "step 273200 , validation loss : 24.7852\n",
      "step 273300 , training  accuracy 0.433333\n",
      "step 273300 , loss : 2.11439\n",
      "step 273300 , validation  accuracy 0.3012\n",
      "step 273300 , validation loss : 23.5558\n",
      "step 273400 , training  accuracy 0.5\n",
      "step 273400 , loss : 2.07481\n",
      "step 273400 , validation  accuracy 0.2854\n",
      "step 273400 , validation loss : 22.5367\n",
      "step 273500 , training  accuracy 0.5\n",
      "step 273500 , loss : 2.0487\n",
      "step 273500 , validation  accuracy 0.3004\n",
      "step 273500 , validation loss : 25.5528\n",
      "step 273600 , training  accuracy 0.633333\n",
      "step 273600 , loss : 2.0868\n",
      "step 273600 , validation  accuracy 0.319\n",
      "step 273600 , validation loss : 26.9533\n",
      "step 273700 , training  accuracy 0.666667\n",
      "step 273700 , loss : 2.01084\n",
      "step 273700 , validation  accuracy 0.315\n",
      "step 273700 , validation loss : 24.4959\n",
      "step 273800 , training  accuracy 0.4\n",
      "step 273800 , loss : 2.17914\n",
      "step 273800 , validation  accuracy 0.3016\n",
      "step 273800 , validation loss : 23.516\n",
      "step 273900 , training  accuracy 0.566667\n",
      "step 273900 , loss : 2.07895\n",
      "step 273900 , validation  accuracy 0.3204\n",
      "step 273900 , validation loss : 26.1081\n",
      "step 274000 , training  accuracy 0.5\n",
      "step 274000 , loss : 2.06609\n",
      "step 274000 , validation  accuracy 0.304\n",
      "step 274000 , validation loss : 23.4576\n",
      "step 274100 , training  accuracy 0.5\n",
      "step 274100 , loss : 2.07014\n",
      "step 274100 , validation  accuracy 0.3232\n",
      "step 274100 , validation loss : 26.0755\n",
      "step 274200 , training  accuracy 0.366667\n",
      "step 274200 , loss : 2.10497\n",
      "step 274200 , validation  accuracy 0.3088\n",
      "step 274200 , validation loss : 24.3867\n",
      "step 274300 , training  accuracy 0.666667\n",
      "step 274300 , loss : 2.00135\n",
      "step 274300 , validation  accuracy 0.3034\n",
      "step 274300 , validation loss : 23.9637\n",
      "step 274400 , training  accuracy 0.566667\n",
      "step 274400 , loss : 2.06052\n",
      "step 274400 , validation  accuracy 0.2984\n",
      "step 274400 , validation loss : 23.672\n",
      "step 274500 , training  accuracy 0.6\n",
      "step 274500 , loss : 2.00168\n",
      "step 274500 , validation  accuracy 0.3168\n",
      "step 274500 , validation loss : 24.7214\n",
      "step 274600 , training  accuracy 0.6\n",
      "step 274600 , loss : 2.0564\n",
      "step 274600 , validation  accuracy 0.3146\n",
      "step 274600 , validation loss : 24.7864\n",
      "step 274700 , training  accuracy 0.366667\n",
      "step 274700 , loss : 2.12937\n",
      "step 274700 , validation  accuracy 0.306\n",
      "step 274700 , validation loss : 24.7346\n",
      "step 274800 , training  accuracy 0.566667\n",
      "step 274800 , loss : 2.04087\n",
      "step 274800 , validation  accuracy 0.3076\n",
      "step 274800 , validation loss : 24.0059\n",
      "step 274900 , training  accuracy 0.7\n",
      "step 274900 , loss : 1.99583\n",
      "step 274900 , validation  accuracy 0.3158\n",
      "step 274900 , validation loss : 25.1832\n",
      "step 275000 , training  accuracy 0.566667\n",
      "step 275000 , loss : 2.07842\n",
      "step 275000 , validation  accuracy 0.3156\n",
      "step 275000 , validation loss : 23.6907\n",
      "step 275100 , training  accuracy 0.733333\n",
      "step 275100 , loss : 1.99372\n",
      "step 275100 , validation  accuracy 0.3062\n",
      "step 275100 , validation loss : 23.9242\n",
      "step 275200 , training  accuracy 0.666667\n",
      "step 275200 , loss : 1.97653\n",
      "step 275200 , validation  accuracy 0.3096\n",
      "step 275200 , validation loss : 24.9081\n",
      "step 275300 , training  accuracy 0.7\n",
      "step 275300 , loss : 1.97931\n",
      "step 275300 , validation  accuracy 0.326\n",
      "step 275300 , validation loss : 26.2367\n",
      "step 275400 , training  accuracy 0.533333\n",
      "step 275400 , loss : 2.06672\n",
      "step 275400 , validation  accuracy 0.3066\n",
      "step 275400 , validation loss : 23.564\n",
      "step 275500 , training  accuracy 0.7\n",
      "step 275500 , loss : 2.04426\n",
      "step 275500 , validation  accuracy 0.3124\n",
      "step 275500 , validation loss : 23.7504\n",
      "step 275600 , training  accuracy 0.6\n",
      "step 275600 , loss : 2.0679\n",
      "step 275600 , validation  accuracy 0.3224\n",
      "step 275600 , validation loss : 24.7992\n",
      "step 275700 , training  accuracy 0.433333\n",
      "step 275700 , loss : 2.16377\n",
      "step 275700 , validation  accuracy 0.3206\n",
      "step 275700 , validation loss : 24.1817\n",
      "step 275800 , training  accuracy 0.466667\n",
      "step 275800 , loss : 2.05759\n",
      "step 275800 , validation  accuracy 0.3186\n",
      "step 275800 , validation loss : 24.3698\n",
      "step 275900 , training  accuracy 0.466667\n",
      "step 275900 , loss : 2.1171\n",
      "step 275900 , validation  accuracy 0.317\n",
      "step 275900 , validation loss : 23.7896\n",
      "step 276000 , training  accuracy 0.566667\n",
      "step 276000 , loss : 2.10327\n",
      "step 276000 , validation  accuracy 0.31\n",
      "step 276000 , validation loss : 25.5105\n",
      "step 276100 , training  accuracy 0.466667\n",
      "step 276100 , loss : 2.09343\n",
      "step 276100 , validation  accuracy 0.3104\n",
      "step 276100 , validation loss : 22.4032\n",
      "step 276200 , training  accuracy 0.533333\n",
      "step 276200 , loss : 2.1104\n",
      "step 276200 , validation  accuracy 0.305\n",
      "step 276200 , validation loss : 24.0549\n",
      "step 276300 , training  accuracy 0.466667\n",
      "step 276300 , loss : 2.14556\n",
      "step 276300 , validation  accuracy 0.313\n",
      "step 276300 , validation loss : 24.0177\n",
      "step 276400 , training  accuracy 0.533333\n",
      "step 276400 , loss : 2.06936\n",
      "step 276400 , validation  accuracy 0.3108\n",
      "step 276400 , validation loss : 23.1424\n",
      "step 276500 , training  accuracy 0.466667\n",
      "step 276500 , loss : 2.06111\n",
      "step 276500 , validation  accuracy 0.316\n",
      "step 276500 , validation loss : 24.3646\n",
      "step 276600 , training  accuracy 0.366667\n",
      "step 276600 , loss : 2.22365\n",
      "step 276600 , validation  accuracy 0.3196\n",
      "step 276600 , validation loss : 25.5195\n",
      "step 276700 , training  accuracy 0.633333\n",
      "step 276700 , loss : 2.00513\n",
      "step 276700 , validation  accuracy 0.3148\n",
      "step 276700 , validation loss : 24.5988\n",
      "step 276800 , training  accuracy 0.466667\n",
      "step 276800 , loss : 2.076\n",
      "step 276800 , validation  accuracy 0.2976\n",
      "step 276800 , validation loss : 22.9204\n",
      "step 276900 , training  accuracy 0.466667\n",
      "step 276900 , loss : 2.10247\n",
      "step 276900 , validation  accuracy 0.3034\n",
      "step 276900 , validation loss : 23.4796\n",
      "step 277000 , training  accuracy 0.6\n",
      "step 277000 , loss : 2.0084\n",
      "step 277000 , validation  accuracy 0.3082\n",
      "step 277000 , validation loss : 24.8944\n",
      "step 277100 , training  accuracy 0.433333\n",
      "step 277100 , loss : 2.07403\n",
      "step 277100 , validation  accuracy 0.3098\n",
      "step 277100 , validation loss : 25.5953\n",
      "step 277200 , training  accuracy 0.533333\n",
      "step 277200 , loss : 2.09542\n",
      "step 277200 , validation  accuracy 0.3146\n",
      "step 277200 , validation loss : 25.0365\n",
      "step 277300 , training  accuracy 0.566667\n",
      "step 277300 , loss : 2.07511\n",
      "step 277300 , validation  accuracy 0.2982\n",
      "step 277300 , validation loss : 24.323\n",
      "step 277400 , training  accuracy 0.633333\n",
      "step 277400 , loss : 2.02189\n",
      "step 277400 , validation  accuracy 0.31\n",
      "step 277400 , validation loss : 24.815\n",
      "step 277500 , training  accuracy 0.466667\n",
      "step 277500 , loss : 2.11573\n",
      "step 277500 , validation  accuracy 0.3042\n",
      "step 277500 , validation loss : 25.4985\n",
      "step 277600 , training  accuracy 0.633333\n",
      "step 277600 , loss : 2.04031\n",
      "step 277600 , validation  accuracy 0.3122\n",
      "step 277600 , validation loss : 25.1909\n",
      "step 277700 , training  accuracy 0.533333\n",
      "step 277700 , loss : 2.07438\n",
      "step 277700 , validation  accuracy 0.3034\n",
      "step 277700 , validation loss : 25.573\n",
      "step 277800 , training  accuracy 0.366667\n",
      "step 277800 , loss : 2.14623\n",
      "step 277800 , validation  accuracy 0.3032\n",
      "step 277800 , validation loss : 24.9373\n",
      "step 277900 , training  accuracy 0.733333\n",
      "step 277900 , loss : 1.9713\n",
      "step 277900 , validation  accuracy 0.3138\n",
      "step 277900 , validation loss : 24.8255\n",
      "step 278000 , training  accuracy 0.533333\n",
      "step 278000 , loss : 2.08582\n",
      "step 278000 , validation  accuracy 0.3114\n",
      "step 278000 , validation loss : 24.7811\n",
      "step 278100 , training  accuracy 0.566667\n",
      "step 278100 , loss : 1.97259\n",
      "step 278100 , validation  accuracy 0.3078\n",
      "step 278100 , validation loss : 23.7283\n",
      "step 278200 , training  accuracy 0.466667\n",
      "step 278200 , loss : 2.14379\n",
      "step 278200 , validation  accuracy 0.3078\n",
      "step 278200 , validation loss : 23.0343\n",
      "step 278300 , training  accuracy 0.6\n",
      "step 278300 , loss : 2.08453\n",
      "step 278300 , validation  accuracy 0.3022\n",
      "step 278300 , validation loss : 24.3103\n",
      "step 278400 , training  accuracy 0.6\n",
      "step 278400 , loss : 2.03112\n",
      "step 278400 , validation  accuracy 0.2902\n",
      "step 278400 , validation loss : 23.0373\n",
      "step 278500 , training  accuracy 0.466667\n",
      "step 278500 , loss : 2.09492\n",
      "step 278500 , validation  accuracy 0.3082\n",
      "step 278500 , validation loss : 22.8381\n",
      "step 278600 , training  accuracy 0.4\n",
      "step 278600 , loss : 2.17216\n",
      "step 278600 , validation  accuracy 0.3038\n",
      "step 278600 , validation loss : 23.8356\n",
      "step 278700 , training  accuracy 0.466667\n",
      "step 278700 , loss : 2.15029\n",
      "step 278700 , validation  accuracy 0.3106\n",
      "step 278700 , validation loss : 23.7614\n",
      "step 278800 , training  accuracy 0.533333\n",
      "step 278800 , loss : 2.08578\n",
      "step 278800 , validation  accuracy 0.3132\n",
      "step 278800 , validation loss : 24.6117\n",
      "step 278900 , training  accuracy 0.533333\n",
      "step 278900 , loss : 2.09901\n",
      "step 278900 , validation  accuracy 0.3076\n",
      "step 278900 , validation loss : 23.898\n",
      "step 279000 , training  accuracy 0.6\n",
      "step 279000 , loss : 2.05511\n",
      "step 279000 , validation  accuracy 0.3126\n",
      "step 279000 , validation loss : 24.6766\n",
      "step 279100 , training  accuracy 0.7\n",
      "step 279100 , loss : 2.00664\n",
      "step 279100 , validation  accuracy 0.309\n",
      "step 279100 , validation loss : 25.7246\n",
      "step 279200 , training  accuracy 0.566667\n",
      "step 279200 , loss : 2.06405\n",
      "step 279200 , validation  accuracy 0.3168\n",
      "step 279200 , validation loss : 24.8982\n",
      "step 279300 , training  accuracy 0.466667\n",
      "step 279300 , loss : 2.12065\n",
      "step 279300 , validation  accuracy 0.3048\n",
      "step 279300 , validation loss : 23.396\n",
      "step 279400 , training  accuracy 0.366667\n",
      "step 279400 , loss : 2.15821\n",
      "step 279400 , validation  accuracy 0.3108\n",
      "step 279400 , validation loss : 24.9922\n",
      "step 279500 , training  accuracy 0.433333\n",
      "step 279500 , loss : 2.13907\n",
      "step 279500 , validation  accuracy 0.3034\n",
      "step 279500 , validation loss : 24.7592\n",
      "step 279600 , training  accuracy 0.633333\n",
      "step 279600 , loss : 1.98134\n",
      "step 279600 , validation  accuracy 0.316\n",
      "step 279600 , validation loss : 25.0811\n",
      "step 279700 , training  accuracy 0.466667\n",
      "step 279700 , loss : 2.11567\n",
      "step 279700 , validation  accuracy 0.305\n",
      "step 279700 , validation loss : 23.7408\n",
      "step 279800 , training  accuracy 0.566667\n",
      "step 279800 , loss : 2.04956\n",
      "step 279800 , validation  accuracy 0.3088\n",
      "step 279800 , validation loss : 22.5744\n",
      "step 279900 , training  accuracy 0.6\n",
      "step 279900 , loss : 2.03837\n",
      "step 279900 , validation  accuracy 0.3168\n",
      "step 279900 , validation loss : 23.6928\n",
      "step 280000 , training  accuracy 0.5\n",
      "step 280000 , loss : 2.05262\n",
      "step 280000 , validation  accuracy 0.3066\n",
      "step 280000 , validation loss : 24.5813\n",
      "step 280100 , training  accuracy 0.466667\n",
      "step 280100 , loss : 2.14792\n",
      "step 280100 , validation  accuracy 0.2916\n",
      "step 280100 , validation loss : 21.4882\n",
      "step 280200 , training  accuracy 0.5\n",
      "step 280200 , loss : 2.06929\n",
      "step 280200 , validation  accuracy 0.3072\n",
      "step 280200 , validation loss : 25.4183\n",
      "step 280300 , training  accuracy 0.633333\n",
      "step 280300 , loss : 2.02477\n",
      "step 280300 , validation  accuracy 0.307\n",
      "step 280300 , validation loss : 24.4304\n",
      "step 280400 , training  accuracy 0.7\n",
      "step 280400 , loss : 2.0717\n",
      "step 280400 , validation  accuracy 0.3004\n",
      "step 280400 , validation loss : 23.6204\n",
      "step 280500 , training  accuracy 0.433333\n",
      "step 280500 , loss : 2.14633\n",
      "step 280500 , validation  accuracy 0.2952\n",
      "step 280500 , validation loss : 24.1027\n",
      "step 280600 , training  accuracy 0.666667\n",
      "step 280600 , loss : 2.02514\n",
      "step 280600 , validation  accuracy 0.2986\n",
      "step 280600 , validation loss : 24.6734\n",
      "step 280700 , training  accuracy 0.466667\n",
      "step 280700 , loss : 2.1068\n",
      "step 280700 , validation  accuracy 0.3094\n",
      "step 280700 , validation loss : 25.5629\n",
      "step 280800 , training  accuracy 0.566667\n",
      "step 280800 , loss : 2.12232\n",
      "step 280800 , validation  accuracy 0.3036\n",
      "step 280800 , validation loss : 26.1398\n",
      "step 280900 , training  accuracy 0.5\n",
      "step 280900 , loss : 2.06462\n",
      "step 280900 , validation  accuracy 0.3072\n",
      "step 280900 , validation loss : 23.7578\n",
      "step 281000 , training  accuracy 0.433333\n",
      "step 281000 , loss : 2.14174\n",
      "step 281000 , validation  accuracy 0.315\n",
      "step 281000 , validation loss : 24.8533\n",
      "step 281100 , training  accuracy 0.4\n",
      "step 281100 , loss : 2.16286\n",
      "step 281100 , validation  accuracy 0.306\n",
      "step 281100 , validation loss : 24.0912\n",
      "step 281200 , training  accuracy 0.566667\n",
      "step 281200 , loss : 2.06295\n",
      "step 281200 , validation  accuracy 0.3168\n",
      "step 281200 , validation loss : 25.2882\n",
      "step 281300 , training  accuracy 0.666667\n",
      "step 281300 , loss : 2.01274\n",
      "step 281300 , validation  accuracy 0.3168\n",
      "step 281300 , validation loss : 24.6138\n",
      "step 281400 , training  accuracy 0.6\n",
      "step 281400 , loss : 2.02529\n",
      "step 281400 , validation  accuracy 0.315\n",
      "step 281400 , validation loss : 25.0278\n",
      "step 281500 , training  accuracy 0.5\n",
      "step 281500 , loss : 2.0712\n",
      "step 281500 , validation  accuracy 0.3022\n",
      "step 281500 , validation loss : 25.5387\n",
      "step 281600 , training  accuracy 0.466667\n",
      "step 281600 , loss : 2.11405\n",
      "step 281600 , validation  accuracy 0.3012\n",
      "step 281600 , validation loss : 23.9736\n",
      "step 281700 , training  accuracy 0.533333\n",
      "step 281700 , loss : 2.04977\n",
      "step 281700 , validation  accuracy 0.3148\n",
      "step 281700 , validation loss : 23.7912\n",
      "step 281800 , training  accuracy 0.6\n",
      "step 281800 , loss : 2.04347\n",
      "step 281800 , validation  accuracy 0.3114\n",
      "step 281800 , validation loss : 24.758\n",
      "step 281900 , training  accuracy 0.533333\n",
      "step 281900 , loss : 2.09722\n",
      "step 281900 , validation  accuracy 0.3166\n",
      "step 281900 , validation loss : 26.2572\n",
      "step 282000 , training  accuracy 0.433333\n",
      "step 282000 , loss : 2.09311\n",
      "step 282000 , validation  accuracy 0.3012\n",
      "step 282000 , validation loss : 23.1653\n",
      "step 282100 , training  accuracy 0.633333\n",
      "step 282100 , loss : 2.0199\n",
      "step 282100 , validation  accuracy 0.3174\n",
      "step 282100 , validation loss : 24.9853\n",
      "step 282200 , training  accuracy 0.466667\n",
      "step 282200 , loss : 2.12452\n",
      "step 282200 , validation  accuracy 0.2982\n",
      "step 282200 , validation loss : 24.3883\n",
      "step 282300 , training  accuracy 0.733333\n",
      "step 282300 , loss : 1.97122\n",
      "step 282300 , validation  accuracy 0.3178\n",
      "step 282300 , validation loss : 26.2501\n",
      "step 282400 , training  accuracy 0.533333\n",
      "step 282400 , loss : 2.12031\n",
      "step 282400 , validation  accuracy 0.303\n",
      "step 282400 , validation loss : 25.5419\n",
      "step 282500 , training  accuracy 0.4\n",
      "step 282500 , loss : 2.11141\n",
      "step 282500 , validation  accuracy 0.2982\n",
      "step 282500 , validation loss : 25.1486\n",
      "step 282600 , training  accuracy 0.6\n",
      "step 282600 , loss : 2.07599\n",
      "step 282600 , validation  accuracy 0.3032\n",
      "step 282600 , validation loss : 25.0392\n",
      "step 282700 , training  accuracy 0.4\n",
      "step 282700 , loss : 2.11756\n",
      "step 282700 , validation  accuracy 0.3092\n",
      "step 282700 , validation loss : 25.1158\n",
      "step 282800 , training  accuracy 0.466667\n",
      "step 282800 , loss : 2.09869\n",
      "step 282800 , validation  accuracy 0.3118\n",
      "step 282800 , validation loss : 26.3533\n",
      "step 282900 , training  accuracy 0.5\n",
      "step 282900 , loss : 2.10437\n",
      "step 282900 , validation  accuracy 0.3168\n",
      "step 282900 , validation loss : 24.8906\n",
      "step 283000 , training  accuracy 0.433333\n",
      "step 283000 , loss : 2.10596\n",
      "step 283000 , validation  accuracy 0.291\n",
      "step 283000 , validation loss : 23.7339\n",
      "step 283100 , training  accuracy 0.633333\n",
      "step 283100 , loss : 2.04988\n",
      "step 283100 , validation  accuracy 0.3018\n",
      "step 283100 , validation loss : 23.1861\n",
      "step 283200 , training  accuracy 0.5\n",
      "step 283200 , loss : 2.08394\n",
      "step 283200 , validation  accuracy 0.3202\n",
      "step 283200 , validation loss : 24.0566\n",
      "step 283300 , training  accuracy 0.366667\n",
      "step 283300 , loss : 2.15524\n",
      "step 283300 , validation  accuracy 0.315\n",
      "step 283300 , validation loss : 23.7526\n",
      "step 283400 , training  accuracy 0.4\n",
      "step 283400 , loss : 2.15227\n",
      "step 283400 , validation  accuracy 0.29\n",
      "step 283400 , validation loss : 22.2367\n",
      "step 283500 , training  accuracy 0.633333\n",
      "step 283500 , loss : 2.01746\n",
      "step 283500 , validation  accuracy 0.301\n",
      "step 283500 , validation loss : 22.8907\n",
      "step 283600 , training  accuracy 0.733333\n",
      "step 283600 , loss : 2.0271\n",
      "step 283600 , validation  accuracy 0.3014\n",
      "step 283600 , validation loss : 24.4285\n",
      "step 283700 , training  accuracy 0.533333\n",
      "step 283700 , loss : 2.09796\n",
      "step 283700 , validation  accuracy 0.3156\n",
      "step 283700 , validation loss : 22.5377\n",
      "step 283800 , training  accuracy 0.666667\n",
      "step 283800 , loss : 2.05532\n",
      "step 283800 , validation  accuracy 0.3078\n",
      "step 283800 , validation loss : 23.85\n",
      "step 283900 , training  accuracy 0.566667\n",
      "step 283900 , loss : 2.04573\n",
      "step 283900 , validation  accuracy 0.3186\n",
      "step 283900 , validation loss : 23.965\n",
      "step 284000 , training  accuracy 0.466667\n",
      "step 284000 , loss : 2.13114\n",
      "step 284000 , validation  accuracy 0.2962\n",
      "step 284000 , validation loss : 23.2931\n",
      "step 284100 , training  accuracy 0.633333\n",
      "step 284100 , loss : 2.05059\n",
      "step 284100 , validation  accuracy 0.3076\n",
      "step 284100 , validation loss : 25.1389\n",
      "step 284200 , training  accuracy 0.5\n",
      "step 284200 , loss : 2.1044\n",
      "step 284200 , validation  accuracy 0.3138\n",
      "step 284200 , validation loss : 25.6117\n",
      "step 284300 , training  accuracy 0.6\n",
      "step 284300 , loss : 2.07111\n",
      "step 284300 , validation  accuracy 0.304\n",
      "step 284300 , validation loss : 24.0325\n",
      "step 284400 , training  accuracy 0.533333\n",
      "step 284400 , loss : 2.12065\n",
      "step 284400 , validation  accuracy 0.3144\n",
      "step 284400 , validation loss : 25.6798\n",
      "step 284500 , training  accuracy 0.5\n",
      "step 284500 , loss : 2.0375\n",
      "step 284500 , validation  accuracy 0.3036\n",
      "step 284500 , validation loss : 24.6721\n",
      "step 284600 , training  accuracy 0.633333\n",
      "step 284600 , loss : 2.01432\n",
      "step 284600 , validation  accuracy 0.3104\n",
      "step 284600 , validation loss : 25.4277\n",
      "step 284700 , training  accuracy 0.6\n",
      "step 284700 , loss : 2.05469\n",
      "step 284700 , validation  accuracy 0.3122\n",
      "step 284700 , validation loss : 24.2218\n",
      "step 284800 , training  accuracy 0.5\n",
      "step 284800 , loss : 2.07457\n",
      "step 284800 , validation  accuracy 0.3178\n",
      "step 284800 , validation loss : 25.4842\n",
      "step 284900 , training  accuracy 0.633333\n",
      "step 284900 , loss : 2.00307\n",
      "step 284900 , validation  accuracy 0.3026\n",
      "step 284900 , validation loss : 23.3652\n",
      "step 285000 , training  accuracy 0.433333\n",
      "step 285000 , loss : 2.12983\n",
      "step 285000 , validation  accuracy 0.3164\n",
      "step 285000 , validation loss : 25.2036\n",
      "step 285100 , training  accuracy 0.466667\n",
      "step 285100 , loss : 2.09924\n",
      "step 285100 , validation  accuracy 0.295\n",
      "step 285100 , validation loss : 22.994\n",
      "step 285200 , training  accuracy 0.5\n",
      "step 285200 , loss : 2.06633\n",
      "step 285200 , validation  accuracy 0.3046\n",
      "step 285200 , validation loss : 21.7499\n",
      "step 285300 , training  accuracy 0.733333\n",
      "step 285300 , loss : 1.97297\n",
      "step 285300 , validation  accuracy 0.3214\n",
      "step 285300 , validation loss : 23.2943\n",
      "step 285400 , training  accuracy 0.6\n",
      "step 285400 , loss : 2.13519\n",
      "step 285400 , validation  accuracy 0.3176\n",
      "step 285400 , validation loss : 24.2159\n",
      "step 285500 , training  accuracy 0.533333\n",
      "step 285500 , loss : 2.01495\n",
      "step 285500 , validation  accuracy 0.3164\n",
      "step 285500 , validation loss : 23.6582\n",
      "step 285600 , training  accuracy 0.5\n",
      "step 285600 , loss : 2.08599\n",
      "step 285600 , validation  accuracy 0.322\n",
      "step 285600 , validation loss : 24.9688\n",
      "step 285700 , training  accuracy 0.566667\n",
      "step 285700 , loss : 2.0535\n",
      "step 285700 , validation  accuracy 0.312\n",
      "step 285700 , validation loss : 24.3974\n",
      "step 285800 , training  accuracy 0.533333\n",
      "step 285800 , loss : 2.07515\n",
      "step 285800 , validation  accuracy 0.305\n",
      "step 285800 , validation loss : 23.1528\n",
      "step 285900 , training  accuracy 0.533333\n",
      "step 285900 , loss : 2.06538\n",
      "step 285900 , validation  accuracy 0.2984\n",
      "step 285900 , validation loss : 23.1347\n",
      "step 286000 , training  accuracy 0.566667\n",
      "step 286000 , loss : 2.00695\n",
      "step 286000 , validation  accuracy 0.3022\n",
      "step 286000 , validation loss : 24.2012\n",
      "step 286100 , training  accuracy 0.7\n",
      "step 286100 , loss : 2.01755\n",
      "step 286100 , validation  accuracy 0.2954\n",
      "step 286100 , validation loss : 23.0384\n",
      "step 286200 , training  accuracy 0.4\n",
      "step 286200 , loss : 2.10835\n",
      "step 286200 , validation  accuracy 0.308\n",
      "step 286200 , validation loss : 24.2087\n",
      "step 286300 , training  accuracy 0.533333\n",
      "step 286300 , loss : 2.0693\n",
      "step 286300 , validation  accuracy 0.3062\n",
      "step 286300 , validation loss : 22.8392\n",
      "step 286400 , training  accuracy 0.4\n",
      "step 286400 , loss : 2.11837\n",
      "step 286400 , validation  accuracy 0.2894\n",
      "step 286400 , validation loss : 24.5583\n",
      "step 286500 , training  accuracy 0.6\n",
      "step 286500 , loss : 2.05395\n",
      "step 286500 , validation  accuracy 0.2972\n",
      "step 286500 , validation loss : 24.3223\n",
      "step 286600 , training  accuracy 0.533333\n",
      "step 286600 , loss : 2.11167\n",
      "step 286600 , validation  accuracy 0.303\n",
      "step 286600 , validation loss : 23.5592\n",
      "step 286700 , training  accuracy 0.433333\n",
      "step 286700 , loss : 2.14628\n",
      "step 286700 , validation  accuracy 0.3002\n",
      "step 286700 , validation loss : 23.8075\n",
      "step 286800 , training  accuracy 0.6\n",
      "step 286800 , loss : 2.02161\n",
      "step 286800 , validation  accuracy 0.32\n",
      "step 286800 , validation loss : 24.8773\n",
      "step 286900 , training  accuracy 0.6\n",
      "step 286900 , loss : 2.0584\n",
      "step 286900 , validation  accuracy 0.3098\n",
      "step 286900 , validation loss : 23.2537\n",
      "step 287000 , training  accuracy 0.433333\n",
      "step 287000 , loss : 2.05786\n",
      "step 287000 , validation  accuracy 0.3118\n",
      "step 287000 , validation loss : 23.2684\n",
      "step 287100 , training  accuracy 0.633333\n",
      "step 287100 , loss : 2.03063\n",
      "step 287100 , validation  accuracy 0.3014\n",
      "step 287100 , validation loss : 24.2331\n",
      "step 287200 , training  accuracy 0.533333\n",
      "step 287200 , loss : 2.08705\n",
      "step 287200 , validation  accuracy 0.3078\n",
      "step 287200 , validation loss : 24.1415\n",
      "step 287300 , training  accuracy 0.533333\n",
      "step 287300 , loss : 2.07291\n",
      "step 287300 , validation  accuracy 0.3178\n",
      "step 287300 , validation loss : 24.6505\n",
      "step 287400 , training  accuracy 0.566667\n",
      "step 287400 , loss : 2.02275\n",
      "step 287400 , validation  accuracy 0.3296\n",
      "step 287400 , validation loss : 26.4989\n",
      "step 287500 , training  accuracy 0.5\n",
      "step 287500 , loss : 2.10365\n",
      "step 287500 , validation  accuracy 0.302\n",
      "step 287500 , validation loss : 25.2727\n",
      "step 287600 , training  accuracy 0.466667\n",
      "step 287600 , loss : 2.12996\n",
      "step 287600 , validation  accuracy 0.3118\n",
      "step 287600 , validation loss : 24.5863\n",
      "step 287700 , training  accuracy 0.433333\n",
      "step 287700 , loss : 2.09668\n",
      "step 287700 , validation  accuracy 0.305\n",
      "step 287700 , validation loss : 24.3267\n",
      "step 287800 , training  accuracy 0.566667\n",
      "step 287800 , loss : 2.06836\n",
      "step 287800 , validation  accuracy 0.3148\n",
      "step 287800 , validation loss : 25.7742\n",
      "step 287900 , training  accuracy 0.466667\n",
      "step 287900 , loss : 2.14192\n",
      "step 287900 , validation  accuracy 0.305\n",
      "step 287900 , validation loss : 24.2182\n",
      "step 288000 , training  accuracy 0.533333\n",
      "step 288000 , loss : 2.09146\n",
      "step 288000 , validation  accuracy 0.307\n",
      "step 288000 , validation loss : 25.3071\n",
      "step 288100 , training  accuracy 0.633333\n",
      "step 288100 , loss : 2.05551\n",
      "step 288100 , validation  accuracy 0.3106\n",
      "step 288100 , validation loss : 24.582\n",
      "step 288200 , training  accuracy 0.666667\n",
      "step 288200 , loss : 2.06949\n",
      "step 288200 , validation  accuracy 0.3116\n",
      "step 288200 , validation loss : 23.9631\n",
      "step 288300 , training  accuracy 0.433333\n",
      "step 288300 , loss : 2.15665\n",
      "step 288300 , validation  accuracy 0.3106\n",
      "step 288300 , validation loss : 25.2357\n",
      "step 288400 , training  accuracy 0.7\n",
      "step 288400 , loss : 1.9668\n",
      "step 288400 , validation  accuracy 0.309\n",
      "step 288400 , validation loss : 24.7359\n",
      "step 288500 , training  accuracy 0.4\n",
      "step 288500 , loss : 2.12322\n",
      "step 288500 , validation  accuracy 0.3216\n",
      "step 288500 , validation loss : 24.2837\n",
      "step 288600 , training  accuracy 0.433333\n",
      "step 288600 , loss : 2.09734\n",
      "step 288600 , validation  accuracy 0.3134\n",
      "step 288600 , validation loss : 25.0642\n",
      "step 288700 , training  accuracy 0.5\n",
      "step 288700 , loss : 2.08917\n",
      "step 288700 , validation  accuracy 0.303\n",
      "step 288700 , validation loss : 23.3665\n",
      "step 288800 , training  accuracy 0.5\n",
      "step 288800 , loss : 2.06599\n",
      "step 288800 , validation  accuracy 0.3132\n",
      "step 288800 , validation loss : 24.4994\n",
      "step 288900 , training  accuracy 0.533333\n",
      "step 288900 , loss : 2.05571\n",
      "step 288900 , validation  accuracy 0.3094\n",
      "step 288900 , validation loss : 22.8835\n",
      "step 289000 , training  accuracy 0.6\n",
      "step 289000 , loss : 2.01941\n",
      "step 289000 , validation  accuracy 0.299\n",
      "step 289000 , validation loss : 23.7321\n",
      "step 289100 , training  accuracy 0.566667\n",
      "step 289100 , loss : 2.09302\n",
      "step 289100 , validation  accuracy 0.307\n",
      "step 289100 , validation loss : 24.6433\n",
      "step 289200 , training  accuracy 0.666667\n",
      "step 289200 , loss : 1.98568\n",
      "step 289200 , validation  accuracy 0.315\n",
      "step 289200 , validation loss : 24.166\n",
      "step 289300 , training  accuracy 0.4\n",
      "step 289300 , loss : 2.10892\n",
      "step 289300 , validation  accuracy 0.3132\n",
      "step 289300 , validation loss : 24.2265\n",
      "step 289400 , training  accuracy 0.5\n",
      "step 289400 , loss : 2.07682\n",
      "step 289400 , validation  accuracy 0.3154\n",
      "step 289400 , validation loss : 24.3718\n",
      "step 289500 , training  accuracy 0.5\n",
      "step 289500 , loss : 2.10867\n",
      "step 289500 , validation  accuracy 0.3114\n",
      "step 289500 , validation loss : 24.8382\n",
      "step 289600 , training  accuracy 0.433333\n",
      "step 289600 , loss : 2.13003\n",
      "step 289600 , validation  accuracy 0.304\n",
      "step 289600 , validation loss : 23.8882\n",
      "step 289700 , training  accuracy 0.5\n",
      "step 289700 , loss : 2.1064\n",
      "step 289700 , validation  accuracy 0.2996\n",
      "step 289700 , validation loss : 23.1599\n",
      "step 289800 , training  accuracy 0.5\n",
      "step 289800 , loss : 2.10321\n",
      "step 289800 , validation  accuracy 0.3194\n",
      "step 289800 , validation loss : 25.6322\n",
      "step 289900 , training  accuracy 0.5\n",
      "step 289900 , loss : 2.0687\n",
      "step 289900 , validation  accuracy 0.3078\n",
      "step 289900 , validation loss : 24.0982\n",
      "step 290000 , training  accuracy 0.6\n",
      "step 290000 , loss : 2.02959\n",
      "step 290000 , validation  accuracy 0.3102\n",
      "step 290000 , validation loss : 24.2871\n",
      "step 290100 , training  accuracy 0.366667\n",
      "step 290100 , loss : 2.1396\n",
      "step 290100 , validation  accuracy 0.3144\n",
      "step 290100 , validation loss : 24.6002\n",
      "step 290200 , training  accuracy 0.6\n",
      "step 290200 , loss : 2.04228\n",
      "step 290200 , validation  accuracy 0.314\n",
      "step 290200 , validation loss : 24.3371\n",
      "step 290300 , training  accuracy 0.533333\n",
      "step 290300 , loss : 2.06929\n",
      "step 290300 , validation  accuracy 0.3174\n",
      "step 290300 , validation loss : 24.3126\n",
      "step 290400 , training  accuracy 0.633333\n",
      "step 290400 , loss : 2.04624\n",
      "step 290400 , validation  accuracy 0.3082\n",
      "step 290400 , validation loss : 23.3008\n",
      "step 290500 , training  accuracy 0.733333\n",
      "step 290500 , loss : 1.98423\n",
      "step 290500 , validation  accuracy 0.296\n",
      "step 290500 , validation loss : 25.3694\n",
      "step 290600 , training  accuracy 0.6\n",
      "step 290600 , loss : 2.05085\n",
      "step 290600 , validation  accuracy 0.3018\n",
      "step 290600 , validation loss : 23.2087\n",
      "step 290700 , training  accuracy 0.7\n",
      "step 290700 , loss : 1.92963\n",
      "step 290700 , validation  accuracy 0.3314\n",
      "step 290700 , validation loss : 25.5331\n",
      "step 290800 , training  accuracy 0.5\n",
      "step 290800 , loss : 2.06938\n",
      "step 290800 , validation  accuracy 0.3052\n",
      "step 290800 , validation loss : 23.5221\n",
      "step 290900 , training  accuracy 0.666667\n",
      "step 290900 , loss : 1.98896\n",
      "step 290900 , validation  accuracy 0.3176\n",
      "step 290900 , validation loss : 25.2222\n",
      "step 291000 , training  accuracy 0.566667\n",
      "step 291000 , loss : 2.1105\n",
      "step 291000 , validation  accuracy 0.2926\n",
      "step 291000 , validation loss : 24.1822\n",
      "step 291100 , training  accuracy 0.533333\n",
      "step 291100 , loss : 2.07518\n",
      "step 291100 , validation  accuracy 0.307\n",
      "step 291100 , validation loss : 25.8388\n",
      "step 291200 , training  accuracy 0.566667\n",
      "step 291200 , loss : 2.03014\n",
      "step 291200 , validation  accuracy 0.31\n",
      "step 291200 , validation loss : 25.2214\n",
      "step 291300 , training  accuracy 0.633333\n",
      "step 291300 , loss : 2.0265\n",
      "step 291300 , validation  accuracy 0.3088\n",
      "step 291300 , validation loss : 24.627\n",
      "step 291400 , training  accuracy 0.6\n",
      "step 291400 , loss : 2.01763\n",
      "step 291400 , validation  accuracy 0.3028\n",
      "step 291400 , validation loss : 23.8637\n",
      "step 291500 , training  accuracy 0.433333\n",
      "step 291500 , loss : 2.12569\n",
      "step 291500 , validation  accuracy 0.3062\n",
      "step 291500 , validation loss : 24.5348\n",
      "step 291600 , training  accuracy 0.666667\n",
      "step 291600 , loss : 2.0457\n",
      "step 291600 , validation  accuracy 0.305\n",
      "step 291600 , validation loss : 24.3277\n",
      "step 291700 , training  accuracy 0.5\n",
      "step 291700 , loss : 2.13642\n",
      "step 291700 , validation  accuracy 0.2942\n",
      "step 291700 , validation loss : 23.6399\n",
      "step 291800 , training  accuracy 0.533333\n",
      "step 291800 , loss : 2.06629\n",
      "step 291800 , validation  accuracy 0.3178\n",
      "step 291800 , validation loss : 24.6454\n",
      "step 291900 , training  accuracy 0.6\n",
      "step 291900 , loss : 2.07987\n",
      "step 291900 , validation  accuracy 0.312\n",
      "step 291900 , validation loss : 23.9044\n",
      "step 292000 , training  accuracy 0.533333\n",
      "step 292000 , loss : 2.04963\n",
      "step 292000 , validation  accuracy 0.3012\n",
      "step 292000 , validation loss : 23.798\n",
      "step 292100 , training  accuracy 0.366667\n",
      "step 292100 , loss : 2.12652\n",
      "step 292100 , validation  accuracy 0.3022\n",
      "step 292100 , validation loss : 25.2094\n",
      "step 292200 , training  accuracy 0.466667\n",
      "step 292200 , loss : 2.11356\n",
      "step 292200 , validation  accuracy 0.2994\n",
      "step 292200 , validation loss : 25.5349\n",
      "step 292300 , training  accuracy 0.566667\n",
      "step 292300 , loss : 2.04896\n",
      "step 292300 , validation  accuracy 0.3122\n",
      "step 292300 , validation loss : 24.0966\n",
      "step 292400 , training  accuracy 0.6\n",
      "step 292400 , loss : 2.06211\n",
      "step 292400 , validation  accuracy 0.3132\n",
      "step 292400 , validation loss : 23.8313\n",
      "step 292500 , training  accuracy 0.5\n",
      "step 292500 , loss : 2.04183\n",
      "step 292500 , validation  accuracy 0.318\n",
      "step 292500 , validation loss : 24.5696\n",
      "step 292600 , training  accuracy 0.533333\n",
      "step 292600 , loss : 2.07401\n",
      "step 292600 , validation  accuracy 0.3016\n",
      "step 292600 , validation loss : 23.6468\n",
      "step 292700 , training  accuracy 0.633333\n",
      "step 292700 , loss : 2.09916\n",
      "step 292700 , validation  accuracy 0.3114\n",
      "step 292700 , validation loss : 24.9307\n",
      "step 292800 , training  accuracy 0.7\n",
      "step 292800 , loss : 2.00226\n",
      "step 292800 , validation  accuracy 0.3062\n",
      "step 292800 , validation loss : 24.5134\n",
      "step 292900 , training  accuracy 0.7\n",
      "step 292900 , loss : 2.00311\n",
      "step 292900 , validation  accuracy 0.3238\n",
      "step 292900 , validation loss : 24.3132\n",
      "step 293000 , training  accuracy 0.366667\n",
      "step 293000 , loss : 2.15438\n",
      "step 293000 , validation  accuracy 0.304\n",
      "step 293000 , validation loss : 24.5031\n",
      "step 293100 , training  accuracy 0.433333\n",
      "step 293100 , loss : 2.11855\n",
      "step 293100 , validation  accuracy 0.3118\n",
      "step 293100 , validation loss : 24.9151\n",
      "step 293200 , training  accuracy 0.566667\n",
      "step 293200 , loss : 2.02004\n",
      "step 293200 , validation  accuracy 0.3036\n",
      "step 293200 , validation loss : 23.512\n",
      "step 293300 , training  accuracy 0.566667\n",
      "step 293300 , loss : 2.01475\n",
      "step 293300 , validation  accuracy 0.3128\n",
      "step 293300 , validation loss : 25.0123\n",
      "step 293400 , training  accuracy 0.366667\n",
      "step 293400 , loss : 2.15956\n",
      "step 293400 , validation  accuracy 0.2938\n",
      "step 293400 , validation loss : 23.9741\n",
      "step 293500 , training  accuracy 0.633333\n",
      "step 293500 , loss : 2.03546\n",
      "step 293500 , validation  accuracy 0.3014\n",
      "step 293500 , validation loss : 25.2355\n",
      "step 293600 , training  accuracy 0.566667\n",
      "step 293600 , loss : 2.04755\n",
      "step 293600 , validation  accuracy 0.3038\n",
      "step 293600 , validation loss : 23.9155\n",
      "step 293700 , training  accuracy 0.6\n",
      "step 293700 , loss : 2.04547\n",
      "step 293700 , validation  accuracy 0.298\n",
      "step 293700 , validation loss : 23.9345\n",
      "step 293800 , training  accuracy 0.466667\n",
      "step 293800 , loss : 2.08231\n",
      "step 293800 , validation  accuracy 0.2994\n",
      "step 293800 , validation loss : 23.5038\n",
      "step 293900 , training  accuracy 0.533333\n",
      "step 293900 , loss : 2.10735\n",
      "step 293900 , validation  accuracy 0.3132\n",
      "step 293900 , validation loss : 24.5301\n",
      "step 294000 , training  accuracy 0.4\n",
      "step 294000 , loss : 2.14679\n",
      "step 294000 , validation  accuracy 0.302\n",
      "step 294000 , validation loss : 25.8098\n",
      "step 294100 , training  accuracy 0.566667\n",
      "step 294100 , loss : 2.01516\n",
      "step 294100 , validation  accuracy 0.325\n",
      "step 294100 , validation loss : 26.4504\n",
      "step 294200 , training  accuracy 0.533333\n",
      "step 294200 , loss : 2.11038\n",
      "step 294200 , validation  accuracy 0.298\n",
      "step 294200 , validation loss : 25.2759\n",
      "step 294300 , training  accuracy 0.6\n",
      "step 294300 , loss : 2.04757\n",
      "step 294300 , validation  accuracy 0.2968\n",
      "step 294300 , validation loss : 25.4877\n",
      "step 294400 , training  accuracy 0.6\n",
      "step 294400 , loss : 2.11845\n",
      "step 294400 , validation  accuracy 0.3032\n",
      "step 294400 , validation loss : 23.2554\n",
      "step 294500 , training  accuracy 0.566667\n",
      "step 294500 , loss : 2.01854\n",
      "step 294500 , validation  accuracy 0.3054\n",
      "step 294500 , validation loss : 24.2476\n",
      "step 294600 , training  accuracy 0.5\n",
      "step 294600 , loss : 2.11791\n",
      "step 294600 , validation  accuracy 0.3032\n",
      "step 294600 , validation loss : 23.4867\n",
      "step 294700 , training  accuracy 0.533333\n",
      "step 294700 , loss : 2.09223\n",
      "step 294700 , validation  accuracy 0.3014\n",
      "step 294700 , validation loss : 24.3671\n",
      "step 294800 , training  accuracy 0.366667\n",
      "step 294800 , loss : 2.14466\n",
      "step 294800 , validation  accuracy 0.3\n",
      "step 294800 , validation loss : 23.5755\n",
      "step 294900 , training  accuracy 0.5\n",
      "step 294900 , loss : 2.09735\n",
      "step 294900 , validation  accuracy 0.307\n",
      "step 294900 , validation loss : 23.5085\n",
      "step 295000 , training  accuracy 0.466667\n",
      "step 295000 , loss : 2.15483\n",
      "step 295000 , validation  accuracy 0.3112\n",
      "step 295000 , validation loss : 24.5052\n",
      "step 295100 , training  accuracy 0.6\n",
      "step 295100 , loss : 2.0775\n",
      "step 295100 , validation  accuracy 0.3134\n",
      "step 295100 , validation loss : 23.9931\n",
      "step 295200 , training  accuracy 0.666667\n",
      "step 295200 , loss : 2.02301\n",
      "step 295200 , validation  accuracy 0.3058\n",
      "step 295200 , validation loss : 23.9262\n",
      "step 295300 , training  accuracy 0.733333\n",
      "step 295300 , loss : 1.96901\n",
      "step 295300 , validation  accuracy 0.3168\n",
      "step 295300 , validation loss : 25.2273\n",
      "step 295400 , training  accuracy 0.6\n",
      "step 295400 , loss : 2.0414\n",
      "step 295400 , validation  accuracy 0.3072\n",
      "step 295400 , validation loss : 23.5624\n",
      "step 295500 , training  accuracy 0.633333\n",
      "step 295500 , loss : 2.09224\n",
      "step 295500 , validation  accuracy 0.2932\n",
      "step 295500 , validation loss : 24.0768\n",
      "step 295600 , training  accuracy 0.566667\n",
      "step 295600 , loss : 2.024\n",
      "step 295600 , validation  accuracy 0.3122\n",
      "step 295600 , validation loss : 25.6098\n",
      "step 295700 , training  accuracy 0.6\n",
      "step 295700 , loss : 2.06882\n",
      "step 295700 , validation  accuracy 0.3212\n",
      "step 295700 , validation loss : 25.8706\n",
      "step 295800 , training  accuracy 0.7\n",
      "step 295800 , loss : 2.00507\n",
      "step 295800 , validation  accuracy 0.3188\n",
      "step 295800 , validation loss : 25.3091\n",
      "step 295900 , training  accuracy 0.566667\n",
      "step 295900 , loss : 2.06817\n",
      "step 295900 , validation  accuracy 0.3156\n",
      "step 295900 , validation loss : 24.5761\n",
      "step 296000 , training  accuracy 0.433333\n",
      "step 296000 , loss : 2.12139\n",
      "step 296000 , validation  accuracy 0.2968\n",
      "step 296000 , validation loss : 24.3882\n",
      "step 296100 , training  accuracy 0.633333\n",
      "step 296100 , loss : 2.07697\n",
      "step 296100 , validation  accuracy 0.3108\n",
      "step 296100 , validation loss : 24.6475\n",
      "step 296200 , training  accuracy 0.533333\n",
      "step 296200 , loss : 2.08098\n",
      "step 296200 , validation  accuracy 0.2996\n",
      "step 296200 , validation loss : 23.7958\n",
      "step 296300 , training  accuracy 0.466667\n",
      "step 296300 , loss : 2.09922\n",
      "step 296300 , validation  accuracy 0.3026\n",
      "step 296300 , validation loss : 25.2857\n",
      "step 296400 , training  accuracy 0.466667\n",
      "step 296400 , loss : 2.09287\n",
      "step 296400 , validation  accuracy 0.3082\n",
      "step 296400 , validation loss : 25.0102\n",
      "step 296500 , training  accuracy 0.6\n",
      "step 296500 , loss : 2.06095\n",
      "step 296500 , validation  accuracy 0.3086\n",
      "step 296500 , validation loss : 25.1053\n",
      "step 296600 , training  accuracy 0.566667\n",
      "step 296600 , loss : 2.08068\n",
      "step 296600 , validation  accuracy 0.3096\n",
      "step 296600 , validation loss : 25.6153\n",
      "step 296700 , training  accuracy 0.5\n",
      "step 296700 , loss : 2.0951\n",
      "step 296700 , validation  accuracy 0.2952\n",
      "step 296700 , validation loss : 23.555\n",
      "step 296800 , training  accuracy 0.6\n",
      "step 296800 , loss : 2.05395\n",
      "step 296800 , validation  accuracy 0.2962\n",
      "step 296800 , validation loss : 25.3252\n",
      "step 296900 , training  accuracy 0.533333\n",
      "step 296900 , loss : 2.0711\n",
      "step 296900 , validation  accuracy 0.3136\n",
      "step 296900 , validation loss : 24.8808\n",
      "step 297000 , training  accuracy 0.466667\n",
      "step 297000 , loss : 2.12335\n",
      "step 297000 , validation  accuracy 0.2926\n",
      "step 297000 , validation loss : 24.2326\n",
      "step 297100 , training  accuracy 0.333333\n",
      "step 297100 , loss : 2.191\n",
      "step 297100 , validation  accuracy 0.2984\n",
      "step 297100 , validation loss : 24.4005\n",
      "step 297200 , training  accuracy 0.533333\n",
      "step 297200 , loss : 2.11044\n",
      "step 297200 , validation  accuracy 0.3146\n",
      "step 297200 , validation loss : 25.3366\n",
      "step 297300 , training  accuracy 0.466667\n",
      "step 297300 , loss : 2.11968\n",
      "step 297300 , validation  accuracy 0.2902\n",
      "step 297300 , validation loss : 22.9734\n",
      "step 297400 , training  accuracy 0.433333\n",
      "step 297400 , loss : 2.15501\n",
      "step 297400 , validation  accuracy 0.3142\n",
      "step 297400 , validation loss : 24.9756\n",
      "step 297500 , training  accuracy 0.4\n",
      "step 297500 , loss : 2.1778\n",
      "step 297500 , validation  accuracy 0.2954\n",
      "step 297500 , validation loss : 23.8026\n",
      "step 297600 , training  accuracy 0.633333\n",
      "step 297600 , loss : 2.03971\n",
      "step 297600 , validation  accuracy 0.3126\n",
      "step 297600 , validation loss : 24.0668\n",
      "step 297700 , training  accuracy 0.333333\n",
      "step 297700 , loss : 2.1576\n",
      "step 297700 , validation  accuracy 0.3118\n",
      "step 297700 , validation loss : 25.0507\n",
      "step 297800 , training  accuracy 0.5\n",
      "step 297800 , loss : 2.08698\n",
      "step 297800 , validation  accuracy 0.31\n",
      "step 297800 , validation loss : 24.5867\n",
      "step 297900 , training  accuracy 0.5\n",
      "step 297900 , loss : 2.03612\n",
      "step 297900 , validation  accuracy 0.2974\n",
      "step 297900 , validation loss : 24.9868\n",
      "step 298000 , training  accuracy 0.633333\n",
      "step 298000 , loss : 2.05697\n",
      "step 298000 , validation  accuracy 0.3004\n",
      "step 298000 , validation loss : 24.3849\n",
      "step 298100 , training  accuracy 0.5\n",
      "step 298100 , loss : 2.09943\n",
      "step 298100 , validation  accuracy 0.2888\n",
      "step 298100 , validation loss : 23.5069\n",
      "step 298200 , training  accuracy 0.633333\n",
      "step 298200 , loss : 2.01758\n",
      "step 298200 , validation  accuracy 0.3178\n",
      "step 298200 , validation loss : 24.8246\n",
      "step 298300 , training  accuracy 0.4\n",
      "step 298300 , loss : 2.14972\n",
      "step 298300 , validation  accuracy 0.2982\n",
      "step 298300 , validation loss : 24.3163\n",
      "step 298400 , training  accuracy 0.466667\n",
      "step 298400 , loss : 2.10096\n",
      "step 298400 , validation  accuracy 0.3072\n",
      "step 298400 , validation loss : 24.0676\n",
      "step 298500 , training  accuracy 0.566667\n",
      "step 298500 , loss : 2.05308\n",
      "step 298500 , validation  accuracy 0.3094\n",
      "step 298500 , validation loss : 24.0041\n",
      "step 298600 , training  accuracy 0.6\n",
      "step 298600 , loss : 2.06116\n",
      "step 298600 , validation  accuracy 0.304\n",
      "step 298600 , validation loss : 24.6223\n",
      "step 298700 , training  accuracy 0.5\n",
      "step 298700 , loss : 2.05737\n",
      "step 298700 , validation  accuracy 0.319\n",
      "step 298700 , validation loss : 25.1698\n",
      "step 298800 , training  accuracy 0.533333\n",
      "step 298800 , loss : 2.13914\n",
      "step 298800 , validation  accuracy 0.294\n",
      "step 298800 , validation loss : 23.1158\n",
      "step 298900 , training  accuracy 0.5\n",
      "step 298900 , loss : 2.08183\n",
      "step 298900 , validation  accuracy 0.3158\n",
      "step 298900 , validation loss : 23.7961\n",
      "step 299000 , training  accuracy 0.6\n",
      "step 299000 , loss : 2.08331\n",
      "step 299000 , validation  accuracy 0.303\n",
      "step 299000 , validation loss : 24.0262\n",
      "step 299100 , training  accuracy 0.533333\n",
      "step 299100 , loss : 2.11273\n",
      "step 299100 , validation  accuracy 0.3126\n",
      "step 299100 , validation loss : 24.3107\n",
      "step 299200 , training  accuracy 0.533333\n",
      "step 299200 , loss : 2.10359\n",
      "step 299200 , validation  accuracy 0.3192\n",
      "step 299200 , validation loss : 24.725\n",
      "step 299300 , training  accuracy 0.466667\n",
      "step 299300 , loss : 2.09492\n",
      "step 299300 , validation  accuracy 0.3052\n",
      "step 299300 , validation loss : 23.6408\n",
      "step 299400 , training  accuracy 0.6\n",
      "step 299400 , loss : 2.09115\n",
      "step 299400 , validation  accuracy 0.3158\n",
      "step 299400 , validation loss : 25.7527\n",
      "step 299500 , training  accuracy 0.533333\n",
      "step 299500 , loss : 2.10431\n",
      "step 299500 , validation  accuracy 0.3054\n",
      "step 299500 , validation loss : 25.059\n",
      "step 299600 , training  accuracy 0.5\n",
      "step 299600 , loss : 2.10337\n",
      "step 299600 , validation  accuracy 0.3104\n",
      "step 299600 , validation loss : 24.3056\n",
      "step 299700 , training  accuracy 0.5\n",
      "step 299700 , loss : 2.07039\n",
      "step 299700 , validation  accuracy 0.3088\n",
      "step 299700 , validation loss : 23.2079\n",
      "step 299800 , training  accuracy 0.6\n",
      "step 299800 , loss : 2.04616\n",
      "step 299800 , validation  accuracy 0.3156\n",
      "step 299800 , validation loss : 24.5467\n",
      "step 299900 , training  accuracy 0.4\n",
      "step 299900 , loss : 2.12825\n",
      "step 299900 , validation  accuracy 0.313\n",
      "step 299900 , validation loss : 23.9431\n",
      "--- Training Time : 7979.76005507 ---\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "#sm_conv= tf.nn.softmax(y_conv)\n",
    "    #cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "    start_time = time.time()\n",
    "\n",
    "    regular=0.01*(tf.reduce_sum(tf.square(y_conv)))\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( y_conv, y_))\n",
    "with tf.device('/gpu:0'):\n",
    "    cost = cost+regular\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cost) #1e-4\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            correct_prediction = tf.equal(tf.argmax(y_conv,1) ,tf.argmax(y_,1))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\")) \n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "if divide_flag ==True:\n",
    "    n_batch =len(train_images)\n",
    "    batch_count=0\n",
    "\n",
    "for i in range(iterate):    \n",
    "    if divide_flag ==True:\n",
    "        if batch_count >= n_batch:\n",
    "            batch_count =0\n",
    "        train_img =np.load(file_locate+train_images[batch_count])\n",
    "    \n",
    "        train_lab =np.load(file_locate+train_labels[batch_count])\n",
    "    batch_xs , batch_ys = next_batch(batch_size, train_img , train_lab)\n",
    "   # batch_val_xs  , batch_val_ys = next_batch(20 , val_img , val_lab)\n",
    "    if i%100 ==0: # in here add to validation \n",
    "        try:\n",
    "            val_accuracy = sess.run( accuracy , feed_dict={x:val_img , y_:val_lab , keep_prob: 1.0})        \n",
    "            val_loss = sess.run(cost , feed_dict = {x:val_img , y_: val_lab , keep_prob: 1.0})\n",
    "            \n",
    "            train_accuracy = sess.run( accuracy , feed_dict={x:batch_xs , y_:batch_ys , keep_prob: 1.0})        \n",
    "            train_loss = sess.run(cost , feed_dict = {x:batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "\n",
    "            #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "            print(\"step %d , training  accuracy %g\" %(i,train_accuracy))\n",
    "            print(\"step %d , loss : %g\" %(i,train_loss))\n",
    "            train_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(train_loss) +'\\tval accuracy:\\t'+str(train_accuracy)+'\\n'\n",
    "          \n",
    "            print(\"step %d , validation  accuracy %g\" %(i,val_accuracy))\n",
    "            print(\"step %d , validation loss : %g\" %(i,val_loss))\n",
    "            val_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(val_loss) +'\\tval accuracy:\\t'+str(val_accuracy)+'\\n'\n",
    "            \n",
    "            \n",
    "            f.write(val_str)\n",
    "            f.write(train_str)\n",
    "            batch_count+=1\n",
    "        except :\n",
    "            list_acc=[]\n",
    "            list_loss=[]\n",
    "            n_divide=len(val_img)/batch_size\n",
    "            j=0\n",
    "            for j in range(n_divide):\n",
    "                \n",
    "                # j*batch_size :(j+1)*batch_size\n",
    "                val_accuracy,val_loss = sess.run([accuracy ,cost], feed_dict={x:val_img[ j*batch_size :(j+1)*batch_size] , y_:val_lab[ j*batch_size :(j+1)*batch_size ] , keep_prob: 1.0})        \n",
    "                list_acc.append(float(val_accuracy))\n",
    "                list_loss.append(float(val_loss))\n",
    "            #right above code have to modify\n",
    "            val_accuracy,val_loss = sess.run([accuracy ,cost], feed_dict={x:val_img[ j*batch_size :] , y_:val_lab[ j*batch_size :  ] , keep_prob: 1.0})         \n",
    "            list_acc.append(val_accuracy)\n",
    "            list_loss.append(val_loss)\n",
    "            \n",
    "            list_acc=np.asarray(list_acc)\n",
    "            list_loss= np.asarray(list_loss)\n",
    "            \n",
    "            val_accuracy=np.mean(list_acc)\n",
    "            val_loss = np.mean(list_loss)\n",
    "            \n",
    "            #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "            \n",
    "            train_accuracy = sess.run( accuracy , feed_dict={x:batch_xs , y_:batch_ys , keep_prob: 1.0})        \n",
    "            train_loss = sess.run(cost , feed_dict = {x:batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "\n",
    "            print(\"step %d , training  accuracy %g\" %(i,train_accuracy))\n",
    "            print(\"step %d , loss : %g\" %(i,train_loss))\n",
    "            train_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(train_loss) +'\\tval accuracy:\\t'+str(train_accuracy)+'\\n'\n",
    "            \n",
    "            print(\"step %d , validation  accuracy %g\" %(i,val_accuracy))\n",
    "            print(\"step %d , validation loss : %g\" %(i,val_loss))\n",
    "            val_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(val_loss) +'\\tval accuracy:\\t'+str(val_accuracy)+'\\n'\n",
    "           \n",
    "            \n",
    "            f.write(val_str)\n",
    "            f.write(train_str)\n",
    "            batch_count+=1\n",
    "    \n",
    "    sess.run(train_step ,feed_dict={x:batch_xs , y_:batch_ys , keep_prob : 0.7})\n",
    "    \n",
    "print(\"--- Training Time : %s ---\" % (time.time() - start_time))\n",
    "train_time=\"--- Training Time : ---:\\t\" +str(time.time() - start_time)\n",
    "f.write(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print ''\n",
    "print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2 , testidation  accuracy 0.3044\n",
      "step 2 , testidation loss : 24.3214\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_accuracy = sess.run( accuracy , feed_dict={x:test_img , y_:test_lab , keep_prob: 1.0})        \n",
    "    test_loss = sess.run(cost , feed_dict = {x:test_img , y_: test_lab , keep_prob: 1.0})\n",
    "\n",
    "    #result = sess.run(sm_conv , feed_dict = {x:test_img , y_:batch_ys , keep_prob :1.0})\n",
    "    print(\"step %d , testidation  accuracy %g\" %(i,test_accuracy))\n",
    "    print(\"step %d , testidation loss : %g\" %(i,test_loss))\n",
    "    test_str = 'step:\\t'+str(i)+'\\ttest_loss:\\t'+str(test_loss) +'\\ttest accuracy:\\t'+str(test_accuracy)+'\\n'\n",
    "\n",
    "    f.write(test_str)\n",
    "except :\n",
    "    list_acc=[]\n",
    "    list_loss=[]\n",
    "    n_divide=len(test_img)/batch_size\n",
    "    for j in range(n_divide):\n",
    "\n",
    "        # j*batch_size :(j+1)*batch_size\n",
    "        test_accuracy,test_loss = sess.run([accuracy ,cost], feed_dict={x:test_img[ j*batch_size :(j+1)*batch_size] , y_:test_lab[ j*batch_size :(j+1)*batch_size ] , keep_prob: 1.0})        \n",
    "        list_acc.append(float(test_accuracy))\n",
    "        list_loss.append(float(test_loss))\n",
    "    test_accuracy , test_loss=sess.run([accuracy,cost] , feed_dict={x:test_img[(j+1)*batch_size : ] , y_:test_lab[(j+1)*(batch_size) : ] , keep_prob : 1.0})\n",
    "    #right above code have to modify\n",
    "\n",
    "    list_acc.append(test_accuracy)\n",
    "    list_loss.append(test_loss)\n",
    "    list_acc=np.asarray(list_acc)\n",
    "    list_loss= np.asarray(list_loss)\n",
    "\n",
    "    test_accuracy=np.mean(list_acc)\n",
    "    test_loss = np.mean(list_loss)\n",
    "\n",
    "    #result = sess.run(sm_conv , feed_dict = {x:test_img , y_:batch_ys , keep_prob :1.0})\n",
    "    print(\"step %d , testidation  accuracy %g\" %(i,test_accuracy))\n",
    "    print(\"step %d , testidation loss : %g\" %(i,test_loss))\n",
    "    test_str = 'step:\\t'+str(i)+'\\ttest_loss:\\t'+str(test_loss) +'\\ttest accuracy:\\t'+str(test_accuracy)+'\\n'\n",
    "\n",
    "    f.write(test_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
