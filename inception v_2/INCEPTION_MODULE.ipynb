{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INCEPTION MODULE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def STEM_A(x , device_):\n",
    "    with tf.device(device_):\n",
    "        in_ch=x.get_shape()[3]\n",
    "        out_ch1=32 ; out_ch2=32;out_ch3=64;out_ch4=96;\n",
    "\n",
    "        c_ksize1=[3,3,in_ch , out_ch1]\n",
    "        c_ksize2=[3,3,out_ch1 , out_ch2]\n",
    "        c_ksize3=[3,3,out_ch2 , out_ch3]\n",
    "        c_ksize4=[3,3,out_ch3 , out_ch4]\n",
    "        w_conv1 , b_conv1 =make_weights_biases('STEM_A' , 'W1' , c_ksize1 ,device_name = '/gpu:0')\n",
    "        w_conv2 , b_conv2= make_weights_biases('STEM_A' , 'W2' , c_ksize2 ,device_name = '/gpu:0')\n",
    "        w_conv3 , b_conv3= make_weights_biases('STEM_A' , 'W3' , c_ksize3 ,device_name = '/gpu:0')\n",
    "        w_conv4 , b_conv4= make_weights_biases('STEM_A' , 'W4' , c_ksize4 ,device_name = '/gpu:0')\n",
    "\n",
    "        c_strides1=[1,2,2,1]\n",
    "        c_strides2=[1,1,1,1]\n",
    "        c_strides3=[1,1,1,1]\n",
    "        c_strides4=[1,2,2,1]\n",
    "\n",
    "        c_pooling1='VALID'\n",
    "        c_pooling2='VALID'\n",
    "        c_pooling3='SAME'\n",
    "        c_pooling4='VALID'\n",
    "\n",
    "        b_p_ksize4=[1,3,3,1]\n",
    "        b_p_strides4=[1,2,2,1]\n",
    "        b_p_padding4 ='VALID'\n",
    "\n",
    "\n",
    "\n",
    "        layer1=tf.nn.conv2d(    x ,      w_conv1, c_strides1, c_pooling1  )+b_conv1\n",
    "        layer1=tf.nn.relu(layer1)\n",
    "        layer2=tf.nn.conv2d(    layer1 , w_conv2, c_strides2, c_pooling2  )+b_conv2\n",
    "        layer2=tf.nn.relu(layer2)\n",
    "        layer3=tf.nn.conv2d(    layer2 , w_conv3, c_strides3, c_pooling3  )+b_conv3\n",
    "        layer3=tf.nn.relu(layer3)\n",
    "        layer4=tf.nn.conv2d(    layer3 , w_conv4, c_strides4, c_pooling4  )+b_conv4\n",
    "        layer4=tf.nn.relu(layer4)\n",
    "\n",
    "\n",
    "        b_layer4=tf.nn.max_pool(layer3 , b_p_ksize4, b_p_strides4, b_p_padding4 ) #b is branch\n",
    "        b_layer4=tf.nn.relu(b_layer4)\n",
    "        print layer1\n",
    "        print layer2\n",
    "        print layer3\n",
    "        print layer4\n",
    "        print b_layer4\n",
    "\n",
    "\n",
    "        concat_layer=tf.concat(3 , [layer4 , b_layer4])\n",
    "        ret_layer=concat_layer\n",
    "        print concat_layer\n",
    "        return ret_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def STEM_B( x , device_):\n",
    "    with tf.device(device_):\n",
    "        in_ch=x.get_shape()[3]\n",
    "\n",
    "\n",
    "        #########################################################################\n",
    "        out_ch1=64 ; out_ch2=64;out_ch3=64;out_ch4=96;\n",
    "        ##############################right side##################################\n",
    "        c_ksize1=[1,1,in_ch , out_ch1]\n",
    "        c_ksize2=[7,1,out_ch1 , out_ch2]\n",
    "        c_ksize3=[1,7,out_ch2 , out_ch3]\n",
    "        c_ksize4=[3,3,out_ch3 , out_ch4]\n",
    "\n",
    "        w_conv1 , b_conv1 =make_weights_biases('STEM_B' , 'W1' , c_ksize1 ,device_name = device_)\n",
    "        w_conv2 , b_conv2= make_weights_biases('STEM_B' , 'W2' , c_ksize2 ,device_name = device_)\n",
    "        w_conv3 , b_conv3= make_weights_biases('STEM_B' , 'W3' , c_ksize3 ,device_name = device_)\n",
    "        w_conv4 , b_conv4= make_weights_biases('STEM_B' , 'W4' , c_ksize4 ,device_name = device_)\n",
    "\n",
    "        c_strides1=[1,1,1,1]\n",
    "        c_strides2=[1,1,1,1]\n",
    "        c_strides3=[1,1,1,1]\n",
    "        c_strides4=[1,1,1,1]\n",
    "\n",
    "        c_pooling1='SAME'\n",
    "        c_pooling2='SAME'\n",
    "        c_pooling3='SAME'\n",
    "        c_pooling4='VALID'\n",
    "        \n",
    "        layer1 = tf.nn.conv2d(x ,      w_conv1 , c_strides1 , c_pooling1)+b_conv1\n",
    "        layer1 = tf.nn.relu(layer1)\n",
    "        layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 , c_pooling2)+b_conv2\n",
    "        layer2 = tf.nn.relu(layer2)\n",
    "        layer3 = tf.nn.conv2d(layer2 , w_conv3 , c_strides3 , c_pooling3)+b_conv3\n",
    "        layer3 = tf.nn.relu(layer3)\n",
    "        layer4 = tf.nn.conv2d(layer3 , w_conv4 , c_strides4 , c_pooling4)+b_conv4\n",
    "        layer4 = tf.nn.relu(layer4)\n",
    "\n",
    "        ##############################left side##################################\n",
    "        b_out_ch1=64 ; b_out_ch2=96;    \n",
    "        #########################################################################\n",
    "        b_c_ksize1=[1,1,in_ch , b_out_ch1]\n",
    "        b_c_ksize2=[3,3,b_out_ch1 , b_out_ch2]\n",
    "        b_w_conv1 , b_b_conv1 =make_weights_biases('STEM_B' , 'b_W1' , b_c_ksize1 ,device_name = device_)\n",
    "        b_w_conv2 , b_b_conv2= make_weights_biases('STEM_B' , 'b_W2' , b_c_ksize2 ,device_name = device_)\n",
    "\n",
    "        b_c_strides1=[1,1,1,1]\n",
    "        b_c_strides2=[1,1,1,1]\n",
    "\n",
    "        b_c_pooling1='SAME'\n",
    "        b_c_pooling2='VALID'\n",
    "        \n",
    "        b_layer1 =tf.nn.conv2d(    x ,      b_w_conv1, b_c_strides1, b_c_pooling1  ) + b_b_conv1\n",
    "        b_layer1 = tf.nn.relu(layer1)\n",
    "        b_layer2=tf.nn.conv2d(  b_layer1 , b_w_conv2, b_c_strides2, b_c_pooling2  ) + b_b_conv2\n",
    "\n",
    "        ##############################concatenate layers###########################\n",
    "        concat_layer=tf.concat(3 , [layer4 , b_layer2])\n",
    "        ret_layer=concat_layer\n",
    "    return ret_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def STEM_C( x , device_ ):\n",
    "    with tf.device(device_):\n",
    "        in_ch=x.get_shape()[3]\n",
    "        #########################################################################\n",
    "\n",
    "        out_ch = 192\n",
    "\n",
    "\n",
    "        c_ksize=[3,3,in_ch,out_ch]\n",
    "        w_conv , b_conv =make_weights_biases('STEM_C' , 'W1' , c_ksize ,device_name = device_)\n",
    "        c_strides=[1,1,1,1]\n",
    "        c_pooling='SAME'\n",
    "\n",
    "        layer = tf.nn.conv2d(x , w_conv   , c_strides   , c_pooling)+b_conv\n",
    "        layer = tf.nn.relu(layer)\n",
    "        \n",
    "        #########################################################################\n",
    "        \n",
    "        b_p_ksize=[1,2,2,1]\n",
    "        b_p_strides=[1,1,1,1]\n",
    "        b_p_pooling='SAME'\n",
    "\n",
    "        b_layer = tf.nn.max_pool(x , b_p_ksize , b_p_strides , b_p_pooling)\n",
    "        b_layer = tf.nn.relu(b_layer)\n",
    "        #########################################################################\n",
    "\n",
    "        print layer\n",
    "        print b_layer\n",
    "\n",
    "        concat_layer=tf.concat(3,[layer , b_layer])\n",
    "        ret_layer = concat_layer\n",
    "    return ret_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULE A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MODULE_A(x , device_):\n",
    "\n",
    "    \"\"\"\n",
    "    input X shape is [n_batch , row , col, out_ch]\n",
    "    35 x 35 grid\n",
    "    \"\"\"\n",
    "\n",
    "    #################################################################################\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch1=64 ; out_ch2= 96;\n",
    "    c_ksize1 = [1 , 1 ,in_ch , out_ch1 ]\n",
    "    c_ksize2 = [3 , 3 ,out_ch1 , out_ch2 ]\n",
    "    w_conv1 , b_conv1 = make_weights_biases ('INCEPTION_MODULE_A' , 'W1' , c_ksize1 ,device_)\n",
    "    w_conv2 , b_conv2 = make_weights_biases('INCEPTION_MODUEL_A' ,'W1' , c_ksize2 ,device_)\n",
    "\n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2=[1,1,1,1]\n",
    "    \n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2='SAME'\n",
    "    layer1 = tf.nn.conv2d(x , w_conv1 , c_strides1 ,c_pooling1 )\n",
    "    layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 ,c_pooling2 )\n",
    "\n",
    "    #################################################################################                     \n",
    "\n",
    "    b1_p_ksize   =[1,2,2,1]\n",
    "    b1_p_strides =[1,1,1,1]\n",
    "    b1_p_pooling='SAME'\n",
    "\n",
    "\n",
    "    b1_out_ch = 96;\n",
    "    b1_c_ksize  =[1,1, in_ch , b1_out_ch]\n",
    "    b1_c_strides=[1,1,1,1]\n",
    "    b1_c_pooling ='SAME'\n",
    "\n",
    "    b1_w_conv , b1_b_conv =make_weights_biases('INCEPTION_MODULE_A','b1_W',b1_c_ksize , device_)\n",
    "\n",
    "\n",
    "    b1_layer1=tf.nn.avg_pool(x, b1_p_ksize , b1_p_strides,b1_p_pooling)\n",
    "    b1_layer1=tf.nn.relu(b1_layer1)\n",
    "    b1_layer2=tf.nn.conv2d(b1_layer1 , b1_w_conv , b1_c_strides , b1_c_pooling)+b1_b_conv\n",
    "    b1_layer2=tf.nn.relu(b1_layer2)\n",
    "\n",
    "    #################################################################################                     \n",
    "\n",
    "    b2_out_ch=96\n",
    "    b2_c_ksize = [1,1,in_ch , b2_out_ch ]\n",
    "    b2_w_conv , b2_b_conv = make_weights_biases('INCEPTION_MODULE_A','b2_W',b2_c_ksize , device_)\n",
    "    b2_c_strides=[1,1,1,1]\n",
    "    b2_c_pooling='SAME'\n",
    "\n",
    "    b2_layer = tf.nn.conv2d( x, b2_w_conv , b2_c_strides ,b2_c_pooling ) +b2_b_conv \n",
    "    b2_layer = tf.nn.relu(b2_layer)\n",
    "\n",
    "\n",
    "\n",
    "    #################################################################################                     \n",
    "\n",
    "\n",
    "    b3_out_ch1=64;b3_out_ch2=96;b3_out_ch3=96;\n",
    "    b3_c_ksize1 =[1,1,in_ch , b3_out_ch1]\n",
    "    b3_c_ksize2 =[3,3,b3_out_ch1 , b3_out_ch2]\n",
    "    b3_c_ksize3 =[3,3,b3_out_ch2 , b3_out_ch3]\n",
    "    b3_w_conv1 , b3_b_conv1 = make_weights_biases('INCEPTION_MODULE_A','b3_W1',b3_c_ksize1 , device_)\n",
    "    b3_w_conv2 , b3_b_conv2 = make_weights_biases('INCEPTION_MODULE_A','b3_W2',b3_c_ksize2 , device_)\n",
    "    b3_w_conv3 , b3_b_conv3 = make_weights_biases('INCEPTION_MODULE_A','b3_W3',b3_c_ksize3 , device_)\n",
    "    b3_c_strides1=[1,1,1,1]\n",
    "    b3_c_strides2=[1,1,1,1]\n",
    "    b3_c_strides3=[1,1,1,1]\n",
    "    b3_c_pooling1='SAME'\n",
    "    b3_c_pooling2='SAME'\n",
    "    b3_c_pooling3='SAME'\n",
    "\n",
    "    b3_layer1 = tf.nn.conv2d(x , b3_w_conv1 , b3_c_strides1 ,b3_c_pooling1)+b3_b_conv1 \n",
    "    b3_layer1 = tf.nn.relu(b3_layer1)\n",
    "    b3_layer2 = tf.nn.conv2d(b3_layer1 , b3_w_conv2 , b3_c_strides2 ,b3_c_pooling2)+b3_b_conv2 \n",
    "    b3_layer2 = tf.nn.relu(b3_layer2)\n",
    "    b3_layer3 = tf.nn.conv2d(b3_layer2 , b3_w_conv3 , b3_c_strides3 ,b3_c_pooling3)+b3_b_conv3 \n",
    "    b3_layer3 = tf.nn.relu(b3_layer3)\n",
    "\n",
    "    #################################################################################                     \n",
    "    concat_A=tf.concat(3,[layer2 , b1_layer2])\n",
    "    concat_B=tf.concat(3,[concat_A , b2_layer])\n",
    "    concat_C=tf.concat(3,[concat_B , b3_layer3])\n",
    "\n",
    "    return concat_C\n",
    "\n",
    "    #################################################################################                     \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODUEL B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MODULE_B(x , device):\n",
    "\n",
    "    \"\"\"\n",
    "    for 17 X 17 grid \n",
    "    \"\"\"\n",
    "    in_ch =x.get_shape()[3]\n",
    "    out_ch1 =192 ; out_ch2=224; out_ch3 =256\n",
    "    c_ksize1 = [1,1, in_ch  ,out_ch1]\n",
    "    c_ksize2 = [1,7, out_ch1,out_ch2]\n",
    "    c_ksize3 = [7,1, out_ch2,out_ch3]\n",
    "\n",
    "    w_conv1 , b_conv1 =make_weights_biases('INCEPTION_MODULE_B' ,'W1' ,  c_ksize1 , device)\n",
    "    w_conv2 , b_conv2 =make_weights_biases('INCEPTION_MODULE_B' ,'W2' ,  c_ksize2 , device)\n",
    "    w_conv3 , b_conv3 =make_weights_biases('INCEPTION_MODULE_B' ,'W3' ,  c_ksize3 , device)\n",
    "    \n",
    "    c_strides1 =[1,1,1,1]\n",
    "    c_strides2 =[1,1,1,1]\n",
    "    c_strides3 =[1,1,1,1]\n",
    "    \n",
    "    c_pooling1 ='SAME'\n",
    "    c_pooling2 ='SAME'\n",
    "    c_pooling3 ='SAME'\n",
    "\n",
    "\n",
    "    layer1 = tf.nn.conv2d(x, w_conv1,c_strides1 , c_pooling1 ) +b_conv1\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "    layer2 = tf.nn.conv2d(layer1, w_conv2,c_strides2 , c_pooling2 ) +b_conv2\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "    layer3 = tf.nn.conv2d(layer2, w_conv3,c_strides3 , c_pooling3 ) +b_conv3\n",
    "    layer3 = tf.nn.relu(layer3)\n",
    "\n",
    "\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b1_p_ksize=[1,2,2,1]\n",
    "    b1_p_strides=[1,1,1,1]\n",
    "    b1_p_pooling ='SAME'\n",
    "\n",
    "    b1_out_ch = 128\n",
    "    b1_c_ksize=[1,1,in_ch,b1_out_ch]\n",
    "    b1_w_conv , b1_b_conv = make_weights_biases('INCEPTION_MODULE_B','b1_W1',b1_c_ksize, device )\n",
    "    b1_c_strides=[1,1,1,1]\n",
    "    b1_c_pooling='SAME'\n",
    "\n",
    "\n",
    "    b1_layer1=tf.nn.avg_pool(x , b1_p_ksize , b1_p_strides , b1_p_pooling )\n",
    "    b1_layer1=tf.nn.relu(b1_layer1)\n",
    "    b1_layer2 =tf.nn.conv2d(b1_layer1 ,b1_w_conv , b1_c_strides, b1_c_pooling )+b1_b_conv \n",
    "    b1_layer2 =tf.nn.relu(b1_layer2)\n",
    "\n",
    "    ################################################################################# \n",
    "    b2_out_ch=384\n",
    "    b2_c_ksize=[1,1,in_ch,b2_out_ch]\n",
    "    b2_w_conv , b2_b_conv =make_weights_biases('INCEPTION_MODULE_B','b2_W1' ,b2_c_ksize , device)\n",
    "    b2_c_strides=[1,1,1,1]\n",
    "    b2_c_pooling='SAME'\n",
    "    b2_layer = tf.nn.conv2d(x,b2_w_conv , b2_c_strides , b2_c_pooling)+b2_b_conv\n",
    "    b2_layer = tf.nn.relu(b2_layer)\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b3_out_ch1=192; b3_out_ch2 =192; b3_out_ch3=224 ; b3_out_ch4=224 ; b3_out_ch5 =256\n",
    "    b3_c_ksize1=[1,1,in_ch,b3_out_ch1]\n",
    "    b3_c_ksize2=[1,7,b3_out_ch1 , b3_out_ch2]\n",
    "    b3_c_ksize3=[7,1,b3_out_ch2 , b3_out_ch3]\n",
    "    b3_c_ksize4=[1,7,b3_out_ch3 , b3_out_ch4]\n",
    "    b3_c_ksize5=[7,1,b3_out_ch4 , b3_out_ch5]\n",
    "\n",
    "    b3_w_conv1 , b3_b_conv1=make_weights_biases('INCEPTION_MODULE_B','b3_W1',b3_c_ksize1, device)\n",
    "    b3_w_conv2 , b3_b_conv2=make_weights_biases('INCEPTION_MODULE_B','b3_W2',b3_c_ksize2, device)\n",
    "    b3_w_conv3 , b3_b_conv3=make_weights_biases('INCEPTION_MODULE_B','b3_W3',b3_c_ksize3, device)\n",
    "    b3_w_conv4 , b3_b_conv4=make_weights_biases('INCEPTION_MODULE_B','b3_W4',b3_c_ksize4, device)\n",
    "    b3_w_conv5 , b3_b_conv5=make_weights_biases('INCEPTION_MODULE_B','b3_W5',b3_c_ksize5, device)\n",
    "\n",
    "\n",
    "    b3_layer1 = tf.nn.conv2d(x,b3_w_conv1 , b2_c_strides , b2_c_pooling)+b3_b_conv1\n",
    "    b3_layer1 = tf.nn.relu(b3_layer1)\n",
    "    b3_layer2 = tf.nn.conv2d(b3_layer1,b3_w_conv2 , b2_c_strides , b2_c_pooling)+b3_b_conv2\n",
    "    b3_layer2 = tf.nn.relu(b3_layer2)\n",
    "    b3_layer3 = tf.nn.conv2d(b3_layer2,b3_w_conv3 , b2_c_strides , b2_c_pooling)+b3_b_conv3\n",
    "    b3_layer3 = tf.nn.relu(b3_layer3)\n",
    "    b3_layer4 = tf.nn.conv2d(b3_layer3,b3_w_conv4 , b2_c_strides , b2_c_pooling)+b3_b_conv4\n",
    "    b3_layer4 = tf.nn.relu(b3_layer4)\n",
    "    b3_layer5 = tf.nn.conv2d(b3_layer4,b3_w_conv5 , b2_c_strides , b2_c_pooling)+b3_b_conv5\n",
    "    b3_layer5 = tf.nn.relu(b3_layer5)\n",
    "\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    layerA=tf.concat(3, [layer3 , b1_layer2] )\n",
    "    layerB=tf.concat(3, [layerA , b2_layer] )\n",
    "    layerC=tf.concat(3, [layerB , b3_layer5] )\n",
    "\n",
    "    print layerC\n",
    "    return layerC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULE C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MODULE_C(x , device):\n",
    "\n",
    "    \"\"\"\n",
    "    for 8 X 8 grid modules\n",
    "    \"\"\"\n",
    "    print x.get_shape()\n",
    "    in_ch=x.get_shape()[3]\n",
    "    \n",
    "    out_ch1 = 384 ; out_ch2_a =256 ;out_ch2_b = 256\n",
    "    c_ksize1 = [1,1,in_ch , out_ch1]\n",
    "    c_ksize2_a = [1,3,out_ch1 , out_ch2_a]\n",
    "    c_ksize2_b = [3,1,out_ch2_a , out_ch2_b]\n",
    "    w_conv1 ,b_conv1=make_weights_biases('INCEPTION_MODULE_C','W1', c_ksize1 ,device)\n",
    "    w_conv2_a ,b_conv2_a=make_weights_biases('INCEPTION_MODULE_C','W2_a', c_ksize2_a ,device)\n",
    "    w_conv2_b ,b_conv2_b=make_weights_biases('INCEPTION_MODULE_C','W2_b', c_ksize2_b ,device)\n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2_a=[1,1,1,1]\n",
    "    c_strides2_b=[1,1,1,1]\n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2_a='SAME'\n",
    "    c_pooling2_b='SAME'\n",
    "\n",
    "    layer1 = tf.nn.conv2d(x, w_conv1 ,c_strides1 ,c_pooling1)+b_conv1\n",
    "    layer1=tf.nn.relu(layer1)\n",
    "    layer2_a = tf.nn.conv2d(layer1,  w_conv2_a ,c_strides2_a ,c_pooling2_a )+b_conv2_a\n",
    "    layer2_a = tf.nn.relu(layer2_a)\n",
    "    layer2_b = tf.nn.conv2d(layer1  , w_conv2_a ,c_strides2_a ,c_pooling2_b)+b_conv2_b\n",
    "    layer2_b = tf.nn.relu(layer2_b)\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b1_p_ksize=[1,2,2,1]\n",
    "    b1_p_strides=[1,1,1,1]\n",
    "    b1_p_pooling='SAME'\n",
    "\n",
    "    b1_out_ch =256\n",
    "    b1_c_ksize=[1,1,in_ch , b1_out_ch]\n",
    "    b1_w_conv , b1_b_conv= make_weights_biases('INCEPTION_MODULE_C' , 'b1_W1' , b1_c_ksize , device)\n",
    "    b1_c_pooling = 'SAME';b1_c_strides = [1,1,1,1];\n",
    "    b1_layer1 = tf.nn.avg_pool(x , b1_p_ksize , b1_p_strides , b1_p_pooling)\n",
    "    b1_layer2 = tf.nn.conv2d(b1_layer1 , b1_w_conv , b1_c_strides  ,b1_c_pooling)+b1_b_conv\n",
    "    b1_layer2 = tf.nn.relu(b1_layer2)\n",
    "    ################################################################################# \n",
    "    b2_out_ch=256\n",
    "    b2_c_ksize=[1,1,in_ch,b2_out_ch]\n",
    "    b2_w_conv , b2_b_conv= make_weights_biases('INCEPTION_MODULE_C' , 'b2_W' , b2_c_ksize , device)\n",
    "    b2_c_pooling = 'SAME';b2_c_strides=[1,1,1,1];\n",
    "    b2_layer = tf.nn.conv2d(x , b2_w_conv , b2_c_strides  ,b2_c_pooling)+b2_b_conv\n",
    "    b2_layer= tf.nn.relu(b2_layer)\n",
    "   \n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b3_out_ch1=384;b3_out_ch2=448;b3_out_ch3=512;b3_out_ch4_a=256;b3_out_ch4_b=256\n",
    "    b3_c_ksize1 =[1,1,in_ch , b3_out_ch1]\n",
    "    b3_c_ksize2 =[1,3,b3_out_ch1 , b3_out_ch2]\n",
    "    b3_c_ksize3 =[3,1,b3_out_ch2 , b3_out_ch3]\n",
    "    b3_c_ksize4_a =[3,1,b3_out_ch3 , b3_out_ch4_a]\n",
    "    b3_c_ksize4_b =[1,3,b3_out_ch3, b3_out_ch4_b]\n",
    "\n",
    "    b3_w_conv1 , b3_b_conv1 = make_weights_biases('INCEPTION_MODULE_C','b3_W1',b3_c_ksize1 , device)\n",
    "    b3_w_conv2 , b3_b_conv2 = make_weights_biases('INCEPTION_MODULE_C','b3_W2',b3_c_ksize2 , device)\n",
    "    b3_w_conv3 , b3_b_conv3 = make_weights_biases('INCEPTION_MODULE_C','b3_W3',b3_c_ksize3 , device)\n",
    "    b3_w_conv4_a , b3_b_conv4_a = make_weights_biases('INCEPTION_MODULE_C','b3_W4_a',b3_c_ksize4_a , device)\n",
    "    b3_w_conv4_b , b3_b_conv4_b = make_weights_biases('INCEPTION_MODULE_C','b3_W4_b',b3_c_ksize4_b , device)\n",
    "\n",
    "    b3_c_strides1=[1,1,1,1]\n",
    "    b3_c_strides2=[1,1,1,1]\n",
    "    b3_c_strides3=[1,1,1,1]\n",
    "    b3_c_strides4_a=[1,1,1,1]\n",
    "    b3_c_strides4_b=[1,1,1,1]\n",
    "\n",
    "    b3_c_pooling1='SAME'\n",
    "    b3_c_pooling2='SAME'\n",
    "    b3_c_pooling3='SAME'\n",
    "    b3_c_pooling4_a='SAME'\n",
    "    b3_c_pooling4_b='SAME'\n",
    "\n",
    "    b3_laer1 = tf.nn.conv2d(x , b3_w_conv1 , b3_c_strides1 ,b3_c_pooling1)+b3_b_conv1 \n",
    "    b3_layer1 = tf.nn.relu(b3_laer1)\n",
    "    b3_layer2 = tf.nn.conv2d(b3_laer1 , b3_w_conv2 , b3_c_strides2 ,b3_c_pooling2)+b3_b_conv2 \n",
    "    b3_layer2 = tf.nn.relu(b3_layer2)\n",
    "    b3_layer3 = tf.nn.conv2d(b3_layer2 , b3_w_conv3 , b3_c_strides3 ,b3_c_pooling3)+b3_b_conv3 \n",
    "    b3_layer3 = tf.nn.relu(b3_layer3)\n",
    "\n",
    "    b3_layer4_a = tf.nn.conv2d(b3_layer3 , b3_w_conv4_a , b3_c_strides4_a ,b3_c_pooling4_a)+b3_b_conv4_a \n",
    "    b3_layer4_a = tf.nn.relu(b3_layer4_a)\n",
    "\n",
    "    b3_layer4_b = tf.nn.conv2d(b3_layer3 , b3_w_conv4_b , b3_c_strides4_b ,b3_c_pooling4_b)+b3_b_conv4_b \n",
    "    b3_layer4_b = tf.nn.relu(b3_layer4_b)\n",
    "\n",
    "\n",
    "    ################################################################################# \n",
    "\n",
    "    layerA = tf.concat(3 , [layer2_a, layer2_b])\n",
    "    layerB = tf.concat(3 , [layerA  , b1_layer2])\n",
    "    layerC = tf.concat(3 , [layerB  , b2_layer])\n",
    "    layerD = tf.concat(3 , [layerC  , b3_layer4_a])\n",
    "    layerE = tf.concat(3 , [layerD  , b3_layer4_b])\n",
    "\n",
    "    return layerE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDUCTION A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def REDUCTION_A(x , device):\n",
    "    ####################################################################################\n",
    "   \n",
    "    \"\"\"\n",
    "    usage:\n",
    "    x shape =[ n_batch , row , col , ch] \n",
    "    \"\"\"\n",
    "    print x.get_shape()\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch = 384\n",
    "    c_ksize= [3,3,in_ch , out_ch]\n",
    "    w_conv , b_conv =make_weights_biases('INCEPTION_REDUCTION_A','W1',c_ksize,device)\n",
    "    c_strides=[1,2,2,1]\n",
    "    c_pooling='VALID'\n",
    "    layer=tf.nn.conv2d(x,w_conv,c_strides , c_pooling)+b_conv\n",
    "    layer=tf.nn.relu(layer)\n",
    "\n",
    "    ####################################################################################\n",
    "   \n",
    "    b1_p_ksize=[1,3,3,1]\n",
    "    b1_p_strides=[1,2,2,1]\n",
    "    b1_p_pooling='VALID'\n",
    "    b1_layer = tf.nn.max_pool(x,b1_p_ksize , b1_p_strides , b1_p_pooling)\n",
    "    ####################################################################################\n",
    "   \n",
    "    b2_out_ch1 = 192; b2_out_ch2=288 ;b2_out_ch3 = 256;\n",
    "    b2_c_ksize1=[1,1,in_ch,b2_out_ch1]\n",
    "    b2_c_ksize2=[3,3,b2_out_ch1,b2_out_ch2]\n",
    "    b2_c_ksize3=[3,3,b2_out_ch2,b2_out_ch3]\n",
    "    b2_w_conv1 , b2_b_conv1 = make_weights_biases('INCEPTION_REDUCTION_A' ,'b2_W1' , b2_c_ksize1 , device)\n",
    "    b2_w_conv2 , b2_b_conv2 = make_weights_biases('INCEPTION_REDUCTION_A' ,'b2_W2' , b2_c_ksize2 , device)\n",
    "    b2_w_conv3 , b2_b_conv3 = make_weights_biases('INCEPTION_REDUCTION_A' ,'b2_W3' , b2_c_ksize3 , device)\n",
    "    \n",
    "    b2_c_strides1=[1,1,1,1]\n",
    "    b2_c_strides2=[1,1,1,1]\n",
    "    b2_c_strides3=[1,2,2,1]\n",
    "    b2_c_pooling1='SAME'\n",
    "    b2_c_pooling2='SAME'\n",
    "    b2_c_pooling3='VALID'\n",
    "    \n",
    "    b2_layer1 = tf.nn.conv2d(x        , b2_w_conv1 ,b2_c_strides1 ,b2_c_pooling1)+b2_b_conv1\n",
    "    b2_layer1 = tf.nn.relu(b2_layer1)\n",
    "    b2_layer2 = tf.nn.conv2d(b2_layer1, b2_w_conv2 ,b2_c_strides2 ,b2_c_pooling2)+b2_b_conv2\n",
    "    b2_layer2 = tf.nn.relu(b2_layer2)\n",
    "    b2_layer3 = tf.nn.conv2d(b2_layer2, b2_w_conv3 ,b2_c_strides3 ,b2_c_pooling3)+b2_b_conv3\n",
    "    b2_layer3 = tf.nn.relu(b2_layer3)\n",
    "    \n",
    "    print layer.get_shape()\n",
    "    print b1_layer.get_shape()\n",
    "    print b2_layer3.get_shape()\n",
    "    ####################################################################################\n",
    "   \n",
    "    layerA=tf.concat(3 ,[layer ,b1_layer ])\n",
    "    layerB=tf.concat(3 ,[layerA ,b2_layer3])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return layerB\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDUCTION B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def REDUCTION_B(x , device):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ####################################################################################\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch1=192 ; out_ch2=192;\n",
    "\n",
    "    c_ksize1 =[1,1,in_ch , out_ch1]\n",
    "    c_ksize2 =[3,3,out_ch1,out_ch2]\n",
    "    w_conv1, b_conv1 = make_weights_biases('INCEPTION_REDUCTION_B','W1',c_ksize1,device)\n",
    "    w_conv2, b_conv2 = make_weights_biases('INCEPTION_REDUCTION_B','W2',c_ksize2,device)\n",
    "    \n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2=[1,2,2,1]\n",
    "    \n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2='VALID'\n",
    "    \n",
    "    layer1 = tf.nn.conv2d(x,w_conv1 , c_strides1, c_pooling1)\n",
    "    layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 , c_pooling2)    \n",
    "    \n",
    "    b1_p_ksize=[1,3,3,1]\n",
    "    b1_p_strides=[1,2,2,1]\n",
    "    b1_p_pooling='VALID'\n",
    "    \n",
    "    b1_layer1=tf.nn.max_pool(x ,b1_p_ksize , b1_p_strides , b1_p_pooling)\n",
    "    \n",
    "    ####################################################################################\n",
    "    b2_out_ch1=256 ; b2_out_ch2 = 256 ; b2_out_ch3=320 ; b2_out_ch4=320;\n",
    "    b2_p_ksize1 =[1,1,in_ch , b2_out_ch1]\n",
    "    b2_p_ksize2 =[1,7,b2_out_ch1 , b2_out_ch2]\n",
    "    b2_p_ksize3 =[7,1,b2_out_ch2 , b2_out_ch3]\n",
    "    b2_p_ksize4 =[3,3,b2_out_ch3 , b2_out_ch4]\n",
    "    \n",
    "    b2_w_conv1, b2_b_conv1 = make_weights_biases('INCEPTION_REDUCTION_B','b2_W1' ,b2_c_ksize1,device)\n",
    "    b2_w_conv2, b2_b_conv2 = make_weights_biases('INCEPTION_REDUCTION_B','b2_W2' ,b2_c_ksize2,device)\n",
    "    b2_w_conv3, b2_b_conv3 = make_weights_biases('INCEPTION_REDUCTION_B','b2_W3' ,b2_c_ksize3,device)\n",
    "    b2_w_conv4, b2_b_conv4 = make_weights_biases('INCEPTION_REDUCTION_B','b2_W4' ,b2_c_ksize4,device)\n",
    "    \n",
    "    b2_c_strides1=[1,1,1,1]\n",
    "    b2_c_strides2=[1,1,1,1]\n",
    "    b2_c_strides3=[1,1,1,1]\n",
    "    b2_c_strides4=[1,1,1,1]\n",
    "    \n",
    "    b2_c_pooling1= 'SAME'\n",
    "    b2_c_pooling2= 'SAME'\n",
    "    b2_c_pooling3 = 'SAME'\n",
    "    b2_c_pooling4 = 'VALID'\n",
    "    \n",
    "    b2_layer1 = tf.nn.conv2d(x, b2_w_conv1 , b2_c_strides1 , b2_c_pooling1 )+b2_b_conv1\n",
    "    b2_layer2 = tf.nn.conv2d(b2_layer1, b2_w_conv2 , b2_c_strides2 , b2_c_pooling2 )+b2_b_conv2\n",
    "    b2_layer3 = tf.nn.conv2d(b2_layer2, b2_w_conv3 , b2_c_strides3 , b2_c_pooling3 )+b2_b_conv3\n",
    "    b2_layer4 = tf.nn.conv2d(b2_layer3, b2_w_conv4 , b2_c_strides4 , b2_c_pooling4 )+b2_b_conv4\n",
    "    \n",
    "    ####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
