{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#conv Neural Network\n",
    "# tensorboard --logdir=/home/ncc/notebook/learn/tensorboard/log\n",
    "\"\"\"\n",
    "created by kim Seong jung\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load Training , Validation , Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_ch =3\n",
    "n_classes=10\n",
    "img_row=32\n",
    "img_col=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    def next_batch(batch_size , image , label):\n",
    "\n",
    "        a=np.random.randint(np.shape(image)[0] -batch_size)\n",
    "        batch_x = image[a:a+batch_size,:]\n",
    "        batch_y= label[a:a+batch_size,:]\n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define Variable , and placeholder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "x_= tf.placeholder(\"float\",shape=[None,img_row , img_col , in_ch],  name = 'x-input')\n",
    "y_= tf.placeholder(\"float\",shape=[None , n_classes] , name = 'y-input')\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "x_image= tf.reshape(x_,[-1,img_row,img_col,in_ch])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"def weight_variable(name,shape):\n",
    "    #initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    initial = tf.get_variable(name,shape=shape , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)\"\"\"\n",
    "def bias_variable(shape , name):\n",
    "    initial = tf.constant(0.1 , shape=shape , )\n",
    "    return tf.Variable(initial , name=name)\n",
    "\n",
    "def conv2d(x,w,strides_ , name):\n",
    "    return tf.nn.conv2d(x,w, strides = strides_, padding='SAME' , name = name)\n",
    "\n",
    "def max_pool(x , ksize , strides , padding , name ):\n",
    "    return tf.nn.max_pool(x ,ksize , strides , padding ,name=name)\n",
    "def make_weights_biases(layer_name , w_name , b_name,ksize ,device_name,initializer='xavier'):\n",
    "    if len(ksize)==4: # convolution filter shape [batch , row , col , color_ch]\n",
    "        out_ch=ksize[3]\n",
    "    elif len(ksize)==2: #fully connected layer shape [in_ch , output_ch]\n",
    "        out_ch=ksize[1]\n",
    "    with tf.device(device_name):\n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            try:\n",
    "                w_conv = tf.get_variable(w_name, ksize , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv = tf.get_variable(w_name, ksize , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            try:\n",
    "                b_conv = bias_variable([out_ch] , name=b_name)\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv = bias_variable([out_ch],name=b_name)\n",
    "    return w_conv , b_conv \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_A(x , device_):\n",
    "    with tf.device(device_):\n",
    "        in_ch=x.get_shape()[3]\n",
    "        out_ch1=32 ; out_ch2=32;out_ch3=64;out_ch4=96;\n",
    "\n",
    "        c_ksize1=[3,3,in_ch , out_ch1]\n",
    "        c_ksize2=[3,3,out_ch1 , out_ch2]\n",
    "        c_ksize3=[3,3,out_ch2 , out_ch3]\n",
    "        c_ksize4=[3,3,out_ch3 , out_ch4]\n",
    "        w_conv1 , b_conv1 =make_weights_biases('STEM_A' , 'W1' ,'B1', c_ksize1 ,device_name = device_)\n",
    "        w_conv2 , b_conv2= make_weights_biases('STEM_A' , 'W2' ,'B2',c_ksize2 ,device_name = device_)\n",
    "        w_conv3 , b_conv3= make_weights_biases('STEM_A' , 'W3' ,'B3' ,c_ksize3 ,device_name = device_)\n",
    "        w_conv4 , b_conv4= make_weights_biases('STEM_A' , 'W4' ,'B4', c_ksize4 ,device_name = device_)\n",
    "\n",
    "        c_strides1=[1,2,2,1]\n",
    "        c_strides2=[1,1,1,1]\n",
    "        c_strides3=[1,1,1,1]\n",
    "        c_strides4=[1,2,2,1]\n",
    "\n",
    "        c_pooling1='VALID'\n",
    "        c_pooling2='VALID'\n",
    "        c_pooling3='SAME'\n",
    "        c_pooling4='VALID'\n",
    "\n",
    "        b_p_ksize4=[1,3,3,1]\n",
    "        b_p_strides4=[1,2,2,1]\n",
    "        b_p_padding4 ='VALID'\n",
    "\n",
    "\n",
    "        with tf.variable_scope('STEM_A') as scope: \n",
    "            layer1=tf.nn.conv2d(    x ,      w_conv1, c_strides1, c_pooling1 ,name='layer1'  )+b_conv1\n",
    "            layer1=tf.nn.relu(layer1,name='layer1_relu')\n",
    "            layer2=tf.nn.conv2d(    layer1 , w_conv2, c_strides2, c_pooling2,name='layer2'  )+b_conv2\n",
    "            layer2=tf.nn.relu(layer2,name='layer2_relu')\n",
    "            layer3=tf.nn.conv2d(    layer2 , w_conv3, c_strides3, c_pooling3,name='layer3'  )+b_conv3\n",
    "            layer3=tf.nn.relu(layer3 , name='layer3_relu')\n",
    "            layer4=tf.nn.conv2d(    layer3 , w_conv4, c_strides4, c_pooling4 ,name='layer4' )+b_conv4\n",
    "            layer4=tf.nn.relu(layer4,name='layer4_relu')\n",
    "\n",
    "\n",
    "            b_layer4=tf.nn.max_pool(layer3 , b_p_ksize4, b_p_strides4, b_p_padding4 ,name='b_layer4') #b is branch\n",
    "            b_layer4=tf.nn.relu(b_layer4 , name = 'b_layer_relu')\n",
    "            print layer1\n",
    "            print layer2\n",
    "            print layer3\n",
    "            print layer4\n",
    "            print b_layer4\n",
    "\n",
    "\n",
    "            concat_layer=tf.concat(3 , [layer4 , b_layer4] , name='CONCAT')\n",
    "            return concat_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_B( x , device_):\n",
    "    with tf.device(device_):\n",
    "\n",
    "        in_ch=x.get_shape()[3]\n",
    "        #########################################################################\n",
    "        out_ch1=64 ; out_ch2=64;out_ch3=64;out_ch4=96;\n",
    "        ##############################right side##################################\n",
    "        c_ksize1=[1,1,in_ch , out_ch1]\n",
    "        c_ksize2=[7,1,out_ch1 , out_ch2]\n",
    "        c_ksize3=[1,7,out_ch2 , out_ch3]\n",
    "        c_ksize4=[3,3,out_ch3 , out_ch4]\n",
    "\n",
    "        w_conv1 , b_conv1 =make_weights_biases('STEM_B' , 'W1' ,'B1', c_ksize1 ,device_name = device_)\n",
    "        w_conv2 , b_conv2= make_weights_biases('STEM_B' , 'W2' ,'B2',c_ksize2 ,device_name = device_)\n",
    "        w_conv3 , b_conv3= make_weights_biases('STEM_B' , 'W3' ,'B3' ,c_ksize3 ,device_name = device_)\n",
    "        w_conv4 , b_conv4= make_weights_biases('STEM_B' , 'W4' ,'B4', c_ksize4 ,device_name = device_)\n",
    "\n",
    "\n",
    "        c_strides1=[1,1,1,1]\n",
    "        c_strides2=[1,1,1,1]\n",
    "        c_strides3=[1,1,1,1]\n",
    "        c_strides4=[1,1,1,1]\n",
    "\n",
    "        c_pooling1='SAME'\n",
    "        c_pooling2='SAME'\n",
    "        c_pooling3='SAME'\n",
    "        c_pooling4='VALID'\n",
    "\n",
    "        layer1 = tf.nn.conv2d(x ,      w_conv1 , c_strides1 , c_pooling1 ,name='STEM_B_layer1')+b_conv1\n",
    "        layer1 = tf.nn.relu(layer1 , name='STEM_B_layer1_relu')\n",
    "        layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 , c_pooling2 , name='STEM_B_layer2')+b_conv2\n",
    "        layer2 = tf.nn.relu(layer2,name='STEM_B_layer2_relu')\n",
    "        layer3 = tf.nn.conv2d(layer2 , w_conv3 , c_strides3 , c_pooling3,name='STEM_B_layer3')+b_conv3\n",
    "        layer3 = tf.nn.relu(layer3,name='STEM_B_layer3_relu')\n",
    "        layer4 = tf.nn.conv2d(layer3 , w_conv4 , c_strides4 , c_pooling4,name='STEM_B_layer4')+b_conv4\n",
    "        layer4 = tf.nn.relu(layer4,name='STEM_B_layer3_relu')\n",
    "\n",
    "        ##############################left side##################################\n",
    "        b_out_ch1=64 ; b_out_ch2=96;    \n",
    "        #########################################################################\n",
    "        b_c_ksize1=[1,1,in_ch , b_out_ch1]\n",
    "        b_c_ksize2=[3,3,b_out_ch1 , b_out_ch2]\n",
    "        b_w_conv1 , b_b_conv1 =make_weights_biases('STEM_B' , 'b_W1' , b_c_ksize1 ,device_name = device_)\n",
    "        b_w_conv2 , b_b_conv2= make_weights_biases('STEM_B' , 'b_W2' , b_c_ksize2 ,device_name = device_)\n",
    "\n",
    "        b_c_strides1=[1,1,1,1]\n",
    "        b_c_strides2=[1,1,1,1]\n",
    "\n",
    "        b_c_pooling1='SAME'\n",
    "        b_c_pooling2='VALID'\n",
    "\n",
    "        b_layer1 =tf.nn.conv2d(    x ,      b_w_conv1, b_c_strides1, b_c_pooling1,name='STEM_B_b_layer1'  ) + b_b_conv1\n",
    "        b_layer1 = tf.nn.relu(b_layer1,name='STEM_B_b_layer1_relu')\n",
    "        b_layer2=tf.nn.conv2d(  b_layer1 , b_w_conv2, b_c_strides2, b_c_pooling2,name='STEM_B_b_layer2'  ) + b_b_conv2\n",
    "        b_layer2= tf.nn.relu(b_layer2 , name='STEM_B_b_layer2_relu')\n",
    "        ##############################concatenate layers###########################\n",
    "        concat_layer=tf.concat(3 , [layer4 , b_layer2] , name=\"STEM_B_CONCAT\")\n",
    "        ret_layer=concat_layer\n",
    "    return ret_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_C( x , device_ ):\n",
    "    with tf.device(device_):\n",
    "        in_ch=x.get_shape()[3]\n",
    "        #########################################################################\n",
    "\n",
    "        out_ch = 192\n",
    "\n",
    "\n",
    "        c_ksize=[3,3,in_ch,out_ch]\n",
    "        w_conv , b_conv =make_weights_biases('STEM_C' , 'W1' , c_ksize ,device_name = device_)\n",
    "        c_strides=[1,1,1,1]\n",
    "        c_pooling='SAME'\n",
    "\n",
    "        layer = tf.nn.conv2d(x , w_conv   , c_strides   , c_pooling)+b_conv\n",
    "        layer = tf.nn.relu(layer)\n",
    "        \n",
    "        #########################################################################\n",
    "        \n",
    "        b_p_ksize=[1,2,2,1]\n",
    "        b_p_strides=[1,1,1,1]\n",
    "        b_p_pooling='SAME'\n",
    "\n",
    "        b_layer = tf.nn.max_pool(x , b_p_ksize , b_p_strides , b_p_pooling)\n",
    "        b_layer = tf.nn.relu(b_layer)\n",
    "        #########################################################################\n",
    "\n",
    "        print layer\n",
    "        print b_layer\n",
    "\n",
    "        concat_layer=tf.concat(3,[layer , b_layer])\n",
    "        ret_layer = concat_layer\n",
    "    return ret_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FLAT(x):\n",
    "    \n",
    "    row=int(x.get_shape()[1])\n",
    "    col=int(x.get_shape()[2])\n",
    "    ch=int(x.get_shape()[3])\n",
    "    \n",
    "    res_x = tf.reshape(x , shape=[-1,row*col*ch] ,name='flat_layer');\n",
    "    return res_x\n",
    "    #connect fully connected layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FC_A(x , n_classes , device_ ,dropout_rate):\n",
    "    with tf.device(device_):\n",
    "    \n",
    "        fully_ch1=1024; fully_ch2=1024\n",
    "\n",
    "        fc_ksize1=[x.get_shape()[1],fully_ch1]\n",
    "        fc_ksize2=[fully_ch1,fully_ch2]\n",
    "\n",
    "        w_fc1 ,b_fc1 = make_weights_biases('fc1' , 'fc_W1' ,'fc_B1' ,fc_ksize1 ,  device_)\n",
    "        w_fc2 ,b_fc2 = make_weights_biases('fc2' , 'fc_W2' ,'fc_B2' ,fc_ksize2 ,  device_)\n",
    "    \n",
    "        h_fc1=tf.matmul(x, w_fc1 ,name='h_fc1')+b_fc1\n",
    "        h_fc1=tf.nn.dropout(h_fc1 , dropout_rate , name='h_fc1_dropout')\n",
    "        h_fc2=tf.matmul(h_fc1 , w_fc2 ,name='h_fc2')+b_fc2\n",
    "        h_fc2=tf.nn.dropout(h_fc2 , dropout_rate,name='h_fc2_dropout')\n",
    "        end_fc=h_fc2\n",
    "\n",
    "        end_ksize=[end_fc.get_shape()[1] , n_classes]   \n",
    "        w_end ,b_end = make_weights_biases('fc_end' , 'fc_end_W' , 'fc_end_B' ,end_ksize ,  device_)\n",
    "        y_conv = tf.matmul(end_fc , w_end)+b_end\n",
    "\n",
    "        print w_fc1.get_shape()\n",
    "    return y_conv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FC_B(x , n_classes , device_ ):\n",
    "    with tf.device(device_):\n",
    "\n",
    "        end_ksize=[x.get_shape()[1] , n_classes]   \n",
    "        w_end ,b_end = make_weights_biases('fc_end' , 'fc_end_W' , end_ksize ,  device_)\n",
    "        y_conv = tf.matmul(x , w_end)+b_end\n",
    "\n",
    "   \n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_MODULE_A(x , device_ , layer_name = 'INCEPTION_MODULE_A'):\n",
    "\n",
    "    \"\"\"\n",
    "    input X shape is [n_batch , row , col, out_ch]\n",
    "    35 x 35 grid\n",
    "    \"\"\"\n",
    "\n",
    "    #################################################################################\n",
    "    in_ch=x.get_shape()[3]\n",
    "    print x.get_shape()\n",
    "    out_ch1=64 ; out_ch2= 96;\n",
    "    c_ksize1 = [1 , 1 ,in_ch , out_ch1 ]\n",
    "    c_ksize2 = [3 , 3 ,out_ch1 , out_ch2 ]\n",
    "    w_conv1 , b_conv1 = make_weights_biases (layer_name , 'W1' , c_ksize1 ,device_)\n",
    "    w_conv2 , b_conv2 = make_weights_biases(layer_name ,'W2' , c_ksize2 ,device_)\n",
    "\n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2=[1,1,1,1]\n",
    "    \n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2='SAME'\n",
    "    layer1 = tf.nn.conv2d(x , w_conv1 , c_strides1 ,c_pooling1 )\n",
    "    layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 ,c_pooling2 )\n",
    "\n",
    "    #################################################################################                     \n",
    "\n",
    "    b1_p_ksize   =[1,2,2,1]\n",
    "    b1_p_strides =[1,1,1,1]\n",
    "    b1_p_pooling='SAME'\n",
    "\n",
    "\n",
    "    b1_out_ch = 96;\n",
    "    b1_c_ksize  =[1,1, in_ch , b1_out_ch]\n",
    "    b1_c_strides=[1,1,1,1]\n",
    "    b1_c_pooling ='SAME'\n",
    "\n",
    "    b1_w_conv , b1_b_conv =make_weights_biases(layer_name,'b1_W',b1_c_ksize , device_)\n",
    "\n",
    "\n",
    "    b1_layer1=tf.nn.avg_pool(x, b1_p_ksize , b1_p_strides,b1_p_pooling )\n",
    "    b1_layer1=tf.nn.relu(b1_layer1)\n",
    "    b1_layer2=tf.nn.conv2d(b1_layer1 , b1_w_conv , b1_c_strides , b1_c_pooling)+b1_b_conv\n",
    "    b1_layer2=tf.nn.relu(b1_layer2)\n",
    "\n",
    "    #################################################################################                     \n",
    "\n",
    "    b2_out_ch=96\n",
    "    b2_c_ksize = [1,1,in_ch , b2_out_ch ]\n",
    "    b2_w_conv , b2_b_conv = make_weights_biases(layer_name,'b2_W',b2_c_ksize , device_)\n",
    "    b2_c_strides=[1,1,1,1]\n",
    "    b2_c_pooling='SAME'\n",
    "\n",
    "    b2_layer = tf.nn.conv2d( x, b2_w_conv , b2_c_strides ,b2_c_pooling ) +b2_b_conv \n",
    "    b2_layer = tf.nn.relu(b2_layer)\n",
    "\n",
    "\n",
    "\n",
    "    #################################################################################                     \n",
    "\n",
    "\n",
    "    b3_out_ch1=64;b3_out_ch2=96;b3_out_ch3=96;\n",
    "    b3_c_ksize1 =[1,1,in_ch , b3_out_ch1]\n",
    "    b3_c_ksize2 =[3,3,b3_out_ch1 , b3_out_ch2]\n",
    "    b3_c_ksize3 =[3,3,b3_out_ch2 , b3_out_ch3]\n",
    "    b3_w_conv1 , b3_b_conv1 = make_weights_biases(layer_name,'b3_W1',b3_c_ksize1 , device_)\n",
    "    b3_w_conv2 , b3_b_conv2 = make_weights_biases(layer_name,'b3_W2',b3_c_ksize2 , device_)\n",
    "    b3_w_conv3 , b3_b_conv3 = make_weights_biases(layer_name,'b3_W3',b3_c_ksize3 , device_)\n",
    "    b3_c_strides1=[1,1,1,1]\n",
    "    b3_c_strides2=[1,1,1,1]\n",
    "    b3_c_strides3=[1,1,1,1]\n",
    "    b3_c_pooling1='SAME'\n",
    "    b3_c_pooling2='SAME'\n",
    "    b3_c_pooling3='SAME'\n",
    "\n",
    "    b3_layer1 = tf.nn.conv2d(x , b3_w_conv1 , b3_c_strides1 ,b3_c_pooling1)+b3_b_conv1 \n",
    "    b3_layer1 = tf.nn.relu(b3_layer1)\n",
    "    b3_layer2 = tf.nn.conv2d(b3_layer1 , b3_w_conv2 , b3_c_strides2 ,b3_c_pooling2)+b3_b_conv2 \n",
    "    b3_layer2 = tf.nn.relu(b3_layer2)\n",
    "    b3_layer3 = tf.nn.conv2d(b3_layer2 , b3_w_conv3 , b3_c_strides3 ,b3_c_pooling3)+b3_b_conv3 \n",
    "    b3_layer3 = tf.nn.relu(b3_layer3)\n",
    "\n",
    "    #################################################################################                     \n",
    "    concat_A=tf.concat(3,[layer2 , b1_layer2])\n",
    "    concat_B=tf.concat(3,[concat_A , b2_layer])\n",
    "    concat_C=tf.concat(3,[concat_B , b3_layer3])\n",
    "\n",
    "    return concat_C\n",
    "\n",
    "    #################################################################################                     \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_MODULE_B(x , device ,layer_name='INCEPTION_MODULE_B'):\n",
    "\n",
    "    \"\"\"\n",
    "    for 17 X 17 grid \n",
    "    \"\"\"\n",
    "    in_ch =x.get_shape()[3]\n",
    "    out_ch1 =192 ; out_ch2=224; out_ch3 =256\n",
    "    c_ksize1 = [1,1, in_ch  ,out_ch1]\n",
    "    c_ksize2 = [1,7, out_ch1,out_ch2]\n",
    "    c_ksize3 = [7,1, out_ch2,out_ch3]\n",
    "\n",
    "    w_conv1 , b_conv1 =make_weights_biases( layer_name,'W1' ,  c_ksize1 , device)\n",
    "    w_conv2 , b_conv2 =make_weights_biases( layer_name ,'W2' ,  c_ksize2 , device)\n",
    "    w_conv3 , b_conv3 =make_weights_biases( layer_name ,'W3' ,  c_ksize3 , device)\n",
    "    \n",
    "    c_strides1 =[1,1,1,1]\n",
    "    c_strides2 =[1,1,1,1]\n",
    "    c_strides3 =[1,1,1,1]\n",
    "    \n",
    "    c_pooling1 ='SAME'\n",
    "    c_pooling2 ='SAME'\n",
    "    c_pooling3 ='SAME'\n",
    "\n",
    "\n",
    "    layer1 = tf.nn.conv2d(x, w_conv1,c_strides1 , c_pooling1 ) +b_conv1\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "    layer2 = tf.nn.conv2d(layer1, w_conv2,c_strides2 , c_pooling2 ) +b_conv2\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "    layer3 = tf.nn.conv2d(layer2, w_conv3,c_strides3 , c_pooling3 ) +b_conv3\n",
    "    layer3 = tf.nn.relu(layer3)\n",
    "\n",
    "\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b1_p_ksize=[1,2,2,1]\n",
    "    b1_p_strides=[1,1,1,1]\n",
    "    b1_p_pooling ='SAME'\n",
    "\n",
    "    b1_out_ch = 128\n",
    "    b1_c_ksize=[1,1,in_ch,b1_out_ch]\n",
    "    b1_w_conv , b1_b_conv = make_weights_biases(layer_name,'b1_W1',b1_c_ksize, device )\n",
    "    b1_c_strides=[1,1,1,1]\n",
    "    b1_c_pooling='SAME'\n",
    "\n",
    "\n",
    "    b1_layer1=tf.nn.avg_pool(x , b1_p_ksize , b1_p_strides , b1_p_pooling )\n",
    "    b1_layer1=tf.nn.relu(b1_layer1)\n",
    "    b1_layer2 =tf.nn.conv2d(b1_layer1 ,b1_w_conv , b1_c_strides, b1_c_pooling )+b1_b_conv \n",
    "    b1_layer2 =tf.nn.relu(b1_layer2)\n",
    "\n",
    "    ################################################################################# \n",
    "    b2_out_ch=384\n",
    "    b2_c_ksize=[1,1,in_ch,b2_out_ch]\n",
    "    b2_w_conv , b2_b_conv =make_weights_biases(layer_name,'b2_W1' ,b2_c_ksize , device)\n",
    "    b2_c_strides=[1,1,1,1]\n",
    "    b2_c_pooling='SAME'\n",
    "    b2_layer = tf.nn.conv2d(x,b2_w_conv , b2_c_strides , b2_c_pooling)+b2_b_conv\n",
    "    b2_layer = tf.nn.relu(b2_layer)\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b3_out_ch1=192; b3_out_ch2 =192; b3_out_ch3=224 ; b3_out_ch4=224 ; b3_out_ch5 =256\n",
    "    b3_c_ksize1=[1,1,in_ch,b3_out_ch1]\n",
    "    b3_c_ksize2=[1,7,b3_out_ch1 , b3_out_ch2]\n",
    "    b3_c_ksize3=[7,1,b3_out_ch2 , b3_out_ch3]\n",
    "    b3_c_ksize4=[1,7,b3_out_ch3 , b3_out_ch4]\n",
    "    b3_c_ksize5=[7,1,b3_out_ch4 , b3_out_ch5]\n",
    "\n",
    "    b3_w_conv1 , b3_b_conv1=make_weights_biases(layer_name,'b3_W1',b3_c_ksize1, device)\n",
    "    b3_w_conv2 , b3_b_conv2=make_weights_biases(layer_name,'b3_W2',b3_c_ksize2, device)\n",
    "    b3_w_conv3 , b3_b_conv3=make_weights_biases(layer_name,'b3_W3',b3_c_ksize3, device)\n",
    "    b3_w_conv4 , b3_b_conv4=make_weights_biases(layer_name,'b3_W4',b3_c_ksize4, device)\n",
    "    b3_w_conv5 , b3_b_conv5=make_weights_biases(layer_name,'b3_W5',b3_c_ksize5, device)\n",
    "\n",
    "\n",
    "    b3_layer1 = tf.nn.conv2d(x,b3_w_conv1 , b2_c_strides , b2_c_pooling)+b3_b_conv1\n",
    "    b3_layer1 = tf.nn.relu(b3_layer1)\n",
    "    b3_layer2 = tf.nn.conv2d(b3_layer1,b3_w_conv2 , b2_c_strides , b2_c_pooling)+b3_b_conv2\n",
    "    b3_layer2 = tf.nn.relu(b3_layer2)\n",
    "    b3_layer3 = tf.nn.conv2d(b3_layer2,b3_w_conv3 , b2_c_strides , b2_c_pooling)+b3_b_conv3\n",
    "    b3_layer3 = tf.nn.relu(b3_layer3)\n",
    "    b3_layer4 = tf.nn.conv2d(b3_layer3,b3_w_conv4 , b2_c_strides , b2_c_pooling)+b3_b_conv4\n",
    "    b3_layer4 = tf.nn.relu(b3_layer4)\n",
    "    b3_layer5 = tf.nn.conv2d(b3_layer4,b3_w_conv5 , b2_c_strides , b2_c_pooling)+b3_b_conv5\n",
    "    b3_layer5 = tf.nn.relu(b3_layer5)\n",
    "\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    layerA=tf.concat(3, [layer3 , b1_layer2] )\n",
    "    layerB=tf.concat(3, [layerA , b2_layer] )\n",
    "    layerC=tf.concat(3, [layerB , b3_layer5] )\n",
    "\n",
    "    print layerC\n",
    "    return layerC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_MODULE_C(x , device , layer_name='INCEPTION_MODULE_C'):\n",
    "\n",
    "    \"\"\"\n",
    "    for 8 X 8 grid modules\n",
    "    \"\"\"\n",
    "    print x.get_shape()\n",
    "    in_ch=x.get_shape()[3]\n",
    "    \n",
    "    out_ch1 = 384 ; out_ch2_a =256 ;out_ch2_b = 256\n",
    "    c_ksize1 = [1,1,in_ch , out_ch1]\n",
    "    c_ksize2_a = [1,3,out_ch1 , out_ch2_a]\n",
    "    c_ksize2_b = [3,1,out_ch1 , out_ch2_b]\n",
    "    w_conv1 ,b_conv1=make_weights_biases(layer_name,'W1', c_ksize1 ,device)\n",
    "    w_conv2_a ,b_conv2_a=make_weights_biases(layer_name,'W2_a', c_ksize2_a ,device)\n",
    "    w_conv2_b ,b_conv2_b=make_weights_biases(layer_name,'W2_b', c_ksize2_b ,device)\n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2_a=[1,1,1,1]\n",
    "    c_strides2_b=[1,1,1,1]\n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2_a='SAME'\n",
    "    c_pooling2_b='SAME'\n",
    "\n",
    "    layer1 = tf.nn.conv2d(x, w_conv1 ,c_strides1 ,c_pooling1)+b_conv1\n",
    "    layer1=tf.nn.relu(layer1)\n",
    "    layer2_a = tf.nn.conv2d(layer1,  w_conv2_a ,c_strides2_a ,c_pooling2_a )+b_conv2_a\n",
    "    layer2_a = tf.nn.relu(layer2_a)\n",
    "    layer2_b = tf.nn.conv2d(layer1  , w_conv2_a ,c_strides2_a ,c_pooling2_b)+b_conv2_b\n",
    "    layer2_b = tf.nn.relu(layer2_b)\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b1_p_ksize=[1,2,2,1]\n",
    "    b1_p_strides=[1,1,1,1]\n",
    "    b1_p_pooling='SAME'\n",
    "\n",
    "    b1_out_ch =256\n",
    "    b1_c_ksize=[1,1,in_ch , b1_out_ch]\n",
    "    b1_w_conv , b1_b_conv= make_weights_biases(layer_name , 'b1_W1' , b1_c_ksize , device)\n",
    "    b1_c_pooling = 'SAME';b1_c_strides = [1,1,1,1];\n",
    "    \n",
    "    b1_layer1 = tf.nn.avg_pool(x , b1_p_ksize , b1_p_strides , b1_p_pooling)\n",
    "    b1_layer2 = tf.nn.conv2d(b1_layer1 , b1_w_conv , b1_c_strides  ,b1_c_pooling)+b1_b_conv\n",
    "    b1_layer2 = tf.nn.relu(b1_layer2)\n",
    "    ################################################################################# \n",
    "    b2_out_ch=256\n",
    "    b2_c_ksize=[1,1,in_ch,b2_out_ch]\n",
    "    b2_w_conv , b2_b_conv= make_weights_biases(layer_name , 'b2_W' , b2_c_ksize , device)\n",
    "    b2_c_pooling = 'SAME';b2_c_strides=[1,1,1,1];\n",
    "    b2_layer = tf.nn.conv2d(x , b2_w_conv , b2_c_strides  ,b2_c_pooling)+b2_b_conv\n",
    "    b2_layer= tf.nn.relu(b2_layer)\n",
    "   \n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b3_out_ch1=384;b3_out_ch2=448;b3_out_ch3=512;b3_out_ch4_a=256;b3_out_ch4_b=256\n",
    "    b3_c_ksize1 =[1,1,in_ch , b3_out_ch1]\n",
    "    b3_c_ksize2 =[1,3,b3_out_ch1 , b3_out_ch2]\n",
    "    b3_c_ksize3 =[3,1,b3_out_ch2 , b3_out_ch3]\n",
    "    b3_c_ksize4_a =[3,1,b3_out_ch3 , b3_out_ch4_a]\n",
    "    b3_c_ksize4_b =[1,3,b3_out_ch3, b3_out_ch4_b]\n",
    "\n",
    "    b3_w_conv1 , b3_b_conv1 = make_weights_biases(layer_name,'b3_W1',b3_c_ksize1 , device)\n",
    "    b3_w_conv2 , b3_b_conv2 = make_weights_biases(layer_name,'b3_W2',b3_c_ksize2 , device)\n",
    "    b3_w_conv3 , b3_b_conv3 = make_weights_biases(layer_name,'b3_W3',b3_c_ksize3 , device)\n",
    "    b3_w_conv4_a , b3_b_conv4_a = make_weights_biases(layer_name,'b3_W4_a',b3_c_ksize4_a , device)\n",
    "    b3_w_conv4_b , b3_b_conv4_b = make_weights_biases(layer_name,'b3_W4_b',b3_c_ksize4_b , device)\n",
    "\n",
    "    b3_c_strides1=[1,1,1,1]\n",
    "    b3_c_strides2=[1,1,1,1]\n",
    "    b3_c_strides3=[1,1,1,1]\n",
    "    b3_c_strides4_a=[1,1,1,1]\n",
    "    b3_c_strides4_b=[1,1,1,1]\n",
    "\n",
    "    b3_c_pooling1='SAME'\n",
    "    b3_c_pooling2='SAME'\n",
    "    b3_c_pooling3='SAME'\n",
    "    b3_c_pooling4_a='SAME'\n",
    "    b3_c_pooling4_b='SAME'\n",
    "\n",
    "    b3_laer1 = tf.nn.conv2d(x , b3_w_conv1 , b3_c_strides1 ,b3_c_pooling1)+b3_b_conv1 \n",
    "    b3_layer1 = tf.nn.relu(b3_laer1)\n",
    "    b3_layer2 = tf.nn.conv2d(b3_laer1 , b3_w_conv2 , b3_c_strides2 ,b3_c_pooling2)+b3_b_conv2 \n",
    "    b3_layer2 = tf.nn.relu(b3_layer2)\n",
    "    b3_layer3 = tf.nn.conv2d(b3_layer2 , b3_w_conv3 , b3_c_strides3 ,b3_c_pooling3)+b3_b_conv3 \n",
    "    b3_layer3 = tf.nn.relu(b3_layer3)\n",
    "\n",
    "    b3_layer4_a = tf.nn.conv2d(b3_layer3 , b3_w_conv4_a , b3_c_strides4_a ,b3_c_pooling4_a)+b3_b_conv4_a \n",
    "    b3_layer4_a = tf.nn.relu(b3_layer4_a)\n",
    "\n",
    "    b3_layer4_b = tf.nn.conv2d(b3_layer3 , b3_w_conv4_b , b3_c_strides4_b ,b3_c_pooling4_b)+b3_b_conv4_b \n",
    "    b3_layer4_b = tf.nn.relu(b3_layer4_b)\n",
    "\n",
    "\n",
    "    ################################################################################# \n",
    "\n",
    "    layerA = tf.concat(3 , [layer2_a, layer2_b])\n",
    "    layerB = tf.concat(3 , [layerA  , b1_layer2])\n",
    "    layerC = tf.concat(3 , [layerB  , b2_layer])\n",
    "    layerD = tf.concat(3 , [layerC  , b3_layer4_a])\n",
    "    layerE = tf.concat(3 , [layerD  , b3_layer4_b])\n",
    "\n",
    "    return layerE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def INCEPTION_REDUCTION_A(x , device , layer_name = 'INCEPTION_REDUCTION_A'):\n",
    "    ####################################################################################\n",
    "   \n",
    "    \"\"\"\n",
    "    usage:\n",
    "    x shape =[ n_batch , row , col , ch] \n",
    "    \"\"\"\n",
    "    print x.get_shape()\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch = 384\n",
    "    c_ksize= [3,3,in_ch , out_ch]\n",
    "    w_conv , b_conv =make_weights_biases(layer_name,'W1',c_ksize,device)\n",
    "    c_strides=[1,2,2,1]\n",
    "    c_pooling='VALID'\n",
    "    layer=tf.nn.conv2d(x,w_conv,c_strides , c_pooling)+b_conv\n",
    "    layer=tf.nn.relu(layer)\n",
    "\n",
    "    ####################################################################################\n",
    "   \n",
    "    b1_p_ksize=[1,3,3,1]\n",
    "    b1_p_strides=[1,2,2,1]\n",
    "    b1_p_pooling='VALID'\n",
    "    b1_layer = tf.nn.max_pool(x,b1_p_ksize , b1_p_strides , b1_p_pooling)\n",
    "    ####################################################################################\n",
    "   \n",
    "    b2_out_ch1 = 192; b2_out_ch2=288 ;b2_out_ch3 = 256;\n",
    "    b2_c_ksize1=[1,1,in_ch,b2_out_ch1]\n",
    "    b2_c_ksize2=[3,3,b2_out_ch1,b2_out_ch2]\n",
    "    b2_c_ksize3=[3,3,b2_out_ch2,b2_out_ch3]\n",
    "    b2_w_conv1 , b2_b_conv1 = make_weights_biases(layer_name ,'b2_W1' , b2_c_ksize1 , device)\n",
    "    b2_w_conv2 , b2_b_conv2 = make_weights_biases(layer_name ,'b2_W2' , b2_c_ksize2 , device)\n",
    "    b2_w_conv3 , b2_b_conv3 = make_weights_biases(layer_name ,'b2_W3' , b2_c_ksize3 , device)\n",
    "    \n",
    "    b2_c_strides1=[1,1,1,1]\n",
    "    b2_c_strides2=[1,1,1,1]\n",
    "    b2_c_strides3=[1,2,2,1]\n",
    "    b2_c_pooling1='SAME'\n",
    "    b2_c_pooling2='SAME'\n",
    "    b2_c_pooling3='VALID'\n",
    "    \n",
    "    b2_layer1 = tf.nn.conv2d(x        , b2_w_conv1 ,b2_c_strides1 ,b2_c_pooling1)+b2_b_conv1\n",
    "    b2_layer1 = tf.nn.relu(b2_layer1)\n",
    "    b2_layer2 = tf.nn.conv2d(b2_layer1, b2_w_conv2 ,b2_c_strides2 ,b2_c_pooling2)+b2_b_conv2\n",
    "    b2_layer2 = tf.nn.relu(b2_layer2)\n",
    "    b2_layer3 = tf.nn.conv2d(b2_layer2, b2_w_conv3 ,b2_c_strides3 ,b2_c_pooling3)+b2_b_conv3\n",
    "    b2_layer3 = tf.nn.relu(b2_layer3)\n",
    "    \n",
    "    print layer.get_shape()\n",
    "    print b1_layer.get_shape()\n",
    "    print b2_layer3.get_shape()\n",
    "    ####################################################################################\n",
    "   \n",
    "    layerA=tf.concat(3 ,[layer ,b1_layer ])\n",
    "    layerB=tf.concat(3 ,[layerA ,b2_layer3])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return layerB\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_REDUCTION_B(x , device  , layer_name = 'INCEPTION_REDUCTION_B'):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ####################################################################################\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch1=192 ; out_ch2=192;\n",
    "\n",
    "    c_ksize1 =[1,1,in_ch , out_ch1]\n",
    "    c_ksize2 =[3,3,out_ch1,out_ch2]\n",
    "    w_conv1, b_conv1 = make_weights_biases(layer_name,'W1',c_ksize1,device)\n",
    "    w_conv2, b_conv2 = make_weights_biases(layer_name,'W2',c_ksize2,device)\n",
    "    \n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2=[1,2,2,1]\n",
    "    \n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2='VALID'\n",
    "    \n",
    "    layer1 = tf.nn.conv2d(x,w_conv1 , c_strides1, c_pooling1)\n",
    "    layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 , c_pooling2)    \n",
    "    \n",
    "    b1_p_ksize=[1,3,3,1]\n",
    "    b1_p_strides=[1,2,2,1]\n",
    "    b1_p_pooling='VALID'\n",
    "    \n",
    "    b1_layer1=tf.nn.max_pool(x ,b1_p_ksize , b1_p_strides , b1_p_pooling)\n",
    "    \n",
    "    ####################################################################################\n",
    "    b2_out_ch1=256 ; b2_out_ch2 = 256 ; b2_out_ch3=320 ; b2_out_ch4=320;\n",
    "    b2_p_ksize1 =[1,1,in_ch , b2_out_ch1]\n",
    "    b2_p_ksize2 =[1,7,b2_out_ch1 , b2_out_ch2]\n",
    "    b2_p_ksize3 =[7,1,b2_out_ch2 , b2_out_ch3]\n",
    "    b2_p_ksize4 =[3,3,b2_out_ch3 , b2_out_ch4]\n",
    "    \n",
    "    b2_w_conv1, b2_b_conv1 = make_weights_biases(layer_name,'b2_W1' ,b2_c_ksize1,device)\n",
    "    b2_w_conv2, b2_b_conv2 = make_weights_biases(layer_name,'b2_W2' ,b2_c_ksize2,device)\n",
    "    b2_w_conv3, b2_b_conv3 = make_weights_biases(layer_name,'b2_W3' ,b2_c_ksize3,device)\n",
    "    b2_w_conv4, b2_b_conv4 = make_weights_biases(layer_name,'b2_W4' ,b2_c_ksize4,device)\n",
    "    \n",
    "    b2_c_strides1=[1,1,1,1]\n",
    "    b2_c_strides2=[1,1,1,1]\n",
    "    b2_c_strides3=[1,1,1,1]\n",
    "    b2_c_strides4=[1,1,1,1]\n",
    "    \n",
    "    b2_c_pooling1= 'SAME'\n",
    "    b2_c_pooling2= 'SAME'\n",
    "    b2_c_pooling3 = 'SAME'\n",
    "    b2_c_pooling4 = 'VALID'\n",
    "    \n",
    "    b2_layer1 = tf.nn.conv2d(x, b2_w_conv1 , b2_c_strides1 , b2_c_pooling1 )+b2_b_conv1\n",
    "    b2_layer2 = tf.nn.conv2d(b2_layer1, b2_w_conv2 , b2_c_strides2 , b2_c_pooling2 )+b2_b_conv2\n",
    "    b2_layer3 = tf.nn.conv2d(b2_layer2, b2_w_conv3 , b2_c_strides3 , b2_c_pooling3 )+b2_b_conv3\n",
    "    b2_layer4 = tf.nn.conv2d(b2_layer3, b2_w_conv4 , b2_c_strides4 , b2_c_pooling4 )+b2_b_conv4\n",
    "    \n",
    "    ####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_list(folder_path):\n",
    "    \"\"\"\n",
    "    return ret_train_img_list ,ret_train_lab_list \n",
    "    \n",
    "    \"\"\"\n",
    "    list_files=os.walk(folder_path).next()[2]\n",
    "    ret_train_img_list=[]\n",
    "    ret_train_lab_list=[]\n",
    "    np_train_imgs=[]\n",
    "    np_train_labs=[]\n",
    "    for i , ele in enumerate(list_files):\n",
    "\n",
    "        if 'train'  in ele and 'img'in ele:\n",
    "            ret_train_img_list.append(ele)\n",
    "        elif 'train' in ele  and  'lab' in ele:\n",
    "            ret_train_lab_list.append(ele)\n",
    "    \n",
    "    ret_train_img_list.sort(key=natural_keys)\n",
    "    ret_train_lab_list.sort(key = natural_keys)\n",
    "    for i  in range(len(ret_train_img_list)):\n",
    "        np_train_imgs.append(np.load(folder_path+ret_train_img_list[i]))\n",
    "        np_train_labs.append(np.load(folder_path+ret_train_lab_list[i]))\n",
    "    \n",
    "    return np_train_imgs ,np_train_labs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col , label):\n",
    "    \n",
    "    n_img = np.shape(np_img)[0] \n",
    "    n_ret_img = n_img*(img_row - crop_img_row) * (img_col - crop_img_col)*2\n",
    "    ret_images = np.zeros([n_ret_img ,crop_img_row , crop_img_col,color_ch])\n",
    "    len_label= np.shape(label)[1]\n",
    "    ret_labels =  np.zeros([n_ret_img  ,len_label])\n",
    "    #print \"n_augmented image size : \" , n_ret_img \n",
    "    #print \"n classes :\", len_label\n",
    "    #copy label in factor by 2014\n",
    "    \n",
    "    if len(np.shape(np_img))==2:\n",
    "        np_img=np.reshape(np_img , newshape = [np.shape(np_img)[0] , img_row , img_col ,color_ch])\n",
    "        print np.shape(np_img)\n",
    "    for n  in range(len(np_img)):\n",
    "        ret_labels[n*2 , : ] = label[n,:]\n",
    "        ret_labels[n*2+1 , : ] = label[n,:]\n",
    "        for r in range(img_row - crop_img_row):\n",
    "            for c in range(img_col - crop_img_col):\n",
    "                \n",
    "                cropped_img = np_img[n, r:crop_img_row +r , c:crop_img_col+c ,: ]\n",
    "                \n",
    "                ret_images[n*2,:,:,:]=cropped_img  \n",
    "                ret_images[(n*2+1) , :,:,:] =np.fliplr(cropped_img )\n",
    "\n",
    "    \n",
    "    return ret_images ,ret_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_test_img(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col ):\n",
    "    left_top =(0,0)\n",
    "    right_top =(  img_row  - crop_img_row  , 0 )\n",
    "    center =  ((img_row  - crop_img_row)/2  , (img_col - crop_img_row)/2)\n",
    "    left_buttom = (0,(img_col - crop_img_row)/2 )\n",
    "    right_buttom =  (img_row  - crop_img_row , img_col - crop_img_row)\n",
    "    \n",
    "    left_top_images  = np_img[: , left_top[0]:crop_img_row+left_top[0] , left_top[1] : crop_img_col+left_top[1] , :  ]\n",
    "    right_top_images = np_img[: , right_top[0]:crop_img_row +right_top[0], right_top[1] : crop_img_col +right_top[1], :  ]\n",
    "    center_images    = np_img[: , center[0]:crop_img_row +center[0], center[1] : crop_img_col +center[1], :  ]\n",
    "    left_buttom_images=np_img[: , left_buttom[0]:crop_img_row +left_buttom[0], left_buttom[1] : crop_img_col +left_buttom[1], :  ]\n",
    "    right_buttom_images= np_img[: , right_buttom[0]:crop_img_row+right_buttom[0] , right_buttom[1] : crop_img_col +right_buttom[1] , :  ]\n",
    "\n",
    "    \n",
    "        \n",
    "    return left_top_images , right_top_images , center_images , left_buttom_images , right_buttom_images \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TRAIN_STRUCTURE_A(y_conv , y_ , device_ ):\n",
    "    \"\"\"\n",
    "    Return Value : cost , train_step ,correct_prediction , accuracy \n",
    "    \n",
    "    \"\"\"\n",
    "    with tf.device(device_):\n",
    "    #sm_conv= tf.nn.softmax(y_conv)\n",
    "        #cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "\n",
    "        softmax=tf.nn.softmax(y_conv)\n",
    "        regular=0.01*(tf.reduce_sum(tf.square(y_conv)))\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( y_conv, y_))\n",
    "    with tf.device(device_):\n",
    "        cost = cost+regular\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cost) #1e-4\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            with tf.name_scope('correct_prediction'):\n",
    "                correct_prediction = tf.equal(tf.argmax(y_conv,1) ,tf.argmax(y_,1))\n",
    "            with tf.name_scope('accuracy'):\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\")) \n",
    "    return cost , train_step ,correct_prediction , accuracy,softmax \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def START_SESS():\n",
    "    sess = tf.Session()\n",
    "  \n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    return sess \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Terminal Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dirname = '/home/ncc/notebook/mammo/result/'\n",
    "def make_logdir(dirname):\n",
    "  \n",
    "\n",
    "    count=0\n",
    "    while(True):\n",
    "        if not os.path.isdir(dirname):\n",
    "            os.mkdir(dirname)\n",
    "            break\n",
    "        elif not os.path.isdir(dirname + str(count)):\n",
    "            dirname=dirname+str(count)\n",
    "            os.mkdir(dirname)\n",
    "            break\n",
    "        else:\n",
    "            count+=1\n",
    "    print 'it is recorded at :'+str(count)\n",
    "\n",
    "    f=open(dirname+\"/log.txt\",'w')\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def write_log(step,train_acc, train_loss , val_acc , val_loss ,fp):\n",
    "    \"\"\"\n",
    "    fp = File Pointer\n",
    "    \n",
    "    \"\"\"\n",
    "    #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "    print step\n",
    "    print(\"step %d , training  accuracy %g\" %(step,train_acc))\n",
    "    print(\"step %d , loss : %g\" %(step,train_loss))\n",
    "    train_str = 'step:\\t'+str(step)+'\\ttrain_loss:\\t'+str(train_loss) +'\\ttrain_accuracy:\\t'+str(train_acc)+'\\n'\n",
    "\n",
    "    print(\"step %d , validation  accuracy %g\" %(step,val_acc))\n",
    "    print(\"step %d , validation loss : %g\" %(step,val_loss))\n",
    "    val_str = 'step:\\t'+str(step)+'\\tval_loss:\\t'+str(val_loss) +'\\tval_accuracy:\\t'+str(val_acc)+'\\n'\n",
    "\n",
    "    fp.write(train_str)\n",
    "    fp.write(val_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_TVT(divide_flag,file_locate):\n",
    "    if divide_flag == False:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data Image\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"Test Data Image\",np.shape(test_img)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "        print \"val Data Image\" , np.shape(val_img)\n",
    "        \n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n",
    "        return train_img ,train_lab,val_img,val_lab,test_img,test_lab\n",
    "    if divide_flag == True:\n",
    "        print '트레이닝 파일이 여러개로 분할되어 있습니다. 분할된 트레이닝 파일에 대한 조치가 필요합니다'\n",
    "        train_images, train_labels =get_batch_list(file_locate)\n",
    "        #print train_images ,train_labels\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "        print \"the number of training image batch\",len(train_images)\n",
    "        print \"the number of training label batch\",len(train_labels)\n",
    "        print \"training Data Label\",np.shape(train_labels[0])\n",
    "        print \"training Data Image\",np.shape(train_images[0])\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"Test Data Image\",np.shape(test_img)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "        print \"val Data Image\" , np.shape(val_img)\n",
    "        return train_images, train_labels,val_img,val_lab,test_img,test_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate_from_images(sess, images , labels , tensor_info, place_info , tensorboard_info = None):    \n",
    "    \"\"\"\n",
    "    input : x-\n",
    "    \n",
    "    x type  : numpy \n",
    "    x shape : [n , row , col , ch]\n",
    "    return  acc,  loss\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    print accuracy\n",
    "    acc_list=[]\n",
    "    loss_list=[]\n",
    "    images_labels=zip(images,labels)\n",
    "    for img_ind ,(img,lab)  in enumerate(images_labels):\n",
    "\n",
    "        acc ,loss = sess.run( [tensor_info['accuracy'],tensor_info['cost']] ,\\\n",
    "                             feed_dict={place_info['x_']:img , place_info['y_']: lab , place_info['keep_prob']: 1.0})        \n",
    "        acc_list.append(acc)\n",
    "        loss_list.append(loss)\n",
    "\n",
    "    acc_list=np.asarray(acc_list)\n",
    "    loss_list=np.asarray(loss_list)\n",
    "    acc=np.mean(acc_list)\n",
    "    loss=np.mean(loss_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return  acc,  loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate(img , lab ,tensor_info , place_info,tensorboard_info=None , step=None): #default\n",
    "    \"\"\"\n",
    "    return val_acc,  val_loss, train_acc, train_loss\n",
    "    tensorboard_info['writer']\n",
    "    tensorboard_info['merge']    \n",
    "    \"\"\"    \n",
    "    print 'validate tensorboard' , tensorboard_info\n",
    "    if tensorboard_info ==None:\n",
    "        print 'b'\n",
    "        acc,loss = sess.run([tensor_info['accuracy'],tensor_info['cost']] , feed_dict={place_info['x_']:img , place_info['y_']:lab , place_info['keep_prob']: 1.0})        \n",
    "    else:\n",
    "        print 'a'\n",
    "        summary,acc,loss = sess.run([tensorboard_info['merge'],tensor_info['accuracy'],tensor_info['cost']] , feed_dict={place_info['x_']:img , place_info['y_']:lab , place_info['keep_prob']: 1.0})        \n",
    "        tensorboard_info['writer'].add_summary(summary , step)\n",
    "        \n",
    "        \n",
    "    return acc,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BATCH_TRAINING_DIVIDE_RANDOM(maxiter, batch_size,file_locate,tensor_info, place_info , fp):\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    #with tf.device('/gpu:0'):\n",
    "    train_imgs, train_labs,val_img,val_lab,test_img,test_lab=load_TVT(True,file_locate) #TVT is Train Validation Test  \n",
    "    for step in range(maxiter):\n",
    "        b_ind=random.randrange(0,len(train_imgs))\n",
    "        train_img = train_imgs[b_ind]\n",
    "        train_lab = train_labs[b_ind]\n",
    "        \n",
    "        batch_xs , batch_ys = next_batch(batch_size, train_img , train_lab)       \n",
    "        if step%100 ==0: #여기 if loop에서 validate을 합니다 \n",
    "            try:\n",
    "                val_acc , val_loss= validate(val_img,val_lab,tensor_info,place_info)     \n",
    "                train_acc , train_loss=validate(batch_xs,batch_ys,tensor_info,place_info)\n",
    "            except:\n",
    "                #한번에 트레이닝이 안되면 분할해서 validation한다.\n",
    "                val_imgs, val_labs = divide_images(val_img , val_lab, batch_size)\n",
    "                #print np.shape(val_imgs[0])\n",
    "                val_acc, val_loss =validate_from_images(sess,val_imgs ,val_labs ,tensor_info ,place_info )\n",
    "                train_acc , train_loss=validate(batch_xs,batch_ys,tensor_info ,place_info)\n",
    "                \n",
    "            write_log(step , train_acc, train_loss , val_acc, val_loss , fp)\n",
    "            #softmax_=sess.run(softmax ,feed_dict ={ x:batch_xs , y_:batch_ys , keep_prob:1.0 })\n",
    "            #print softmax_\n",
    "        training(batch_xs,batch_ys,tensor_info,place_info)\n",
    "\n",
    "    ############################################aug_and_training############################\n",
    "    print(\"--- Training Time : %s ---\" % (time.time() - start_time))\n",
    "    train_time=\"--- Training Time : ---:\\t\" +str(time.time() - start_time)\n",
    "    \n",
    "    try:\n",
    "        test_acc , test_loss=validate(test_img , test_lab)\n",
    "    except:\n",
    "        #한번에 트레이닝이 안되면 분할해서 validation한다.\n",
    "        test_imgs, test_labs = divide_images(test_img ,test_lab, batch_size)\n",
    "        #print np.shape(val_imgs[0])\n",
    "        test_acc, test_loss =validate_from_images(sess,test_imgs ,test_labs ,tensor_info,place_info )\n",
    "    print \"test accuracy {0} , test loss {1}\".format(test_acc, test_loss)\n",
    "    fp.write(train_time)\n",
    "    fp.close()\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BATCH_TRAINING_RANDOM(maxiter, batch_size, file_locate, tensor_info , place_info, fp , tensorboard_info=None):\n",
    "    print tensorboard_info\n",
    "    start_time = time.time()\n",
    "    #with tf.device('/gpu:0'):\n",
    "    train_img, train_lab,val_img,val_lab,test_img,test_lab=load_TVT(False,file_locate) #TVT is Train Validation Test  \n",
    "    for step in range(maxiter):    \n",
    "        batch_xs , batch_ys = next_batch(batch_size, train_img , train_lab)       \n",
    "        if step%100 ==0: #여기 if loop에서 validate을 합니다 \n",
    "            try:\n",
    "                if tensorboard_info == None:\n",
    "                    print 'none'\n",
    "                    val_acc , val_loss = validate(val_img , val_lab,tensor_info,place_info,tensorboard_info ,step)\n",
    "                    train_acc , train_loss = validate(batch_xs,batch_ys,tensor_info,place_info)\n",
    "                \n",
    "                else: \n",
    "                    val_acc , val_loss = validate(val_img , val_lab ,tensor_info,place_info,tensorboard_info ,step)\n",
    "                    train_acc , train_loss = validate(batch_xs,batch_ys )\n",
    "                \n",
    "            except:\n",
    "                #한번에 트레이닝이 안되면 분할해서 validation한다.\n",
    "                val_imgs, val_labs = divide_images(val_img , val_lab, batch_size)\n",
    "                #print np.shape(val_imgs[0])\n",
    "                val_acc, val_loss =validate_from_images(sess, val_imgs ,val_labs ,tensor_info ,place_info,tensorboard_info)\n",
    "                train_acc , train_loss=validate(batch_xs,batch_ys,tensor_info ,place_info)\n",
    "                       \n",
    "            write_log(step , train_acc, train_loss , val_acc, val_loss , fp)\n",
    "            #softmax_=sess.run(softmax ,feed_dict ={ x:batch_xs , y_:batch_ys , keep_prob:1.0 })\n",
    "            #print softmax_\n",
    "        training(batch_xs,batch_ys,tensor_info , place_info)\n",
    "\n",
    "    ############################################aug_and_training############################\n",
    "    print(\"--- Training Time : %s ---\" % (time.time() - start_time))\n",
    "    train_time=\"--- Training Time : ---:\\t\" +str(time.time() - start_time)\n",
    "    \n",
    "    try:\n",
    "        test_acc , test_loss=validate(test_img , test_lab)\n",
    "    except:\n",
    "        #한번에 트레이닝이 안되면 분할해서 validation한다.\n",
    "        test_imgs, test_labs = divide_images(test_img ,test_lab, batch_size)\n",
    "        #print np.shape(val_imgs[0])\n",
    "        test_acc, test_loss =validate_from_images(sess,test_imgs ,test_labs ,tensor_info,place_info )\n",
    "    print \"test accuracy {0} , test loss {1}\".format(test_acc, test_loss)\n",
    "    fp.write(train_time)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BATCH_TRAINING_MANUAL(maxiter  , batch_size,file_locate, tensor_info, place_info , fp ):\n",
    "    start_time = time.time()\n",
    "#with tf.device('/gpu:0'):\n",
    "    train_img, train_lab,val_img,val_lab,test_img,test_lab\\\n",
    "    =load_TVT(divide_flag,file_locate)\n",
    "    train_images , train_labels=divide_images(train_img , train_lab , batch_size)\n",
    "    train_images_labels=zip(train_images , train_labels)\n",
    "    \n",
    "    for step,(batch_xs , batch_ys) in train_images_labels:\n",
    "        if step%100 ==0:\n",
    "            try:\n",
    "                val_acc , val_loss=validate(val_img , val_lab)\n",
    "                train_acc , train_loss=validate(batch_xs,batch_ys)\n",
    "            except:\n",
    "                #한번에 트레이닝이 안되면 분할해서 validation한다.\n",
    "                val_imgs, val_labs = divide_images(val_img , val_lab, batch_size)\n",
    "                val_acc, val_loss =validate_from_images(val_imgs ,val_labs ,accuracy, cost )\n",
    "                train_acc , train_loss=validate(batch_xs,batch_ys,accuracy, cost)\n",
    "            write_log(step , train_acc, train_loss , val_acc, val_loss , fp)\n",
    "            np.save('./result/batch_xs' ,batch_xs)\n",
    "            np.save('./result/batch_ys' ,batch_ys)\n",
    "        else:\n",
    "            list_aud_x = aug_8_times(batch_xs)\n",
    "            for ele in list_aug_x:\n",
    "                training(ele ,batch_ys)                    \n",
    "\n",
    "\n",
    "############################################aug_and_training############################\n",
    "    print(\"--- Training Time : %s ---\" % (time.time() - start_time))\n",
    "    train_time=\"--- Training Time : ---:\\t\" +str(time.time() - start_time)\n",
    "    fp.write(train_time)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def divide_images(images , labels,batch_size):\n",
    "    \"\"\"\n",
    "    return list_images,list_labels\n",
    "    \"\"\"\n",
    "    n_divide=len(images)/batch_size\n",
    "\n",
    "    list_images=[]\n",
    "    list_labels=[]\n",
    "    for ind in range(n_divide):\n",
    "        # j*batch_size :(j+1)*batch_size\n",
    "        image =images[ ind*batch_size :(ind+1)*batch_size] \n",
    "        label =labels[ ind*batch_size :(ind+1)*batch_size]\n",
    "        list_images.append(image)\n",
    "        list_labels.append(label)\n",
    "\n",
    "    #right above code have to modify\n",
    "    image = images[ (ind+1)*batch_size :  ] \n",
    "    label = labels[ (ind+1)*batch_size :  ]\n",
    "    list_images.append(image)\n",
    "    list_labels.append(label)\n",
    "\n",
    "    return list_images,list_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  \n",
    "def validate_extract_imgs(val_img , val_lab , train_img , train_lab ):\n",
    "    \"\"\"\n",
    "    extract patch from ori-image\n",
    "    \"\"\"\n",
    "    color_ch = in_ch\n",
    "    val_images  =extract_test_img(val_img , 128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "    train_images=extract_test_img(train_img ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "    val_acc, val_loss =validate_from_images(sess, val_images , val_lab , accuracy ,cost )\n",
    "    train_acc , train_loss =validate_from_images(sess, train_images , train_lab ,accuracy , cost)\n",
    "    \n",
    "    return val_acc , val_loss, train_acc ,train_loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def training(batch_xs , batch_ys , tensor_info , place_info):\n",
    "    sess.run(tensor_info['train_step'] ,feed_dict={place_info['x_']: batch_xs, place_info['y_']:batch_ys , place_info['keep_prob'] : 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug_8_times(x):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    x shape is [n_batch , row ,col , color_ch ]\n",
    "    x type is numpy \n",
    "    this code need too many time to run \n",
    "    we should find solution using parallel method to less run time maybe \n",
    "    \n",
    "    return x,np_rot90,np_rot180,np_rot270,lr_x,np_lr_rot90 ,np_lr_rot180 , np_lr_rot270 \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    n_batch,row,col,ch=np.shape(x)\n",
    "    lr_x = np.flipud(x)\n",
    "\n",
    "    np_rot90 =np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_rot180=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_rot270=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "\n",
    "    np_lr_rot90 =np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_lr_rot180=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_lr_rot270=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    \n",
    "    \n",
    "\n",
    "    for batch_ind in range(n_batch):\n",
    "\n",
    "        rot90=np.rot90(x[batch_ind,:,:,:])\n",
    "        rot180=np.rot90(rot90)\n",
    "        rot270=np.rot90(rot180)\n",
    "\n",
    "        np_rot90[batch_ind,:,:,:] = rot90\n",
    "        np_rot180[batch_ind,:,:,:]=rot180\n",
    "        np_rot270[batch_ind,:,:,:]=rot270\n",
    "\n",
    "        lr_rot90=np.rot90(lr_x[batch_ind,:,:,:])\n",
    "        lr_rot180=np.rot90(lr_rot90)\n",
    "        lr_rot270=np.rot90(lr_rot180)\n",
    "\n",
    "        np_lr_rot90[batch_ind,:,:,:]=lr_rot90\n",
    "        np_lr_rot180[batch_ind,:,:,:]=lr_rot180\n",
    "        np_lr_rot90[batch_ind,:,:,:]=lr_rot270\n",
    "    return x,np_rot90,np_rot180,np_rot270,lr_x,np_lr_rot90 ,np_lr_rot180 , np_lr_rot270 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug_crop(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col , label):\n",
    "    n_img = np.shape(np_img)[0] \n",
    "    n_ret_img = n_img*(img_row - crop_img_row) * (img_col - crop_img_col)*2\n",
    "    ret_images = np.zeros([n_ret_img ,crop_img_row , crop_img_col,color_ch])\n",
    "    len_label= np.shape(label)[1]\n",
    "    ret_labels =  np.zeros([n_ret_img  ,len_label])\n",
    "    #print \"n_augmented image size : \" , n_ret_img \n",
    "    #print \"n classes :\", len_label\n",
    "    #copy label in factor by 2014\n",
    "\n",
    "    if len(np.shape(np_img))==2:\n",
    "        np_img=np.reshape(np_img , newshape = [np.shape(np_img)[0] , img_row , img_col ,color_ch])\n",
    "        print np.shape(np_img)\n",
    "    for n  in range(len(np_img)):\n",
    "        ret_labels[n*2 , : ] = label[n,:]\n",
    "        ret_labels[n*2+1 , : ] = label[n,:]\n",
    "        for r in range(img_row - crop_img_row):\n",
    "            for c in range(img_col - crop_img_col):\n",
    "\n",
    "                cropped_img = np_img[n, r:crop_img_row +r , c:crop_img_col+c ,: ]\n",
    "\n",
    "                ret_images[n*2,:,:,:]=cropped_img  \n",
    "                ret_images[(n*2+1) , :,:,:] =np.fliplr(cropped_img )\n",
    "\n",
    "\n",
    "    return ret_images ,ret_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OPEN_TENSORBOARD(sess,tensor_info , logdir ):\n",
    "    \n",
    "    tensorboard_info={}\n",
    "    tb_acc=tf.scalar_summary(\"accuarcy\" ,tensor_info['accuracy'] )\n",
    "    tb_loss=tf.scalar_summary(\"loss\" ,tensor_info['cost'] )\n",
    "    tb_merge = tf.merge_all_summaries()\n",
    "    writer=tf.train.SummaryWriter(logdir , sess.graph_def )\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    \n",
    "    \n",
    "    tensorboard_info['writer']=writer\n",
    "    tensorboard_info['merge'] =tb_merge\n",
    "  \n",
    "    return tensorboard_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"STEM_A_8/layer1_relu:0\", shape=(?, 15, 15, 32), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"STEM_A_8/layer2_relu:0\", shape=(?, 13, 13, 32), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"STEM_A_8/layer3_relu:0\", shape=(?, 13, 13, 64), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"STEM_A_8/layer4_relu:0\", shape=(?, 6, 6, 96), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"STEM_A_8/b_layer_relu:0\", shape=(?, 6, 6, 64), dtype=float32, device=/device:GPU:0)\n",
      "(5760, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is recorded at :80\n",
      "{'merge': <tf.Tensor 'MergeSummary/MergeSummary:0' shape=() dtype=string>, 'writer': <tensorflow.python.training.summary_io.SummaryWriter object at 0x7f8e1fd57a90>}\n",
      "Training Data Image (50000, 32, 32, 3)\n",
      "Training Data Label (50000, 10)\n",
      "Test Data Label (5000, 10)\n",
      "Test Data Image (5000, 32, 32, 3)\n",
      "val Data Label (5000, 10)\n",
      "val Data Image (5000, 32, 32, 3)\n",
      "validate tensorboard {'merge': <tf.Tensor 'MergeSummary/MergeSummary:0' shape=() dtype=string>, 'writer': <tensorflow.python.training.summary_io.SummaryWriter object at 0x7f8e1fd57a90>}\n",
      "a\n",
      "Tensor(\"accuracy/accuracy/Mean:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "validate tensorboard None\n",
      "b\n",
      "0\n",
      "step 0 , training  accuracy 0\n",
      "step 0 , loss : 690.82\n",
      "step 0 , validation  accuracy 0.110778\n",
      "step 0 , validation loss : 711.426\n",
      "validate tensorboard {'merge': <tf.Tensor 'MergeSummary/MergeSummary:0' shape=() dtype=string>, 'writer': <tensorflow.python.training.summary_io.SummaryWriter object at 0x7f8e1fd57a90>}\n",
      "a\n",
      "Tensor(\"accuracy/accuracy/Mean:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "validate tensorboard None\n",
      "b\n",
      "100\n",
      "step 100 , training  accuracy 0.1\n",
      "step 100 , loss : 41.2336\n",
      "step 100 , validation  accuracy 0.112375\n",
      "step 100 , validation loss : 34.8167\n",
      "validate tensorboard {'merge': <tf.Tensor 'MergeSummary/MergeSummary:0' shape=() dtype=string>, 'writer': <tensorflow.python.training.summary_io.SummaryWriter object at 0x7f8e1fd57a90>}\n",
      "a\n",
      "Tensor(\"accuracy/accuracy/Mean:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "validate tensorboard None\n",
      "b\n",
      "200\n",
      "step 200 , training  accuracy 0.133333\n",
      "step 200 , loss : 21.2848\n",
      "step 200 , validation  accuracy 0.103693\n",
      "step 200 , validation loss : 21.9107\n",
      "validate tensorboard {'merge': <tf.Tensor 'MergeSummary/MergeSummary:0' shape=() dtype=string>, 'writer': <tensorflow.python.training.summary_io.SummaryWriter object at 0x7f8e1fd57a90>}\n",
      "a\n",
      "Tensor(\"accuracy/accuracy/Mean:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "validate tensorboard None\n",
      "b\n",
      "300\n",
      "step 300 , training  accuracy 0.0666667\n",
      "step 300 , loss : 13.0113\n",
      "step 300 , validation  accuracy 0.118164\n",
      "step 300 , validation loss : 14.7012\n",
      "validate tensorboard {'merge': <tf.Tensor 'MergeSummary/MergeSummary:0' shape=() dtype=string>, 'writer': <tensorflow.python.training.summary_io.SummaryWriter object at 0x7f8e1fd57a90>}\n",
      "a\n",
      "Tensor(\"accuracy/accuracy/Mean:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "validate tensorboard None\n",
      "b\n",
      "400\n",
      "step 400 , training  accuracy 0.2\n",
      "step 400 , loss : 9.73335\n",
      "step 400 , validation  accuracy 0.12525\n",
      "step 400 , validation loss : 10.8675\n",
      "--- Training Time : 6.64859485626 ---\n",
      "Tensor(\"accuracy/accuracy/Mean:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "test accuracy 0.122255519032 , test loss 9.3817615509\n"
     ]
    }
   ],
   "source": [
    "tensor_info={};place_info={}\n",
    "file_locate='./cifar_merge/'\n",
    "dirname='./result/'\n",
    "\n",
    "A=STEM_A(x_ , 'gpu:0')\n",
    "\"\"\"\n",
    "B=STEM_B(A , 'gpu:0')\n",
    "C=STEM_C(B , 'gpu:0')\n",
    "D=INCEPTION_MODULE_A(C,'gpu:0', 'INCEPTION_MODULE_A_1')\n",
    "E=INCEPTION_MODULE_A(D,'gpu:0', 'INCEPTION_MODULE_A_2')\n",
    "F=INCEPTION_MODULE_A(E,'gpu:0', 'INCEPTION_MODULE_A_3')\n",
    "G=INCEPTION_MODULE_A(F,'gpu:0', 'INCEPTION_MODULE_A_4')\n",
    "H=INCEPTION_REDUCTION_A(G,'gpu:0' , 'INCEPTION_REDUCTION_A_1')\n",
    "I=INCEPTION_MODULE_B(H,'gpu:0' , 'INCEPTION_REDUCTION_B_1')\n",
    "J=INCEPTION_MODULE_B(I,'gpu:0' , 'INCEPTION_REDUCTION_B_2')\n",
    "K=INCEPTION_MODULE_B(G,'gpu:0' , 'INCEPTION_REDUCTION_B_3')\n",
    "L=INCEPTION_MODULE_B(G,'gpu:0' , 'INCEPTION_REDUCTION_B_4')\n",
    "M=INCEPTION_MODULE_B(G,'gpu:0' , 'INCEPTION_REDUCTION_B_5')\n",
    "\"\"\"\n",
    "\n",
    "flat_=FLAT(A)\n",
    "y_conv=FC_A(flat_ , n_classes ,'/gpu:0' ,dropout_rate=keep_prob)\n",
    "cost , train_step ,correct_prediction , accuracy ,softmax = TRAIN_STRUCTURE_A(y_conv , y_ , '/gpu:0')\n",
    "\n",
    "tensor_info['cost']=cost\n",
    "tensor_info['train_step']=train_step\n",
    "tensor_info['correct_prediction']=correct_prediction\n",
    "tensor_info['accuracy']=accuracy\n",
    "tensor_info['softmax']=softmax\n",
    "\n",
    "place_info['x_']=x_\n",
    "place_info['y_']=y_\n",
    "place_info['keep_prob']=keep_prob\n",
    "\n",
    "\n",
    "logdir='./tensorboard2'\n",
    "sess=START_SESS()\n",
    "tensorboard_info=OPEN_TENSORBOARD(sess ,tensor_info ,logdir)\n",
    "fp=make_logdir(dirname)\n",
    "BATCH_TRAINING_RANDOM(500 , 30,file_locate , tensor_info,place_info ,fp ,tensorboard_info)\n",
    "#BATCH_TRAINING_DIVIDE_RANDOM(100000 , 30,file_locate , tensor_info,place_info ,fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
