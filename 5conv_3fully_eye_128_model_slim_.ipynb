{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2789, 128, 128, 3)\n",
      "128 128\n",
      "128 128\n"
     ]
    }
   ],
   "source": [
    "#conv Neural Network\n",
    "# tensorboard --logdir=/home/ncc/notebook/learn/tensorboard/log\n",
    "\"\"\"\n",
    "created by kim Seong jung\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "\n",
    "file_locate='/home/user01/notebook/eye_numpy_64/'\n",
    "sess = tf.InteractiveSession()\n",
    "test_img=np.load(file_locate+'test_img.npy');\n",
    "try:\n",
    "    print np.shape(test_img)\n",
    "    img_row = np.shape(test_img)[1]\n",
    "    img_col = np.shape(test_img)[2]\n",
    "except:\n",
    "    np.shape(test_img)\n",
    "    test_img=np.reshape(test_img , newshape = [np.shape(test_img)[0] , 32, 32 ,3] )\n",
    "    img_row = np.shape(test_img)[1]\n",
    "    img_col = np.shape(test_img)[2]\n",
    "\n",
    "    \n",
    "divide_flag= False\n",
    "aug_flag = False\n",
    "save_flag = False\n",
    "restore_flag = False\n",
    "batch_size=30\n",
    "print img_row ,img_col\n",
    "n_classes =2\n",
    "in_ch =3\n",
    "out_ch1=100\n",
    "out_ch2=100\n",
    "out_ch3=100\n",
    "out_ch4=100\n",
    "out_ch5=100\n",
    "\n",
    "\n",
    "fully_ch1=1024\n",
    "fully_ch2 =1024\n",
    "fully_ch3 =1024\n",
    "\n",
    "\n",
    "\n",
    "c_ksize1 =[11,11,in_ch , out_ch1]\n",
    "c_ksize2 =[5,5, out_ch1, out_ch2]\n",
    "c_ksize3 =[3,3, out_ch2, out_ch3]\n",
    "c_ksize4 =[3,3, out_ch3, out_ch4]\n",
    "c_ksize5 =[3,3, out_ch4, out_ch5]\n",
    "\n",
    "c_strides1=[1,4,4,1]\n",
    "c_strides2=[1,1,1,1]\n",
    "c_strides3=[1,1,1,1]\n",
    "c_strides4=[1,1,1,1]\n",
    "c_strides5=[1,1,1,1]\n",
    "\n",
    "\n",
    "\n",
    "p_ksize1=[1,3,3,1]\n",
    "p_ksize2=[1,3,3,1]\n",
    "p_ksize5=[1,3,3,1]\n",
    "\n",
    "p_strides1=[1,2,2,1]\n",
    "p_strides2=[1,2,2,1]\n",
    "p_strides5=[1,2,2,1]\n",
    "\n",
    "iterate=30000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print img_col , img_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if aug_flag == False:\n",
    "    x= tf.placeholder(\"float\",shape=[None,img_row , img_col , in_ch],  name = 'x-input')\n",
    "    y_=tf.placeholder(\"float\",shape=[None , n_classes] , name = 'y-input')\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "    x_image= tf.reshape(x,[-1,img_row,img_col,3])\n",
    "\n",
    "elif aug_flag == True:\n",
    "    crop_img_col =118\n",
    "    crop_img_row =118\n",
    "    \n",
    "    x= tf.placeholder(\"float\",shape=[None,crop_img_row , crop_img_row , in_ch],  name = 'x-input')\n",
    "    y_=tf.placeholder(\"float\",shape=[None , n_classes] , name = 'y-input')\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "    x_image= tf.reshape(x,[-1,crop_img_row,crop_img_col,in_ch])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/user01/notebook'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (22302, 128, 128, 3)\n",
      "Training Data Label (22302, 2)\n",
      "Test Data Label (2789, 2)\n",
      "val Data Label (2787, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:3'):\n",
    "#with tf.device('/gpu:1'):\n",
    "\n",
    "    if divide_flag == False:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_img)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n",
    "\n",
    "    if divide_flag == True:\n",
    "        train_img=np.load(file_locate+'train_img_1.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab_1.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"def weight_variable(name,shape):\n",
    "    #initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    initial = tf.get_variable(name,shape=shape , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)\"\"\"\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1 , shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    def next_batch(batch_size , image , label):\n",
    "\n",
    "        a=np.random.randint(np.shape(image)[0] -batch_size)\n",
    "        batch_x = image[a:a+batch_size,:]\n",
    "        batch_y= label[a:a+batch_size,:]\n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def conv2d(x,w,strides_):\n",
    "    return tf.nn.conv2d(x,w, strides = strides_, padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x , ksize=[1,2,2,1] ,strides = [1,2,2,1] , padding = 'SAME')\n",
    "def max_pool(x , ksize , strides , padding='SAME'):\n",
    "    return tf.nn.max_pool(x ,ksize , strides , padding )\n",
    "def make_weights_biases(layer_name , w_name , ksize ,device_name,initializer='xavier'):\n",
    "    if len(ksize)==4: # convolution filter shape [batch , row , col , color_ch]\n",
    "        out_ch=ksize[3]\n",
    "    elif len(ksize)==2: #fully connected layer shape [in_ch , output_ch]\n",
    "        out_ch=ksize[1]\n",
    "    with tf.device(device_name):\n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            try:\n",
    "                w_conv = tf.get_variable(w_name, ksize , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv = tf.get_variable(w_name, ksize , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            try:\n",
    "                b_conv = bias_variable([out_ch])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv = bias_variable([out_ch])\n",
    "    return w_conv , b_conv \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make weights and biases that is used to convolution layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11, 3, 100)\n",
      "(5, 5, 100, 100)\n",
      "(3, 3, 100, 100)\n",
      "(3, 3, 100, 100)\n",
      "(3, 3, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "w_conv1 , b_conv1 =make_weights_biases('layer1' , 'W1' , c_ksize1 ,device_name = '/gpu:2')\n",
    "w_conv2 , b_conv2= make_weights_biases('layer2' , 'W2' , c_ksize2 ,device_name = '/gpu:2')\n",
    "w_conv3 , b_conv3= make_weights_biases('layer3' , 'W3' , c_ksize3 ,device_name = '/gpu:2')\n",
    "w_conv4 , b_conv4= make_weights_biases('layer4' , 'W4' , c_ksize4 ,device_name = '/gpu:2')\n",
    "w_conv5 , b_conv5= make_weights_biases('layer5' , 'W5' , c_ksize5 ,device_name = '/gpu:2')\n",
    "\n",
    "print w_conv1.get_shape()\n",
    "print w_conv2.get_shape()\n",
    "print w_conv3.get_shape()\n",
    "print w_conv4.get_shape()\n",
    "print w_conv5.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# connect Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_5:0\", shape=(?, 128, 128, 3), dtype=float32)\n",
      "Tensor(\"MaxPool_3:0\", shape=(?, 16, 16, 100), dtype=float32, device=/device:GPU:4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print x_image\n",
    "#conncect hidden layer \n",
    "with tf.device('/gpu:4'):\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image , w_conv1 ,c_strides1)+b_conv1)\n",
    "    h_conv1 = max_pool(h_conv1 , p_ksize1 , p_strides1)\n",
    "    print h_conv1\n",
    "    \n",
    "    #print conv2d(h_pool1 , w_conv2).get_shape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_4:0\", shape=(?, 8, 8, 100), dtype=float32, device=/device:GPU:4)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:4'):\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1 , w_conv2 ,c_strides2)+b_conv2)\n",
    "    h_conv2 = max_pool(h_conv2 , p_ksize2 , p_strides2)#pooling   \n",
    "    print h_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_7:0\", shape=(?, 8, 8, 100), dtype=float32, device=/device:GPU:4)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:4'):\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2 , w_conv3,c_strides3)+b_conv3)\n",
    "    print h_conv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_8:0\", shape=(?, 8, 8, 100), dtype=float32, device=/device:GPU:4)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:4'):\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3 , w_conv4,c_strides4)+b_conv4)\n",
    "    print h_conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_5:0\", shape=(?, 4, 4, 100), dtype=float32, device=/device:GPU:4)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:4'):\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_conv4, w_conv5,c_strides5)+b_conv5)\n",
    "    h_conv5= max_pool(h_conv5 , p_ksize5 , p_strides5) #pooling \n",
    "    print h_conv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end_conv = h_conv5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "end_conv_row=int(h_conv5.get_shape()[1])\n",
    "end_conv_col=int(h_conv5.get_shape()[2])\n",
    "end_conv_ch=int(h_conv5.get_shape()[3])\n",
    "#connect fully connected layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flat convolution layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:2'): # flat conv layer \n",
    "    end_flat_conv =tf.reshape(end_conv, [-1,end_conv_col*end_conv_row*end_conv_ch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make weights and biases that used fully connected layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_ksize1=[end_conv_col*end_conv_row*end_conv_ch,fully_ch1]\n",
    "fc_ksize2=[fully_ch1,fully_ch2]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_fc1 ,b_fc1 = make_weights_biases('fc1' , 'fc_W1' , fc_ksize1 ,  '/gpu:3')\n",
    "w_fc2 ,b_fc2 = make_weights_biases('fc2' , 'fc_W2' , fc_ksize2 ,  '/gpu:3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_fc1=tf.matmul(end_flat_conv , w_fc1 )+b_fc1\n",
    "h_fc1=tf.nn.dropout(h_fc1 , keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_fc2=tf.matmul(h_fc1 , w_fc2 )+b_fc2\n",
    "h_fc2=tf.nn.dropout(h_fc2 , keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_fc=h_fc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "end_ksize=[end_fc.get_shape()[1] , n_classes]   \n",
    "w_end ,b_end = make_weights_biases('fc_end' , 'fc_end_W' , end_ksize ,  '/gpu:3')\n",
    "y_conv = tf.matmul(end_fc , w_end)+b_end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is recorded at :81\n"
     ]
    }
   ],
   "source": [
    "#dirname = '/home/ncc/notebook/mammo/result/'\n",
    "\n",
    "dirname='/home/user01/notebook/'\n",
    "    \n",
    "count=0\n",
    "while(True):\n",
    "    if not os.path.isdir(dirname):\n",
    "        os.mkdir(dirname)\n",
    "        break\n",
    "    elif not os.path.isdir(dirname + str(count)):\n",
    "        dirname=dirname+str(count)\n",
    "        os.mkdir(dirname)\n",
    "        break\n",
    "    else:\n",
    "        count+=1\n",
    "print 'it is recorded at :'+str(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=open(dirname+\"/log.txt\",'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_list(folder_path):\n",
    "    list_files=os.walk(folder_path).next()[2]\n",
    "    print list_files\n",
    "    ret_train_img_list=[]\n",
    "    ret_train_lab_list=[]\n",
    "    for i , ele in enumerate(list_files):\n",
    "\n",
    "        if 'train'  in ele and 'img'in ele:\n",
    "            ret_train_img_list.append(ele)\n",
    "        elif 'train' in ele  and  'lab' in ele:\n",
    "            ret_train_lab_list.append(ele)\n",
    "    return ret_train_img_list ,ret_train_lab_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_lab.npy', 'val_lab.npy', 'train_img.npy', 'test_img.npy', 'val_img.npy', 'train_lab.npy']\n"
     ]
    }
   ],
   "source": [
    "train_images , train_labels  = get_batch_list(file_locate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_img.npy']\n",
      "['train_lab.npy']\n"
     ]
    }
   ],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "\n",
    "train_images.sort(key=natural_keys)\n",
    "train_labels.sort(key = natural_keys)\n",
    "print(train_images)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col , label):\n",
    "    \n",
    "    n_img = np.shape(np_img)[0] \n",
    "    n_ret_img = n_img*(img_row - crop_img_row) * (img_col - crop_img_col)*2\n",
    "    ret_images = np.zeros([n_ret_img ,crop_img_row , crop_img_col,color_ch])\n",
    "    len_label= np.shape(label)[1]\n",
    "    ret_labels =  np.zeros([n_ret_img  ,len_label])\n",
    "    #print \"n_augmented image size : \" , n_ret_img \n",
    "    #print \"n classes :\", len_label\n",
    "    #copy label in factor by 2014\n",
    "    count=0\n",
    "    if len(np.shape(np_img))==2:\n",
    "        np_img=np.reshape(np_img , newshape = [np.shape(np_img)[0] , img_row , img_col ,color_ch])\n",
    "        print np.shape(np_img)\n",
    "    for n  in range(len(np_img)):\n",
    "        for r in range(img_row - crop_img_row):\n",
    "            for c in range(img_col - crop_img_col):\n",
    "                \n",
    "                ret_labels[n*2 +count, : ] = label[n,:]\n",
    "                ret_labels[n*2+1+count , : ] = label[n,:]\n",
    "                cropped_img = np_img[n, r:crop_img_row +r , c:crop_img_col+c ,: ]                \n",
    "                ret_images[n*2+count,:,:,:]=cropped_img  \n",
    "                ret_images[(n*2+1)+count , :,:,:] =np.fliplr(cropped_img )\n",
    "                count+=1\n",
    "    \n",
    "    return ret_images ,ret_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_test_img(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col ):\n",
    "    left_top =(0,0)\n",
    "    right_top =(  img_row  - crop_img_row  , 0 )\n",
    "    center =  ((img_row  - crop_img_row)/2  , (img_col - crop_img_row)/2)\n",
    "    left_buttom = (0,(img_col - crop_img_row)/2 )\n",
    "    right_buttom =  (img_row  - crop_img_row , img_col - crop_img_row)\n",
    "    \n",
    "    left_top_images  = np_img[: , left_top[0]:crop_img_row+left_top[0] , left_top[1] : crop_img_col+left_top[1] , :  ]\n",
    "    right_top_images = np_img[: , right_top[0]:crop_img_row +right_top[0], right_top[1] : crop_img_col +right_top[1], :  ]\n",
    "    center_images    = np_img[: , center[0]:crop_img_row +center[0], center[1] : crop_img_col +center[1], :  ]\n",
    "    left_buttom_images=np_img[: , left_buttom[0]:crop_img_row +left_buttom[0], left_buttom[1] : crop_img_col +left_buttom[1], :  ]\n",
    "    right_buttom_images= np_img[: , right_buttom[0]:crop_img_row+right_buttom[0] , right_buttom[1] : crop_img_col +right_buttom[1] , :  ]\n",
    "\n",
    "    \n",
    "        \n",
    "    return left_top_images , right_top_images , center_images , left_buttom_images , right_buttom_images \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save and restore Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if save_flag == True:\n",
    "    global_step = tf.Variable(0 , trainable = False ,name = 'global_step' )\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    save_path = './ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if restore_flag == True:\n",
    "    ckpt = tf.train.get_checkpoint_state(save_path)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        print ckpt.model_checkpoint_path\n",
    "        saver.restore(sess , ckpt.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if save_flag == True:\n",
    "    a=sess.run(global_step)\n",
    "    print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:3'):\n",
    "#sm_conv= tf.nn.softmax(y_conv)\n",
    "    #cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "    start_time = time.time()\n",
    "\n",
    "    regular=0.01*(tf.reduce_sum(tf.square(y_conv)))\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( y_conv, y_))\n",
    "with tf.device('/gpu:4'):\n",
    "    cost = cost+regular\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cost) #1e-4\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            correct_prediction = tf.equal(tf.argmax(y_conv,1) ,tf.argmax(y_,1))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\")) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "step 0 , training  accuracy 0.466667\n",
      "step 0 , loss : 42.4895\n",
      "step 0 , validation  accuracy 0.494438\n",
      "step 0 , validation loss : 3483.31\n",
      "model saved\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value beta1_power\n\t [[Node: beta1_power/read = Identity[T=DT_FLOAT, _class=[\"loc:@layer1/W1\"], _device=\"/job:localhost/replica:0/task:0/gpu:2\"](beta1_power)]]\n\t [[Node: beta1_power/read/_261 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:3\", send_device=\"/job:localhost/replica:0/task:0/gpu:2\", send_device_incarnation=1, tensor_name=\"edge_88_beta1_power/read\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:3\"]()]]\n\nCaused by op u'beta1_power/read', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-33-9f10ad7cbec0>\", line 10, in <module>\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(cost) #1e-4\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 198, in minimize\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 311, in apply_gradients\n    self._create_slots(var_list)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/adam.py\", line 113, in _create_slots\n    trainable=False)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 215, in __init__\n    dtype=dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 327, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 1128, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value beta1_power\n\t [[Node: beta1_power/read = Identity[T=DT_FLOAT, _class=[\"loc:@layer1/W1\"], _device=\"/job:localhost/replica:0/task:0/gpu:2\"](beta1_power)]]\n\t [[Node: beta1_power/read/_261 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:3\", send_device=\"/job:localhost/replica:0/task:0/gpu:2\", send_device_incarnation=1, tensor_name=\"edge_88_beta1_power/read\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:3\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-04f94834627d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_ys\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Training Time : %s ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value beta1_power\n\t [[Node: beta1_power/read = Identity[T=DT_FLOAT, _class=[\"loc:@layer1/W1\"], _device=\"/job:localhost/replica:0/task:0/gpu:2\"](beta1_power)]]\n\t [[Node: beta1_power/read/_261 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:3\", send_device=\"/job:localhost/replica:0/task:0/gpu:2\", send_device_incarnation=1, tensor_name=\"edge_88_beta1_power/read\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:3\"]()]]\n\nCaused by op u'beta1_power/read', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-33-9f10ad7cbec0>\", line 10, in <module>\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(cost) #1e-4\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 198, in minimize\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 311, in apply_gradients\n    self._create_slots(var_list)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/adam.py\", line 113, in _create_slots\n    trainable=False)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 215, in __init__\n    dtype=dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 327, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 1128, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value beta1_power\n\t [[Node: beta1_power/read = Identity[T=DT_FLOAT, _class=[\"loc:@layer1/W1\"], _device=\"/job:localhost/replica:0/task:0/gpu:2\"](beta1_power)]]\n\t [[Node: beta1_power/read/_261 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:3\", send_device=\"/job:localhost/replica:0/task:0/gpu:2\", send_device_incarnation=1, tensor_name=\"edge_88_beta1_power/read\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:3\"]()]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "if divide_flag ==True:\n",
    "    n_batch =len(train_images)\n",
    "    batch_count=0\n",
    "\n",
    "for i in range(iterate): \n",
    "    #print i\n",
    "    if divide_flag ==True:\n",
    "        print batch_count , i\n",
    "        if batch_count >= n_batch:    \n",
    "            train_img =np.load(file_locate+train_images[batch_count])\n",
    "            train_lab =np.load(file_locate+train_labels[batch_count])\n",
    "        \n",
    "    batch_xs , batch_ys = next_batch(batch_size, train_img , train_lab)    \n",
    "    if i%100 ==0: # in here add to validation \n",
    "        try:\n",
    "            if aug_flag == True:\n",
    "                color_ch = in_ch\n",
    "                val_images=extract_test_img(val_img ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "                val_acc_list=[]\n",
    "                val_loss_list=[]\n",
    "                for img_ind ,ele  in enumerate(val_images): \n",
    "                    val_accuracy = sess.run( accuracy , feed_dict={x:ele , y_:val_lab , keep_prob: 1.0})        \n",
    "                    val_loss = sess.run(cost , feed_dict = {x:ele , y_: val_lab , keep_prob: 1.0})\n",
    "\n",
    "                    val_acc_list.append(val_accuracy)\n",
    "                    val_loss_list.append(val_loss)\n",
    "\n",
    "                val_acc_list=np.asarray(val_acc_list)\n",
    "                val_loss_list=np.asarray(val_loss_list)\n",
    "                val_acc=np.mean(val_acc_list)\n",
    "                val_loss=np.mean(val_loss_list)\n",
    "\n",
    "\n",
    "                train_images=extract_test_img(val_img ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "                train_acc_list=[]\n",
    "                train_loss_list=[]\n",
    "                for img_ind ,ele  in enumerate(train_images): \n",
    "                    train_accuracy = sess.run( accuracy , feed_dict={x:ele , y_:batch_ys , keep_prob: 1.0})        \n",
    "                    train_loss = sess.run(cost , feed_dict = {x:ele , y_: batch_ys , keep_prob: 1.0})\n",
    "\n",
    "                    train_acc_list.append(train_accuracy)\n",
    "                    train_loss_list.append(train_loss)\n",
    "\n",
    "                train_acc_list=np.asarray(train_acc_list)\n",
    "                train_loss_list=np.asarray(train_loss_list)\n",
    "                train_acc=np.mean(train_acc_list)\n",
    "                train_loss=np.mean(train_loss_list)\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "                val_accuracy = sess.run( accuracy , feed_dict={x:val_img , y_:val_lab , keep_prob: 1.0})        \n",
    "                val_loss = sess.run(cost , feed_dict = {x:val_img , y_: val_lab , keep_prob: 1.0})\n",
    "\n",
    "                train_accuracy = sess.run( accuracy , feed_dict={x:batch_xs , y_:batch_ys , keep_prob: 1.0})        \n",
    "                train_loss = sess.run(cost , feed_dict = {x:batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "\n",
    "            #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "            print i\n",
    "            print(\"step %d , training  accuracy %g\" %(i,train_accuracy))\n",
    "            print(\"step %d , loss : %g\" %(i,train_loss))\n",
    "            train_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(train_loss) +'\\tval accuracy:\\t'+str(train_accuracy)+'\\n'\n",
    "\n",
    "            print(\"step %d , validation  accuracy %g\" %(i,val_accuracy))\n",
    "            print(\"step %d , validation loss : %g\" %(i,val_loss))\n",
    "            val_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(val_loss) +'\\tval accuracy:\\t'+str(val_accuracy)+'\\n'\n",
    "\n",
    "\n",
    "            f.write(val_str)\n",
    "            f.write(train_str)\n",
    "            if divide_flag ==True:\n",
    "                batch_count+=1\n",
    "        except :\n",
    "            val_acc_list=[]\n",
    "            val_loss_list=[]\n",
    "            train_acc_list=[]\n",
    "            train_loss_list=[]\n",
    "            n_divide=len(val_img)/batch_size\n",
    "            j=0\n",
    "            if aug_flag == True:\n",
    "                for j in range(n_divide):\n",
    "\n",
    "                    # j*batch_size :(j+1)*batch_size\n",
    "                    val_batch_xs =val_img[ j*batch_size :(j+1)*batch_size] \n",
    "                    val_batch_ys=val_lab[ j*batch_size :(j+1)*batch_size]\n",
    "                    val_images = extract_test_img( val_batch_xs  ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "                    \n",
    "                    for img_ind, ele in enumerate(val_images):                        \n",
    "                        val_accuracy,val_loss = sess.run([accuracy ,cost], feed_dict={x:ele , y_:val_batch_ys , keep_prob: 1.0})        \n",
    "                        val_acc_list.append(float(val_accuracy))\n",
    "                        val_loss_list.append(float(val_loss))\n",
    "                    #right above code have to modify\n",
    "                val_batch_xs = val_img[ (j+1)*batch_size :  ] \n",
    "                val_batch_ys = val_lab[ (j+1)*batch_size :  ]\n",
    "                val_images = extract_test_img( val_batch_xs  ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "                for img_ind , ele in enumerate(val_images):                        \n",
    "                    val_accuracy,val_loss = sess.run([accuracy ,cost], feed_dict={x:ele , y_:val_batch_ys , keep_prob: 1.0})        \n",
    "                    val_acc_list.append(float(val_accuracy))\n",
    "                    val_loss_list.append(float(val_loss))\n",
    "                \n",
    "                val_acc_list=np.asarray(val_acc_list)\n",
    "                val_loss_list= np.asarray(val_loss_list)\n",
    "\n",
    "                val_acc=np.mean(val_acc_list)\n",
    "                val_loss = np.mean(val_loss_list)\n",
    "\n",
    "                #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "                train_images = extract_test_img( batch_xs  ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "                for img_ind, ele in enumerate(train_images):\n",
    "                    train_accuracy,train_loss = sess.run([accuracy ,cost], feed_dict={x:ele , y_:batch_ys , keep_prob: 1.0})        \n",
    "                    train_acc_list.append(float(train_accuracy))\n",
    "                    train_loss_list.append(float(train_loss))\n",
    "                train_acc_list=np.asarray(train_acc_list) \n",
    "                train_loss_list= np.asarray(train_loss_list)\n",
    "                train_accuracy=np.mean(train_acc_list)\n",
    "                train_loss=np.mean(train_loss_list)\n",
    "            else:\n",
    "                \n",
    "                for j in range(n_divide):\n",
    "                    # j*batch_size :(j+1)*batch_size\n",
    "                    val_batch_xs =  val_img[ j*batch_size :(j+1)*batch_size] \n",
    "                    val_batch_ys =  val_lab[ j*batch_size :(j+1)*batch_size]                        \n",
    "                    val_accuracy,val_loss = sess.run([accuracy ,cost], feed_dict={x:val_batch_xs , y_:val_batch_ys , keep_prob: 1.0})        \n",
    "                    list_acc.append(float(val_accuracy))\n",
    "                    list_loss.append(float(val_loss))\n",
    "                    #right above code have to modify\n",
    "                val_batch_xs = val_img[ (j+1)*batch_size :  ] \n",
    "                val_batch_ys = val_lab[ (j+1)*batch_size :  ]\n",
    "                list_acc=np.asarray(list_acc)\n",
    "                list_loss= np.asarray(list_loss)\n",
    "                val_accuracy=np.mean(list_acc)\n",
    "                val_loss = np.mean(list_loss)\n",
    "\n",
    "                #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "\n",
    "                train_accuracy = sess.run( accuracy , feed_dict={x:batch_xs , y_:batch_ys , keep_prob: 1.0})        \n",
    "                train_loss = sess.run(cost , feed_dict = {x:batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "                                      \n",
    "                                      \n",
    "                                      \n",
    "            print(\"step %d , training  accuracy %g\" %(i,train_accuracy))\n",
    "            print(\"step %d , loss : %g\" %(i,train_loss))\n",
    "            train_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(train_loss) +'\\tval accuracy:\\t'+str(train_accuracy)+'\\n'\n",
    "\n",
    "            print(\"step %d , validation  accuracy %g\" %(i,val_accuracy))\n",
    "            print(\"step %d , validation loss : %g\" %(i,val_loss))\n",
    "            val_str = 'step:\\t'+str(i)+'\\tval_loss:\\t'+str(val_loss) +'\\tval accuracy:\\t'+str(val_accuracy)+'\\n'\n",
    "\n",
    "            f.write(val_str)\n",
    "            f.write(train_str)\n",
    "            if divide_flag == True:\n",
    "                batch_count+=1\n",
    "        if save_flag == True:\n",
    "            global_ind=global_step.assign(i).eval()\n",
    "            saver.save(sess , save_path + \"/model.ckpt\", global_step = global_ind)\n",
    "        print 'model saved'\n",
    "    if aug_flag == True:\n",
    "        aug_batch_xs , aug_batch_ys=aug(np_img=batch_xs[:int(batch_size)] ,img_row= img_row  ,img_col =img_col\\\n",
    "                                        , color_ch=3, crop_img_row =118, crop_img_col =118, label = batch_ys )\n",
    "        \n",
    "        #after augmentation process ,\n",
    "        #print 'a'\n",
    "        share= len(aug_batch_xs) / batch_size\n",
    "        #print share\n",
    "        for i in xrange(share):\n",
    "            #print i\n",
    "            batch_xs=aug_batch_xs[i*batch_size : (i+1)*batch_size,:,:,:]  \n",
    "            batch_ys=aug_batch_ys[i*batch_size : (i+1)*batch_size,:]  \n",
    "            sess.run(train_step ,feed_dict={x: batch_xs, y_:batch_ys , keep_prob : 0.7})\n",
    "            #print 'training'\n",
    "        #print (i+1)*batch_size \n",
    "        #batch_xs=aug_batch_xs[(i+1)*batch_size :,:,:,:]  \n",
    "        #batch_ys = aug_batch_ys[(i+1)*batch_size:,:]  \n",
    "        #sess.run(train_step ,feed_dict={x: batch_xs, y_:batch_ys , keep_prob : 0.7})\n",
    "        #print 'last training'\n",
    "        #print len(aug_batch_xs)\n",
    "        share= len(aug_batch_xs) / batch_size\n",
    "\n",
    "        \n",
    "    else:\n",
    "        sess.run(train_step ,feed_dict={x: batch_xs, y_:batch_ys , keep_prob : 0.7})\n",
    "    \n",
    "print(\"--- Training Time : %s ---\" % (time.time() - start_time))\n",
    "train_time=\"--- Training Time : ---:\\t\" +str(time.time() - start_time)\n",
    "f.write(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aug_batch_xs , aug_batch_ys=aug(np_img=batch_xs[:] ,img_row= img_row  ,img_col =img_col\\\n",
    "                                        , color_ch=3, crop_img_row =118, crop_img_col =118, label = batch_ys )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=103 \n",
    "share=a/10\n",
    "for i in range(share):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print ''\n",
    "print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    test_accuracy = sess.run( accuracy , feed_dict={x:test_img , y_:test_lab , keep_prob: 1.0})        \n",
    "    test_loss = sess.run(cost , feed_dict = {x:test_img , y_: test_lab , keep_prob: 1.0})\n",
    "\n",
    "    #result = sess.run(sm_conv , feed_dict = {x:test_img , y_:batch_ys , keep_prob :1.0})\n",
    "    print(\"step %d , testidation  accuracy %g\" %(i,test_accuracy))\n",
    "    print(\"step %d , testidation loss : %g\" %(i,test_loss))\n",
    "    test_str = 'step:\\t'+str(i)+'\\ttest_loss:\\t'+str(test_loss) +'\\ttest accuracy:\\t'+str(test_accuracy)+'\\n'\n",
    "\n",
    "    f.write(test_str)\n",
    "except :\n",
    "    list_acc=[]\n",
    "    list_loss=[]\n",
    "    n_divide=len(test_img)/batch_size\n",
    "    for j in range(n_divide):\n",
    "\n",
    "        # j*batch_size :(j+1)*batch_size\n",
    "        test_accuracy,test_loss = sess.run([accuracy ,cost], feed_dict={x:test_img[ j*batch_size :(j+1)*batch_size] , y_:test_lab[ j*batch_size :(j+1)*batch_size ] , keep_prob: 1.0})        \n",
    "        list_acc.append(float(test_accuracy))\n",
    "        list_loss.append(float(test_loss))\n",
    "    test_accuracy , test_loss=sess.run([accuracy,cost] , feed_dict={x:test_img[(j+1)*batch_size : ] , y_:test_lab[(j+1)*(batch_size) : ] , keep_prob : 1.0})\n",
    "    #right above code have to modify\n",
    "\n",
    "    list_acc.append(test_accuracy)\n",
    "    list_loss.append(test_loss)\n",
    "    list_acc=np.asarray(list_acc)\n",
    "    list_loss= np.asarray(list_loss)\n",
    "\n",
    "    test_accuracy=np.mean(list_acc)\n",
    "    test_loss = np.mean(list_loss)\n",
    "\n",
    "    #result = sess.run(sm_conv , feed_dict = {x:test_img , y_:batch_ys , keep_prob :1.0})\n",
    "    print(\"step %d , testidation  accuracy %g\" %(i,test_accuracy))\n",
    "    print(\"step %d , testidation loss : %g\" %(i,test_loss))\n",
    "    test_str = 'step:\\t'+str(i)+'\\ttest_loss:\\t'+str(test_loss) +'\\ttest accuracy:\\t'+str(test_accuracy)+'\\n'\n",
    "\n",
    "    f.write(test_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
