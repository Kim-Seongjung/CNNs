{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libcudart.so.8.0: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-788f912bb015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0m_default_dlopen_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdlopenflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_default_dlopen_flags\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_default_dlopen_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcudart.so.8.0: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "#conv Neural Network\n",
    "# tensorboard --logdir=/home/ncc/notebook/learn/tensorboard/log\n",
    "\"\"\"\n",
    "created by kim Seong jung\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "file_locate='./eye_numpy_64/'\n",
    "#file_locate ='/media/seongjung/Seagate Backup Plus Drive/data/Eye/npy/npy_128/'\n",
    "sess = tf.InteractiveSession()\n",
    "test_img=np.load(file_locate+'test_img.npy');\n",
    "test_lab=np.load(file_locate+'test_lab.npy');\n",
    "try:\n",
    "    print np.shape(test_img)\n",
    "    print np.shape(test_lab)\n",
    "    img_row = np.shape(test_img)[1]\n",
    "    img_col = np.shape(test_img)[2]\n",
    "except:\n",
    "    np.shape(test_img)\n",
    "    test_img=np.reshape(test_img , newshape = [np.shape(test_img)[0] , 32, 32 ,3] )\n",
    "    img_row = np.shape(test_img)[1]\n",
    "    img_col = np.shape(test_img)[2]\n",
    "\n",
    "    \n",
    "divide_flag= True\n",
    "aug_flag = True\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "train_img=test_img[0:15]\n",
    "train_lab=test_lab[0:15]\n",
    "val_img =test_img[15:30]\n",
    "val_lab =test_lab[15:30]\n",
    "test_img = test_img[30:45]\n",
    "test_lab =test_lab[30:45]\n",
    "path='/home/seongjung/바탕화면/sample/'\n",
    "\n",
    "np.save(path+'train_img',train_img)\n",
    "np.save(path+'train_lab',train_lab)\n",
    "np.save(path+'val_img',val_img)\n",
    "np.save(path+'val_lab',val_lab)\n",
    "np.save(path+'test_img',test_img)\n",
    "np.save(path+'test_lab',test_lab)\n",
    "\n",
    "print np.shape(train_img)\n",
    "print np.shape(train_lab)\n",
    "print np.shape(val_img)\n",
    "print np.shape(val_lab)\n",
    "print np.shape(test_img)\n",
    "print np.shape(test_img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load Training , Validation , Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "#with tf.device('/gpu:0'):\n",
    "    if divide_flag == False:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_img)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n",
    "\n",
    "    if divide_flag == True:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "\n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_ch =3\n",
    "n_classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    def next_batch(batch_size , image , label):\n",
    "\n",
    "        a=np.random.randint(np.shape(image)[0] -batch_size)\n",
    "        batch_x = image[a:a+batch_size,:]\n",
    "        batch_y= label[a:a+batch_size,:]\n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define Variable , and placeholder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "x = tf.placeholder(\"float\",shape=[None,img_row , img_col , in_ch],  name = 'x-input')\n",
    "y_= tf.placeholder(\"float\",shape=[None , n_classes] , name = 'y-input')\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "x_image= tf.reshape(x,[-1,img_row,img_col,3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"def weight_variable(name,shape):\n",
    "    #initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    initial = tf.get_variable(name,shape=shape , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)\"\"\"\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1 , shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def conv2d(x,w,strides_):\n",
    "    return tf.nn.conv2d(x,w, strides = strides_, padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x , ksize=[1,2,2,1] ,strides = [1,2,2,1] , padding = 'SAME')\n",
    "def max_pool(x , ksize , strides , padding='SAME'):\n",
    "    return tf.nn.max_pool(x ,ksize , strides , padding )\n",
    "def make_weights_biases(layer_name , w_name , ksize ,device_name,initializer='xavier'):\n",
    "    if len(ksize)==4: # convolution filter shape [batch , row , col , color_ch]\n",
    "        out_ch=ksize[3]\n",
    "    elif len(ksize)==2: #fully connected layer shape [in_ch , output_ch]\n",
    "        out_ch=ksize[1]\n",
    "    with tf.device(device_name):\n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            try:\n",
    "                w_conv = tf.get_variable(w_name, ksize , initializer = tf.contrib.layers.xavier_initializer())\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                w_conv = tf.get_variable(w_name, ksize , initializer = tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            try:\n",
    "                b_conv = bias_variable([out_ch])\n",
    "            except:\n",
    "                scope.reuse_variables()\n",
    "                b_conv = bias_variable([out_ch])\n",
    "    return w_conv , b_conv \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_A(x , device_):\n",
    "    with tf.device(device_):\n",
    "        in_ch=x.get_shape()[3]\n",
    "        out_ch1=32 ; out_ch2=32;out_ch3=64;out_ch4=96;\n",
    "\n",
    "        c_ksize1=[3,3,in_ch , out_ch1]\n",
    "        c_ksize2=[3,3,out_ch1 , out_ch2]\n",
    "        c_ksize3=[3,3,out_ch2 , out_ch3]\n",
    "        c_ksize4=[3,3,out_ch3 , out_ch4]\n",
    "        w_conv1 , b_conv1 =make_weights_biases('STEM_A' , 'W1' , c_ksize1 ,device_name = '/gpu:0')\n",
    "        w_conv2 , b_conv2= make_weights_biases('STEM_A' , 'W2' , c_ksize2 ,device_name = '/gpu:0')\n",
    "        w_conv3 , b_conv3= make_weights_biases('STEM_A' , 'W3' , c_ksize3 ,device_name = '/gpu:0')\n",
    "        w_conv4 , b_conv4= make_weights_biases('STEM_A' , 'W4' , c_ksize4 ,device_name = '/gpu:0')\n",
    "\n",
    "        c_strides1=[1,2,2,1]\n",
    "        c_strides2=[1,1,1,1]\n",
    "        c_strides3=[1,1,1,1]\n",
    "        c_strides4=[1,2,2,1]\n",
    "\n",
    "        c_pooling1='VALID'\n",
    "        c_pooling2='VALID'\n",
    "        c_pooling3='SAME'\n",
    "        c_pooling4='VALID'\n",
    "\n",
    "        b_p_ksize4=[1,3,3,1]\n",
    "        b_p_strides4=[1,2,2,1]\n",
    "        b_p_padding4 ='VALID'\n",
    "\n",
    "\n",
    "\n",
    "        layer1=tf.nn.conv2d(    x ,      w_conv1, c_strides1, c_pooling1  )+b_conv1\n",
    "        layer1=tf.nn.relu(layer1)\n",
    "        layer2=tf.nn.conv2d(    layer1 , w_conv2, c_strides2, c_pooling2  )+b_conv2\n",
    "        layer2=tf.nn.relu(layer2)\n",
    "        layer3=tf.nn.conv2d(    layer2 , w_conv3, c_strides3, c_pooling3  )+b_conv3\n",
    "        layer3=tf.nn.relu(layer3)\n",
    "        layer4=tf.nn.conv2d(    layer3 , w_conv4, c_strides4, c_pooling4  )+b_conv4\n",
    "        layer4=tf.nn.relu(layer4)\n",
    "\n",
    "\n",
    "        b_layer4=tf.nn.max_pool(layer3 , b_p_ksize4, b_p_strides4, b_p_padding4 ) #b is branch\n",
    "        b_layer4=tf.nn.relu(b_layer4)\n",
    "        print layer1\n",
    "        print layer2\n",
    "        print layer3\n",
    "        print layer4\n",
    "        print b_layer4\n",
    "\n",
    "\n",
    "        concat_layer=tf.concat(3 , [layer4 , b_layer4])\n",
    "        ret_layer=concat_layer\n",
    "        print concat_layer\n",
    "        return ret_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_B( x , device_):\n",
    "    with tf.device(device_):\n",
    "        in_ch=x.get_shape()[3]\n",
    "\n",
    "\n",
    "        #########################################################################\n",
    "        out_ch1=64 ; out_ch2=64;out_ch3=64;out_ch4=96;\n",
    "        ##############################right side##################################\n",
    "        c_ksize1=[1,1,in_ch , out_ch1]\n",
    "        c_ksize2=[7,1,out_ch1 , out_ch2]\n",
    "        c_ksize3=[1,7,out_ch2 , out_ch3]\n",
    "        c_ksize4=[3,3,out_ch3 , out_ch4]\n",
    "\n",
    "        w_conv1 , b_conv1 =make_weights_biases('STEM_B' , 'W1' , c_ksize1 ,device_name = device_)\n",
    "        w_conv2 , b_conv2= make_weights_biases('STEM_B' , 'W2' , c_ksize2 ,device_name = device_)\n",
    "        w_conv3 , b_conv3= make_weights_biases('STEM_B' , 'W3' , c_ksize3 ,device_name = device_)\n",
    "        w_conv4 , b_conv4= make_weights_biases('STEM_B' , 'W4' , c_ksize4 ,device_name = device_)\n",
    "\n",
    "        c_strides1=[1,1,1,1]\n",
    "        c_strides2=[1,1,1,1]\n",
    "        c_strides3=[1,1,1,1]\n",
    "        c_strides4=[1,1,1,1]\n",
    "\n",
    "        c_pooling1='SAME'\n",
    "        c_pooling2='SAME'\n",
    "        c_pooling3='SAME'\n",
    "        c_pooling4='VALID'\n",
    "        \n",
    "        layer1 = tf.nn.conv2d(x ,      w_conv1 , c_strides1 , c_pooling1)+b_conv1\n",
    "        layer1 = tf.nn.relu(layer1)\n",
    "        layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 , c_pooling2)+b_conv2\n",
    "        layer2 = tf.nn.relu(layer2)\n",
    "        layer3 = tf.nn.conv2d(layer2 , w_conv3 , c_strides3 , c_pooling3)+b_conv3\n",
    "        layer3 = tf.nn.relu(layer3)\n",
    "        layer4 = tf.nn.conv2d(layer3 , w_conv4 , c_strides4 , c_pooling4)+b_conv4\n",
    "        layer4 = tf.nn.relu(layer4)\n",
    "\n",
    "        ##############################left side##################################\n",
    "        b_out_ch1=64 ; b_out_ch2=96;    \n",
    "        #########################################################################\n",
    "        b_c_ksize1=[1,1,in_ch , b_out_ch1]\n",
    "        b_c_ksize2=[3,3,b_out_ch1 , b_out_ch2]\n",
    "        b_w_conv1 , b_b_conv1 =make_weights_biases('STEM_B' , 'b_W1' , b_c_ksize1 ,device_name = device_)\n",
    "        b_w_conv2 , b_b_conv2= make_weights_biases('STEM_B' , 'b_W2' , b_c_ksize2 ,device_name = device_)\n",
    "\n",
    "        b_c_strides1=[1,1,1,1]\n",
    "        b_c_strides2=[1,1,1,1]\n",
    "\n",
    "        b_c_pooling1='SAME'\n",
    "        b_c_pooling2='VALID'\n",
    "        \n",
    "        b_layer1 =tf.nn.conv2d(    x ,      b_w_conv1, b_c_strides1, b_c_pooling1  ) + b_b_conv1\n",
    "        b_layer1 = tf.nn.relu(layer1)\n",
    "        b_layer2=tf.nn.conv2d(  b_layer1 , b_w_conv2, b_c_strides2, b_c_pooling2  ) + b_b_conv2\n",
    "\n",
    "        ##############################concatenate layers###########################\n",
    "        concat_layer=tf.concat(3 , [layer4 , b_layer2])\n",
    "        ret_layer=concat_layer\n",
    "    return ret_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_C( x , device_ ):\n",
    "    with tf.device(device_):\n",
    "        in_ch=x.get_shape()[3]\n",
    "        #########################################################################\n",
    "\n",
    "        out_ch = 192\n",
    "\n",
    "\n",
    "        c_ksize=[3,3,in_ch,out_ch]\n",
    "        w_conv , b_conv =make_weights_biases('STEM_C' , 'W1' , c_ksize ,device_name = device_)\n",
    "        c_strides=[1,1,1,1]\n",
    "        c_pooling='SAME'\n",
    "\n",
    "        layer = tf.nn.conv2d(x , w_conv   , c_strides   , c_pooling)+b_conv\n",
    "        layer = tf.nn.relu(layer)\n",
    "        \n",
    "        #########################################################################\n",
    "        \n",
    "        b_p_ksize=[1,2,2,1]\n",
    "        b_p_strides=[1,1,1,1]\n",
    "        b_p_pooling='SAME'\n",
    "\n",
    "        b_layer = tf.nn.max_pool(x , b_p_ksize , b_p_strides , b_p_pooling)\n",
    "        b_layer = tf.nn.relu(b_layer)\n",
    "        #########################################################################\n",
    "\n",
    "        print layer\n",
    "        print b_layer\n",
    "\n",
    "        concat_layer=tf.concat(3,[layer , b_layer])\n",
    "        ret_layer = concat_layer\n",
    "    return ret_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FLAT(x):\n",
    "    \n",
    "    row=int(x.get_shape()[1])\n",
    "    col=int(x.get_shape()[2])\n",
    "    ch=int(x.get_shape()[3])\n",
    "    \n",
    "    res_x = tf.reshape(x , shape=[-1,row*col*ch])\n",
    "    return res_x\n",
    "    #connect fully connected layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FC_A(x , n_classes , device_ ):\n",
    "    with tf.device(device_):\n",
    "    \n",
    "        fully_ch1=1024; fully_ch2=1024\n",
    "\n",
    "        fc_ksize1=[x.get_shape()[1],fully_ch1]\n",
    "        fc_ksize2=[fully_ch1,fully_ch2]\n",
    "\n",
    "        w_fc1 ,b_fc1 = make_weights_biases('fc1' , 'fc_W1' , fc_ksize1 ,  device_)\n",
    "        w_fc2 ,b_fc2 = make_weights_biases('fc2' , 'fc_W2' , fc_ksize2 ,  device_)\n",
    "\n",
    "        h_fc1=tf.matmul(x, w_fc1 )+b_fc1\n",
    "        h_fc1=tf.nn.dropout(h_fc1 , keep_prob)\n",
    "        h_fc2=tf.matmul(h_fc1 , w_fc2 )+b_fc2\n",
    "        h_fc2=tf.nn.dropout(h_fc2 , keep_prob)\n",
    "        end_fc=h_fc2\n",
    "\n",
    "        end_ksize=[end_fc.get_shape()[1] , n_classes]   \n",
    "        w_end ,b_end = make_weights_biases('fc_end' , 'fc_end_W' , end_ksize ,  device_)\n",
    "        y_conv = tf.matmul(end_fc , w_end)+b_end\n",
    "\n",
    "        print w_fc1.get_shape()\n",
    "    return y_conv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FC_B(x , n_classes , device_ ):\n",
    "    with tf.device(device_):\n",
    "\n",
    "        end_ksize=[x.get_shape()[1] , n_classes]   \n",
    "        w_end ,b_end = make_weights_biases('fc_end' , 'fc_end_W' , end_ksize ,  device_)\n",
    "        y_conv = tf.matmul(x , w_end)+b_end\n",
    "\n",
    "   \n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_MODULE_A(x , device_):\n",
    "\n",
    "    \"\"\"\n",
    "    input X shape is [n_batch , row , col, out_ch]\n",
    "    35 x 35 grid\n",
    "    \"\"\"\n",
    "\n",
    "    #################################################################################\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch1=64 ; out_ch2= 96;\n",
    "    c_ksize1 = [1 , 1 ,in_ch , out_ch1 ]\n",
    "    c_ksize2 = [3 , 3 ,out_ch1 , out_ch2 ]\n",
    "    w_conv1 , b_conv1 = make_weights_biases ('INCEPTION_MODULE_A' , 'W1' , c_ksize1 ,device_)\n",
    "    w_conv2 , b_conv2 = make_weights_biases('INCEPTION_MODUEL_A' ,'W1' , c_ksize2 ,device_)\n",
    "\n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2=[1,1,1,1]\n",
    "    \n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2='SAME'\n",
    "    layer1 = tf.nn.conv2d(x , w_conv1 , c_strides1 ,c_pooling1 )\n",
    "    layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 ,c_pooling2 )\n",
    "\n",
    "    #################################################################################                     \n",
    "\n",
    "    b1_p_ksize   =[1,2,2,1]\n",
    "    b1_p_strides =[1,1,1,1]\n",
    "    b1_p_pooling='SAME'\n",
    "\n",
    "\n",
    "    b1_out_ch = 96;\n",
    "    b1_c_ksize  =[1,1, in_ch , b1_out_ch]\n",
    "    b1_c_strides=[1,1,1,1]\n",
    "    b1_c_pooling ='SAME'\n",
    "\n",
    "    b1_w_conv , b1_b_conv =make_weights_biases('INCEPTION_MODULE_A','b1_W',b1_c_ksize , device_)\n",
    "\n",
    "\n",
    "    b1_layer1=tf.nn.avg_pool(x, b1_p_ksize , b1_p_strides,b1_p_pooling)\n",
    "    b1_layer1=tf.nn.relu(b1_layer1)\n",
    "    b1_layer2=tf.nn.conv2d(b1_layer1 , b1_w_conv , b1_c_strides , b1_c_pooling)+b1_b_conv\n",
    "    b1_layer2=tf.nn.relu(b1_layer2)\n",
    "\n",
    "    #################################################################################                     \n",
    "\n",
    "    b2_out_ch=96\n",
    "    b2_c_ksize = [1,1,in_ch , b2_out_ch ]\n",
    "    b2_w_conv , b2_b_conv = make_weights_biases('INCEPTION_MODULE_A','b2_W',b2_c_ksize , device_)\n",
    "    b2_c_strides=[1,1,1,1]\n",
    "    b2_c_pooling='SAME'\n",
    "\n",
    "    b2_layer = tf.nn.conv2d( x, b2_w_conv , b2_c_strides ,b2_c_pooling ) +b2_b_conv \n",
    "    b2_layer = tf.nn.relu(b2_layer)\n",
    "\n",
    "\n",
    "\n",
    "    #################################################################################                     \n",
    "\n",
    "\n",
    "    b3_out_ch1=64;b3_out_ch2=96;b3_out_ch3=96;\n",
    "    b3_c_ksize1 =[1,1,in_ch , b3_out_ch1]\n",
    "    b3_c_ksize2 =[3,3,b3_out_ch1 , b3_out_ch2]\n",
    "    b3_c_ksize3 =[3,3,b3_out_ch2 , b3_out_ch3]\n",
    "    b3_w_conv1 , b3_b_conv1 = make_weights_biases('INCEPTION_MODULE_A','b3_W1',b3_c_ksize1 , device_)\n",
    "    b3_w_conv2 , b3_b_conv2 = make_weights_biases('INCEPTION_MODULE_A','b3_W2',b3_c_ksize2 , device_)\n",
    "    b3_w_conv3 , b3_b_conv3 = make_weights_biases('INCEPTION_MODULE_A','b3_W3',b3_c_ksize3 , device_)\n",
    "    b3_c_strides1=[1,1,1,1]\n",
    "    b3_c_strides2=[1,1,1,1]\n",
    "    b3_c_strides3=[1,1,1,1]\n",
    "    b3_c_pooling1='SAME'\n",
    "    b3_c_pooling2='SAME'\n",
    "    b3_c_pooling3='SAME'\n",
    "\n",
    "    b3_layer1 = tf.nn.conv2d(x , b3_w_conv1 , b3_c_strides1 ,b3_c_pooling1)+b3_b_conv1 \n",
    "    b3_layer1 = tf.nn.relu(b3_layer1)\n",
    "    b3_layer2 = tf.nn.conv2d(b3_layer1 , b3_w_conv2 , b3_c_strides2 ,b3_c_pooling2)+b3_b_conv2 \n",
    "    b3_layer2 = tf.nn.relu(b3_layer2)\n",
    "    b3_layer3 = tf.nn.conv2d(b3_layer2 , b3_w_conv3 , b3_c_strides3 ,b3_c_pooling3)+b3_b_conv3 \n",
    "    b3_layer3 = tf.nn.relu(b3_layer3)\n",
    "\n",
    "    #################################################################################                     \n",
    "    concat_A=tf.concat(3,[layer2 , b1_layer2])\n",
    "    concat_B=tf.concat(3,[concat_A , b2_layer])\n",
    "    concat_C=tf.concat(3,[concat_B , b3_layer3])\n",
    "\n",
    "    return concat_C\n",
    "\n",
    "    #################################################################################                     \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_MODULE_B(x , device):\n",
    "\n",
    "    \"\"\"\n",
    "    for 17 X 17 grid \n",
    "    \"\"\"\n",
    "    in_ch =x.get_shape()[3]\n",
    "    out_ch1 =192 ; out_ch2=224; out_ch3 =256\n",
    "    c_ksize1 = [1,1, in_ch  ,out_ch1]\n",
    "    c_ksize2 = [1,7, out_ch1,out_ch2]\n",
    "    c_ksize3 = [7,1, out_ch2,out_ch3]\n",
    "\n",
    "    w_conv1 , b_conv1 =make_weights_biases('INCEPTION_MODULE_B' ,'W1' ,  c_ksize1 , device)\n",
    "    w_conv2 , b_conv2 =make_weights_biases('INCEPTION_MODULE_B' ,'W2' ,  c_ksize2 , device)\n",
    "    w_conv3 , b_conv3 =make_weights_biases('INCEPTION_MODULE_B' ,'W3' ,  c_ksize3 , device)\n",
    "    \n",
    "    c_strides1 =[1,1,1,1]\n",
    "    c_strides2 =[1,1,1,1]\n",
    "    c_strides3 =[1,1,1,1]\n",
    "    \n",
    "    c_pooling1 ='SAME'\n",
    "    c_pooling2 ='SAME'\n",
    "    c_pooling3 ='SAME'\n",
    "\n",
    "\n",
    "    layer1 = tf.nn.conv2d(x, w_conv1,c_strides1 , c_pooling1 ) +b_conv1\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "    layer2 = tf.nn.conv2d(layer1, w_conv2,c_strides2 , c_pooling2 ) +b_conv2\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "    layer3 = tf.nn.conv2d(layer2, w_conv3,c_strides3 , c_pooling3 ) +b_conv3\n",
    "    layer3 = tf.nn.relu(layer3)\n",
    "\n",
    "\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b1_p_ksize=[1,2,2,1]\n",
    "    b1_p_strides=[1,1,1,1]\n",
    "    b1_p_pooling ='SAME'\n",
    "\n",
    "    b1_out_ch = 128\n",
    "    b1_c_ksize=[1,1,in_ch,b1_out_ch]\n",
    "    b1_w_conv , b1_b_conv = make_weights_biases('INCEPTION_MODULE_B','b1_W1',b1_c_ksize, device )\n",
    "    b1_c_strides=[1,1,1,1]\n",
    "    b1_c_pooling='SAME'\n",
    "\n",
    "\n",
    "    b1_layer1=tf.nn.avg_pool(x , b1_p_ksize , b1_p_strides , b1_p_pooling )\n",
    "    b1_layer1=tf.nn.relu(b1_layer1)\n",
    "    b1_layer2 =tf.nn.conv2d(b1_layer1 ,b1_w_conv , b1_c_strides, b1_c_pooling )+b1_b_conv \n",
    "    b1_layer2 =tf.nn.relu(b1_layer2)\n",
    "\n",
    "    ################################################################################# \n",
    "    b2_out_ch=384\n",
    "    b2_c_ksize=[1,1,in_ch,b2_out_ch]\n",
    "    b2_w_conv , b2_b_conv =make_weights_biases('INCEPTION_MODULE_B','b2_W1' ,b2_c_ksize , device)\n",
    "    b2_c_strides=[1,1,1,1]\n",
    "    b2_c_pooling='SAME'\n",
    "    b2_layer = tf.nn.conv2d(x,b2_w_conv , b2_c_strides , b2_c_pooling)+b2_b_conv\n",
    "    b2_layer = tf.nn.relu(b2_layer)\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b3_out_ch1=192; b3_out_ch2 =192; b3_out_ch3=224 ; b3_out_ch4=224 ; b3_out_ch5 =256\n",
    "    b3_c_ksize1=[1,1,in_ch,b3_out_ch1]\n",
    "    b3_c_ksize2=[1,7,b3_out_ch1 , b3_out_ch2]\n",
    "    b3_c_ksize3=[7,1,b3_out_ch2 , b3_out_ch3]\n",
    "    b3_c_ksize4=[1,7,b3_out_ch3 , b3_out_ch4]\n",
    "    b3_c_ksize5=[7,1,b3_out_ch4 , b3_out_ch5]\n",
    "\n",
    "    b3_w_conv1 , b3_b_conv1=make_weights_biases('INCEPTION_MODULE_B','b3_W1',b3_c_ksize1, device)\n",
    "    b3_w_conv2 , b3_b_conv2=make_weights_biases('INCEPTION_MODULE_B','b3_W2',b3_c_ksize2, device)\n",
    "    b3_w_conv3 , b3_b_conv3=make_weights_biases('INCEPTION_MODULE_B','b3_W3',b3_c_ksize3, device)\n",
    "    b3_w_conv4 , b3_b_conv4=make_weights_biases('INCEPTION_MODULE_B','b3_W4',b3_c_ksize4, device)\n",
    "    b3_w_conv5 , b3_b_conv5=make_weights_biases('INCEPTION_MODULE_B','b3_W5',b3_c_ksize5, device)\n",
    "\n",
    "\n",
    "    b3_layer1 = tf.nn.conv2d(x,b3_w_conv1 , b2_c_strides , b2_c_pooling)+b3_b_conv1\n",
    "    b3_layer1 = tf.nn.relu(b3_layer1)\n",
    "    b3_layer2 = tf.nn.conv2d(b3_layer1,b3_w_conv2 , b2_c_strides , b2_c_pooling)+b3_b_conv2\n",
    "    b3_layer2 = tf.nn.relu(b3_layer2)\n",
    "    b3_layer3 = tf.nn.conv2d(b3_layer2,b3_w_conv3 , b2_c_strides , b2_c_pooling)+b3_b_conv3\n",
    "    b3_layer3 = tf.nn.relu(b3_layer3)\n",
    "    b3_layer4 = tf.nn.conv2d(b3_layer3,b3_w_conv4 , b2_c_strides , b2_c_pooling)+b3_b_conv4\n",
    "    b3_layer4 = tf.nn.relu(b3_layer4)\n",
    "    b3_layer5 = tf.nn.conv2d(b3_layer4,b3_w_conv5 , b2_c_strides , b2_c_pooling)+b3_b_conv5\n",
    "    b3_layer5 = tf.nn.relu(b3_layer5)\n",
    "\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    layerA=tf.concat(3, [layer3 , b1_layer2] )\n",
    "    layerB=tf.concat(3, [layerA , b2_layer] )\n",
    "    layerC=tf.concat(3, [layerB , b3_layer5] )\n",
    "\n",
    "    print layerC\n",
    "    return layerC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_MODULE_C(x , device):\n",
    "\n",
    "    \"\"\"\n",
    "    for 8 X 8 grid modules\n",
    "    \"\"\"\n",
    "    print x.get_shape()\n",
    "    in_ch=x.get_shape()[3]\n",
    "    \n",
    "    out_ch1 = 384 ; out_ch2_a =256 ;out_ch2_b = 256\n",
    "    c_ksize1 = [1,1,in_ch , out_ch1]\n",
    "    c_ksize2_a = [1,3,out_ch1 , out_ch2_a]\n",
    "    c_ksize2_b = [3,1,out_ch1 , out_ch2_b]\n",
    "    w_conv1 ,b_conv1=make_weights_biases('INCEPTION_MODULE_C','W1', c_ksize1 ,device)\n",
    "    w_conv2_a ,b_conv2_a=make_weights_biases('INCEPTION_MODULE_C','W2_a', c_ksize2_a ,device)\n",
    "    w_conv2_b ,b_conv2_b=make_weights_biases('INCEPTION_MODULE_C','W2_b', c_ksize2_b ,device)\n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2_a=[1,1,1,1]\n",
    "    c_strides2_b=[1,1,1,1]\n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2_a='SAME'\n",
    "    c_pooling2_b='SAME'\n",
    "\n",
    "    layer1 = tf.nn.conv2d(x, w_conv1 ,c_strides1 ,c_pooling1)+b_conv1\n",
    "    layer1=tf.nn.relu(layer1)\n",
    "    layer2_a = tf.nn.conv2d(layer1,  w_conv2_a ,c_strides2_a ,c_pooling2_a )+b_conv2_a\n",
    "    layer2_a = tf.nn.relu(layer2_a)\n",
    "    layer2_b = tf.nn.conv2d(layer1  , w_conv2_a ,c_strides2_a ,c_pooling2_b)+b_conv2_b\n",
    "    layer2_b = tf.nn.relu(layer2_b)\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b1_p_ksize=[1,2,2,1]\n",
    "    b1_p_strides=[1,1,1,1]\n",
    "    b1_p_pooling='SAME'\n",
    "\n",
    "    b1_out_ch =256\n",
    "    b1_c_ksize=[1,1,in_ch , b1_out_ch]\n",
    "    b1_w_conv , b1_b_conv= make_weights_biases('INCEPTION_MODULE_C' , 'b1_W1' , b1_c_ksize , device)\n",
    "    b1_c_pooling = 'SAME';b1_c_strides = [1,1,1,1];\n",
    "    \n",
    "    b1_layer1 = tf.nn.avg_pool(x , b1_p_ksize , b1_p_strides , b1_p_pooling)\n",
    "    b1_layer2 = tf.nn.conv2d(b1_layer1 , b1_w_conv , b1_c_strides  ,b1_c_pooling)+b1_b_conv\n",
    "    b1_layer2 = tf.nn.relu(b1_layer2)\n",
    "    ################################################################################# \n",
    "    b2_out_ch=256\n",
    "    b2_c_ksize=[1,1,in_ch,b2_out_ch]\n",
    "    b2_w_conv , b2_b_conv= make_weights_biases('INCEPTION_MODULE_C' , 'b2_W' , b2_c_ksize , device)\n",
    "    b2_c_pooling = 'SAME';b2_c_strides=[1,1,1,1];\n",
    "    b2_layer = tf.nn.conv2d(x , b2_w_conv , b2_c_strides  ,b2_c_pooling)+b2_b_conv\n",
    "    b2_layer= tf.nn.relu(b2_layer)\n",
    "   \n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b3_out_ch1=384;b3_out_ch2=448;b3_out_ch3=512;b3_out_ch4_a=256;b3_out_ch4_b=256\n",
    "    b3_c_ksize1 =[1,1,in_ch , b3_out_ch1]\n",
    "    b3_c_ksize2 =[1,3,b3_out_ch1 , b3_out_ch2]\n",
    "    b3_c_ksize3 =[3,1,b3_out_ch2 , b3_out_ch3]\n",
    "    b3_c_ksize4_a =[3,1,b3_out_ch3 , b3_out_ch4_a]\n",
    "    b3_c_ksize4_b =[1,3,b3_out_ch3, b3_out_ch4_b]\n",
    "\n",
    "    b3_w_conv1 , b3_b_conv1 = make_weights_biases('INCEPTION_MODULE_C','b3_W1',b3_c_ksize1 , device)\n",
    "    b3_w_conv2 , b3_b_conv2 = make_weights_biases('INCEPTION_MODULE_C','b3_W2',b3_c_ksize2 , device)\n",
    "    b3_w_conv3 , b3_b_conv3 = make_weights_biases('INCEPTION_MODULE_C','b3_W3',b3_c_ksize3 , device)\n",
    "    b3_w_conv4_a , b3_b_conv4_a = make_weights_biases('INCEPTION_MODULE_C','b3_W4_a',b3_c_ksize4_a , device)\n",
    "    b3_w_conv4_b , b3_b_conv4_b = make_weights_biases('INCEPTION_MODULE_C','b3_W4_b',b3_c_ksize4_b , device)\n",
    "\n",
    "    b3_c_strides1=[1,1,1,1]\n",
    "    b3_c_strides2=[1,1,1,1]\n",
    "    b3_c_strides3=[1,1,1,1]\n",
    "    b3_c_strides4_a=[1,1,1,1]\n",
    "    b3_c_strides4_b=[1,1,1,1]\n",
    "\n",
    "    b3_c_pooling1='SAME'\n",
    "    b3_c_pooling2='SAME'\n",
    "    b3_c_pooling3='SAME'\n",
    "    b3_c_pooling4_a='SAME'\n",
    "    b3_c_pooling4_b='SAME'\n",
    "\n",
    "    b3_laer1 = tf.nn.conv2d(x , b3_w_conv1 , b3_c_strides1 ,b3_c_pooling1)+b3_b_conv1 \n",
    "    b3_layer1 = tf.nn.relu(b3_laer1)\n",
    "    b3_layer2 = tf.nn.conv2d(b3_laer1 , b3_w_conv2 , b3_c_strides2 ,b3_c_pooling2)+b3_b_conv2 \n",
    "    b3_layer2 = tf.nn.relu(b3_layer2)\n",
    "    b3_layer3 = tf.nn.conv2d(b3_layer2 , b3_w_conv3 , b3_c_strides3 ,b3_c_pooling3)+b3_b_conv3 \n",
    "    b3_layer3 = tf.nn.relu(b3_layer3)\n",
    "\n",
    "    b3_layer4_a = tf.nn.conv2d(b3_layer3 , b3_w_conv4_a , b3_c_strides4_a ,b3_c_pooling4_a)+b3_b_conv4_a \n",
    "    b3_layer4_a = tf.nn.relu(b3_layer4_a)\n",
    "\n",
    "    b3_layer4_b = tf.nn.conv2d(b3_layer3 , b3_w_conv4_b , b3_c_strides4_b ,b3_c_pooling4_b)+b3_b_conv4_b \n",
    "    b3_layer4_b = tf.nn.relu(b3_layer4_b)\n",
    "\n",
    "\n",
    "    ################################################################################# \n",
    "\n",
    "    layerA = tf.concat(3 , [layer2_a, layer2_b])\n",
    "    layerB = tf.concat(3 , [layerA  , b1_layer2])\n",
    "    layerC = tf.concat(3 , [layerB  , b2_layer])\n",
    "    layerD = tf.concat(3 , [layerC  , b3_layer4_a])\n",
    "    layerE = tf.concat(3 , [layerD  , b3_layer4_b])\n",
    "\n",
    "    return layerE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def INCEPTION_REDUCTION_A(x , device):\n",
    "    ####################################################################################\n",
    "   \n",
    "    \"\"\"\n",
    "    usage:\n",
    "    x shape =[ n_batch , row , col , ch] \n",
    "    \"\"\"\n",
    "    print x.get_shape()\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch = 384\n",
    "    c_ksize= [3,3,in_ch , out_ch]\n",
    "    w_conv , b_conv =make_weights_biases('INCEPTION_REDUCTION_A','W1',c_ksize,device)\n",
    "    c_strides=[1,2,2,1]\n",
    "    c_pooling='VALID'\n",
    "    layer=tf.nn.conv2d(x,w_conv,c_strides , c_pooling)+b_conv\n",
    "    layer=tf.nn.relu(layer)\n",
    "\n",
    "    ####################################################################################\n",
    "   \n",
    "    b1_p_ksize=[1,3,3,1]\n",
    "    b1_p_strides=[1,2,2,1]\n",
    "    b1_p_pooling='VALID'\n",
    "    b1_layer = tf.nn.max_pool(x,b1_p_ksize , b1_p_strides , b1_p_pooling)\n",
    "    ####################################################################################\n",
    "   \n",
    "    b2_out_ch1 = 192; b2_out_ch2=288 ;b2_out_ch3 = 256;\n",
    "    b2_c_ksize1=[1,1,in_ch,b2_out_ch1]\n",
    "    b2_c_ksize2=[3,3,b2_out_ch1,b2_out_ch2]\n",
    "    b2_c_ksize3=[3,3,b2_out_ch2,b2_out_ch3]\n",
    "    b2_w_conv1 , b2_b_conv1 = make_weights_biases('INCEPTION_REDUCTION_A' ,'b2_W1' , b2_c_ksize1 , device)\n",
    "    b2_w_conv2 , b2_b_conv2 = make_weights_biases('INCEPTION_REDUCTION_A' ,'b2_W2' , b2_c_ksize2 , device)\n",
    "    b2_w_conv3 , b2_b_conv3 = make_weights_biases('INCEPTION_REDUCTION_A' ,'b2_W3' , b2_c_ksize3 , device)\n",
    "    \n",
    "    b2_c_strides1=[1,1,1,1]\n",
    "    b2_c_strides2=[1,1,1,1]\n",
    "    b2_c_strides3=[1,2,2,1]\n",
    "    b2_c_pooling1='SAME'\n",
    "    b2_c_pooling2='SAME'\n",
    "    b2_c_pooling3='VALID'\n",
    "    \n",
    "    b2_layer1 = tf.nn.conv2d(x        , b2_w_conv1 ,b2_c_strides1 ,b2_c_pooling1)+b2_b_conv1\n",
    "    b2_layer1 = tf.nn.relu(b2_layer1)\n",
    "    b2_layer2 = tf.nn.conv2d(b2_layer1, b2_w_conv2 ,b2_c_strides2 ,b2_c_pooling2)+b2_b_conv2\n",
    "    b2_layer2 = tf.nn.relu(b2_layer2)\n",
    "    b2_layer3 = tf.nn.conv2d(b2_layer2, b2_w_conv3 ,b2_c_strides3 ,b2_c_pooling3)+b2_b_conv3\n",
    "    b2_layer3 = tf.nn.relu(b2_layer3)\n",
    "    \n",
    "    print layer.get_shape()\n",
    "    print b1_layer.get_shape()\n",
    "    print b2_layer3.get_shape()\n",
    "    ####################################################################################\n",
    "   \n",
    "    layerA=tf.concat(3 ,[layer ,b1_layer ])\n",
    "    layerB=tf.concat(3 ,[layerA ,b2_layer3])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return layerB\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_REDUCTION_B(x , device):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ####################################################################################\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch1=192 ; out_ch2=192;\n",
    "\n",
    "    c_ksize1 =[1,1,in_ch , out_ch1]\n",
    "    c_ksize2 =[3,3,out_ch1,out_ch2]\n",
    "    w_conv1, b_conv1 = make_weights_biases('INCEPTION_REDUCTION_B','W1',c_ksize1,device)\n",
    "    w_conv2, b_conv2 = make_weights_biases('INCEPTION_REDUCTION_B','W2',c_ksize2,device)\n",
    "    \n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2=[1,2,2,1]\n",
    "    \n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2='VALID'\n",
    "    \n",
    "    layer1 = tf.nn.conv2d(x,w_conv1 , c_strides1, c_pooling1)\n",
    "    layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 , c_pooling2)    \n",
    "    \n",
    "    b1_p_ksize=[1,3,3,1]\n",
    "    b1_p_strides=[1,2,2,1]\n",
    "    b1_p_pooling='VALID'\n",
    "    \n",
    "    b1_layer1=tf.nn.max_pool(x ,b1_p_ksize , b1_p_strides , b1_p_pooling)\n",
    "    \n",
    "    ####################################################################################\n",
    "    b2_out_ch1=256 ; b2_out_ch2 = 256 ; b2_out_ch3=320 ; b2_out_ch4=320;\n",
    "    b2_p_ksize1 =[1,1,in_ch , b2_out_ch1]\n",
    "    b2_p_ksize2 =[1,7,b2_out_ch1 , b2_out_ch2]\n",
    "    b2_p_ksize3 =[7,1,b2_out_ch2 , b2_out_ch3]\n",
    "    b2_p_ksize4 =[3,3,b2_out_ch3 , b2_out_ch4]\n",
    "    \n",
    "    b2_w_conv1, b2_b_conv1 = make_weights_biases('INCEPTION_REDUCTION_B','b2_W1' ,b2_c_ksize1,device)\n",
    "    b2_w_conv2, b2_b_conv2 = make_weights_biases('INCEPTION_REDUCTION_B','b2_W2' ,b2_c_ksize2,device)\n",
    "    b2_w_conv3, b2_b_conv3 = make_weights_biases('INCEPTION_REDUCTION_B','b2_W3' ,b2_c_ksize3,device)\n",
    "    b2_w_conv4, b2_b_conv4 = make_weights_biases('INCEPTION_REDUCTION_B','b2_W4' ,b2_c_ksize4,device)\n",
    "    \n",
    "    b2_c_strides1=[1,1,1,1]\n",
    "    b2_c_strides2=[1,1,1,1]\n",
    "    b2_c_strides3=[1,1,1,1]\n",
    "    b2_c_strides4=[1,1,1,1]\n",
    "    \n",
    "    b2_c_pooling1= 'SAME'\n",
    "    b2_c_pooling2= 'SAME'\n",
    "    b2_c_pooling3 = 'SAME'\n",
    "    b2_c_pooling4 = 'VALID'\n",
    "    \n",
    "    b2_layer1 = tf.nn.conv2d(x, b2_w_conv1 , b2_c_strides1 , b2_c_pooling1 )+b2_b_conv1\n",
    "    b2_layer2 = tf.nn.conv2d(b2_layer1, b2_w_conv2 , b2_c_strides2 , b2_c_pooling2 )+b2_b_conv2\n",
    "    b2_layer3 = tf.nn.conv2d(b2_layer2, b2_w_conv3 , b2_c_strides3 , b2_c_pooling3 )+b2_b_conv3\n",
    "    b2_layer4 = tf.nn.conv2d(b2_layer3, b2_w_conv4 , b2_c_strides4 , b2_c_pooling4 )+b2_b_conv4\n",
    "    \n",
    "    ####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_list(folder_path):\n",
    "    \"\"\"\n",
    "    return ret_train_img_list ,ret_train_lab_list \n",
    "    \n",
    "    \"\"\"\n",
    "    list_files=os.walk(folder_path).next()[2]\n",
    "    ret_train_img_list=[]\n",
    "    ret_train_lab_list=[]\n",
    "    for i , ele in enumerate(list_files):\n",
    "\n",
    "        if 'train'  in ele and 'img'in ele:\n",
    "            ret_train_img_list.append(ele)\n",
    "        elif 'train' in ele  and  'lab' in ele:\n",
    "            ret_train_lab_list.append(ele)\n",
    "    return ret_train_img_list ,ret_train_lab_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images , train_labels  = get_batch_list(file_locate)\n",
    "print train_images , train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "\n",
    "train_images.sort(key=natural_keys)\n",
    "train_labels.sort(key = natural_keys)\n",
    "print(train_images)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col , label):\n",
    "    \n",
    "    n_img = np.shape(np_img)[0] \n",
    "    n_ret_img = n_img*(img_row - crop_img_row) * (img_col - crop_img_col)*2\n",
    "    ret_images = np.zeros([n_ret_img ,crop_img_row , crop_img_col,color_ch])\n",
    "    len_label= np.shape(label)[1]\n",
    "    ret_labels =  np.zeros([n_ret_img  ,len_label])\n",
    "    #print \"n_augmented image size : \" , n_ret_img \n",
    "    #print \"n classes :\", len_label\n",
    "    #copy label in factor by 2014\n",
    "    \n",
    "    if len(np.shape(np_img))==2:\n",
    "        np_img=np.reshape(np_img , newshape = [np.shape(np_img)[0] , img_row , img_col ,color_ch])\n",
    "        print np.shape(np_img)\n",
    "    for n  in range(len(np_img)):\n",
    "        ret_labels[n*2 , : ] = label[n,:]\n",
    "        ret_labels[n*2+1 , : ] = label[n,:]\n",
    "        for r in range(img_row - crop_img_row):\n",
    "            for c in range(img_col - crop_img_col):\n",
    "                \n",
    "                cropped_img = np_img[n, r:crop_img_row +r , c:crop_img_col+c ,: ]\n",
    "                \n",
    "                ret_images[n*2,:,:,:]=cropped_img  \n",
    "                ret_images[(n*2+1) , :,:,:] =np.fliplr(cropped_img )\n",
    "\n",
    "    \n",
    "    return ret_images ,ret_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_test_img(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col ):\n",
    "    left_top =(0,0)\n",
    "    right_top =(  img_row  - crop_img_row  , 0 )\n",
    "    center =  ((img_row  - crop_img_row)/2  , (img_col - crop_img_row)/2)\n",
    "    left_buttom = (0,(img_col - crop_img_row)/2 )\n",
    "    right_buttom =  (img_row  - crop_img_row , img_col - crop_img_row)\n",
    "    \n",
    "    left_top_images  = np_img[: , left_top[0]:crop_img_row+left_top[0] , left_top[1] : crop_img_col+left_top[1] , :  ]\n",
    "    right_top_images = np_img[: , right_top[0]:crop_img_row +right_top[0], right_top[1] : crop_img_col +right_top[1], :  ]\n",
    "    center_images    = np_img[: , center[0]:crop_img_row +center[0], center[1] : crop_img_col +center[1], :  ]\n",
    "    left_buttom_images=np_img[: , left_buttom[0]:crop_img_row +left_buttom[0], left_buttom[1] : crop_img_col +left_buttom[1], :  ]\n",
    "    right_buttom_images= np_img[: , right_buttom[0]:crop_img_row+right_buttom[0] , right_buttom[1] : crop_img_col +right_buttom[1] , :  ]\n",
    "\n",
    "    \n",
    "        \n",
    "    return left_top_images , right_top_images , center_images , left_buttom_images , right_buttom_images \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TRAIN_STRUCTURE_A(y_conv , y_ , device_ = '/gpu:4'):\n",
    "    \"\"\"\n",
    "    Return Value : cost , train_step ,correct_prediction , accuracy \n",
    "    \n",
    "    \"\"\"\n",
    "    with tf.device(device_):\n",
    "    #sm_conv= tf.nn.softmax(y_conv)\n",
    "        #cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "\n",
    "        softmax=tf.nn.softmax(y_conv)\n",
    "        regular=0.01*(tf.reduce_sum(tf.square(y_conv)))\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( y_conv, y_))\n",
    "    with tf.device(device_):\n",
    "        cost = cost+regular\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cost) #1e-4\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            with tf.name_scope('correct_prediction'):\n",
    "                correct_prediction = tf.equal(tf.argmax(y_conv,1) ,tf.argmax(y_,1))\n",
    "            with tf.name_scope('accuracy'):\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\")) \n",
    "    return cost , train_step ,correct_prediction , accuracy,softmax \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def START_SESS():\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    return sess \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Terminal Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dirname = '/home/ncc/notebook/mammo/result/'\n",
    "def make_logdir(dirname):\n",
    "  \n",
    "\n",
    "    count=0\n",
    "    while(True):\n",
    "        if not os.path.isdir(dirname):\n",
    "            os.mkdir(dirname)\n",
    "            break\n",
    "        elif not os.path.isdir(dirname + str(count)):\n",
    "            dirname=dirname+str(count)\n",
    "            os.mkdir(dirname)\n",
    "            break\n",
    "        else:\n",
    "            count+=1\n",
    "    print 'it is recorded at :'+str(count)\n",
    "\n",
    "    f=open(dirname+\"/log.txt\",'w')\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def write_log(step,train_acc, train_loss , val_acc , val_loss ,fp):\n",
    "    \"\"\"\n",
    "    fp = File Pointer\n",
    "    \n",
    "    \"\"\"\n",
    "    #result = sess.run(sm_conv , feed_dict = {x:val_img , y_:batch_ys , keep_prob :1.0})\n",
    "    print step\n",
    "    print(\"step %d , training  accuracy %g\" %(step,train_acc))\n",
    "    print(\"step %d , loss : %g\" %(step,train_loss))\n",
    "    train_str = 'step:\\t'+str(step)+'\\tval_loss:\\t'+str(train_loss) +'\\tval accuracy:\\t'+str(train_acc)+'\\n'\n",
    "\n",
    "    print(\"step %d , validation  accuracy %g\" %(step,val_acc))\n",
    "    print(\"step %d , validation loss : %g\" %(step,val_loss))\n",
    "    val_str = 'step:\\t'+str(step)+'\\tval_loss:\\t'+str(val_loss) +'\\tval accuracy:\\t'+str(val_acc)+'\\n'\n",
    "\n",
    "    fp.write(train_str)\n",
    "    fp.write(val_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_TVT(divide_flag,file_locate):\n",
    "    if divide_flag == False:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data Image\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"Test Data Image\",np.shape(test_img)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "        print \"val Data Image\" , np.shape(val_img)\n",
    "        \n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n",
    "        return train_img ,train_lab,val_img,val_lab,test_img,test_lab\n",
    "   \n",
    "    if divide_flag == True:\n",
    "        print '트레이닝 파일이 여러개로 분할되어 있습니다. 분할된 트레이닝 파일에 대한 조치가 필요합니다'\n",
    "        train_images, train_labels =get_batch_list(file_locate)\n",
    "        print train_images ,train_labels\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "        print \"the number of training image batch\",len(train_images)\n",
    "        print \"the number of training label batch\",len(train_labels)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"Test Data Image\",np.shape(test_img)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "        print \"val Data Image\" , np.shape(val_img)\n",
    "        return train_images, train_labels,val_img,val_lab,test_img,test_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate_from_images(sess, images , labels , accuracy , cost ):\n",
    "    \"\"\"\n",
    "    input : x-\n",
    "    \n",
    "    x type  : numpy \n",
    "    x shape : [n , row , col , ch]\n",
    "    return  acc,  loss\n",
    "\n",
    "    \"\"\"\n",
    "    print accuracy\n",
    "    acc_list=[]\n",
    "    loss_list=[]\n",
    "    images_labels=zip(images,labels)\n",
    "    for img_ind ,(img,lab)  in enumerate(images_labels):\n",
    "\n",
    "        acc ,loss = sess.run( [accuracy,cost] ,feed_dict={x:img , y_: lab , keep_prob: 1.0})        \n",
    "        acc_list.append(acc)\n",
    "        loss_list.append(loss)\n",
    "\n",
    "    acc_list=np.asarray(acc_list)\n",
    "    loss_list=np.asarray(loss_list)\n",
    "    acc=np.mean(acc_list)\n",
    "    loss=np.mean(loss_list)\n",
    "    \n",
    "    return  acc,  loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BATCH_TRAINING_RANDOM(maxiter, batch_size,file_locate, cost , train_step ,correct_prediction , \\\n",
    "                   accuracy ,softmax, fp ):\n",
    "    start_time = time.time()\n",
    "    #with tf.device('/gpu:0'):\n",
    "    train_img, train_lab,val_img,val_lab,test_img,test_lab\\\n",
    "    =load_TVT(False,file_locate) #TVT is Train Validation Test  \n",
    "    for step in range(maxiter):    \n",
    "        batch_xs , batch_ys = next_batch(batch_size, train_img , train_lab)       \n",
    "        if step%100 ==0: #여기 if loop에서 validate을 합니다 \n",
    "            try:\n",
    "                val_acc , val_loss=validate(val_img , val_lab)\n",
    "                train_acc , train_loss=validate(batch_xs,batch_ys)\n",
    "            except:\n",
    "                #한번에 트레이닝이 안되면 분할해서 validation한다.\n",
    "                val_imgs, val_labs = divide_images(val_img , val_lab, batch_size)\n",
    "                print np.shape(val_imgs[0])\n",
    "                val_acc, val_loss =validate_from_images(sess,val_imgs ,val_labs ,accuracy ,cost )\n",
    "                train_acc , train_loss=validate(batch_xs,batch_ys,accuracy ,cost)\n",
    "\n",
    "            write_log(step , train_acc, train_loss , val_acc, val_loss , fp)\n",
    "            softmax_=sess.run(softmax ,feed_dict ={ x:batch_xs , y_:batch_ys , keep_prob:1.0 })\n",
    "            print softmax_\n",
    "            training(batch_xs,batch_ys)\n",
    "\n",
    "    ############################################aug_and_training############################\n",
    "    print(\"--- Training Time : %s ---\" % (time.time() - start_time))\n",
    "    train_time=\"--- Training Time : ---:\\t\" +str(time.time() - start_time)\n",
    "    fp.write(train_time)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BATCH_TRAINING_MANUAL(maxiter  , batch_size,file_locate, cost , train_step ,correct_prediction , \\\n",
    "                   accuracy , fp ):\n",
    "    start_time = time.time()\n",
    "#with tf.device('/gpu:0'):\n",
    "    train_img, train_lab,val_img,val_lab,test_img,test_lab\\\n",
    "    =load_TVT(divide_flag,file_locate)\n",
    "    train_images , train_labels=divide_images(train_img , train_lab , batch_size)\n",
    "    train_images_labels=zip(train_images , train_labels)\n",
    "    \n",
    "    for step,(batch_xs , batch_ys) in train_images_labels:\n",
    "        if step%100 ==0:\n",
    "            try:\n",
    "                val_acc , val_loss=validate(val_img , val_lab)\n",
    "                train_acc , train_loss=validate(batch_xs,batch_ys)\n",
    "            except:\n",
    "                #한번에 트레이닝이 안되면 분할해서 validation한다.\n",
    "                val_imgs, val_labs = divide_images(val_img , val_lab, batch_size)\n",
    "                val_acc, val_loss =validate_from_images(val_imgs ,val_labs ,accuracy, cost )\n",
    "                train_acc , train_loss=validate(batch_xs,batch_ys,accuracy, cost)\n",
    "            write_log(step , train_acc, train_loss , val_acc, val_loss , fp)\n",
    "            np.save('./result/batch_xs' ,batch_xs)\n",
    "            np.save('./result/batch_ys' ,batch_ys)\n",
    "        else:\n",
    "            list_aud_x = aug_8_times(batch_xs)\n",
    "            for ele in list_aug_x:\n",
    "                training(ele ,batch_ys)                    \n",
    "\n",
    "\n",
    "############################################aug_and_training############################\n",
    "    print(\"--- Training Time : %s ---\" % (time.time() - start_time))\n",
    "    train_time=\"--- Training Time : ---:\\t\" +str(time.time() - start_time)\n",
    "    fp.write(train_time)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(img , lab ,accuracy ,cost ): #default\n",
    "    \"\"\"\n",
    "    return val_acc,  val_loss, train_acc, train_loss\n",
    "    \"\"\"    \n",
    "    acc,loss = sess.run([accuracy,cost] , feed_dict={x:img , y_:lab , keep_prob: 1.0})        \n",
    "    return acc,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def divide_images(images , labels,batch_size):\n",
    "    \"\"\"\n",
    "    return list_images,list_labels\n",
    "    \"\"\"\n",
    "    n_divide=len(images)/batch_size\n",
    "\n",
    "    list_images=[]\n",
    "    list_labels=[]\n",
    "    for ind in range(n_divide):\n",
    "        # j*batch_size :(j+1)*batch_size\n",
    "        image =images[ ind*batch_size :(ind+1)*batch_size] \n",
    "        label =labels[ ind*batch_size :(ind+1)*batch_size]\n",
    "        list_images.append(image)\n",
    "        list_labels.append(label)\n",
    "\n",
    "    #right above code have to modify\n",
    "    image = images[ (ind+1)*batch_size :  ] \n",
    "    label = labels[ (ind+1)*batch_size :  ]\n",
    "    list_images.append(image)\n",
    "    list_labels.append(label)\n",
    "\n",
    "    return list_images,list_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  \n",
    "def validate_extract_imgs(val_img , val_lab , train_img , train_lab ):\n",
    "    \"\"\"\n",
    "    extract patch from ori-image\n",
    "    \"\"\"\n",
    "    color_ch = in_ch\n",
    "    val_images  =extract_test_img(val_img , 128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "    train_images=extract_test_img(train_img ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "    val_acc, val_loss =validate_from_images(sess, val_images , val_lab , accuracy ,cost )\n",
    "    train_acc , train_loss =validate_from_images(sess, train_images , train_lab ,accuracy , cost)\n",
    "    \n",
    "    return val_acc , val_loss, train_acc ,train_loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def training(batch_xs , batch_ys):\n",
    "    sess.run(train_step ,feed_dict={x: batch_xs, y_:batch_ys , keep_prob : 0.7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug_8_times(x):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    x shape is [n_batch , row ,col , color_ch ]\n",
    "    x type is numpy \n",
    "    this code need too many time to run \n",
    "    we should find solution using parallel method to less run time maybe \n",
    "    \n",
    "    return x,np_rot90,np_rot180,np_rot270,lr_x,np_lr_rot90 ,np_lr_rot180 , np_lr_rot270 \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    n_batch,row,col,ch=np.shape(x)\n",
    "    lr_x = np.flipud(x)\n",
    "\n",
    "    np_rot90 =np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_rot180=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_rot270=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "\n",
    "    np_lr_rot90 =np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_lr_rot180=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_lr_rot270=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    \n",
    "    \n",
    "\n",
    "    for batch_ind in range(n_batch):\n",
    "\n",
    "        rot90=np.rot90(x[batch_ind,:,:,:])\n",
    "        rot180=np.rot90(rot90)\n",
    "        rot270=np.rot90(rot180)\n",
    "\n",
    "        np_rot90[batch_ind,:,:,:] = rot90\n",
    "        np_rot180[batch_ind,:,:,:]=rot180\n",
    "        np_rot270[batch_ind,:,:,:]=rot270\n",
    "\n",
    "        lr_rot90=np.rot90(lr_x[batch_ind,:,:,:])\n",
    "        lr_rot180=np.rot90(lr_rot90)\n",
    "        lr_rot270=np.rot90(lr_rot180)\n",
    "\n",
    "        np_lr_rot90[batch_ind,:,:,:]=lr_rot90\n",
    "        np_lr_rot180[batch_ind,:,:,:]=lr_rot180\n",
    "        np_lr_rot90[batch_ind,:,:,:]=lr_rot270\n",
    "    return x,np_rot90,np_rot180,np_rot270,lr_x,np_lr_rot90 ,np_lr_rot180 , np_lr_rot270 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug_crop(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col , label):\n",
    "    n_img = np.shape(np_img)[0] \n",
    "    n_ret_img = n_img*(img_row - crop_img_row) * (img_col - crop_img_col)*2\n",
    "    ret_images = np.zeros([n_ret_img ,crop_img_row , crop_img_col,color_ch])\n",
    "    len_label= np.shape(label)[1]\n",
    "    ret_labels =  np.zeros([n_ret_img  ,len_label])\n",
    "    #print \"n_augmented image size : \" , n_ret_img \n",
    "    #print \"n classes :\", len_label\n",
    "    #copy label in factor by 2014\n",
    "\n",
    "    if len(np.shape(np_img))==2:\n",
    "        np_img=np.reshape(np_img , newshape = [np.shape(np_img)[0] , img_row , img_col ,color_ch])\n",
    "        print np.shape(np_img)\n",
    "    for n  in range(len(np_img)):\n",
    "        ret_labels[n*2 , : ] = label[n,:]\n",
    "        ret_labels[n*2+1 , : ] = label[n,:]\n",
    "        for r in range(img_row - crop_img_row):\n",
    "            for c in range(img_col - crop_img_col):\n",
    "\n",
    "                cropped_img = np_img[n, r:crop_img_row +r , c:crop_img_col+c ,: ]\n",
    "\n",
    "                ret_images[n*2,:,:,:]=cropped_img  \n",
    "                ret_images[(n*2+1) , :,:,:] =np.fliplr(cropped_img )\n",
    "\n",
    "\n",
    "    return ret_images ,ret_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dirname='./result/'\n",
    "A=STEM_A(x ,'/gpu:0')\n",
    "B=STEM_B(A ,'/gpu:0')\n",
    "C=STEM_C(B ,'/gpu:0')\n",
    "D=INCEPTION_MODULE_A(C,'/gpu:1')\n",
    "E=INCEPTION_REDUCTION_A(D,'/gpu:1')\n",
    "F=INCEPTION_MODULE_B(E,'/gpu:1')\n",
    "G=INCEPTION_MODULE_C(F,'/gpu:1')\n",
    "flat_G=FLAT(G)\n",
    "y_conv=FC_A(flat_G , 2,'/gpu:2')\n",
    "cost , train_step ,correct_prediction , accuracy ,softmax = TRAIN_STRUCTURE_A(y_conv , y_)\n",
    "sess=START_SESS()\n",
    "fp=make_logdir(dirname)\n",
    "BATCH_TRAINING_RANDOM(240000 , 30,file_locate , cost , train_step ,correct_prediction , accuracy ,softmax ,fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "BATCH_TRAINING_RANDOM(120000 , 30,file_locate , cost , train_step ,correct_prediction , accuracy ,softmax ,fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
